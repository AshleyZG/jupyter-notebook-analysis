{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does thid notebook do?  \n",
    "using agglomerative clustering to find posible decision points in all notebooks  \n",
    "\n",
    "# File mapping \n",
    "sklearn | clustering | ---: `./sklearn_dp.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_func import process_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \"\"\"tree sturcture to record currently found decision points\"\"\"\n",
    "    def __init__(self, funcs = []):\n",
    "        \"\"\"init a tree with a list of functions or []\"\"\"\n",
    "        super(Tree, self).__init__()\n",
    "        self.root = {}\n",
    "        for f in funcs:\n",
    "            self.add_func(f)\n",
    "    \n",
    "    def add_func(self, func):\n",
    "        \"\"\"add function to tree\"\"\"\n",
    "        tokens = func.split('.')\n",
    "        cur_root = self.root\n",
    "        for t in tokens:\n",
    "            if t not in cur_root:\n",
    "                cur_root[t] = {}\n",
    "            cur_root = cur_root[t]\n",
    "            \n",
    "    def add_funcs(self, funcs):\n",
    "        \"\"\"add functions to tree\"\"\"\n",
    "        for f in funcs:\n",
    "            self.add_func(f)\n",
    "#         print(self.root)\n",
    "\n",
    "    def check_node(self, node):\n",
    "        \"\"\"delete leaves if very deep but not wide\"\"\"\n",
    "        if len(node)<3:\n",
    "            return {}\n",
    "        else:\n",
    "            node = {k: check_node(node[k]) for k in node}\n",
    "            return node\n",
    "    \n",
    "    def cut_tree(self):\n",
    "        self.cut_root = {'statsmodels': self.check_node(self.root['statsmodels'])}\n",
    "        \n",
    "    def tolist(self, prefix, tree):\n",
    "        results = []\n",
    "        for k in tree:\n",
    "            if tree[k] =={}:\n",
    "                results.append('{}.{}'.format(prefix,k) if prefix!='' else k)\n",
    "            else:\n",
    "                results+=self.tolist('{}.{}'.format(prefix,k) if prefix!='' else k, tree[k])\n",
    "        return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./func_counter.json','r') as f:\n",
    "    func_counter = json.load(f)[\"func_counter\"]\n",
    "statsmodels_counter = {k: func_counter[k] for k in func_counter if k.startswith('sklearn.')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is the point to do clustering before choosing representative functions?\n",
    "Why can't we just sort all the functions and choose short ones? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_path = '/projects/bdata/jupyter/target'\n",
    "nb_path = '/projects/bdata/jupyter/target'\n",
    "notebooks = os.listdir(nb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter notebooks (which import sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels_notebooks = []\n",
    "for i, nb in enumerate(notebooks):\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    with open(os.path.join(nb_path, nb),'r') as f:\n",
    "#         print('--')\n",
    "        content = f.read()\n",
    "    tokens = content.split()\n",
    "    if 'sklearn' in tokens:\n",
    "        statsmodels_notebooks.append(nb)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete loops:\n",
    "eg  \n",
    "**sklearn.tree.DecisionTreeClassifier.fit.fit.fit**  \n",
    "is equal to   \n",
    "**sklearn.tree.DecisionTreeClassifier.fit**  \n",
    "  \n",
    "the only difference is that the first one is called multiple times  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_loop(func):\n",
    "    \"\"\"\n",
    "    delete continue loops in a function\n",
    "    simplify **sklearn.tree.DecisionTreeClassifier.fit.fit.fit** \n",
    "          to **sklearn.tree.DecisionTreeClassifier.fit**\n",
    "    \"\"\"\n",
    "    tokens = func.split('.')\n",
    "    new_tokens = []\n",
    "    for t in tokens:\n",
    "        if new_tokens == [] or t!=new_tokens[-1]:\n",
    "            new_tokens.append(t)\n",
    "    return '.'.join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_loop_statsmodels_funcs = []\n",
    "for k in statsmodels_counter:\n",
    "    t = delete_loop(k)\n",
    "    if t not in no_loop_statsmodels_funcs:\n",
    "        no_loop_statsmodels_funcs.append(t)\n",
    "no_loop_statsmodels_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func2vector = {}\n",
    "vector_size = len(statsmodels_notebooks)\n",
    "err_files = []\n",
    "for i, nb in enumerate(statsmodels_notebooks):\n",
    "    if i%10000 == 0:\n",
    "        print('Log: {} notebooks processed'.format(i))\n",
    "    funcs = []\n",
    "    try:\n",
    "        funcs, linenos = process_file(os.path.join(nb_path, nb))\n",
    "    except Exception as e:\n",
    "        err_files.append(nb)\n",
    "    funcs = [func for func in funcs if func in no_loop_statsmodels_funcs]\n",
    "    for func in funcs:\n",
    "#         if not func.startswith('statsmodels'):\n",
    "#             continue\n",
    "        if func not in func2vector:\n",
    "            func2vector[func] = np.zeros(vector_size)\n",
    "        func2vector[func][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2func = list(func2vector.keys())\n",
    "func2idx = {f: i for i, f in enumerate(idx2func)}\n",
    "vectors = [func2vector[f] for f in idx2func]\n",
    "occur_matrix = np.stack(vectors)\n",
    "cooccur_matrix = np.dot(occur_matrix, occur_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('statsmodels_cooccur_mat.npy', cooccur_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccur_matrix = np.load('keras_cooccur_mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1- cooccur_matrix/cooccur_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cluster.AgglomerativeClustering(n_clusters = None, distance_threshold=0.996, affinity=\"precomputed\", linkage=\"average\").fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_clusters = {}\n",
    "# new_clusters = [[]]*model.n_clusters_\n",
    "for i, l in enumerate(model.labels_):\n",
    "    if l not in new_clusters:\n",
    "        new_clusters[l] = []\n",
    "    new_clusters[l].append(idx2func[i])\n",
    "#     print(i)\n",
    "clusters = list(new_clusters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: find representatives in clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./statsmodels_cluster.json','w') as fout:\n",
    "    json.dump(clusters,fout, ensure_ascii=False,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./keras_cluster.json','r') as f:\n",
    "    clusters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_root = []\n",
    "sets = []\n",
    "has_root = []\n",
    "\n",
    "def find_root_in_cluster(cluster):\n",
    "    \"\"\"\n",
    "    find a representative function in a cluster like:\n",
    "     ['sklearn.preprocessing.MinMaxScaler',\n",
    "      'sklearn.preprocessing.MinMaxScaler.fit_transform',\n",
    "      'sklearn.preprocessing.MinMaxScaler.transform']\n",
    "    return a list []\n",
    "    \"\"\"\n",
    "#     if len(cluster)>3:\n",
    "#         return []\n",
    "    cluster = sorted(cluster)\n",
    "    last_root = '*'\n",
    "    cluster_roots = []\n",
    "    for f in cluster:\n",
    "        if not f.startswith(last_root):\n",
    "            cluster_roots.append(f)\n",
    "            last_root = f\n",
    "        elif f not in has_root:\n",
    "            has_root.append(f)\n",
    "    cluster_roots = [r for r in cluster_roots if not any([r.startswith(root) for root in roots])]\n",
    "    return cluster_roots\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = []\n",
    "tree = Tree()\n",
    "for c in tqdm(clusters):\n",
    "#     roots+=find_root_in_cluster(c)\n",
    "#     print(c)\n",
    "    funcs = find_root_in_cluster(c)\n",
    "    roots+=funcs\n",
    "#     print(funcs)\n",
    "    tree.add_funcs(funcs)\n",
    "print(json.dumps(tree.root, ensure_ascii=False, indent=2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(tree.tolist('',tree.root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.cut_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(tree.tolist('',tree.cut_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(tree.tolist('',tree.cut_root)):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted(tree.tolist('',tree.cut_root)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels_dp = {r: statsmodels_counter[r] for r in roots if statsmodels_counter[r]>5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in statsmodels_dp:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./statsmodels_dp.txt','w') as fout:\n",
    "    fout.write('\\n'.join(statsmodels_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./statsmodels_dp.txt','r') as f:\n",
    "    statsmodels_dp = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract structure from statsmodels_roots\n",
    "statsmodels_roots = ['.'.join(f.split('.')[:-1]) for f in sorted(tree.tolist('',tree.cut_root))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('statsmodels.api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('statsmodels.api.datasets')\n",
    "# dir(statsmodels.api.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('statsmodels.api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = import_module('datasets', package = 'statsmodels.api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(statsmodels.api.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in roots_counter:\n",
    "    try:\n",
    "        mod = import_module(r)\n",
    "        print(r, roots_counter[r]/len(dir(mod)))\n",
    "    except:\n",
    "        print(r, '-')\n",
    "#     print(dir(mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels_dp = sorted(tree.tolist('',tree.cut_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots_counter = {}\n",
    "for r in statsmodels_roots:\n",
    "    if r not in roots_counter:\n",
    "        roots_counter[r]=0\n",
    "    roots_counter[r]+=1\n",
    "    \n",
    "    \n",
    "frequent_roots = []\n",
    "for r in roots_counter:\n",
    "    try:\n",
    "        mod = import_module(r)\n",
    "        if  roots_counter[r]/len(dir(mod))>0.1:\n",
    "            frequent_roots.append(r)\n",
    "#         print(r, roots_counter[r]/len(dir(mod)))\n",
    "    except:\n",
    "#         print(r, '-')\n",
    "        pass\n",
    "#     print(dir(mod))\n",
    "    \n",
    "# frequent_roots = {r: roots_counter[r] for r in roots_counter if roots_counter[r]>=5}\n",
    "for r in frequent_roots:\n",
    "#     if r==\"statsmodels\":continue\n",
    "    try:\n",
    "        mod = import_module(r)\n",
    "#         print(mod.__all__)\n",
    "        try:\n",
    "            dps = ['{}.{}'.format(r, obj) for obj in mod.__all__] \n",
    "        except:\n",
    "            dps =  ['{}.{}'.format(r, obj) for obj in dir(mod) if not obj.startswith('_')]\n",
    "#         dps = ['{}.{}'.format(r, obj) for obj in dir(mod) if not obj.startswith('_')]\n",
    "        statsmodels_dp+=dps\n",
    "#         print(dps)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "statsmodels_dp = sorted(list(set(statsmodels_dp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(statsmodels_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in statsmodels_dp:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = func2vector[\"sklearn.cluster.Birch.fit\"]\n",
    "v2 = func2vector[\"sklearn.cluster.Birch\"]\n",
    "v3 = func2vector[\"sklearn.cluster.AgglomerativeClustering.labels_.astype\"]\n",
    "np.linalg.norm(v1- v3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
