{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# with open('')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1971it [00:00, 19707.15it/s]\u001b[A\n",
      "4562it [00:00, 21229.44it/s]\u001b[A\n",
      "6746it [00:00, 21408.53it/s]\u001b[A\n",
      "9343it [00:00, 22599.19it/s]\u001b[A\n",
      "12139it [00:00, 23830.36it/s]\u001b[A\n",
      "14608it [00:00, 24079.94it/s]\u001b[A\n",
      "17335it [00:00, 24955.62it/s]\u001b[A\n",
      "19841it [00:00, 24986.56it/s]\u001b[A\n",
      "22643it [00:00, 25822.17it/s]\u001b[A\n",
      "25216it [00:01, 25791.44it/s]\u001b[A\n",
      "27771it [00:01, 25714.93it/s]\u001b[A\n",
      "30599it [00:01, 26426.35it/s]\u001b[A\n",
      "33347it [00:01, 26732.38it/s]\u001b[A\n",
      "36124it [00:01, 26963.94it/s]\u001b[A\n",
      "38815it [00:01, 26232.95it/s]\u001b[A\n",
      "41439it [00:01, 25731.53it/s]\u001b[A\n",
      "44177it [00:01, 26203.92it/s]\u001b[A\n",
      "46801it [00:01, 26166.69it/s]\u001b[A\n",
      "49421it [00:01, 26038.76it/s]\u001b[A\n",
      "52027it [00:02, 25902.30it/s]\u001b[A\n",
      "54686it [00:02, 26101.77it/s]\u001b[A\n",
      "57298it [00:02, 25693.77it/s]\u001b[A\n",
      "59903it [00:02, 25798.50it/s]\u001b[A\n",
      "62504it [00:02, 25859.37it/s]\u001b[A\n",
      "65208it [00:02, 26199.57it/s]\u001b[A\n",
      "68018it [00:02, 26741.68it/s]\u001b[A\n",
      "70697it [00:02, 26374.62it/s]\u001b[A\n",
      "73368it [00:02, 26468.67it/s]\u001b[A\n",
      "76018it [00:02, 25680.58it/s]\u001b[A\n",
      "78810it [00:03, 26309.72it/s]\u001b[A\n",
      "81600it [00:03, 26763.13it/s]\u001b[A\n",
      "84285it [00:03, 26492.76it/s]\u001b[A\n",
      "86992it [00:03, 26662.12it/s]\u001b[A\n",
      "89676it [00:03, 26714.71it/s]\u001b[A\n",
      "92376it [00:03, 26797.18it/s]\u001b[A\n",
      "95094it [00:03, 26874.24it/s]\u001b[A\n",
      "97784it [00:03, 26696.44it/s]\u001b[A\n",
      "100519it [00:03, 26888.68it/s]\u001b[A\n",
      "103210it [00:03, 25671.39it/s]\u001b[A\n",
      "106204it [00:04, 26817.16it/s]\u001b[A\n",
      "108944it [00:04, 26987.86it/s]\u001b[A\n",
      "111659it [00:04, 26463.03it/s]\u001b[A\n",
      "114319it [00:04, 26022.33it/s]\u001b[A\n",
      "117198it [00:04, 26789.70it/s]\u001b[A\n",
      "120127it [00:04, 27492.23it/s]\u001b[A\n",
      "122891it [00:04, 27095.78it/s]\u001b[A\n",
      "125612it [00:04, 26685.79it/s]\u001b[A\n",
      "128309it [00:04, 26768.68it/s]\u001b[A\n",
      "130993it [00:04, 26347.35it/s]\u001b[A\n",
      "133634it [00:05, 25890.51it/s]\u001b[A\n",
      "136230it [00:05, 25696.07it/s]\u001b[A\n",
      "138848it [00:05, 25838.71it/s]\u001b[A\n",
      "141498it [00:05, 26029.73it/s]\u001b[A\n",
      "144104it [00:05, 25973.81it/s]\u001b[A\n",
      "146704it [00:05, 25837.36it/s]\u001b[A\n",
      "148409it [00:41, 158.57it/s]  \u001b[A\n",
      "148409it [00:41, 158.57it/s]\u001b[A\n",
      "152047it [00:41, 226.11it/s]\u001b[A\n",
      "156111it [00:41, 322.25it/s]\u001b[A\n",
      "159919it [00:41, 458.69it/s]\u001b[A\n",
      "163877it [00:41, 652.01it/s]\u001b[A\n",
      "168052it [00:41, 925.25it/s]\u001b[A\n",
      "171838it [00:41, 1307.99it/s]\u001b[A\n",
      "175773it [00:41, 1842.32it/s]\u001b[A\n",
      "179437it [00:42, 2576.36it/s]\u001b[A\n",
      "183054it [00:42, 3570.22it/s]\u001b[A\n",
      "186658it [00:42, 4889.65it/s]\u001b[A\n",
      "190247it [00:44, 3357.60it/s]\u001b[A\n",
      "193991it [00:44, 4619.03it/s]\u001b[A\n",
      "197783it [00:44, 6271.17it/s]\u001b[A\n",
      "201774it [00:44, 8393.22it/s]\u001b[A\n",
      "205797it [00:44, 11005.72it/s]\u001b[A\n",
      "209650it [00:44, 14007.66it/s]\u001b[A\n",
      "213774it [00:44, 17467.29it/s]\u001b[A\n",
      "217814it [00:44, 21051.60it/s]\u001b[A\n",
      "221694it [00:44, 24232.39it/s]\u001b[A\n",
      "225533it [00:45, 27022.87it/s]\u001b[A\n",
      "229329it [00:45, 29311.64it/s]\u001b[A\n",
      "233117it [00:45, 31443.20it/s]\u001b[A\n",
      "236881it [00:47, 5807.96it/s] \u001b[A\n",
      "240765it [00:47, 7797.35it/s]\u001b[A\n",
      "244475it [00:47, 10218.38it/s]\u001b[A\n",
      "248682it [00:47, 13220.99it/s]\u001b[A\n",
      "252726it [00:47, 16565.51it/s]\u001b[A\n",
      "256414it [00:47, 19316.44it/s]\u001b[A\n",
      "259942it [00:47, 22124.18it/s]\u001b[A\n",
      "263416it [00:47, 24278.24it/s]\u001b[A\n",
      "267395it [00:47, 27492.51it/s]\u001b[A\n",
      "271569it [00:48, 30627.74it/s]\u001b[A\n",
      "275691it [00:48, 33182.01it/s]\u001b[A\n",
      "279956it [00:48, 35549.52it/s]\u001b[A\n",
      "284108it [00:48, 37151.82it/s]\u001b[A\n",
      "288138it [00:48, 37872.53it/s]\u001b[A\n",
      "292213it [00:48, 38691.69it/s]\u001b[A\n",
      "296498it [00:48, 39851.70it/s]\u001b[A\n",
      "300605it [00:51, 5268.90it/s] \u001b[A\n",
      "304699it [00:51, 7133.54it/s]\u001b[A\n",
      "308790it [00:51, 9482.12it/s]\u001b[A\n",
      "312795it [00:51, 12297.65it/s]\u001b[A\n",
      "317081it [00:51, 15644.17it/s]\u001b[A\n",
      "321267it [00:51, 19263.16it/s]\u001b[A\n",
      "325479it [00:51, 23008.77it/s]\u001b[A\n",
      "329792it [00:51, 26752.74it/s]\u001b[A\n",
      "333907it [00:51, 29872.69it/s]\u001b[A\n",
      "338034it [00:51, 32570.56it/s]\u001b[A\n",
      "342151it [00:52, 34736.04it/s]\u001b[A\n",
      "346411it [00:52, 36772.49it/s]\u001b[A\n",
      "350622it [00:52, 38225.69it/s]\u001b[A\n",
      "354904it [00:52, 39495.55it/s]\u001b[A\n",
      "359111it [00:52, 39541.84it/s]\u001b[A\n",
      "363527it [00:52, 40821.00it/s]\u001b[A\n",
      "367936it [00:52, 41747.79it/s]\u001b[A\n",
      "372212it [00:52, 41799.24it/s]\u001b[A\n",
      "376463it [00:55, 4493.50it/s] \u001b[A\n",
      "380581it [00:55, 6131.46it/s]\u001b[A\n",
      "384604it [00:55, 8220.83it/s]\u001b[A\n",
      "388960it [00:55, 10865.05it/s]\u001b[A\n",
      "392996it [00:56, 13908.79it/s]\u001b[A\n",
      "397133it [00:56, 17367.00it/s]\u001b[A\n",
      "401291it [00:56, 21042.49it/s]\u001b[A\n",
      "405498it [00:56, 24754.25it/s]\u001b[A\n",
      "409564it [00:56, 27893.09it/s]\u001b[A\n",
      "413755it [00:56, 31002.76it/s]\u001b[A\n",
      "417878it [00:56, 33494.93it/s]\u001b[A\n",
      "422203it [00:56, 35925.40it/s]\u001b[A\n",
      "426367it [00:56, 37405.72it/s]\u001b[A\n",
      "430782it [00:56, 39200.51it/s]\u001b[A\n",
      "435016it [00:57, 39583.74it/s]\u001b[A\n",
      "439381it [00:57, 40673.83it/s]\u001b[A\n",
      "443610it [00:57, 40759.17it/s]\u001b[A\n",
      "447934it [00:57, 41471.08it/s]\u001b[A\n",
      "452257it [00:57, 41978.54it/s]\u001b[A\n",
      "456514it [00:57, 41243.76it/s]\u001b[A\n",
      "460683it [00:57, 40921.89it/s]\u001b[A\n",
      "464807it [00:57, 40586.04it/s]\u001b[A\n",
      "468932it [00:57, 40780.02it/s]\u001b[A\n",
      "473027it [01:01, 3587.98it/s] \u001b[A\n",
      "477182it [01:01, 4942.54it/s]\u001b[A\n",
      "481311it [01:01, 6716.16it/s]\u001b[A\n",
      "485623it [01:01, 8994.05it/s]\u001b[A\n",
      "489821it [01:01, 11767.66it/s]\u001b[A\n",
      "494029it [01:01, 14986.83it/s]\u001b[A\n",
      "497999it [01:02, 18343.71it/s]\u001b[A\n",
      "501931it [01:02, 21615.02it/s]\u001b[A\n",
      "505794it [01:02, 24592.23it/s]\u001b[A\n",
      "509585it [01:02, 27306.07it/s]\u001b[A\n",
      "513342it [01:02, 29548.39it/s]\u001b[A\n",
      "517069it [01:02, 31306.15it/s]\u001b[A\n",
      "520769it [01:02, 32742.56it/s]\u001b[A\n",
      "524513it [01:02, 34020.63it/s]\u001b[A\n",
      "528219it [01:02, 34835.52it/s]\u001b[A\n",
      "532063it [01:02, 35842.91it/s]\u001b[A\n",
      "535885it [01:03, 36524.08it/s]\u001b[A\n",
      "539653it [01:03, 36632.57it/s]\u001b[A\n",
      "543421it [01:03, 36922.68it/s]\u001b[A\n",
      "547235it [01:03, 37278.71it/s]\u001b[A\n",
      "551004it [01:03, 37322.09it/s]\u001b[A\n",
      "554845it [01:03, 37636.46it/s]\u001b[A\n",
      "558738it [01:03, 38013.50it/s]\u001b[A\n",
      "562555it [01:03, 37966.26it/s]\u001b[A\n",
      "566556it [01:03, 38555.51it/s]\u001b[A\n",
      "570422it [01:03, 38465.13it/s]\u001b[A\n",
      "574337it [01:04, 38665.86it/s]\u001b[A\n",
      "578209it [01:04, 38583.15it/s]\u001b[A\n",
      "582071it [01:04, 38443.30it/s]\u001b[A\n",
      "585918it [01:04, 38365.22it/s]\u001b[A\n",
      "589757it [01:09, 2585.57it/s] \u001b[A\n",
      "593525it [01:09, 3588.14it/s]\u001b[A\n",
      "597174it [01:09, 4918.56it/s]\u001b[A\n",
      "600906it [01:09, 6650.83it/s]\u001b[A\n",
      "604276it [01:09, 8658.82it/s]\u001b[A\n",
      "607514it [01:09, 11037.89it/s]\u001b[A\n",
      "610703it [01:09, 13605.96it/s]\u001b[A\n",
      "613829it [01:09, 16344.69it/s]\u001b[A\n",
      "617001it [01:09, 19125.07it/s]\u001b[A\n",
      "620131it [01:10, 21408.06it/s]\u001b[A\n",
      "623213it [01:10, 23485.04it/s]\u001b[A\n",
      "626309it [01:10, 25318.00it/s]\u001b[A\n",
      "629385it [01:10, 26578.26it/s]\u001b[A\n",
      "632441it [01:10, 27539.94it/s]\u001b[A\n",
      "635519it [01:10, 28434.72it/s]\u001b[A\n",
      "638571it [01:10, 28762.89it/s]\u001b[A\n",
      "641595it [01:10, 29065.59it/s]\u001b[A\n",
      "644606it [01:10, 29207.07it/s]\u001b[A\n",
      "647717it [01:10, 29688.46it/s]\u001b[A\n",
      "650739it [01:11, 29463.47it/s]\u001b[A\n",
      "653723it [01:11, 29405.56it/s]\u001b[A\n",
      "656690it [01:11, 29252.94it/s]\u001b[A\n",
      "659634it [01:11, 29007.38it/s]\u001b[A\n",
      "662577it [01:11, 29129.86it/s]\u001b[A\n",
      "665500it [01:11, 29153.47it/s]\u001b[A\n",
      "668431it [01:11, 29198.29it/s]\u001b[A\n",
      "671356it [01:11, 29089.31it/s]\u001b[A\n",
      "674400it [01:11, 29477.71it/s]\u001b[A\n",
      "677446it [01:11, 29762.69it/s]\u001b[A\n",
      "680426it [01:12, 29613.72it/s]\u001b[A\n",
      "683442it [01:12, 29774.18it/s]\u001b[A\n",
      "686422it [01:12, 29607.62it/s]\u001b[A\n",
      "689493it [01:12, 29926.00it/s]\u001b[A\n",
      "692513it [01:12, 29973.01it/s]\u001b[A\n",
      "695512it [01:12, 29562.46it/s]\u001b[A\n",
      "698514it [01:12, 29696.54it/s]\u001b[A\n",
      "701486it [01:12, 29635.47it/s]\u001b[A\n",
      "704484it [01:12, 29697.97it/s]\u001b[A\n",
      "707455it [01:12, 29449.79it/s]\u001b[A\n",
      "710450it [01:13, 29597.20it/s]\u001b[A\n",
      "713551it [01:13, 30007.05it/s]\u001b[A\n",
      "716554it [01:13, 29842.89it/s]\u001b[A\n",
      "719540it [01:13, 29571.59it/s]\u001b[A\n",
      "722653it [01:13, 30021.95it/s]\u001b[A\n",
      "725659it [01:13, 29770.41it/s]\u001b[A\n",
      "728659it [01:13, 29832.92it/s]\u001b[A\n",
      "731666it [01:13, 29901.79it/s]\u001b[A\n",
      "734658it [01:13, 29459.87it/s]\u001b[A\n",
      "737695it [01:13, 29726.95it/s]\u001b[A\n",
      "740670it [01:19, 1677.98it/s] \u001b[A\n",
      "744276it [01:19, 2350.24it/s]\u001b[A\n",
      "747858it [01:19, 3265.65it/s]\u001b[A\n",
      "751648it [01:19, 4499.02it/s]\u001b[A\n",
      "755417it [01:20, 6114.21it/s]\u001b[A\n",
      "759146it [01:20, 8161.02it/s]\u001b[A\n",
      "763164it [01:20, 10724.65it/s]\u001b[A\n",
      "767003it [01:20, 13682.51it/s]\u001b[A\n",
      "770941it [01:20, 17012.66it/s]\u001b[A\n",
      "774989it [01:20, 20594.23it/s]\u001b[A\n",
      "778987it [01:20, 24099.81it/s]\u001b[A\n",
      "782879it [01:20, 27062.97it/s]\u001b[A\n",
      "786802it [01:20, 29839.03it/s]\u001b[A\n",
      "790683it [01:20, 31899.05it/s]\u001b[A\n",
      "794541it [01:21, 33266.90it/s]\u001b[A\n",
      "798351it [01:21, 34274.25it/s]\u001b[A\n",
      "802191it [01:21, 35412.13it/s]\u001b[A\n",
      "806052it [01:21, 36314.14it/s]\u001b[A\n",
      "809866it [01:21, 36620.17it/s]\u001b[A\n",
      "813656it [01:21, 36697.42it/s]\u001b[A\n",
      "817416it [01:21, 36666.95it/s]\u001b[A\n",
      "821175it [01:21, 36933.68it/s]\u001b[A\n",
      "824913it [01:21, 36789.48it/s]\u001b[A\n",
      "828668it [01:21, 37013.04it/s]\u001b[A\n",
      "832400it [01:22, 37102.12it/s]\u001b[A\n",
      "836407it [01:22, 37944.77it/s]\u001b[A\n",
      "840218it [01:22, 37714.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "844001it [01:22, 37479.01it/s]\u001b[A\n",
      "847790it [01:22, 37586.44it/s]\u001b[A\n",
      "851555it [01:22, 37491.98it/s]\u001b[A\n",
      "855408it [01:22, 37796.42it/s]\u001b[A\n",
      "859347it [01:22, 38260.56it/s]\u001b[A\n",
      "863177it [01:22, 37968.34it/s]\u001b[A\n",
      "867013it [01:23, 38041.03it/s]\u001b[A\n",
      "870926it [01:23, 38359.92it/s]\u001b[A\n",
      "874765it [01:23, 38229.19it/s]\u001b[A\n",
      "878590it [01:23, 38061.47it/s]\u001b[A\n",
      "882398it [01:23, 37742.10it/s]\u001b[A\n",
      "886174it [01:23, 37510.52it/s]\u001b[A\n",
      "889975it [01:23, 37655.65it/s]\u001b[A\n",
      "893877it [01:23, 38054.39it/s]\u001b[A\n",
      "897792it [01:23, 38376.05it/s]\u001b[A\n",
      "901632it [01:23, 37892.57it/s]\u001b[A\n",
      "905545it [01:24, 38255.03it/s]\u001b[A\n",
      "909374it [01:24, 38243.44it/s]\u001b[A\n",
      "913201it [01:24, 37889.12it/s]\u001b[A\n",
      "916992it [01:24, 37794.52it/s]\u001b[A\n",
      "920815it [01:24, 37923.35it/s]\u001b[A\n",
      "924609it [01:24, 37919.68it/s]\u001b[A\n",
      "928402it [01:31, 1768.78it/s] \u001b[A\n",
      "932175it [01:31, 2477.04it/s]\u001b[A\n",
      "935809it [01:31, 3438.17it/s]\u001b[A\n",
      "939567it [01:31, 4726.33it/s]\u001b[A\n",
      "943246it [01:31, 6399.55it/s]\u001b[A\n",
      "946703it [01:31, 8465.46it/s]\u001b[A\n",
      "950465it [01:32, 11029.72it/s]\u001b[A\n",
      "954043it [01:32, 13917.11it/s]\u001b[A\n",
      "957726it [01:32, 17110.27it/s]\u001b[A\n",
      "961405it [01:32, 20380.88it/s]\u001b[A\n",
      "965149it [01:32, 23592.33it/s]\u001b[A\n",
      "968801it [01:32, 26232.34it/s]\u001b[A\n",
      "972423it [01:32, 28452.32it/s]\u001b[A\n",
      "976022it [01:32, 29996.89it/s]\u001b[A\n",
      "979572it [01:32, 31269.35it/s]\u001b[A\n",
      "983111it [01:32, 32400.58it/s]\u001b[A\n",
      "986641it [01:33, 32838.19it/s]\u001b[A\n",
      "990129it [01:33, 33064.26it/s]\u001b[A\n",
      "993767it [01:33, 33992.91it/s]\u001b[A\n",
      "997407it [01:33, 34679.00it/s]\u001b[A\n",
      "1000954it [01:33, 34576.75it/s]\u001b[A\n",
      "1004467it [01:33, 34729.16it/s]\u001b[A\n",
      "1007979it [01:33, 34516.68it/s]\u001b[A\n",
      "1011588it [01:33, 34973.51it/s]\u001b[A\n",
      "1015106it [01:33, 34992.46it/s]\u001b[A\n",
      "1018652it [01:33, 35129.87it/s]\u001b[A\n",
      "1022176it [01:34, 35062.85it/s]\u001b[A\n",
      "1025690it [01:34, 34906.66it/s]\u001b[A\n",
      "1029186it [01:34, 34738.16it/s]\u001b[A\n",
      "1032788it [01:34, 35112.16it/s]\u001b[A\n",
      "1036416it [01:34, 35453.14it/s]\u001b[A\n",
      "1039965it [01:34, 35283.36it/s]\u001b[A\n",
      "1043498it [01:34, 35296.47it/s]\u001b[A\n",
      "1047114it [01:34, 35550.70it/s]\u001b[A\n",
      "1050788it [01:34, 35896.22it/s]\u001b[A\n",
      "1054380it [01:34, 35608.47it/s]\u001b[A\n",
      "1057943it [01:35, 34908.57it/s]\u001b[A\n",
      "1061684it [01:35, 35622.39it/s]\u001b[A\n",
      "1065253it [01:35, 35317.32it/s]\u001b[A\n",
      "1068790it [01:35, 35332.99it/s]\u001b[A\n",
      "1072327it [01:35, 35194.75it/s]\u001b[A\n",
      "1075896it [01:35, 35340.79it/s]\u001b[A\n",
      "1079433it [01:35, 35008.31it/s]\u001b[A\n",
      "1082936it [01:35, 34581.61it/s]\u001b[A\n",
      "1086411it [01:35, 34631.79it/s]\u001b[A\n",
      "1089877it [01:35, 34626.70it/s]\u001b[A\n",
      "1093478it [01:36, 35030.02it/s]\u001b[A\n",
      "1096984it [01:36, 34603.60it/s]\u001b[A\n",
      "1100583it [01:36, 34984.42it/s]\u001b[A\n",
      "1104159it [01:36, 35209.16it/s]\u001b[A\n",
      "1107754it [01:36, 35428.10it/s]\u001b[A\n",
      "1111359it [01:36, 35612.11it/s]\u001b[A\n",
      "1114922it [01:36, 35299.17it/s]\u001b[A\n",
      "1118455it [01:36, 35304.51it/s]\u001b[A\n",
      "1122131it [01:36, 35724.38it/s]\u001b[A\n",
      "1125767it [01:37, 35911.28it/s]\u001b[A\n",
      "1129360it [01:37, 35793.14it/s]\u001b[A\n",
      "1132975it [01:37, 35895.72it/s]\u001b[A\n",
      "1136566it [01:37, 35805.59it/s]\u001b[A\n",
      "1140148it [01:37, 35508.84it/s]\u001b[A\n",
      "1143837it [01:37, 35910.84it/s]\u001b[A\n",
      "1147511it [01:37, 36153.94it/s]\u001b[A\n",
      "1151129it [01:37, 35607.37it/s]\u001b[A\n",
      "1154991it [01:37, 36459.67it/s]\u001b[A\n",
      "1158645it [01:46, 1349.55it/s] \u001b[A\n",
      "1162342it [01:46, 1898.23it/s]\u001b[A\n",
      "1166095it [01:46, 2653.90it/s]\u001b[A\n",
      "1171184it [01:46, 10951.39it/s][A\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "with open('./graphs/cell_with_func_markdown_1_12.txt','r') as f:\n",
    "#     for g in tqdm(graphs):\n",
    "    for l in tqdm(f):\n",
    "        graphs.append(json.loads(l))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171184"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate(graphs):\n",
    "    g[\"id\"] = i\n",
    "    if g[\"file\"]==graphs[i-1][\"file\"]:\n",
    "#         assert\n",
    "#         g[\"\"]\n",
    "        assert  g[\"target_lineno\"]>graphs[i-1][\"target_lineno\"]\n",
    "        g[\"neighbor_cells\"] = [i-1]\n",
    "    else:\n",
    "        g[\"neighbor_cells\"] = [-1]\n",
    "\n",
    "#     print(g[\"file\"], g[\"target_lineno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = [f for f in os.listdir('/projects/bdata/jupyter/_7_1') if f.endswith('.ipynb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260078"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pys = os.listdir('/projects/bdata/jupyter/target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header(content):\n",
    "    lines = content.split('\\n')\n",
    "    header_lineno = []\n",
    "    header_lines = []\n",
    "    header_level = []\n",
    "    for i, l in enumerate(lines):\n",
    "        if l.startswith('# #'):\n",
    "            header = re.sub('[^0-9a-zA-Z]+', ' ', l)\n",
    "            header_lines.append(header)\n",
    "            header_lineno.append(i)\n",
    "            header_level.append(len(l.split()[1]))\n",
    "#     raise NotImplementedError\n",
    "    return header_lineno, header_lines, header_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 62, 104, 137, 169, 205, 229, 243, 257, 325, 337, 370, 381, 389, 397],\n",
       " [' Produce Sky flats',\n",
       "  ' 1 Get the master bias ',\n",
       "  ' 2 Get the scaled darks',\n",
       "  ' 3 Raw sky flats',\n",
       "  ' a Read the skyflat images',\n",
       "  ' b Substract overscan and trim',\n",
       "  ' c Substract the bias',\n",
       "  ' d Substract the dark by scaling with exposure',\n",
       "  ' e Shows the reordered flats',\n",
       "  ' c Combination sigma clip and master flat',\n",
       "  ' d Generate the Master flat',\n",
       "  ' Save the file',\n",
       "  ' Shows the flat',\n",
       "  ' Save master flat',\n",
       "  ' Show the histograms on flats'],\n",
       " [1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_header(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in graphs:\n",
    "    if g[\"header\"]=='[EMPTY]':\n",
    "        g[\"header\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pys = [f for f in os.listdir('/projects/bdata/jupyter/target') if f.endswith('.py')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162610"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_pys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1585/162610 [00:15<25:48, 104.00it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4655b42f2478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_pys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/projects/bdata/jupyter/target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mheader_lineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     header[py] = {\"header_lineno\":header_lineno,\n",
      "\u001b[0;32m~/anaconda3/envs/allennlp/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "header = {}\n",
    "for py in tqdm(target_pys):\n",
    "    with open(os.path.join('/projects/bdata/jupyter/target', py), 'r') as f:\n",
    "        content = f.read()\n",
    "    header_lineno, header_lines, header_level = get_header(content)\n",
    "    header[py] = {\"header_lineno\":header_lineno,\n",
    "                 \"header_lines\":header_lines,\n",
    "                 \"header_level\":header_level}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162610/162610 [00:03<00:00, 47373.23it/s]\n"
     ]
    }
   ],
   "source": [
    "uni_gram_counter = {}\n",
    "for py in tqdm(header):\n",
    "    for h in header[py][\"header_lines\"]:\n",
    "        grams = [t.lower() for t in h.split() if t]\n",
    "        for t in grams:\n",
    "            if t not in uni_gram_counter:\n",
    "                uni_gram_counter[t]=0\n",
    "            uni_gram_counter[t]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'data',\n",
       " 'and',\n",
       " 'of',\n",
       " 'a',\n",
       " '1',\n",
       " 'model',\n",
       " 'to',\n",
       " '2',\n",
       " 'for',\n",
       " 'with',\n",
       " '3',\n",
       " 'in',\n",
       " 'question',\n",
       " 'regression',\n",
       " '4',\n",
       " 'on',\n",
       " 'is',\n",
       " '5',\n",
       " 'test',\n",
       " 'feature',\n",
       " 'learning',\n",
       " 'using',\n",
       " 's',\n",
       " 'from',\n",
       " 'we',\n",
       " 'training',\n",
       " 'features',\n",
       " 'analysis',\n",
       " 'this',\n",
       " '0',\n",
       " 'part',\n",
       " 'linear',\n",
       " 'plot',\n",
       " 'implementation',\n",
       " 'that',\n",
       " 'what',\n",
       " 'dataset',\n",
       " 'classification',\n",
       " 'set',\n",
       " '6',\n",
       " 'load',\n",
       " 'by',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'i',\n",
       " 'are',\n",
       " 'x',\n",
       " 'k',\n",
       " 'logistic',\n",
       " 'you',\n",
       " 'random',\n",
       " 'it',\n",
       " 'your',\n",
       " 'classifier',\n",
       " 'models',\n",
       " 'create',\n",
       " 'as',\n",
       " 'results',\n",
       " 'example',\n",
       " 'use',\n",
       " 'problem',\n",
       " 'all',\n",
       " 'cross',\n",
       " 'step',\n",
       " 'how',\n",
       " 'function',\n",
       " 'best',\n",
       " '7',\n",
       " '10',\n",
       " 'machine',\n",
       " 'variables',\n",
       " 'de',\n",
       " 'n',\n",
       " 'our',\n",
       " 'matrix',\n",
       " 'an',\n",
       " 'project',\n",
       " 'exercise',\n",
       " 'get',\n",
       " 'can',\n",
       " 'python',\n",
       " 'split',\n",
       " 'values',\n",
       " 'testing',\n",
       " 'do',\n",
       " 'or',\n",
       " 'be',\n",
       " 'performance',\n",
       " 'decision',\n",
       " 'one',\n",
       " 'at',\n",
       " 't',\n",
       " 'distribution',\n",
       " 'tree',\n",
       " 'time',\n",
       " 'y',\n",
       " 'learn',\n",
       " 'into',\n",
       " 'each',\n",
       " 'evaluation',\n",
       " 'fit',\n",
       " 'clustering',\n",
       " 'scikit',\n",
       " '8',\n",
       " 'confusion',\n",
       " 'forest',\n",
       " 'number',\n",
       " 'selection',\n",
       " 'functions',\n",
       " 'compute',\n",
       " 'accuracy',\n",
       " 'vs',\n",
       " 'p',\n",
       " 'not',\n",
       " 'let',\n",
       " 'mean',\n",
       " 'svm',\n",
       " 'class',\n",
       " 'if',\n",
       " 'score',\n",
       " 'some',\n",
       " 'pca',\n",
       " 'knn',\n",
       " 'naive',\n",
       " 'more',\n",
       " 'run',\n",
       " 'have',\n",
       " 'parameters',\n",
       " 'now',\n",
       " 'b',\n",
       " 'code',\n",
       " 'columns',\n",
       " 'image',\n",
       " 'check',\n",
       " 'predict',\n",
       " 'c',\n",
       " 'value',\n",
       " 'introduction',\n",
       " 'predicting',\n",
       " 'first',\n",
       " 'import',\n",
       " 'other',\n",
       " 'algorithm',\n",
       " 'exploration',\n",
       " 'prediction',\n",
       " 'vector',\n",
       " 'make',\n",
       " 'calculate',\n",
       " 'final',\n",
       " 'build',\n",
       " 'metrics',\n",
       " 'bayes',\n",
       " 'scipy',\n",
       " 'will',\n",
       " 'different',\n",
       " 'numpy',\n",
       " 'sklearn',\n",
       " 'between',\n",
       " 'error',\n",
       " 'out',\n",
       " 'network',\n",
       " 'new',\n",
       " 'two',\n",
       " 'text',\n",
       " 'font',\n",
       " 'images',\n",
       " 'predictions',\n",
       " 'up',\n",
       " '9',\n",
       " 'trees',\n",
       " 'neural',\n",
       " 'o',\n",
       " 'building',\n",
       " 'means',\n",
       " 'evaluating',\n",
       " 'find',\n",
       " 'does',\n",
       " 'search',\n",
       " 'nbsp',\n",
       " 'which',\n",
       " 'color',\n",
       " 'plots',\n",
       " 'getting',\n",
       " 'method',\n",
       " 'e',\n",
       " 'file',\n",
       " 'based',\n",
       " 'variable',\n",
       " 'define',\n",
       " 'tuning',\n",
       " 'variance',\n",
       " 'see',\n",
       " 'plotting',\n",
       " 'points',\n",
       " 'layer',\n",
       " 'r',\n",
       " 'compare',\n",
       " 'd',\n",
       " 'but',\n",
       " 'no',\n",
       " 'preprocessing',\n",
       " 'importance',\n",
       " 'so',\n",
       " 'summary',\n",
       " 'sample',\n",
       " 'look',\n",
       " 'supervised',\n",
       " 'gradient',\n",
       " 'why',\n",
       " 'task',\n",
       " 'libraries',\n",
       " 'about',\n",
       " 'there',\n",
       " 'loading',\n",
       " 'grid',\n",
       " 'missing',\n",
       " 'correlation',\n",
       " 'print',\n",
       " 'pandas',\n",
       " 'output',\n",
       " 'fitting',\n",
       " 'same',\n",
       " 'choosing',\n",
       " 'optimal',\n",
       " 'array',\n",
       " 'setup',\n",
       " 'creating',\n",
       " 'conclusion',\n",
       " 'support',\n",
       " 'target',\n",
       " 'dataframe',\n",
       " 'read',\n",
       " 'than',\n",
       " 'simple',\n",
       " 'f',\n",
       " 'visualization',\n",
       " 'm',\n",
       " 'only',\n",
       " 'words',\n",
       " 'try',\n",
       " 'nanodegree',\n",
       " 'modeling',\n",
       " 'exploring',\n",
       " 'exploratory',\n",
       " 'above',\n",
       " 'engineer',\n",
       " 'methods',\n",
       " 'notebook',\n",
       " 'average',\n",
       " 'bonus',\n",
       " 'lasso',\n",
       " 'table',\n",
       " 'save',\n",
       " 'add',\n",
       " 'visualizing',\n",
       " 'most',\n",
       " 'statistics',\n",
       " 'visualize',\n",
       " 'input',\n",
       " 'here',\n",
       " 'kernel',\n",
       " 'finding',\n",
       " '11',\n",
       " 'right',\n",
       " 'curves',\n",
       " 'coefficients',\n",
       " 'practice',\n",
       " 'cluster',\n",
       " 'categorical',\n",
       " 'single',\n",
       " 'started',\n",
       " 'curve',\n",
       " 'top',\n",
       " 'point',\n",
       " 'basic',\n",
       " 'pipeline',\n",
       " 'explore',\n",
       " 'sets',\n",
       " 'com',\n",
       " 'when',\n",
       " 'preprocess',\n",
       " 'map',\n",
       " 'regularization',\n",
       " 'application',\n",
       " 'labels',\n",
       " 'datasets',\n",
       " 'non',\n",
       " 'type',\n",
       " 'ridge',\n",
       " 'list',\n",
       " 'write',\n",
       " 'roc',\n",
       " 'rate',\n",
       " 'left',\n",
       " 'column',\n",
       " 'neighbors',\n",
       " 'work',\n",
       " 'used',\n",
       " 'information',\n",
       " 'nearest',\n",
       " 'samples',\n",
       " 'total',\n",
       " 'terms',\n",
       " 'line',\n",
       " 'preparing',\n",
       " 'log',\n",
       " 'bagging',\n",
       " 'clusters',\n",
       " 'then',\n",
       " 'numerical',\n",
       " 'frequency',\n",
       " 'csv',\n",
       " 'size',\n",
       " 'us',\n",
       " 'over',\n",
       " 'http',\n",
       " 'need',\n",
       " 'review',\n",
       " 'below',\n",
       " 'sub',\n",
       " 'series',\n",
       " 'loss',\n",
       " 'age',\n",
       " 'these',\n",
       " 'distributions',\n",
       " 'cleaning',\n",
       " 'like',\n",
       " 'processing',\n",
       " 'parameter',\n",
       " 'gaussian',\n",
       " 'max',\n",
       " 'bias',\n",
       " 'per',\n",
       " 'assignment',\n",
       " 'sum',\n",
       " 'beta',\n",
       " 'prices',\n",
       " 'classifiers',\n",
       " 'evaluate',\n",
       " 'initial',\n",
       " 'observation',\n",
       " '12',\n",
       " 'has',\n",
       " 'files',\n",
       " 'https',\n",
       " 'note',\n",
       " 'multiple',\n",
       " 'system',\n",
       " 'solution',\n",
       " 'arrays',\n",
       " 'generate',\n",
       " 'figure',\n",
       " 'show',\n",
       " 'better',\n",
       " 'process',\n",
       " 'prepare',\n",
       " 'comparing',\n",
       " 'center',\n",
       " 'frac',\n",
       " 'hypothesis',\n",
       " 'weights',\n",
       " 'word',\n",
       " 'pre',\n",
       " 'student',\n",
       " 'dummy',\n",
       " 'predictor',\n",
       " 'precision',\n",
       " 'keras',\n",
       " 'networks',\n",
       " 'id',\n",
       " 'gridsearch',\n",
       " '20',\n",
       " 'any',\n",
       " 'observations',\n",
       " 'perform',\n",
       " 'would',\n",
       " 'page',\n",
       " 'lab',\n",
       " 'housing',\n",
       " 'alpha',\n",
       " 'style',\n",
       " 'where',\n",
       " 'many',\n",
       " 'la',\n",
       " 'result',\n",
       " 'iris',\n",
       " 'case',\n",
       " 'name',\n",
       " 'org',\n",
       " 'just',\n",
       " 'reading',\n",
       " '15',\n",
       " 'recall',\n",
       " 'lda',\n",
       " 'optimization',\n",
       " 'activity',\n",
       " 'was',\n",
       " '50',\n",
       " 'boosting',\n",
       " 'sampling',\n",
       " 'identify',\n",
       " 'reduction',\n",
       " 'probability',\n",
       " 'distance',\n",
       " 'space',\n",
       " 'fold',\n",
       " 'good',\n",
       " 'statistical',\n",
       " 'imports',\n",
       " 'extracting',\n",
       " 'should',\n",
       " 'df',\n",
       " 'dt',\n",
       " 'level',\n",
       " 'well',\n",
       " 'true',\n",
       " 'job',\n",
       " 'topic',\n",
       " 'high',\n",
       " 'price',\n",
       " 'xgboost',\n",
       " 'median',\n",
       " 'matplotlib',\n",
       " 'did',\n",
       " 'making',\n",
       " 'density',\n",
       " 'comparison',\n",
       " 'difference',\n",
       " 'pruning',\n",
       " 'questions',\n",
       " 'statsmodels',\n",
       " 'challenge',\n",
       " 'filter',\n",
       " 'null',\n",
       " 'normal',\n",
       " 'also',\n",
       " 'transform',\n",
       " 'odds',\n",
       " 'remove',\n",
       " 'predicted',\n",
       " 'important',\n",
       " 'engineering',\n",
       " 'span',\n",
       " 'change',\n",
       " 'least',\n",
       " 'answer',\n",
       " 'hot',\n",
       " 'stats',\n",
       " 'report',\n",
       " 'w',\n",
       " 'removed',\n",
       " 'graph',\n",
       " 'overview',\n",
       " 'approach',\n",
       " 'next',\n",
       " 'resources',\n",
       " 'nn',\n",
       " 'scatter',\n",
       " 'br',\n",
       " 'they',\n",
       " 'z',\n",
       " 'polynomial',\n",
       " 'extract',\n",
       " 'standard',\n",
       " 'clean',\n",
       " 'income',\n",
       " 'kaggle',\n",
       " 'scaling',\n",
       " 'digits',\n",
       " 'softmax',\n",
       " 'analyzing',\n",
       " 'dimensionality',\n",
       " 'boston',\n",
       " 'select',\n",
       " 'examples',\n",
       " 'convert',\n",
       " 'layman',\n",
       " 'their',\n",
       " 'before',\n",
       " 'submission',\n",
       " 'tf',\n",
       " 'via',\n",
       " 'index',\n",
       " 'types',\n",
       " 'ensemble',\n",
       " 'independent',\n",
       " 'going',\n",
       " 'contents',\n",
       " 'html',\n",
       " 'apply',\n",
       " 'take',\n",
       " 'shape',\n",
       " 'user',\n",
       " 'given',\n",
       " 'algorithms',\n",
       " 'deep',\n",
       " 'shuffle',\n",
       " 'machines',\n",
       " 'last',\n",
       " 'population',\n",
       " 'them',\n",
       " 'en',\n",
       " 'week',\n",
       " 'background',\n",
       " 'label',\n",
       " 'steps',\n",
       " 'group',\n",
       " 'database',\n",
       " 'squared',\n",
       " 'my',\n",
       " 'vectors',\n",
       " 'want',\n",
       " 'after',\n",
       " 'continuous',\n",
       " 'detection',\n",
       " 'forests',\n",
       " 'np',\n",
       " 'following',\n",
       " 'day',\n",
       " 'descent',\n",
       " 'start',\n",
       " '2015',\n",
       " '2016',\n",
       " 'exercises',\n",
       " 'scores',\n",
       " 'mins',\n",
       " 'description',\n",
       " 'correlations',\n",
       " 'count',\n",
       " 'numbers',\n",
       " 'principal',\n",
       " 'component',\n",
       " 'order',\n",
       " 'ratio',\n",
       " 'outliers',\n",
       " 'packages',\n",
       " 'homework',\n",
       " 'classes',\n",
       " 'mnist',\n",
       " 'metric',\n",
       " 'neurals',\n",
       " '100',\n",
       " 'without',\n",
       " 'bayesian',\n",
       " 'transformation',\n",
       " 'plt',\n",
       " 'scale',\n",
       " 'min',\n",
       " 'real',\n",
       " 'convolutional',\n",
       " 'display',\n",
       " 'modules',\n",
       " 'format',\n",
       " 'way',\n",
       " 'tests',\n",
       " 're',\n",
       " 'squares',\n",
       " 'filtering',\n",
       " 'baseline',\n",
       " 'year',\n",
       " 'g',\n",
       " 'choose',\n",
       " 'setting',\n",
       " 'required',\n",
       " 'version',\n",
       " 'both',\n",
       " 'binary',\n",
       " 'red',\n",
       " 'components',\n",
       " 'working',\n",
       " 'spatial',\n",
       " 'very',\n",
       " 'extraction',\n",
       " 'matrices',\n",
       " 'extra',\n",
       " 'ipython',\n",
       " 'encoding',\n",
       " 'state',\n",
       " 'further',\n",
       " 'signal',\n",
       " 'through',\n",
       " 'references',\n",
       " 'three',\n",
       " 'sentiment',\n",
       " 'end',\n",
       " 'greedy',\n",
       " 'histogram',\n",
       " 'second',\n",
       " 'depth',\n",
       " 'range',\n",
       " 'idf',\n",
       " 'effect',\n",
       " 'multi',\n",
       " 'full',\n",
       " 'j',\n",
       " 'estimation',\n",
       " 'tell',\n",
       " 'u',\n",
       " 'original',\n",
       " 'location',\n",
       " 'l',\n",
       " '2d',\n",
       " 'discriminant',\n",
       " 'sales',\n",
       " 'document',\n",
       " 'calculating',\n",
       " 'v',\n",
       " 'useful',\n",
       " 'raw',\n",
       " 'adding',\n",
       " 'blue',\n",
       " 'science',\n",
       " 'importing',\n",
       " 'demo',\n",
       " 'reference',\n",
       " 'ii',\n",
       " 'odor',\n",
       " 'axis',\n",
       " 'drop',\n",
       " 'understanding',\n",
       " 'effects',\n",
       " 'probabilities',\n",
       " 'computing',\n",
       " 'gini',\n",
       " 'cell',\n",
       " 'weight',\n",
       " 'source',\n",
       " 'running',\n",
       " 'section',\n",
       " 'sup',\n",
       " 'hyperparameters',\n",
       " 'preparation',\n",
       " 'describe',\n",
       " 'tradeoff',\n",
       " 'similarity',\n",
       " 'energy',\n",
       " 'citibike',\n",
       " 'object',\n",
       " 'objectives',\n",
       " 'response',\n",
       " 'predictive',\n",
       " 'module',\n",
       " 'auc',\n",
       " 'para',\n",
       " 'implement',\n",
       " 'optional',\n",
       " 'tutorial',\n",
       " 'cv',\n",
       " '13',\n",
       " 'great',\n",
       " 'cost',\n",
       " 'normalize',\n",
       " 'unsupervised',\n",
       " 'lets',\n",
       " 'additional',\n",
       " 'validate',\n",
       " 'epsilon',\n",
       " 'those',\n",
       " 'l1',\n",
       " 'reviews',\n",
       " 'api',\n",
       " 'script',\n",
       " 'advanced',\n",
       " 'discussion',\n",
       " 'net',\n",
       " 'kmeans',\n",
       " '30',\n",
       " 'intervention',\n",
       " 'lesson',\n",
       " 'looking',\n",
       " 'rows',\n",
       " 'overfitting',\n",
       " 'examine',\n",
       " 'fully',\n",
       " 'que',\n",
       " 'tensorflow',\n",
       " 'events',\n",
       " 'batch',\n",
       " 'layers',\n",
       " 'es',\n",
       " 'dimensional',\n",
       " 'coefficient',\n",
       " 'helper',\n",
       " 'confidence',\n",
       " 'could',\n",
       " 'false',\n",
       " 'small',\n",
       " 'notes',\n",
       " 'noise',\n",
       " '25',\n",
       " 'term',\n",
       " 'category',\n",
       " 'were',\n",
       " 'likelihood',\n",
       " 'hand',\n",
       " 'estimator',\n",
       " 'gender',\n",
       " 'another',\n",
       " 'splitting',\n",
       " 'el',\n",
       " 'dictionary',\n",
       " 'estimators',\n",
       " 'chapter',\n",
       " 'common',\n",
       " 'bag',\n",
       " 'architecture',\n",
       " 'go',\n",
       " 'maximum',\n",
       " 'much',\n",
       " 'low',\n",
       " 'normalization',\n",
       " 'back',\n",
       " 'quick',\n",
       " 'open',\n",
       " 'checking',\n",
       " 'topics',\n",
       " 'guided',\n",
       " '14',\n",
       " 'positive',\n",
       " 'date',\n",
       " 'area',\n",
       " 'global',\n",
       " 'intro',\n",
       " 'regressor',\n",
       " 'subset',\n",
       " 'titanic',\n",
       " 'temperature',\n",
       " 'names',\n",
       " 'higher',\n",
       " 'tabular',\n",
       " 'length',\n",
       " 'similar',\n",
       " 'sparse',\n",
       " 'base',\n",
       " 'complexity',\n",
       " 'todo',\n",
       " 'relationship',\n",
       " 'svc',\n",
       " 'attributes',\n",
       " 'cnn',\n",
       " 'explain',\n",
       " 'may',\n",
       " 'eda',\n",
       " 'deeper',\n",
       " 'station',\n",
       " 'l2',\n",
       " 'experiment',\n",
       " 'interpretation',\n",
       " 'transforming',\n",
       " 'des',\n",
       " 'times',\n",
       " 'negative',\n",
       " 'its',\n",
       " 'h',\n",
       " 'describing',\n",
       " 'general',\n",
       " 'findings',\n",
       " 'relevance',\n",
       " 'large',\n",
       " 'checkpoint',\n",
       " 'normalizing',\n",
       " 'local',\n",
       " 'recognition',\n",
       " 'merge',\n",
       " 'since',\n",
       " 'word2vec',\n",
       " 'box',\n",
       " 'salary',\n",
       " 'autocorrelation',\n",
       " 'custom',\n",
       " 'view',\n",
       " '16',\n",
       " 'key',\n",
       " 'residuals',\n",
       " 'convolution',\n",
       " 'equation',\n",
       " 'seaborn',\n",
       " 'own',\n",
       " 'generated',\n",
       " 'conclusions',\n",
       " 'interpreting',\n",
       " 'measure',\n",
       " 'threshold',\n",
       " 'survival',\n",
       " 'improving',\n",
       " 'info',\n",
       " 'entropy',\n",
       " 'found',\n",
       " 'github',\n",
       " 'again',\n",
       " 'few',\n",
       " 'representation',\n",
       " 'encode',\n",
       " 'bar',\n",
       " 'rmse',\n",
       " 'theta',\n",
       " 'programming',\n",
       " 'sensitivity',\n",
       " 'interpret',\n",
       " 'corpus',\n",
       " 'optimized',\n",
       " 'determine',\n",
       " 'comments',\n",
       " 'library',\n",
       " 'construct',\n",
       " 'rbf',\n",
       " 'big',\n",
       " 'title',\n",
       " 'errors',\n",
       " 'boost',\n",
       " 'numeric',\n",
       " 'lambda',\n",
       " 'design',\n",
       " 'together',\n",
       " 'query',\n",
       " 'power',\n",
       " 'selecting',\n",
       " 'content',\n",
       " '2017',\n",
       " 'market',\n",
       " 'actual',\n",
       " 'cart',\n",
       " 'don',\n",
       " 'estimate',\n",
       " 'outlier',\n",
       " 'structure',\n",
       " 'improve',\n",
       " 'trained',\n",
       " 'goal',\n",
       " 'problems',\n",
       " 'skewed',\n",
       " 'less',\n",
       " 'monthly',\n",
       " 'rides',\n",
       " 'histograms',\n",
       " 'predictors',\n",
       " 'scoring',\n",
       " 'study',\n",
       " 'da',\n",
       " 'quality',\n",
       " 'because',\n",
       " 'credit',\n",
       " 'who',\n",
       " 'populate',\n",
       " 'due',\n",
       " 'mathbf',\n",
       " 'specific',\n",
       " 'll',\n",
       " 'categories',\n",
       " 'things',\n",
       " 'frame',\n",
       " 'ols',\n",
       " 'ml',\n",
       " 'item',\n",
       " 'row',\n",
       " 'lines',\n",
       " 'performace',\n",
       " 'ucb1',\n",
       " 'main',\n",
       " 'goodness',\n",
       " 'sigma',\n",
       " 'los',\n",
       " 'users',\n",
       " 'simulation',\n",
       " 'tables',\n",
       " 'residual',\n",
       " 'statement',\n",
       " 'download',\n",
       " 'tune',\n",
       " 'generating',\n",
       " 'store',\n",
       " 'adaboost',\n",
       " 'con',\n",
       " 'initialize',\n",
       " 'png',\n",
       " 'against',\n",
       " 'default',\n",
       " 'www',\n",
       " 'return',\n",
       " 'un',\n",
       " 'et',\n",
       " 'degree',\n",
       " 'crime',\n",
       " 'instead',\n",
       " 'definition',\n",
       " 'done',\n",
       " 'across',\n",
       " 'f1',\n",
       " 'think',\n",
       " 'perceptron',\n",
       " 'too',\n",
       " 'gamma',\n",
       " 'q',\n",
       " 'applying',\n",
       " 'available',\n",
       " 'prestige',\n",
       " 'dbscan',\n",
       " 'rating',\n",
       " 'percentage',\n",
       " 'weather',\n",
       " 'self',\n",
       " 'systems',\n",
       " 'operations',\n",
       " 'include',\n",
       " 'dict',\n",
       " 'combining',\n",
       " 'docs',\n",
       " 'integration',\n",
       " 'doc',\n",
       " 'transfer',\n",
       " 'people',\n",
       " 'indexing',\n",
       " 'zero',\n",
       " 'math',\n",
       " 'consider',\n",
       " 'em',\n",
       " 'dimension',\n",
       " 'sentence',\n",
       " 'guess',\n",
       " 'repeat',\n",
       " 'deviation',\n",
       " 'significant',\n",
       " 'combine',\n",
       " 'fill',\n",
       " 'latent',\n",
       " 'rank',\n",
       " '17',\n",
       " 'partial',\n",
       " 'square',\n",
       " 'na',\n",
       " 'implementing',\n",
       " 'customer',\n",
       " 'connected',\n",
       " 'lecture',\n",
       " 'estimating',\n",
       " 'datos',\n",
       " 'down',\n",
       " 'analyze',\n",
       " 'lower',\n",
       " 'shows',\n",
       " 'introducing',\n",
       " 'groups',\n",
       " 'race',\n",
       " 'mode',\n",
       " 'web',\n",
       " 'month',\n",
       " 'mathrm',\n",
       " 'within',\n",
       " 'sex',\n",
       " 'donors',\n",
       " 'sign',\n",
       " 'individual',\n",
       " 'cells',\n",
       " 'carlo',\n",
       " 'se',\n",
       " 'mining',\n",
       " 'monte',\n",
       " 'absolute',\n",
       " 'charityml',\n",
       " 'previous',\n",
       " 'brewing',\n",
       " 'event',\n",
       " 'trying',\n",
       " '3d',\n",
       " 'counts',\n",
       " 'le',\n",
       " 'quadratic',\n",
       " 'wrangling',\n",
       " 'tasks',\n",
       " 'future',\n",
       " 'movies',\n",
       " 'removing',\n",
       " 'equations',\n",
       " 'fourier',\n",
       " 'decomposition',\n",
       " 'fits',\n",
       " 'developing',\n",
       " 'dimensions',\n",
       " 'ada',\n",
       " 'being',\n",
       " 'etc',\n",
       " 'window',\n",
       " 'algebra',\n",
       " 'explained',\n",
       " '2014',\n",
       " 'form',\n",
       " 'looks',\n",
       " 'classify',\n",
       " 'attribute',\n",
       " 'team',\n",
       " 'every',\n",
       " 'know',\n",
       " 'gain',\n",
       " 'body',\n",
       " 'product',\n",
       " 'minutes',\n",
       " 'rnn',\n",
       " 'under',\n",
       " 'binomial',\n",
       " ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(uni_gram_counter.keys(), key=lambda x: -uni_gram_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162610/162610 [00:06<00:00, 26479.61it/s]\n"
     ]
    }
   ],
   "source": [
    "bi_gram_counter = {}\n",
    "for py in tqdm(header):\n",
    "    for h in header[py][\"header_lines\"]:\n",
    "        grams = [t.lower() for t in h.split() if t]\n",
    "        bi_grams = ['{} {}'.format(t, grams[i+1]) for i, t in enumerate(grams[:-1])]\n",
    "        for t in bi_grams:\n",
    "            if t not in bi_gram_counter:\n",
    "                bi_gram_counter[t]=0\n",
    "            bi_gram_counter[t]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600107"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bi_gram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the data',\n",
       " 'of the',\n",
       " 'logistic regression',\n",
       " 'the model',\n",
       " 'in the',\n",
       " 'cross validation',\n",
       " 'machine learning',\n",
       " 'linear regression',\n",
       " 'for the',\n",
       " 'on the',\n",
       " 'random forest',\n",
       " 'scikit learn',\n",
       " 'training and',\n",
       " 'let s',\n",
       " 'to the',\n",
       " 'the best',\n",
       " 'number of',\n",
       " 'with the',\n",
       " 'decision tree',\n",
       " 'question 1',\n",
       " 'nbsp nbsp',\n",
       " 'question 2',\n",
       " 'naive bayes',\n",
       " 'feature selection',\n",
       " 'load the',\n",
       " 'model performance',\n",
       " 'compute confusion',\n",
       " 'data exploration',\n",
       " 'from the',\n",
       " 'and the',\n",
       " 'question 4',\n",
       " 'confusion on',\n",
       " 'question 3',\n",
       " 'plot the',\n",
       " 'is the',\n",
       " 'a model',\n",
       " 'model evaluation',\n",
       " 'create a',\n",
       " 'k means',\n",
       " 'question 5',\n",
       " '2 2',\n",
       " 'data set',\n",
       " 'best model',\n",
       " '2 1',\n",
       " 'what is',\n",
       " 'supervised learning',\n",
       " 'and test',\n",
       " '1 1',\n",
       " 'engineer nanodegree',\n",
       " 'data analysis',\n",
       " 'feature importance',\n",
       " '1 2',\n",
       " 'and testing',\n",
       " 'for each',\n",
       " 'confusion matrix',\n",
       " 'data and',\n",
       " 'support vector',\n",
       " 'distribution of',\n",
       " 'grid search',\n",
       " 'the same',\n",
       " 'learning engineer',\n",
       " 'using the',\n",
       " 'part 2',\n",
       " 'choosing the',\n",
       " 'part 1',\n",
       " 'look at',\n",
       " 'regression model',\n",
       " 'implementation model',\n",
       " 'we can',\n",
       " 'getting started',\n",
       " 'based on',\n",
       " 'get the',\n",
       " 'train test',\n",
       " 'implementation data',\n",
       " '3 1',\n",
       " 'the dataset',\n",
       " '3 2',\n",
       " 'calculate the',\n",
       " 'test data',\n",
       " 'exploring the',\n",
       " 'to be',\n",
       " 'is a',\n",
       " 'question 6',\n",
       " 'of a',\n",
       " 'in a',\n",
       " 'font color',\n",
       " 'neural network',\n",
       " 'test set',\n",
       " 'data for',\n",
       " 'testing data',\n",
       " 'question 8',\n",
       " 'question 7',\n",
       " '2 3',\n",
       " 'all the',\n",
       " 'preparing the',\n",
       " 'the number',\n",
       " 'model with',\n",
       " 'with a',\n",
       " 'how to',\n",
       " 'split data',\n",
       " 'decision trees',\n",
       " 'part 3',\n",
       " 'introduction to',\n",
       " 'the results',\n",
       " 'step 2',\n",
       " 'at the',\n",
       " 'step 1',\n",
       " 'exploratory data',\n",
       " 'load data',\n",
       " 'test split',\n",
       " 'k nearest',\n",
       " 'model in',\n",
       " 'building a',\n",
       " 'data into',\n",
       " 'are the',\n",
       " 'problem 1',\n",
       " 'the training',\n",
       " 'the test',\n",
       " 'training data',\n",
       " 'regression with',\n",
       " 'use the',\n",
       " 'evaluating model',\n",
       " '2 model',\n",
       " 'build a',\n",
       " 'to a',\n",
       " 'as a',\n",
       " 'model tuning',\n",
       " 'for a',\n",
       " 'find the',\n",
       " 'function to',\n",
       " 'time series',\n",
       " '4 2',\n",
       " 'this is',\n",
       " '4 1',\n",
       " 'neural networks',\n",
       " 'data from',\n",
       " 'to predict',\n",
       " 'step 3',\n",
       " 'model application',\n",
       " 'dummy variables',\n",
       " 'layman s',\n",
       " '5 final',\n",
       " 'in layman',\n",
       " 's terms',\n",
       " 'missing values',\n",
       " 'train the',\n",
       " 'data preprocessing',\n",
       " 'nearest neighbors',\n",
       " '3 3',\n",
       " 'that the',\n",
       " 'feature engineering',\n",
       " 'model on',\n",
       " 'the distribution',\n",
       " 'pruning algorithm',\n",
       " 'vector machines',\n",
       " 'problem 2',\n",
       " 'and split',\n",
       " 'boston housing',\n",
       " 'linear model',\n",
       " 'one hot',\n",
       " 'part 4',\n",
       " 'to use',\n",
       " 'does the',\n",
       " 'to do',\n",
       " 'naive predictor',\n",
       " 'extracting feature',\n",
       " 'neurals removed',\n",
       " 'in scikit',\n",
       " 'random forests',\n",
       " 'in python',\n",
       " 'model to',\n",
       " '1 3',\n",
       " '3 choosing',\n",
       " 'table of',\n",
       " 'data to',\n",
       " 'we will',\n",
       " 'gradient descent',\n",
       " 'visualize the',\n",
       " 'train and',\n",
       " 'for this',\n",
       " 'and target',\n",
       " 'of your',\n",
       " 'what are',\n",
       " 'question 9',\n",
       " 'shuffle and',\n",
       " 'visualizing the',\n",
       " 'the first',\n",
       " 'ridge regression',\n",
       " 'creating a',\n",
       " 'model and',\n",
       " 'bias variance',\n",
       " 'we have',\n",
       " 'the most',\n",
       " 'if you',\n",
       " 'into a',\n",
       " 'you can',\n",
       " 'need to',\n",
       " 'the following',\n",
       " 'and evaluating',\n",
       " '2 4',\n",
       " 'how many',\n",
       " 'gradient boosting',\n",
       " 'the mean',\n",
       " 'to see',\n",
       " 'feature and',\n",
       " 'optimal model',\n",
       " 'question 10',\n",
       " 'discriminant analysis',\n",
       " 'to get',\n",
       " '3 4',\n",
       " 'model for',\n",
       " 'on a',\n",
       " 'check the',\n",
       " 'learning curves',\n",
       " 'into training',\n",
       " 'evaluating models',\n",
       " 'dimensionality reduction',\n",
       " 'step 4',\n",
       " 'training set',\n",
       " 'the models',\n",
       " 'of data',\n",
       " 'want to',\n",
       " 'can be',\n",
       " 'tf idf',\n",
       " 'question 11',\n",
       " 'model selection',\n",
       " 'analysis of',\n",
       " 'explore the',\n",
       " 'to find',\n",
       " 'feature columns',\n",
       " 'a function',\n",
       " '1 classification',\n",
       " 'roc curve',\n",
       " 'predict the',\n",
       " 'fold cross',\n",
       " 'performance metrics',\n",
       " 'the features',\n",
       " 'target columns',\n",
       " 'it is',\n",
       " 'a linear',\n",
       " 'bagging method',\n",
       " '4 3',\n",
       " 'a student',\n",
       " 'fitting a',\n",
       " 'part 5',\n",
       " 'set up',\n",
       " 'preprocess feature',\n",
       " 'identify feature',\n",
       " 'student intervention',\n",
       " 'in this',\n",
       " '5 1',\n",
       " 'vs regression',\n",
       " 'intervention system',\n",
       " 'the optimal',\n",
       " 'classification vs',\n",
       " 'what does',\n",
       " 'fit a',\n",
       " 'dt with',\n",
       " 'problem 3',\n",
       " 'variance tradeoff',\n",
       " 'the coefficients',\n",
       " 'a new',\n",
       " 'as the',\n",
       " '0 0',\n",
       " 'how does',\n",
       " 'a simple',\n",
       " 'out of',\n",
       " 'fit the',\n",
       " 'there is',\n",
       " 'using a',\n",
       " 'for all',\n",
       " 'means clustering',\n",
       " 'regression and',\n",
       " 'final model',\n",
       " 'color blue',\n",
       " 'tree classifier',\n",
       " 'housing prices',\n",
       " 'of contents',\n",
       " 'data in',\n",
       " 'of words',\n",
       " 'loading the',\n",
       " 'data with',\n",
       " 'will be',\n",
       " '1 sub',\n",
       " 'the logistic',\n",
       " 'guided practice',\n",
       " 'sub 1',\n",
       " 'k fold',\n",
       " '5 2',\n",
       " '4 model',\n",
       " 'data science',\n",
       " 'f sub',\n",
       " 'of our',\n",
       " 'component analysis',\n",
       " 'making predictions',\n",
       " 'the accuracy',\n",
       " 'between the',\n",
       " 'there are',\n",
       " '0 1',\n",
       " 'data split',\n",
       " 'do the',\n",
       " 'a single',\n",
       " 'our data',\n",
       " 'the two',\n",
       " 'principal component',\n",
       " 'the odds',\n",
       " '1 create',\n",
       " 'numerical features',\n",
       " 'accuracy of',\n",
       " 'epsilon greedy',\n",
       " 'of each',\n",
       " 'build the',\n",
       " 'vector machine',\n",
       " 'project 2',\n",
       " 'if we',\n",
       " 'least squares',\n",
       " 'define a',\n",
       " 'sub score',\n",
       " 'independent practice',\n",
       " 'create the',\n",
       " 'print the',\n",
       " 'to make',\n",
       " 'final f',\n",
       " 'out the',\n",
       " 'implementation training',\n",
       " 'list of',\n",
       " 'tabular results',\n",
       " 'x t',\n",
       " 'precision recall',\n",
       " 'bag of',\n",
       " 'learning models',\n",
       " 'analyzing model',\n",
       " 'classification with',\n",
       " 'predicting boston',\n",
       " 'deep learning',\n",
       " 'about the',\n",
       " '2 5',\n",
       " 'a random',\n",
       " 'load and',\n",
       " 'evaluation validation',\n",
       " 'iris dataset',\n",
       " 'training the',\n",
       " 'your data',\n",
       " 'evaluate the',\n",
       " 'color red',\n",
       " 'make a',\n",
       " 'feature relevance',\n",
       " 'a decision',\n",
       " 'compute the',\n",
       " 'the confusion',\n",
       " 'r 2',\n",
       " 'value of',\n",
       " 'can you',\n",
       " 'feature extraction',\n",
       " '1 4',\n",
       " 'a training',\n",
       " 'and y',\n",
       " 'unsupervised learning',\n",
       " 'implementation creating',\n",
       " 'tell us',\n",
       " 'for classification',\n",
       " 'and a',\n",
       " 'this notebook',\n",
       " 'compare the',\n",
       " 'metrics and',\n",
       " 'test the',\n",
       " 'we need',\n",
       " 'p value',\n",
       " 'x and',\n",
       " 'don t',\n",
       " 'data cleaning',\n",
       " 'that we',\n",
       " 'analysis and',\n",
       " 'knn model',\n",
       " 'analysis classifier',\n",
       " 'classification report',\n",
       " 'do you',\n",
       " 'up the',\n",
       " 'knn classifier',\n",
       " 'test sets',\n",
       " 'of fit',\n",
       " 'import libraries',\n",
       " 'it s',\n",
       " 'read in',\n",
       " 'data preparation',\n",
       " 'effects of',\n",
       " 'with scikit',\n",
       " 'goodness of',\n",
       " 'a 1',\n",
       " 'the naive',\n",
       " 'of all',\n",
       " '1 load',\n",
       " 'test a',\n",
       " 'the network',\n",
       " 'training a',\n",
       " 'page no',\n",
       " 'describing the',\n",
       " 'and data',\n",
       " 'difference between',\n",
       " 'split the',\n",
       " 'do we',\n",
       " 'span style',\n",
       " 'is not',\n",
       " 'of feature',\n",
       " 'now let',\n",
       " 'and predicting',\n",
       " 'p left',\n",
       " 'define the',\n",
       " 'exercise 2',\n",
       " 'this project',\n",
       " 'learning objectives',\n",
       " 'exercise 1',\n",
       " 'the roc',\n",
       " '5 3',\n",
       " 'is an',\n",
       " 'squared error',\n",
       " 'working with',\n",
       " 'learning the',\n",
       " 'method with',\n",
       " 'continuous features',\n",
       " '1 data',\n",
       " 'the top',\n",
       " 'write a',\n",
       " 'setting up',\n",
       " 'a logistic',\n",
       " 'the classification',\n",
       " '4 4',\n",
       " '3 5',\n",
       " 'mean squared',\n",
       " '1 feature',\n",
       " 'of this',\n",
       " 'plot of',\n",
       " 'we are',\n",
       " '1 5',\n",
       " 'great job',\n",
       " 'initial model',\n",
       " 'from a',\n",
       " 'read the',\n",
       " 'and save',\n",
       " 'project finding',\n",
       " '1 naive',\n",
       " 'can we',\n",
       " 'that are',\n",
       " 'tree model',\n",
       " 'to create',\n",
       " 'more than',\n",
       " 'classification and',\n",
       " 'linear svm',\n",
       " '3 training',\n",
       " 'your model',\n",
       " 'with knn',\n",
       " 'categorical features',\n",
       " 'than the',\n",
       " 'required libraries',\n",
       " 'the iris',\n",
       " 'train a',\n",
       " '6 feature',\n",
       " 'by the',\n",
       " 'an array',\n",
       " 'pre processing',\n",
       " 'style color',\n",
       " 'sum i',\n",
       " 'a name',\n",
       " 'going deeper',\n",
       " '1 n',\n",
       " 'have a',\n",
       " 'monte carlo',\n",
       " 'plotting the',\n",
       " 'scatter plot',\n",
       " '1 0',\n",
       " 'helper functions',\n",
       " 'on nn',\n",
       " 'brewing logistic',\n",
       " 'regression then',\n",
       " 'then going',\n",
       " 'x 2',\n",
       " 'the last',\n",
       " 'transforming skewed',\n",
       " 'model architecture',\n",
       " 'hot encoding',\n",
       " 'skewed continuous',\n",
       " 'normalizing numerical',\n",
       " 'and regression',\n",
       " 'model using',\n",
       " 'the required',\n",
       " 'a few',\n",
       " 'which is',\n",
       " 'linear discriminant',\n",
       " 'relevance observation',\n",
       " 'the total',\n",
       " 'all of',\n",
       " 'predicting pipeline',\n",
       " 'finding donors',\n",
       " 'donors for',\n",
       " 'for charityml',\n",
       " '7 extracting',\n",
       " 'and evaluation',\n",
       " 'missing data',\n",
       " 'optimal parameters',\n",
       " 'looking at',\n",
       " 'predictor performace',\n",
       " 'implementation initial',\n",
       " 'implementation extracting',\n",
       " '8 effects',\n",
       " 'should be',\n",
       " 'improving results',\n",
       " '4 describing',\n",
       " '4 5',\n",
       " 'as well',\n",
       " 'prepare the',\n",
       " 'of features',\n",
       " 'see if',\n",
       " 'the observations',\n",
       " 'set of',\n",
       " 'that you',\n",
       " 'evaluation metrics',\n",
       " 'de la',\n",
       " '0 5',\n",
       " 'n de',\n",
       " 'parameters for',\n",
       " 'the cross',\n",
       " 'cross validate',\n",
       " '1 x',\n",
       " 'on testing',\n",
       " 'project 1',\n",
       " 'i 1',\n",
       " 'x 1',\n",
       " 'the null',\n",
       " 'the difference',\n",
       " 'x y',\n",
       " 'try to',\n",
       " 'problem statement',\n",
       " 'the problem',\n",
       " 'categorical variables',\n",
       " 'that is',\n",
       " 'the neural',\n",
       " 'parameters and',\n",
       " 'the result',\n",
       " 'ada boost',\n",
       " 'run the',\n",
       " 'if the',\n",
       " 'validation and',\n",
       " 'models on',\n",
       " 'the above',\n",
       " 'take a',\n",
       " 'evaluating the',\n",
       " 'use a',\n",
       " 'and plot',\n",
       " 'features and',\n",
       " 'the or',\n",
       " 'regression to',\n",
       " 'regression trees',\n",
       " 'null hypothesis',\n",
       " 'the code',\n",
       " 'example of',\n",
       " 't 1',\n",
       " 'sum of',\n",
       " 'you have',\n",
       " 'linear algebra',\n",
       " 'a good',\n",
       " 'describe the',\n",
       " 'relationship between',\n",
       " 'part a',\n",
       " 'svm classifier',\n",
       " 'fully connected',\n",
       " 'the class',\n",
       " 'performance metric',\n",
       " 'numpy arrays',\n",
       " 'developing a',\n",
       " 'test model',\n",
       " 'into the',\n",
       " 'in our',\n",
       " 'with python',\n",
       " '5 bias',\n",
       " 'x i',\n",
       " 'a performance',\n",
       " 'variables for',\n",
       " 'the decision',\n",
       " 'a id',\n",
       " 'how the',\n",
       " '4 learning',\n",
       " 'a dataframe',\n",
       " 'your own',\n",
       " 'change the',\n",
       " 'is to',\n",
       " 'sentiment analysis',\n",
       " 'what do',\n",
       " 'part b',\n",
       " '8 cross',\n",
       " 'by odor',\n",
       " 'now we',\n",
       " 'best parameters',\n",
       " 'data wrangling',\n",
       " 'types of',\n",
       " 'best guess',\n",
       " 'complexity curves',\n",
       " 'feature observation',\n",
       " 'predicting selling',\n",
       " 'selling prices',\n",
       " 'our model',\n",
       " 'calculate statistics',\n",
       " '7 grid',\n",
       " 'the other',\n",
       " 'summary of',\n",
       " 'a list',\n",
       " 'guess optimal',\n",
       " 'exploratory analysis',\n",
       " 'hypothesis testing',\n",
       " 'implementation calculate',\n",
       " 'implementation shuffle',\n",
       " '6 best',\n",
       " 'implementation define',\n",
       " '2 goodness',\n",
       " '9 optimal',\n",
       " 'the variables',\n",
       " '10 predicting',\n",
       " 'how do',\n",
       " 'data is',\n",
       " 'implementation fitting',\n",
       " '11 applicability',\n",
       " 'and validation',\n",
       " 'standard deviation',\n",
       " 'effect of',\n",
       " 'i e',\n",
       " 'see how',\n",
       " 'collaborative filtering',\n",
       " 'regression using',\n",
       " 'non linear',\n",
       " 'to calculate',\n",
       " 'the classifier',\n",
       " 'on test',\n",
       " 'and max',\n",
       " 'linear models',\n",
       " 'does this',\n",
       " '2 building',\n",
       " 'scipy org',\n",
       " 'a href',\n",
       " 'for plotting',\n",
       " 'exercise 3',\n",
       " 'going to',\n",
       " 'cifar 10',\n",
       " 'intro to',\n",
       " 'forest classifier',\n",
       " 'we ll',\n",
       " 'have the',\n",
       " 'with gini',\n",
       " 'in your',\n",
       " 'example 1',\n",
       " 'train on',\n",
       " 'set the',\n",
       " 'question 12',\n",
       " 'beta 0',\n",
       " 'we want',\n",
       " 'be used',\n",
       " 'information gain',\n",
       " 'with dt',\n",
       " 'so we',\n",
       " 'org doc',\n",
       " 'c5 0',\n",
       " 'instead of',\n",
       " 'gini cart',\n",
       " 'cost function',\n",
       " 'lasso regression',\n",
       " 'docs scipy',\n",
       " '3 data',\n",
       " 'does it',\n",
       " 'can see',\n",
       " 'the original',\n",
       " 'the feature',\n",
       " 'import the',\n",
       " 'roc curves',\n",
       " 'back to',\n",
       " 'median income',\n",
       " 'iris data',\n",
       " 'normal distribution',\n",
       " 'the image',\n",
       " 'bayes classifier',\n",
       " 'p values',\n",
       " 'example 2',\n",
       " '1 predicting',\n",
       " 'convolutional neural',\n",
       " 'examine the',\n",
       " 'make predictions',\n",
       " 'left x',\n",
       " 't test',\n",
       " 'cross val',\n",
       " 'model is',\n",
       " 'ipython notebook',\n",
       " 'parameter tuning',\n",
       " 'interpret the',\n",
       " 'the regression',\n",
       " 'part 6',\n",
       " 'odds ratios',\n",
       " '6 1',\n",
       " 'testing sets',\n",
       " 'will use',\n",
       " 'image classification',\n",
       " 'to train',\n",
       " 'the performance',\n",
       " 'test and',\n",
       " 'test for',\n",
       " 'visualization of',\n",
       " 'getting the',\n",
       " 'using sklearn',\n",
       " 'function for',\n",
       " 'see the',\n",
       " '1 a',\n",
       " 'have to',\n",
       " 'connected layer',\n",
       " '2 6',\n",
       " 'functions to',\n",
       " 'the target',\n",
       " 'what happens',\n",
       " 'this model',\n",
       " '15 mins',\n",
       " 'did you',\n",
       " 'predictions and',\n",
       " 'step 5',\n",
       " 'and their',\n",
       " 'feature scaling',\n",
       " 'save the',\n",
       " 'a look',\n",
       " 'the input',\n",
       " 'how can',\n",
       " 'and train',\n",
       " 'the time',\n",
       " 'hot encode',\n",
       " 'data sets',\n",
       " 'train data',\n",
       " 'matrix and',\n",
       " 'and model',\n",
       " 'correlation matrix',\n",
       " 'mean and',\n",
       " 'the average',\n",
       " 'data mining',\n",
       " 'statistical analysis',\n",
       " 'functions for',\n",
       " 'validation set',\n",
       " 'is it',\n",
       " 'values of',\n",
       " 'task 1',\n",
       " 'the output',\n",
       " 'learning rate',\n",
       " 'right p',\n",
       " 'forest model',\n",
       " 'each of',\n",
       " 'the images',\n",
       " '2 data',\n",
       " 'performance of',\n",
       " 'problem 4',\n",
       " 'way to',\n",
       " 'in sklearn',\n",
       " 'finding the',\n",
       " 'f1 score',\n",
       " 'can use',\n",
       " 'we use',\n",
       " 'what s',\n",
       " 'percentage of',\n",
       " 'features from',\n",
       " 'to plot',\n",
       " 'in each',\n",
       " '1 introduction',\n",
       " 'data using',\n",
       " 'a b',\n",
       " 's look',\n",
       " 'did not',\n",
       " 'part of',\n",
       " 'amazonaws com',\n",
       " 'features for',\n",
       " 'set and',\n",
       " 'with other',\n",
       " 's3 amazonaws',\n",
       " 'housing data',\n",
       " 'regression analysis',\n",
       " 'and then',\n",
       " 'nearest neighbor',\n",
       " 'predictions on',\n",
       " 'https ga',\n",
       " 'ga dash',\n",
       " 'dash s3',\n",
       " 'com production',\n",
       " 'production assets',\n",
       " 'assets logo',\n",
       " 'logo 9f88ae6c9c3871690e33280fcf557f33',\n",
       " '9f88ae6c9c3871690e33280fcf557f33 png',\n",
       " 'you want',\n",
       " '1 import',\n",
       " 'and cross',\n",
       " 'http scikit',\n",
       " 'simple linear',\n",
       " 'quadratic discriminant',\n",
       " 't sne',\n",
       " 'the random',\n",
       " 'citibike data',\n",
       " 'correlation between',\n",
       " 'mean of',\n",
       " 'learn org',\n",
       " 'import data',\n",
       " 'metrics for',\n",
       " 'your results',\n",
       " 'test on',\n",
       " 'load in',\n",
       " 'spatial autocorrelation',\n",
       " 'the parameters',\n",
       " 'of linear',\n",
       " '6 2',\n",
       " 'data frame',\n",
       " '3 6',\n",
       " 'visulize the',\n",
       " 'at least',\n",
       " 'comparison of',\n",
       " 'an example',\n",
       " 'with keras',\n",
       " '1 use',\n",
       " 'get a',\n",
       " 'on your',\n",
       " '10 fold',\n",
       " 'the information',\n",
       " 'project predicting',\n",
       " 'loading data',\n",
       " 'values in',\n",
       " 'the correlation',\n",
       " 'odds of',\n",
       " '2 a',\n",
       " 'in data',\n",
       " 'csv file',\n",
       " 'most important',\n",
       " 'your findings',\n",
       " 'digits data',\n",
       " 'sample data',\n",
       " 'learning activity',\n",
       " 'histogram of',\n",
       " 'it to',\n",
       " 'frac 1',\n",
       " 'e g',\n",
       " 'building the',\n",
       " 'n estimators',\n",
       " 'perform a',\n",
       " 'you will',\n",
       " 'task 2',\n",
       " '5 6',\n",
       " 'save it',\n",
       " 'kernel rbf',\n",
       " 'a regression',\n",
       " 'for our',\n",
       " 'the monthly',\n",
       " 'write this',\n",
       " 'this finding',\n",
       " 'project 3',\n",
       " 'cross tab',\n",
       " 'data points',\n",
       " 'scatter plots',\n",
       " 'topic modeling',\n",
       " '2 exploratory',\n",
       " 'for regression',\n",
       " 'model prediction',\n",
       " 'prepare data',\n",
       " 'finding in',\n",
       " 'or of',\n",
       " 'of determination',\n",
       " 'n 1',\n",
       " 'model 2',\n",
       " 'for prestige',\n",
       " '1 ranked',\n",
       " '2 sup',\n",
       " 'do this',\n",
       " 'org stable',\n",
       " 'sup 2',\n",
       " 'ranked college',\n",
       " 'do not',\n",
       " 'the us',\n",
       " 'github com',\n",
       " 'data visualization',\n",
       " 'through the',\n",
       " 'used for',\n",
       " 'how well',\n",
       " 'monthly rides',\n",
       " 'max depth',\n",
       " 'train model',\n",
       " 'of k',\n",
       " 'make the',\n",
       " 'for data',\n",
       " 'with sklearn',\n",
       " 'output layer',\n",
       " 'text classification',\n",
       " 'are not',\n",
       " 'feature importances',\n",
       " 'numpy and',\n",
       " 'regression on',\n",
       " 'model 1',\n",
       " 'and variance',\n",
       " 'using scikit',\n",
       " 'max pooling',\n",
       " 'to data',\n",
       " 'decsion tree',\n",
       " 'over the',\n",
       " 'principal components',\n",
       " 'r sup',\n",
       " 'read data',\n",
       " 'reading in',\n",
       " 'building classifiers',\n",
       " 'donn es',\n",
       " 'search for',\n",
       " 'accuracy score',\n",
       " 'has a',\n",
       " 'add a',\n",
       " 'bayes methods',\n",
       " 'evaluation of',\n",
       " 'thompson sampling',\n",
       " 'create dummy',\n",
       " 'of these',\n",
       " 'selection and',\n",
       " 's try',\n",
       " 'networks classifier',\n",
       " 'features to',\n",
       " 'x n',\n",
       " 'the new',\n",
       " 'the sample',\n",
       " 'the function',\n",
       " 'with kernel',\n",
       " 'description of',\n",
       " 'the text',\n",
       " 'flatten layer',\n",
       " 'the prediction',\n",
       " 'model the',\n",
       " 's see',\n",
       " 'or not',\n",
       " 'svm svc',\n",
       " 'from sklearn',\n",
       " 'function that',\n",
       " 'some of',\n",
       " 'stochastic gradient',\n",
       " 'y i',\n",
       " 'convolution and',\n",
       " 'https www',\n",
       " 'dealing with',\n",
       " '0 2',\n",
       " 'pooling layer',\n",
       " 'well as',\n",
       " 'polynomial regression',\n",
       " 's test',\n",
       " 'used to',\n",
       " 'fraction of',\n",
       " 'according to',\n",
       " 'with entropy',\n",
       " 'final project',\n",
       " '4 6',\n",
       " 'the standard',\n",
       " 'to determine',\n",
       " 'important features',\n",
       " 'gini impurity',\n",
       " 'python libraries',\n",
       " 'to test',\n",
       " 'using python',\n",
       " 'open source',\n",
       " 'x train',\n",
       " 'dataset and',\n",
       " 'we re',\n",
       " 'numpy array',\n",
       " '5 mins',\n",
       " 'score for',\n",
       " 'hierarchical clustering',\n",
       " 'function of',\n",
       " 'greedy pruning',\n",
       " 'would be',\n",
       " 'when you',\n",
       " '3 a',\n",
       " '1 and',\n",
       " 'due to',\n",
       " 'for training',\n",
       " 'regression in',\n",
       " 'loss function',\n",
       " 'a a',\n",
       " 'a classifier',\n",
       " 'the notebook',\n",
       " 'the final',\n",
       " 'some data',\n",
       " 'bar x',\n",
       " 'you do',\n",
       " 'check point',\n",
       " 'convolutional model',\n",
       " 'show the',\n",
       " 'the value',\n",
       " 's the',\n",
       " 'and predict',\n",
       " 'compare to',\n",
       " 'part c',\n",
       " 'the predicted',\n",
       " 'http docs',\n",
       " 'doc scipy',\n",
       " 'models for',\n",
       " 'probability of',\n",
       " 'frac p',\n",
       " 'on all',\n",
       " 'computing the',\n",
       " 'c4 5',\n",
       " 'be a',\n",
       " 'models with',\n",
       " 'svc with',\n",
       " 'are there',\n",
       " ...]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bi_gram_counter.keys(), key=lambda x: -bi_gram_counter[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 8039/162610 [00:00<00:03, 40283.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Validation\n",
      " Training And Testing\n",
      " Training and Testing\n",
      " Training and testing\n",
      " Training and testing\n",
      " Training and evaluation\n",
      " Training and Prediction\n",
      " Training and evaluation\n",
      " Training and Prediction\n",
      " Training and Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20019/162610 [00:00<00:03, 39886.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Validation\n",
      " Training and Testing\n",
      " Training and Predicting\n",
      " Training and testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27931/162610 [00:00<00:03, 39758.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Validation\n",
      " training and testing \n",
      " Training and evaluation\n",
      " Training and predictions\n",
      " Training and prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 39848/162610 [00:01<00:03, 39913.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and predictions\n",
      " Training and Testing\n",
      " Training and testing\n",
      " Training and Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 52005/162610 [00:01<00:02, 39215.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Predicting\n",
      " Training and evaluation\n",
      " Training and Validation\n",
      " Training And Testing\n",
      " Training and Predicting\n",
      " Training and Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 64020/162610 [00:01<00:02, 39462.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Predicting\n",
      " Training and testing\n",
      " Training and Testing\n",
      " Training and Evatuation\n",
      " Training and predictions\n",
      " Training and Prediction\n",
      " Training and Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 75900/162610 [00:01<00:02, 39369.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Validation\n",
      " training and testing \n",
      " Training and Predicting\n",
      " Training and testing\n",
      " Training And Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 83824/162610 [00:02<00:02, 39223.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and prediction\n",
      " Training and prediction\n",
      " Training and prediction\n",
      " Training and evaluation\n",
      " Training and Validation\n",
      " Training and Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 91851/162610 [00:02<00:01, 39095.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Evaluation\n",
      " Training and Testing\n",
      " Training and Prediction\n",
      " Training and testing\n",
      " Training and Testing\n",
      " Training and Prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 104089/162610 [00:02<00:01, 40243.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and validation\n",
      " Training and Testing\n",
      " Training and testing\n",
      " Training and Prediction\n",
      " Training and Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 112377/162610 [00:02<00:01, 40741.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Testing\n",
      " Training and evaluation\n",
      " Training and evaluation\n",
      " Training and predictions\n",
      " Training and testing\n",
      " Training and Testing\n",
      " Training and Validation\n",
      " Training and Predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 120512/162610 [00:03<00:01, 40008.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and evaluation\n",
      " Training and predictions\n",
      " Training and Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 132738/162610 [00:03<00:00, 40108.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Evaluation\n",
      " Training and evaluation\n",
      " Training and testing\n",
      " Training and Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 144790/162610 [00:03<00:00, 39657.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and optimizing\n",
      " Training And Testing\n",
      " Training and Validation\n",
      " Training and Testing\n",
      " Training and Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 152841/162610 [00:03<00:00, 39991.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and testing\n",
      " Training and evaluation\n",
      " Training and Testing\n",
      " Training and testing\n",
      " Training and Validation\n",
      " Training and evaluation\n",
      " Training and Validation\n",
      " Training and Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162610/162610 [00:04<00:00, 39735.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training and Testing\n",
      " Training and testing\n",
      " training and testing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for py in tqdm(header):\n",
    "    for h in header[py][\"header_lines\"]:\n",
    "        grams = [t.lower() for t in h.split() if t]\n",
    "        bi_grams = ['{} {}'.format(t, grams[i+1]) for i, t in enumerate(grams[:-1])]\n",
    "#         if \n",
    "        if 'training and' in bi_grams and len(grams) <= 3:\n",
    "            print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if Markdown is right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "with open('./graphs/cell_with_func_python23_1_12.txt','r') as f:\n",
    "    for l in f:\n",
    "        graphs.append(json.loads(l))\n",
    "        if len(graphs)==200000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      " Setup and Data\n",
      "--------------------\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from statsmodels.sandbox.regression import gmm\n",
      "\n",
      "dta = pd.read_csv('consumption.csv')\n",
      "\n",
      "dta.iloc[:5]\n",
      "\n",
      "====================\n",
      " subplots\n",
      "--------------------\n",
      "\n",
      "(fig, ax) = plt.subplots(2, 3)\n",
      "\n",
      "fig.tight_layout()\n",
      "\n",
      "====================\n",
      " gridspec\n",
      "--------------------\n",
      "\n",
      "import matplotlib.gridspec as gridspec\n",
      "\n",
      "====================\n",
      " pcolor\n",
      "--------------------\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "p = ax.pcolor((X / (2 * np.pi)), (Y / (2 * np.pi)), Z, cmap=matplotlib.cm.RdBu, vmin=abs(Z).min(), vmax=abs(Z).max())\n",
      "\n",
      "cb = fig.colorbar(p, ax=ax)\n",
      "\n",
      "====================\n",
      " imshow\n",
      "--------------------\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "im = ax.imshow(Z, cmap=matplotlib.cm.RdBu, vmin=abs(Z).min(), vmax=abs(Z).max(), extent=[0, 1, 0, 1])\n",
      "\n",
      "im.set_interpolation('bilinear')\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "\n",
      "====================\n",
      " contour\n",
      "--------------------\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "cnt = ax.contour(Z, cmap=matplotlib.cm.RdBu, vmin=abs(Z).min(), vmax=abs(Z).max(), extent=[0, 1, 0, 1])\n",
      "\n",
      "====================\n",
      " Wire frame plot\n",
      "--------------------\n",
      "\n",
      "fig = plt.figure(figsize=(8, 6))\n",
      "\n",
      "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
      "\n",
      "p = ax.plot_wireframe(X, Y, Z, rstride=4, cstride=4)\n",
      "\n",
      "====================\n",
      " Generating SVG with the svg backend\n",
      "--------------------\n",
      "\n",
      "import matplotlib\n",
      "\n",
      "matplotlib.use('svg')\n",
      "\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import numpy\n",
      "\n",
      "from IPython.display import Image, SVG\n",
      "\n",
      "====================\n",
      " Interactive backend this makes more sense in a python script file \n",
      "--------------------\n",
      "\n",
      "import matplotlib\n",
      "\n",
      "matplotlib.use('Qt4Agg')\n",
      "\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "====================\n",
      " Load Libraries and Create Function\n",
      "--------------------\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "====================\n",
      " Feature Extraction from Natural Language Libraries\n",
      "--------------------\n",
      "\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "\n",
      "hv = HashingVectorizer(n_features=(2 ** 17), non_negative=True)\n",
      "\n",
      "X_hv = hv.fit_transform(amazon.Text)\n",
      "\n",
      "print(X_hv.shape)\n",
      "\n",
      "====================\n",
      " Create Models\n",
      "--------------------\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "svm = linear_model.SGDClassifier()\n",
      "\n",
      "svm.fit(X, y)\n",
      "\n",
      "joblib.dump(svm, 'svm.pkl')\n",
      "\n",
      "svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
      "\n",
      "svm_performance.compute_measures()\n",
      "\n",
      "print(svm_performance.performance_measures)\n",
      "\n",
      "====================\n",
      " d 2\n",
      "--------------------\n",
      "\n",
      "validate(zeroed_R, train_R, 2)\n",
      "\n",
      "====================\n",
      " d 5\n",
      "--------------------\n",
      "\n",
      "validate(zeroed_R, train_R, 5)\n",
      "\n",
      "====================\n",
      " d 10\n",
      "--------------------\n",
      "\n",
      "validate(zeroed_R, train_R, 10)\n",
      "\n",
      "====================\n",
      " d 20\n",
      "--------------------\n",
      "\n",
      "validate(zeroed_R, train_R, 20)\n",
      "\n",
      "====================\n",
      " d 2\n",
      "--------------------\n",
      "\n",
      "d = 2\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U2, X2) = new_update(zeroed_R, alpha=1.5, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "====================\n",
      " d 5\n",
      "--------------------\n",
      "\n",
      "d = 5\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U5, X5) = new_update(zeroed_R, alpha=1, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "====================\n",
      " d 10\n",
      "--------------------\n",
      "\n",
      "d = 10\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U10, V10) = new_update(zeroed_R, alpha=1, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "====================\n",
      " d 20\n",
      "--------------------\n",
      "\n",
      "d = 20\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U20, V20) = new_update(zeroed_R, alpha=1, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "====================\n",
      " d 50\n",
      "--------------------\n",
      "\n",
      "d = 50\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U50, V50) = new_update(zeroed_R, alpha=2, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "====================\n",
      " Bagging Ensembles \n",
      "--------------------\n",
      "\n",
      "from sklearn.ensemble import BaggingClassifier\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=(- 1), random_state=42)\n",
      "\n",
      "bag_clf.fit(X_train, y_train)\n",
      "\n",
      "y_pred = bag_clf.predict(X_test)\n",
      "\n",
      "====================\n",
      " RandomForests \n",
      "--------------------\n",
      "\n",
      "bag_clf = BaggingClassifier(DecisionTreeClassifier(splitter='random', max_leaf_nodes=16, random_state=42), n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=(- 1), random_state=42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for g in graphs[:200]:\n",
    "    if g[\"header\"]!='':\n",
    "        print('='*20)\n",
    "        print(g[\"header\"])\n",
    "        print('-'*20)\n",
    "        print(g[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_lineno': 24,\n",
       " 'file': '/projects/bdata/jupyter/target/nb_464081.py',\n",
       " 'context': \"\\nimport numpy as np\\n\\nimport pandas as pd\\n\\nfrom statsmodels.sandbox.regression import gmm\\n\\ndta = pd.read_csv('consumption.csv')\\n\\ndta.iloc[:5]\\n\",\n",
       " 'target_func': 'none_func',\n",
       " 'nodes': [{'type': 'Module', 'children': [1, 4, 7, 9, 16]},\n",
       "  {'type': 'Import', 'children': [2]},\n",
       "  {'type': 'alias', 'value': 'numpy', 'children': [3]},\n",
       "  {'type': 'identifier', 'value': 'np'},\n",
       "  {'type': 'Import', 'children': [5]},\n",
       "  {'type': 'alias', 'value': 'pandas', 'children': [6]},\n",
       "  {'type': 'identifier', 'value': 'pd'},\n",
       "  {'type': 'ImportFrom',\n",
       "   'value': 'statsmodels.sandbox.regression',\n",
       "   'children': [8]},\n",
       "  {'type': 'alias', 'value': 'gmm'},\n",
       "  {'type': 'Assign', 'children': [10, 11]},\n",
       "  {'type': 'NameStore', 'value': 'dta'},\n",
       "  {'type': 'Call', 'children': [12, 15]},\n",
       "  {'type': 'AttributeLoad', 'children': [13, 14]},\n",
       "  {'type': 'NameLoad', 'value': 'pd'},\n",
       "  {'type': 'attr', 'value': 'read_csv'},\n",
       "  {'type': 'Str', 'value': 'consumption.csv'},\n",
       "  {'type': 'Expr', 'children': [17]},\n",
       "  {'type': 'SubscriptLoad', 'children': [18, 21]},\n",
       "  {'type': 'AttributeLoad', 'children': [19, 20]},\n",
       "  {'type': 'NameLoad', 'value': 'dta'},\n",
       "  {'type': 'attr', 'value': 'iloc'},\n",
       "  {'type': 'Slice', 'children': [22]},\n",
       "  {'type': 'Num', 'value': '5'}],\n",
       " 'funcs': ['pandas.read_csv'],\n",
       " 'neighbor_cells': [-1],\n",
       " 'id': 0,\n",
       " 'header': ' Setup and Data'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare python2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1345388it [01:32, 14615.33it/s]\n"
     ]
    }
   ],
   "source": [
    "python3_graphs = []\n",
    "with open('./graphs/temp_cell_with_func_unsupervised.txt','r') as f:\n",
    "    for l in tqdm(f):\n",
    "        python3_graphs.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1345388/1345388 [00:01<00:00, 1016435.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0973458957564658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "headers = []\n",
    "contexts = []\n",
    "for g in tqdm(python3_graphs):\n",
    "    if g[\"header\"]!=\"\":\n",
    "        headers.append(g[\"header\"])\n",
    "        contexts.append(g[\"context\"])\n",
    "        counter+=1\n",
    "#         print('-'*20)\n",
    "#         print(g[\"header\"])\n",
    "print(counter/len(python3_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      " Setup and Data\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from statsmodels.sandbox.regression import gmm\n",
      "\n",
      "dta = pd.read_csv('consumption.csv')\n",
      "\n",
      "dta.iloc[:5]\n",
      "\n",
      "--------------------\n",
      " subplots\n",
      "\n",
      "(fig, ax) = plt.subplots(2, 3)\n",
      "\n",
      "fig.tight_layout()\n",
      "\n",
      "--------------------\n",
      " gridspec\n",
      "\n",
      "import matplotlib.gridspec as gridspec\n",
      "\n",
      "--------------------\n",
      " pcolor\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "p = ax.pcolor((X / (2 * np.pi)), (Y / (2 * np.pi)), Z, cmap=matplotlib.cm.RdBu, vmin=abs(Z).min(), vmax=abs(Z).max())\n",
      "\n",
      "cb = fig.colorbar(p, ax=ax)\n",
      "\n",
      "--------------------\n",
      " imshow\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "im = ax.imshow(Z, cmap=matplotlib.cm.RdBu, vmin=abs(Z).min(), vmax=abs(Z).max(), extent=[0, 1, 0, 1])\n",
      "\n",
      "im.set_interpolation('bilinear')\n",
      "\n",
      "cb = fig.colorbar(im, ax=ax)\n",
      "\n",
      "--------------------\n",
      " contour\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "cnt = ax.contour(Z, cmap=matplotlib.cm.RdBu, vmin=abs(Z).min(), vmax=abs(Z).max(), extent=[0, 1, 0, 1])\n",
      "\n",
      "--------------------\n",
      " Wire frame plot\n",
      "\n",
      "fig = plt.figure(figsize=(8, 6))\n",
      "\n",
      "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
      "\n",
      "p = ax.plot_wireframe(X, Y, Z, rstride=4, cstride=4)\n",
      "\n",
      "--------------------\n",
      " Generating SVG with the svg backend\n",
      "\n",
      "import matplotlib\n",
      "\n",
      "matplotlib.use('svg')\n",
      "\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import numpy\n",
      "\n",
      "from IPython.display import Image, SVG\n",
      "\n",
      "--------------------\n",
      " Interactive backend this makes more sense in a python script file \n",
      "\n",
      "import matplotlib\n",
      "\n",
      "matplotlib.use('Qt4Agg')\n",
      "\n",
      "import matplotlib.pylab as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Load Libraries and Create Function\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Feature Extraction from Natural Language Libraries\n",
      "\n",
      "from sklearn.feature_extraction.text import HashingVectorizer\n",
      "\n",
      "hv = HashingVectorizer(n_features=(2 ** 17), non_negative=True)\n",
      "\n",
      "X_hv = hv.fit_transform(amazon.Text)\n",
      "\n",
      "print(X_hv.shape)\n",
      "\n",
      "--------------------\n",
      " Create Models\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "svm = linear_model.SGDClassifier()\n",
      "\n",
      "svm.fit(X, y)\n",
      "\n",
      "joblib.dump(svm, 'svm.pkl')\n",
      "\n",
      "svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
      "\n",
      "svm_performance.compute_measures()\n",
      "\n",
      "print(svm_performance.performance_measures)\n",
      "\n",
      "--------------------\n",
      " d 2\n",
      "\n",
      "validate(zeroed_R, train_R, 2)\n",
      "\n",
      "--------------------\n",
      " d 5\n",
      "\n",
      "validate(zeroed_R, train_R, 5)\n",
      "\n",
      "--------------------\n",
      " d 10\n",
      "\n",
      "validate(zeroed_R, train_R, 10)\n",
      "\n",
      "--------------------\n",
      " d 20\n",
      "\n",
      "validate(zeroed_R, train_R, 20)\n",
      "\n",
      "--------------------\n",
      " d 2\n",
      "\n",
      "d = 2\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U2, X2) = new_update(zeroed_R, alpha=1.5, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "--------------------\n",
      " d 5\n",
      "\n",
      "d = 5\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U5, X5) = new_update(zeroed_R, alpha=1, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "--------------------\n",
      " d 10\n",
      "\n",
      "d = 10\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U10, V10) = new_update(zeroed_R, alpha=1, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "--------------------\n",
      " d 20\n",
      "\n",
      "d = 20\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U20, V20) = new_update(zeroed_R, alpha=1, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "--------------------\n",
      " d 50\n",
      "\n",
      "d = 50\n",
      "\n",
      "(U, V) = train_svd(zeroed_R, d)\n",
      "\n",
      "(U50, V50) = new_update(zeroed_R, alpha=2, max_iter=100, dim=d, svd_U=U, svd_V=V)\n",
      "\n",
      "--------------------\n",
      " Bagging Ensembles \n",
      "\n",
      "from sklearn.ensemble import BaggingClassifier\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=500, max_samples=100, bootstrap=True, n_jobs=(- 1), random_state=42)\n",
      "\n",
      "bag_clf.fit(X_train, y_train)\n",
      "\n",
      "y_pred = bag_clf.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " RandomForests \n",
      "\n",
      "bag_clf = BaggingClassifier(DecisionTreeClassifier(splitter='random', max_leaf_nodes=16, random_state=42), n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=(- 1), random_state=42)\n",
      "\n",
      "--------------------\n",
      " Classification Reports \n",
      "\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "rf_pred_train = rf_maxd.predict(X_train)\n",
      "\n",
      "target_names = ['Class_No', 'Class_Yes']\n",
      "\n",
      "print(classification_report(y_train, rf_pred_train, target_names=target_names))\n",
      "\n",
      "--------------------\n",
      " Rerun model with only features of relative importance \n",
      "\n",
      "feature_selection = X[('duration_mins', 'nr_employed', 'euribor3m', 'emp_var_rate', 'pdays', 'strat')]\n",
      "\n",
      "--------------------\n",
      " Write here\n",
      "\n",
      "data_90 = pd.read_csv('/Users/shayneufeld/GitHub/mouse_bandit/data/processed_data/hmm_matrix_full_9010.csv', index_col=0)\n",
      "\n",
      "data_80 = pd.read_csv('/Users/shayneufeld/GitHub/mouse_bandit/data/processed_data/hmm_matrix_full_8020.csv', index_col=0)\n",
      "\n",
      "data_70 = pd.read_csv('/Users/shayneufeld/GitHub/mouse_bandit/data/processed_data/hmm_matrix_full_7030.csv', index_col=0)\n",
      "\n",
      "datas = [data_70, data_80, data_90]\n",
      "\n",
      "models = []\n",
      "\n",
      "--------------------\n",
      " Test number of parameters model flexibility vs BIC\n",
      "\n",
      "stats.head(2)\n",
      "\n",
      "--------------------\n",
      " 1 Train on 90 10 test on 80 20 and 70 30\n",
      "\n",
      "for (i, d) in enumerate([data_90, data_80, data_70]):\n",
      "    if (i == 0):\n",
      "        (model, stats, coefs) = logreg_and_eval(d)\n",
      "    else:\n",
      "        (model, stats_curr, coefs_curr) = logreg_and_eval(data_90, test_data=d)\n",
      "        stats = stats.append(stats_curr)\n",
      "        coefs = coefs.append(coefs_curr)\n",
      "\n",
      "stats_90 = stats.drop(['BIC', 'negative loglikelihood', 'pseudo-R2'], axis=1)\n",
      "\n",
      "--------------------\n",
      " 1 Import Packages and Data \n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from scipy import stats\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "import matplotlib\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "plt.style.use('fivethirtyeight')\n",
      "\n",
      "import warnings\n",
      "\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "pd.options.display.max_columns = 100\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "get_ipython().magic(\"config InlineBackend.figure_format = 'retina'\")\n",
      "\n",
      "--------------------\n",
      " Scatterplots \n",
      "\n",
      "sns.pairplot(df.loc[:, 'Fresh':'Delicassen'])\n",
      "\n",
      "--------------------\n",
      " Looking at Correlations \n",
      "\n",
      "correlations = df.loc[:, 'Fresh':'Delicassen'].corr()\n",
      "\n",
      "--------------------\n",
      " Slicing based on Channel Name \n",
      "\n",
      "sns.pairplot(df[['Fresh', 'Milk', 'Delicassen', 'Grocery', 'channel_name', 'Detergents_Paper']], hue='channel_name')\n",
      "\n",
      "--------------------\n",
      " Visualizing the Clusters \n",
      "\n",
      "sns.pairplot(X, hue='clusters')\n",
      "\n",
      "--------------------\n",
      " We can also play around with the number of clusters let s try only 2 \n",
      "\n",
      "X = df.loc[:, 'Fresh':'Delicassen']\n",
      "\n",
      "kmeans = make_pipeline(MinMaxScaler(), KMeans(n_clusters=2, random_state=4))\n",
      "\n",
      "kmeans.fit(X)\n",
      "\n",
      "X['clusters'] = kmeans.named_steps['kmeans'].labels_\n",
      "\n",
      "--------------------\n",
      " Machine Learning Models Cheat Sheet\n",
      "\n",
      "from IPython.display import Image\n",
      "\n",
      "Image('http://scikit-learn.org/dev/_static/ml_map.png', width=800)\n",
      "\n",
      "--------------------\n",
      " Introduction Iris Dataset\n",
      "\n",
      "from sklearn.datasets import load_iris\n",
      "\n",
      "iris = load_iris()\n",
      "\n",
      "(n_samples, n_features) = iris.data.shape\n",
      "\n",
      "print(iris.keys())\n",
      "\n",
      "print((n_samples, n_features))\n",
      "\n",
      "print(iris.data.shape)\n",
      "\n",
      "print(iris.target.shape)\n",
      "\n",
      "print(iris.target_names)\n",
      "\n",
      "print(iris.feature_names)\n",
      "\n",
      "--------------------\n",
      " 1 Load the iris dataset and create a holdout set that is 50 of the data 50 in training and 50 in test Output the results don t worry about creating the tree visual unless you d like to and discuss them briefly are they good or not \n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " 2 Redo the model with a 75 25 training test split and compare the results Are they better or worse than before Discuss why this may be \n",
      "\n",
      "(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size=0.75, train_size=0.25)\n",
      "\n",
      "--------------------\n",
      " 4 Using the breast cancer data create a classifier to predict the type of seed Perform the above hold out evaluation 50 50 and 75 25 and discuss the results \n",
      "\n",
      "(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size=0.25, train_size=0.75)\n",
      "\n",
      "--------------------\n",
      " Create Time Axis for Measured Mauna Loa CO2 Trend\n",
      "\n",
      "data = filtered_mmlo.mmlo_filtered\n",
      "\n",
      "dt = (data.index[(- 1)] - data.index[0])\n",
      "\n",
      "dt = dt.total_seconds()\n",
      "\n",
      "fs = get_fs(t=m_sec())\n",
      "\n",
      "t = np.arange(0, dt, (1 / fs))\n",
      "\n",
      "--------------------\n",
      " Create Table with Filtered Mauna Loa FFT Peak Properties\n",
      "\n",
      "peaks = fft_peaks_merged_all.loc[['mmlo_filtered_0-2_yr', 'mmlo_filtered_2-3_yr', 'mmlo_filtered_3-4_yr', 'mmlo_filtered_4-6_yr']]\n",
      "\n",
      "peaks.drop(['bin', 'bins_total', 'mag_norm', 'amp_norm', 'pha_norm', 'freq'], axis=1)\n",
      "\n",
      "--------------------\n",
      " Get Single Peak Properties of Filtered Mauna Loa FFT Results for a certain Range of Time Periods \n",
      "\n",
      "peak_f1 = fft_peaks_merged_all.loc['mmlo_filtered_0-2_yr']\n",
      "\n",
      "peak_f2 = fft_peaks_merged_all.loc['mmlo_filtered_2-3_yr']\n",
      "\n",
      "peak_f3 = fft_peaks_merged_all.loc['mmlo_filtered_3-4_yr']\n",
      "\n",
      "peak_f4 = fft_peaks_merged_all.loc['mmlo_filtered_4-6_yr']\n",
      "\n",
      "peak_f5 = fft_peaks_merged_all.loc['mmlo_filtered_6-10_yr']\n",
      "\n",
      "--------------------\n",
      " Gain Settings for Creating Synthetic Frequency Signals\n",
      "\n",
      "gain_fac = 950\n",
      "\n",
      "fac_f1 = 0.63\n",
      "\n",
      "fac_f2 = 1\n",
      "\n",
      "fac_f3 = 1\n",
      "\n",
      "fac_f4 = 1\n",
      "\n",
      "fac_f5 = 0\n",
      "\n",
      "--------------------\n",
      " Alternative approach using SVM\n",
      "\n",
      "import gzip\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import matplotlib.image as imgplot\n",
      "\n",
      "import time\n",
      "\n",
      "from sklearn.preprocessing import Imputer\n",
      "\n",
      "from sklearn.metrics import confusion_matrix\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Loading the features of the cells\n",
      "\n",
      "cells_all = pd.read_csv('/home/dueo/data/Genedata/Cells.csv')\n",
      "\n",
      "cells = cells_all.iloc[cell_rows]\n",
      "\n",
      "np.shape(cells)\n",
      "\n",
      "--------------------\n",
      " Extracting the features and imputing NaNs\n",
      "\n",
      "X_features = np.asmatrix(cells.ix[:, 'AreaShape_Area':])\n",
      "\n",
      "np.shape(X_features)\n",
      "\n",
      "--------------------\n",
      " Normalization\n",
      "\n",
      "Xmean = X_features.mean(axis=0)\n",
      "\n",
      "XStd = np.sqrt(X_features.var(axis=0))\n",
      "\n",
      "X = ((X_features - Xmean) / (XStd + 0.01))\n",
      "\n",
      "--------------------\n",
      " NO DMSO and Separation of complete well \n",
      "\n",
      "Y = (Y - 1)\n",
      "\n",
      "idx_DMSO = np.asarray(np.recfromtxt('DMSO_data.csv'))\n",
      "\n",
      "print('Number of DMSO {}'.format(np.sum(idx_DMSO)))\n",
      "\n",
      "--------------------\n",
      " Permuting the training set\n",
      "\n",
      "perm = np.random.permutation(len(Y_train))\n",
      "\n",
      "X_train_perm = X_train[perm]\n",
      "\n",
      "Y_train_perm = Y_train[perm]\n",
      "\n",
      "--------------------\n",
      " In the case of no DSMO\n",
      "\n",
      "hist = np.histogram(Y_train_perm, bins=[0, 1, 2, 3, 4])\n",
      "\n",
      "NMAX = np.min(hist[0])\n",
      "\n",
      "NMAX = 352\n",
      "\n",
      "(hist, NMAX)\n",
      "\n",
      "--------------------\n",
      " Fisher LDA\n",
      "\n",
      "from sklearn.lda import LDA\n",
      "\n",
      "clf = LDA()\n",
      "\n",
      "clf.fit(X_train_perm, Y_train_perm)\n",
      "\n",
      "--------------------\n",
      " Random Forest\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "--------------------\n",
      " Calucation of the confusion matrix\n",
      "\n",
      "m = confusion_matrix(pred, Y_test)\n",
      "\n",
      "m\n",
      "\n",
      "--------------------\n",
      " 0 PRELIMINARIES \n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "sns.set()\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " RE LOAD THE SAVED DATASET \n",
      "\n",
      "x_var = np.load('A0_DATA.npy')\n",
      "\n",
      "y_var = np.load('A0_DATA_CLASSES.npy')\n",
      "\n",
      "x_val = x_var[:, 0]\n",
      "\n",
      "y_val = x_var[:, 1]\n",
      "\n",
      "plt.scatter(x_val, y_val)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " The sklearn interface makes it superbly easy to implementin SVMs with two lines of code \n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "model = SVC(kernel='linear', C=1)\n",
      "\n",
      "model.fit(x_var, y_var)\n",
      "\n",
      "--------------------\n",
      " Test model\n",
      "\n",
      "\n",
      "def get_next(inp):\n",
      "    idxs = [char_indices[c] for c in inp]\n",
      "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
      "    p = model.predict(arrs)\n",
      "    i = np.argmax(p)\n",
      "    return chars[i]\n",
      "\n",
      "--------------------\n",
      " Create and train model\n",
      "\n",
      "\n",
      "def embedding_input(name, n_in, n_out):\n",
      "    inp = Input(shape=(1,), dtype='int64', name=(name + '_in'))\n",
      "    emb = Embedding(n_in, n_out, input_length=1, name=(name + '_emb'))(inp)\n",
      "    return (inp, Flatten()(emb))\n",
      "\n",
      "--------------------\n",
      " Test model\n",
      "\n",
      "\n",
      "def get_next(inp):\n",
      "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
      "    p = model.predict(idxs)\n",
      "    return chars[np.argmax(p)]\n",
      "\n",
      "--------------------\n",
      " Our first RNN with keras \n",
      "\n",
      "(n_hidden, n_fac, cs, vocab_size) = (256, 42, 8, 86)\n",
      "\n",
      "--------------------\n",
      " Create and train model\n",
      "\n",
      "dense_in = Dense(n_hidden, activation='relu')\n",
      "\n",
      "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
      "\n",
      "dense_out = Dense(vocab_size, activation='softmax', name='output')\n",
      "\n",
      "--------------------\n",
      " Sequence model with keras\n",
      "\n",
      "(n_hidden, n_fac, cs, vocab_size)\n",
      "\n",
      "--------------------\n",
      " Stateful model with keras\n",
      "\n",
      "bs = 64\n",
      "\n",
      "--------------------\n",
      " Theano RNN\n",
      "\n",
      "n_input = vocab_size\n",
      "\n",
      "n_output = vocab_size\n",
      "\n",
      "--------------------\n",
      " Scenario and Problem Statement\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "--------------------\n",
      " Preliminary Analysis\n",
      "\n",
      "clean_hospital_read_df = hospital_read_df[(hospital_read_df['Number of Discharges'] != 'Not Available')]\n",
      "\n",
      "clean_hospital_read_df.loc[:, 'Number of Discharges'] = clean_hospital_read_df['Number of Discharges'].astype(int)\n",
      "\n",
      "clean_hospital_read_df = clean_hospital_read_df.sort_values('Number of Discharges')\n",
      "\n",
      "--------------------\n",
      " Hospitals with number of discharges 100\n",
      "\n",
      "sub100readmit = clean_hospital_read_df[((clean_hospital_read_df['Number of Discharges'] < 100) & (clean_hospital_read_df['Number of Discharges'] > 0))]\n",
      "\n",
      "--------------------\n",
      " Hospitals with number of discharges 1000\n",
      "\n",
      "over1000readmit = clean_hospital_read_df[(clean_hospital_read_df['Number of Discharges'] > 1000)]\n",
      "\n",
      "--------------------\n",
      " Statistical vs Practical Significance \n",
      "\n",
      "print(('N sub100: ' + str(n_sub100)))\n",
      "\n",
      "print(('N over1000: ' + str(n_over1000)))\n",
      "\n",
      "print(('Total N: ' + str(len(clean_hospital_read_df))))\n",
      "\n",
      "print(('100 < N < 1000: ' + str((11578 - (463 + 1188)))))\n",
      "\n",
      "--------------------\n",
      " Setup your imports\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn.datasets import fetch_20newsgroups\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn.decomposition import PCA, TruncatedSVD\n",
      "\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "--------------------\n",
      " 3 Accessing H I\n",
      "\n",
      "NHI = cos_halos.NHI\n",
      "\n",
      "flag_NHI = cos_halos.flag_NHI\n",
      "\n",
      "--------------------\n",
      " Let s examine the flags \n",
      "\n",
      "for j in np.arange(0, 11):\n",
      "    print([ch_name[j], np.round([ch_NSiIII[j], ch_sigNSiIII[j], ch_flagNSiIII[j]], 3)])\n",
      "\n",
      "--------------------\n",
      " Are bag of words features really useful No\n",
      "\n",
      "engine = db.create_root_engine()\n",
      "\n",
      "rawtable = pd.io.sql.read_sql_table('listings', engine, index_col='id')\n",
      "\n",
      "(Xtr2, Xte2, ytr2, yte2) = get_training_test_set(rawtable, make_features=make_features5, categorize_rating=categorize_rating4)\n",
      "\n",
      "--------------------\n",
      " Validation of estimator\n",
      "\n",
      "clf = get_random_forest_clf2()\n",
      "\n",
      "--------------------\n",
      " Confusion matrix\n",
      "\n",
      "sklearn.metrics.confusion_matrix(yte3, clf.predict(Xte3), labels=clf.classes_).T\n",
      "\n",
      "--------------------\n",
      " The constants in units of cm 1 \n",
      "\n",
      "from scipy import constants\n",
      "\n",
      "Har = constants.physical_constants['Hartree energy in eV'][0]\n",
      "\n",
      "print(((D_e + 1) / (((constants.h * constants.c) / constants.e) * Har)), (np.sqrt(pcov.diagonal()[0]) / (((constants.h * constants.c) / constants.e) * Har)))\n",
      "\n",
      "--------------------\n",
      " Import Libraries \n",
      "\n",
      "get_ipython().run_line_magic('pylab', 'inline')\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "from sklearn import cross_validation\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn import grid_search\n",
      "\n",
      "import math\n",
      "\n",
      "--------------------\n",
      " Generate indexes for training test sets \n",
      "\n",
      "kfold_indexes = cross_validation.KFold(len(train_data), 5, shuffle=True)\n",
      "\n",
      "--------------------\n",
      " kNN 2 \n",
      "\n",
      "from sklearn import datasets, metrics\n",
      "\n",
      "from scipy.spatial.distance import cosine, euclidean, minkowski\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from random import shuffle\n",
      "\n",
      "import warnings\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "warnings.simplefilter('ignore')\n",
      "\n",
      "--------------------\n",
      " test\n",
      "\n",
      "model_segment.load_weights(WEIGHTS_SEGMENT_FILEPATH)\n",
      "\n",
      "--------------------\n",
      " Data preparation\n",
      "\n",
      "cars = pd.read_csv('autos.csv', encoding='Latin1', parse_dates=['dateCrawled', 'dateCreated', 'lastSeen'])\n",
      "\n",
      "--------------------\n",
      " Load BOKEH libariry\n",
      "\n",
      "from bokeh.layouts import row, gridplot\n",
      "\n",
      "from bokeh.plotting import figure, output_notebook, show\n",
      "\n",
      "from bokeh.models import Legend\n",
      "\n",
      "TOOLS = 'box_zoom,box_select,crosshair,resize,reset,lasso_select,pan,save,poly_select,tap,wheel_zoom,undo'\n",
      "\n",
      "output_notebook()\n",
      "\n",
      "--------------------\n",
      " Load the pruned algorithm from normal prune\n",
      "\n",
      "ucb1 = np.load('/Users/salemameen/Desktop/banditsbook/python_heart/UCB1/AccuracyAftrerPrune.npy')\n",
      "\n",
      "Accuracy = np.load('/Users/salemameen/Desktop/banditsbook/python_heart/AccuracyBeforePruning.npy')\n",
      "\n",
      "--------------------\n",
      " Load the pruned algorithm from Multiple prune\n",
      "\n",
      "ucb1_Multiple = np.load('/Users/salemameen/Desktop/banditsbook_Prune_many_one_play/python_heart/UCB1/AccuracyAftrerPrune.npy')\n",
      "\n",
      "ThompsonSampling_Multiple = np.load('/Users/salemameen/Desktop/banditsbook_Prune_many_one_play/python_heart/Thompson_Sampling/AccuracyAftrerPrune.npy')\n",
      "\n",
      "--------------------\n",
      " Loading an Example Dataset\n",
      "\n",
      "from sklearn import datasets\n",
      "\n",
      "digits = datasets.load_digits()\n",
      "\n",
      "--------------------\n",
      " Learning and Predicting\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "clf = svm.SVC(gamma=0.001, C=100.0)\n",
      "\n",
      "--------------------\n",
      " Tweets\n",
      "\n",
      "with open('en_US/en_US.twitter.txt') as myfile:\n",
      "    tweets = [next(myfile) for x in myfile]\n",
      "\n",
      "--------------------\n",
      " n gram Generation\n",
      "\n",
      "from nltk.tokenize import TreebankWordTokenizer\n",
      "\n",
      "--------------------\n",
      " Blogs\n",
      "\n",
      "with open('en_US/en_US.blogs.txt') as myfile:\n",
      "    blogs = [next(myfile) for x in myfile]\n",
      "\n",
      "--------------------\n",
      " Case 2 Airport Delays\n",
      "\n",
      "airports = pd.read_csv('../assets/datasets/airport_operations.csv')\n",
      "\n",
      "--------------------\n",
      " Recategorize Drew Pomeranz\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Script starts here\n",
      "\n",
      "pabD = {\n",
      "    \n",
      "}\n",
      "\n",
      "for year in range(2015, 2017):\n",
      "    con = Baseball.get_con(year)\n",
      "    pab = Baseball.get_pitchab_for_pitcher('Drew Pomeranz', con, reg=False)\n",
      "    pab = pab[(~ pab['pitch_type'].isin(['IN', 'PO', 'UN']))]\n",
      "    pabD[year] = pab\n",
      "\n",
      "--------------------\n",
      " Recategorize 2016 pitches\n",
      "\n",
      "pitchab = pabD[2016]\n",
      "\n",
      "print(pitchab['pitch_type'].unique())\n",
      "\n",
      "ptypes = ['FT', 'KC', 'FF', 'CH', 'FC']\n",
      "\n",
      "--------------------\n",
      " Recat 2015\n",
      "\n",
      "pitchab = pabD[2015]\n",
      "\n",
      "print(pitchab['pitch_type'].unique())\n",
      "\n",
      "ptypes = ['FF', 'FT', 'KC', 'CH']\n",
      "\n",
      "--------------------\n",
      " Load the required libraries\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import sklearn as sk\n",
      "\n",
      "import urllib\n",
      "\n",
      "import math\n",
      "\n",
      "--------------------\n",
      " Map\n",
      "\n",
      "(min_lat, max_lat, min_long, max_long) = box = (42.1103, 43.5133, (- 72.6), (- 112.0128))\n",
      "\n",
      "--------------------\n",
      " Test Yellowbrick Covariance Ranking\n",
      "\n",
      "from yellowbrick.features.rankd import Rank2D\n",
      "\n",
      "from yellowbrick.features.radviz import RadViz\n",
      "\n",
      "from yellowbrick.features.pcoords import ParallelCoordinates\n",
      "\n",
      "--------------------\n",
      " Rotten Tomatoes Dataset\n",
      "\n",
      "critics = pd.read_csv('./critics.csv')\n",
      "\n",
      "critics = critics[(~ critics.quote.isnull())]\n",
      "\n",
      "critics.head()\n",
      "\n",
      "--------------------\n",
      " Explore\n",
      "\n",
      "n_reviews = len(critics)\n",
      "\n",
      "n_movies = critics.rtid.unique().size\n",
      "\n",
      "n_critics = critics.critic.unique().size\n",
      "\n",
      "print('Number of reviews: {:d}'.format(n_reviews))\n",
      "\n",
      "print('Number of critics: {:d}'.format(n_critics))\n",
      "\n",
      "print('Number of movies:  {:d}'.format(n_movies))\n",
      "\n",
      "--------------------\n",
      " Imports relevant packages for this session\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "--------------------\n",
      " Lists\n",
      "\n",
      "example_list = [2, 4, 'fg', 8, [3, 4]]\n",
      "\n",
      "print(example_list)\n",
      "\n",
      "print(example_list[0])\n",
      "\n",
      "print(example_list[2:4])\n",
      "\n",
      "print(example_list[(- 2)])\n",
      "\n",
      "example_list[2] = 20\n",
      "\n",
      "print(example_list)\n",
      "\n",
      "print(example_list[4][0])\n",
      "\n",
      "--------------------\n",
      " Tuples\n",
      "\n",
      "example_tuple = (2, 4, 6, 8, 10)\n",
      "\n",
      "print(example_tuple)\n",
      "\n",
      "print(example_tuple[1])\n",
      "\n",
      "--------------------\n",
      " Dictionary\n",
      "\n",
      "example_dictionary = {\n",
      "    'A': 20,\n",
      "    'B': 40,\n",
      "    'C': 60,\n",
      "}\n",
      "\n",
      "print(example_dictionary)\n",
      "\n",
      "print(example_dictionary['B'])\n",
      "\n",
      "example_dictionary['C'] = 100\n",
      "\n",
      "print(example_dictionary)\n",
      "\n",
      "print(example_dictionary.keys())\n",
      "\n",
      "print(example_dictionary.values())\n",
      "\n",
      "aux = example_dictionary.values()\n",
      "\n",
      "--------------------\n",
      " Numpy arrays\n",
      "\n",
      "example_array = np.array([2, 4, '4', 8, 10])\n",
      "\n",
      "print(example_array)\n",
      "\n",
      "print(example_array[0])\n",
      "\n",
      "print(example_array[2:4])\n",
      "\n",
      "print(example_array[(- 2)])\n",
      "\n",
      "example_array[2] = 20\n",
      "\n",
      "print(example_array)\n",
      "\n",
      "--------------------\n",
      " A one dimensional labeled array\n",
      "\n",
      "example_dictionary = {\n",
      "    'A': 20,\n",
      "    'B': 40,\n",
      "    'C': 60,\n",
      "}\n",
      "\n",
      "example_series = pd.Series(example_dictionary)\n",
      "\n",
      "print(example_series)\n",
      "\n",
      "print(example_series[0])\n",
      "\n",
      "print(example_series['B':])\n",
      "\n",
      "--------------------\n",
      " Pandas Dataframes a two dimensional labeled data structure with columns of potentially different types\n",
      "\n",
      "d = [['df', 1.0], ['as', 3], ['bq', 5]]\n",
      "\n",
      "print(type(d))\n",
      "\n",
      "example_series = pd.DataFrame(d, index=['Row1', 'Row2', 'Row3'], columns=['Column1', 'Column2'])\n",
      "\n",
      "print(example_series)\n",
      "\n",
      "example_series.dtypes\n",
      "\n",
      "--------------------\n",
      " center Pandas dataframes\n",
      "\n",
      "get_ipython().run_line_magic('pinfo', 'pd.read_csv')\n",
      "\n",
      "--------------------\n",
      " Indexing and Slicing\n",
      "\n",
      "patients[:3]\n",
      "\n",
      "--------------------\n",
      " Visualizing the data\n",
      "\n",
      "patients.boxplot()\n",
      "\n",
      "--------------------\n",
      " center Machine Learning\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "--------------------\n",
      " Importing Crime Statistics\n",
      "\n",
      "police_stats = pandas.read_csv('/Users/nerenevaz/Downloads/PostcodeData2015.csv', index_col='Postcode')\n",
      "\n",
      "--------------------\n",
      " Exporting file to clean column headers in excel and then reimporting it \n",
      "\n",
      "Rent_Crime.to_csv('/Users/nerenevaz/Downloads/Rent_Crime.csv')\n",
      "\n",
      "--------------------\n",
      " Plotting Rent vs Postcode data\n",
      "\n",
      "seaborn.jointplot(x='Rent_2013', y='Postcode', data=Rent_vs_Crime)\n",
      "\n",
      "seaborn.jointplot(x='Rent_2014', y='Postcode', data=Rent_vs_Crime)\n",
      "\n",
      "seaborn.jointplot(x='Rent_2015', y='Postcode', data=Rent_vs_Crime)\n",
      "\n",
      "--------------------\n",
      " Splitting Data into 2014 2015\n",
      "\n",
      "lat_lon = Rent_vs_Crime[['lat', 'lon']]\n",
      "\n",
      "lat_lon.sample()\n",
      "\n",
      "--------------------\n",
      " Finding Clusters\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "rscaler = preprocessing.RobustScaler()\n",
      "\n",
      "x_scaled = rscaler.fit_transform(Rent_vs_Crime2015)\n",
      "\n",
      "df_normalized = pandas.DataFrame(x_scaled)\n",
      "\n",
      "--------------------\n",
      " Finding Correlation of Features\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "colormap = plt.cm.viridis\n",
      "\n",
      "plt.figure(figsize=(12, 12))\n",
      "\n",
      "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
      "\n",
      "sns.heatmap(Rent_vs_Crime2015.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\n",
      "\n",
      "--------------------\n",
      " Running Regressors\n",
      "\n",
      "Rent_vs_Crime2014.columns.unique()\n",
      "\n",
      "--------------------\n",
      " This score seems wierd\n",
      "\n",
      "brute_force.best_score_\n",
      "\n",
      "--------------------\n",
      " Running Classifiers found code in Kaggle \n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import re\n",
      "\n",
      "import sklearn\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "import plotly.offline as py\n",
      "\n",
      "py.init_notebook_mode(connected=True)\n",
      "\n",
      "import plotly.graph_objs as go\n",
      "\n",
      "import plotly.tools as tls\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "--------------------\n",
      " How it s done\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sn\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (8.0, 6.0)\n",
      "\n",
      "--------------------\n",
      " If you d rather read from the API to get the latest uncomment the details and add comment to the final line \n",
      "\n",
      "stories = pd.read_json('../data/all_lobsters.json')\n",
      "\n",
      "--------------------\n",
      " Let s take a look at the submitter user field as it appears like a dict\n",
      "\n",
      "stories.submitter_user.iloc[3]\n",
      "\n",
      "--------------------\n",
      " Can we combine the user data without potential column overlap \n",
      "\n",
      "set(user_df.columns).intersection(stories.columns)\n",
      "\n",
      "--------------------\n",
      " Let s check for nulls\n",
      "\n",
      "stories.shape\n",
      "\n",
      "--------------------\n",
      " Exercise which columns would be dropped \n",
      "\n",
      "get_ipython().magic('load ../solutions/lobsters_dropped.py')\n",
      "\n",
      "--------------------\n",
      " Let s make the tags easier to use by having them as features in the columns \n",
      "\n",
      "tag_df = stories.tags.apply(pd.Series)\n",
      "\n",
      "--------------------\n",
      " Let s create a dummy df with our tags\n",
      "\n",
      "tag_df = pd.get_dummies(tag_df.apply(pd.Series).stack()).sum(level=0)\n",
      "\n",
      "--------------------\n",
      " Now we can add it back to our stories DataFrame\n",
      "\n",
      "stories = pd.concat([stories.drop('tags', axis=1), tag_df], axis=1)\n",
      "\n",
      "--------------------\n",
      " Another potentially useful feature is the post times \n",
      "\n",
      "stories['created_hour'] = stories.created_at.map((lambda x: x.hour))\n",
      "\n",
      "--------------------\n",
      " Let s analyze some of the correlations in our features so far \n",
      "\n",
      "stories[['created_hour', 'score']].corr()\n",
      "\n",
      "--------------------\n",
      " We might also want need to normalize scores We can use a Scaler MinMaxScaler or Normalizer\n",
      "\n",
      "normed_score = preprocessing.normalize(stories[['score']])\n",
      "\n",
      "--------------------\n",
      " hmm maybe a min max scaler works better for our needs \n",
      "\n",
      "scaler = preprocessing.MinMaxScaler()\n",
      "\n",
      "--------------------\n",
      " Example of a small Tree\n",
      "\n",
      "Image(filename='C:/Users/fr5424/Desktop/cart.png')\n",
      "\n",
      "--------------------\n",
      " Library of thermal resistances\n",
      "\n",
      "get_ipython().run_cell_magic('file', 'HT_thermal_resistance.py', '### definition of thermal resistance ###\\nfrom __future__ import division\\nfrom sympy.interactive import printing\\nprinting.init_printing(use_latex=\\'mathjax\\')\\n\\n\\nfrom IPython.display import display,Image, Latex\\nimport numpy as np\\nimport math\\nimport scipy.constants as sc\\n\\nimport sympy as sym\\n#from sympy import *\\n\\nclass Resistance(object):\\n    \"\"\" Defines thermal resistances for conduction, convection and radiation heat transfer. \\n        First define the object attached with class with the name used in the thermal circuit\\n        and the units, which can only be \\'W\\', \\'W/m\\' or \\'W/m^2\\'\\n        Second use self.conduction, self.convection or self.radiation to calculate your \\n        resistance. Each mode requires different arguments:\\n        .conduction(self,geo,k,r_a,r_b,A,r_a_name,r_b_name,A_name,Ta_name,Tb_name), where geo can only be \\'plane\\',\\n        \\'cylindrical\\' or \\'spherical\\', r_a is the first length and the only that matters in case\\n        of planar conduction, r_b is the second length. r_b must be an input even for planar\\n        (could be 0.). A is the surface area of the system for plane conduction, or the length of the cylinder\\n        for cylindrical conduction. Set to 0 if spherical. All arguments ending with _name are\\n        used to write the flux equations(they are strings preferably LaTeX formatted)\\n        \"\"\"\\n    def __init__(self,name,units):\\n        self.name = name\\n        self.units = units\\n    def conduction(self,geo,k,ra,rb,A,k_name,ra_name,rb_name,A_name,Ta_name,Tb_name):\\n        self.geometry = geo\\n        self.mode = \\'conduction\\'\\n        self.k_name = k_name\\n        self.ra_name = ra_name\\n        self.rb_name = rb_name\\n        self.surface_name = A_name\\n        self.surface_scale = A\\n        self.Ta_name = Ta_name\\n        self.Tb_name = Tb_name\\n        if self.geometry == \\'plane\\':\\n            self.R = ra/(k*A)\\n        elif self.geometry == \\'cylindrical\\':\\n            self.R = np.log(rb/ra)/(2.*math.pi*self.surface_scale*k)\\n        elif self.geometry == \\'spherical\\':\\n            self.R = (1./ra-1./rb)/(4.*math.pi*k)\\n        else :\\n            print(\"geometry is not plane, cylindrical or spherical, cannot compute\")\\n    def convection(self,h,A,h_name,A_name,Ta_name,Tb_name):\\n        self.mode = \\'convection\\'\\n        self.R = 1./(h*A)\\n        self.surface_scale = A\\n        self.h = h\\n        self.h_name = h_name\\n        self.surface_name = A_name\\n        self.Ta_name = Ta_name\\n        self.Tb_name = Tb_name\\n    def radiation(self,eps,T_s,T_sur,A,h_name,A_name,Ta_name,Tb_name):\\n        self.R = 1./(eps*sc.sigma*(T_s+T_sur)*(T_s**2+T_sur**2)*A)\\n        self.mode = \\'radiation\\'\\n        self.surface_scale = A\\n        self.h = eps*sc.sigma*(T_s+T_sur)*(T_s**2+T_sur**2)\\n        self.surface_name = A_name\\n        self.h_name = h_name\\n        self.Ta_name = Ta_name\\n        self.Tb_name = Tb_name\\n    def contact(self,R,A,R_name,A_name,Ta_name,Tb_name):\\n        self.R = R/A\\n        self.mode = \\'contact\\'\\n        self.R_name = R_name\\n        self.surface_scale = A\\n        self.surface_name = A_name\\n        self.Ta_name = Ta_name\\n        self.Tb_name = Tb_name\\n        \\n    def display_equation(self,index):\\n\\n        Tasym = sym.symbols(self.Ta_name)\\n        Tbsym = sym.symbols(self.Tb_name)\\n        if self.units == \\'W\\':\\n            Asym = sym.symbols(self.surface_name)\\n            namesym = \"q_\"+str(index)\\n        elif self.units == \\'W/m\\':\\n            Asym = sym.symbols(self.surface_name)\\n            namesym = \"q\\'_\"+str(index)\\n        elif self.units == \\'W/m^2\\':\\n            namesym = \"q\\'\\'_\"+str(index)\\n        else:\\n            print(\\'units are not properly defined\\')\\n        qsym = sym.symbols(namesym)\\n        Rsym = sym.symbols(self.name[1:-1])\\n        eq = sym.Eq(qsym,(1/Rsym)*(Tasym-Tbsym))\\n        if self.mode == \\'conduction\\':\\n            rasym = sym.symbols(self.ra_name)\\n            rbsym = sym.symbols(self.rb_name)\\n            cstsym = sym.symbols(self.k_name)\\n            if self.geometry == \\'plane\\':\\n                if self.units != \\'W/m^2\\':\\n                    eq1 = sym.Eq(qsym,cstsym*Asym/rasym*(Tasym-Tbsym))\\n                else:\\n                    eq1 = sym.Eq(qsym,cstsym/rasym*(Tasym-Tbsym))\\n            elif self.geometry == \\'cylindrical\\':\\n                if self.units == \\'W\\':\\n                    eq1 = sym.Eq(qsym,2*sym.pi*cstsym/sym.log(rbsym/rasym)*Asym*(Tasym-Tbsym))\\n                else:\\n                    eq1 = sym.Eq(qsym,2*sym.pi*cstsym/sym.log(rbsym/rasym)*(Tasym-Tbsym))\\n            elif self.geometry == \\'spherical\\':\\n                eq1 = sym.Eq(qsym,4*sym.pi*cstsym/(1/rasym-1/rbsym)*(Tasym-Tbsym))\\n                \\n        elif self.mode == \\'convection\\':\\n            cstsym = sym.symbols(self.h_name)\\n            if self.units == \\'W/m^2\\':\\n                eq1 = sym.Eq(qsym,cstsym*(Tasym-Tbsym))\\n            else:\\n                eq1 = sym.Eq(qsym,cstsym*Asym*(Tasym-Tbsym))\\n        elif self.mode == \\'radiation\\':\\n            cstsym = sym.symbols(self.h_name)\\n            if self.units == \\'W/m^2\\':\\n                eq1 = sym.Eq(qsym,cstsym*(Tasym-Tbsym))\\n            else:\\n                eq1 = sym.Eq(qsym,cstsym*Asym*(Tasym-Tbsym))\\n        elif self.mode == \\'contact\\':\\n            cstsym = sym.symbols(self.R_name)\\n            if self.units == \\'W/m^2\\':\\n                eq1 = sym.Eq(qsym,cstsym*(Tasym-Tbsym))\\n            else:\\n                eq1 = sym.Eq(qsym,(Asym/cstsym)*(Tasym-Tbsym))\\n        \\n        return display(eq,eq1)\\n        \\n### summation of thermal resistance (R is a vector) ###\\ndef serial_sum(R,nori,nend):\\n    sum = 0.\\n    for i in range(nori,nend+1):\\n        sum += R[i].R\\n    return sum\\n\\ndef parallel_sum(R,nori,nend):\\n    sum = 0.\\n    for i in range(nori,nend+1):\\n        sum += 1./R[i].R\\n    return 1./sum\\n\\n')\n",
      "\n",
      "--------------------\n",
      " Library of Nu correlations for external flow around a pipe\n",
      "\n",
      "get_ipython().run_cell_magic('file', 'HT_external_convection_cylinder.py', 'def Nu_Hilbert(Re,Pr):\\n    if (Re < 0.4) or (Re > 400000.):\\n        Nu = 0.\\n    else:\\n        if (Re < 4.):\\n            C = 0.989\\n            m = 0.33\\n        elif (Re < 40.):\\n            C = 0.911\\n            m = 0.385\\n        elif (Re < 4000.):\\n            C = 0.683\\n            m = 0.466\\n        elif (Re < 40000.):\\n            C = 0.193\\n            m = 0.618\\n        else:\\n            C = 0.027\\n            m = 0.805\\n        Nu = C*Re**m*Pr**(1./3.)\\n    return Nu\\n\\ndef Nu_Churchill_Bernstein(Re,Pr):\\n    \\n    if (Re*Pr < 0.2):\\n        Nu = 0.\\n    \\n    else:\\n        Nu = 0.3+(0.62*Re**(0.5)*Pr**(1./3.)) \\\\\\n          /(1.+(0.4/Pr)**(2./3.))**(1./4.) \\\\\\n        *(1.+(Re/282000.)**(5./8.))**(4./5.)\\n    return Nu\\n\\ndef Nu_Zukauskas(Re,Pr,Pr_s):\\n    if (Pr <= 10):\\n        n = 0.37\\n    else:\\n        n = 0.36\\n    inbound = True\\n    if (Re < 1.) and (Re > 1.e6):\\n        Nu = 0.\\n    else:\\n        if (Re < 40.):\\n            C = 0.75\\n            m = 0.4\\n        elif (Re < 1000.):\\n            C = 0.51\\n            m = 0.5\\n        elif (Re < 2.e5):\\n            C = 0.26\\n            m = 0.6\\n        else:\\n            C = 0.076\\n            m = 0.7\\n        Nu = C*Re**m*Pr**n*(Pr/Pr_s)**(1./4.)\\n    return Nu')\n",
      "\n",
      "--------------------\n",
      " Library of Nu correlations and functions for internal flow in pipes\n",
      "\n",
      "get_ipython().run_cell_magic('file', 'HT_internal_convection.py', \"import numpy as np\\nimport scipy\\nimport scipy.optimize\\n\\ndef linear_interpolation(x_t,x_1,x_2,y_1,y_2):\\n    return y_1+(y_2-y_1)*(x_t-x_1)/(x_2-x_1)\\n\\ndef pressure_drop_pipe(f,L,D,rho,u_m):\\n    return f*(L/D)*(rho*u_m**2)/2.\\n\\ndef f_pipe_laminar(Re_D):\\n    return 64./Re_D\\n\\ndef f_pipe_colebrook(Re_D,eps):\\n    Re = Re_D\\n    e = eps\\n     \\n    f_0 = (0.790*np.log(Re)- 1.64)**(-2.)\\n    if (e > 0.):\\n        f_1 = 1./(-2.0*np.log10(e/3.71))**2\\n    else:\\n        f_1 = f_0\\n    f_guess = np.max(f_0,f_1)\\n    #f_guess = 0.04\\n    def f_tmp(x):\\n        y = (-2*np.log10((2.51/(Re*np.sqrt(x))) + (e/(3.71))) - 1.0/np.sqrt(x))\\n        return y\\n    y = scipy.optimize.fsolve(f_tmp, f_guess)\\n    return y\\ndef log_mean_temperature(T_s,T_o,T_i):\\n    if (T_s < min(T_o,T_i)):\\n        DT_o = T_o-T_s\\n        DT_i = T_i-T_s\\n    elif (T_s > max(T_o,T_i)):\\n        DT_o = T_s-T_o\\n        DT_i = T_s-T_i\\n    return (DT_o-DT_i)/np.log(DT_o/DT_i)\\n\\ndef T_mx_Ts_constant(T_s,T_mi,P,mdot,Cp,hbar,x):\\n    return T_s-(T_s-T_mi)*np.exp(-P*x*hbar/(mdot*Cp))\\n\\ndef T_mo_T_infty(T_infty,T_mi,P,L,mdot,Cp,R_tot):\\n    return T_infty-(Tinfty-T_mi)*np.exp(-1/(mdot*Cp*Rtot))\\n\\ndef hbar_laminar_isothermal(k,D):\\n    return 3.66*k/D\\n\\ndef hbar_laminar_isoflux(k,D):\\n    return 4.36*k/D\\n\\ndef Nu_turbulent_Dittus_Boelter(Re,Pr,mode):\\n    if (mode == 'heating'):\\n        n = 0.4\\n    elif (mode == 'cooling'):\\n        n = 0.3\\n    return 0.023*Re**(4./5.)*Pr**n\\n\\ndef Nu_turbulent_Sieder_Tate(Re,Pr,mu,mu_s):\\n    return 0.027*Re**(4./5.)*Pr*(1./3.)*(mu/mu_s)**0.14\\n\\ndef Nu_turbulent_Gnielinski(Re,Pr,f):\\n    return (f/8.)*(Re-1000.)*Pr/(1+12.7*(f/8.)**0.5*(Pr**(2./3.)-1.))\\n\\ndef Nu_turbulent_Skupinski(Re,Pr):\\n    return 4.82+0.0185*(Re*Pr)**0.827\\n\\ndef Nu_turbulent_Seban(Re,Pr):\\n    return 5.0+0.025*(Re*Pr)**0.8\")\n",
      "\n",
      "--------------------\n",
      " Library for natural convection around cylinders\n",
      "\n",
      "get_ipython().run_cell_magic('file', 'HT_natural_convection_cylinder.py', 'import numpy as np\\nimport scipy\\nimport scipy.optimize\\n\\ndef Gr(g,beta,DT,D,nu):\\n    return (g*beta*DT*D**3)/(nu**2)\\n\\ndef Ra(g,beta,DT,D,nu,alpha):\\n    return (g*beta*DT*D**3)/(nu*alpha)\\n\\n\\ndef Nu_Morgan(Ra):\\n    if (Ra <= 1e-2):\\n        C=0.675\\n        n=0.058\\n    elif (Ra <= 1e2):\\n        C=1.02\\n        n=0.148\\n    elif (Ra <= 1e4):\\n        C=0.85\\n        n=0.188\\n    elif (Ra <= 1e7):\\n        C=0.480\\n        n=0.250\\n    elif (Ra <= 1e12):\\n        C=0.125\\n        n=0.333\\n    return C*Ra**n\\n\\ndef Nu_Churchill_Chu(Ra,Pr):\\n    return (0.60+(0.387*Ra**(1./6.))/(1.+(0.559/Pr)**(9./16.))**(8./27.))**2 ')\n",
      "\n",
      "--------------------\n",
      " Library of natural convection in enclosure\n",
      "\n",
      "get_ipython().run_cell_magic('file', 'HT_natural_convection_enclosure.py', \"import numpy as np\\nimport scipy\\nimport scipy.optimize\\n\\ndef Gr(g,beta,DT,L,nu):\\n    return (g*beta*DT*L**3)/(nu**2)\\n\\ndef Ra(g,beta,DT,L,nu,alpha):\\n    return (g*beta*DT*L**3)/(nu*alpha)\\n\\ndef Nu_vertical_enclosure(Ra,Pr,H,L):\\n    if (H/L) < 2.:\\n        if Ra*Pr/(0.2+Pr)> 1.e3:\\n            Nu = 0.18*(Pr/(0.2+Pr)*Ra)**0.29\\n        else:\\n            print('Ra is too low for this correlation')\\n            Nu = np.inf\\n    elif H/L < 10:\\n        if Ra < 1e10:\\n            Nu = 0.22*(Pr/(0.2+Pr)*Ra)**0.28*(H/L)**(-0.25)\\n        else:\\n            print('Ra is too high for this correlation')\\n            Nu = np.inf\\n    elif Ra < 1e4:\\n        print('Ra is too low for this correlation')\\n        Nu = np.inf\\n    elif Ra < 1e7:\\n        if Pr > 0.6 and Pr < 2e4:\\n            print('ok')\\n            Nu =0.42*Ra**0.25*Pr**0.012*(H/L)**(-0.3)\\n        else :\\n            print('Pr is out of bounds for this correlation')\\n            Nu = np.inf\\n    elif Ra < 1e9:\\n        if Pr > 0.6 and Pr < 20.:\\n            Nu =0.46*Ra**(1./3.)\\n        else :\\n            print('Pr is out of bounds for this correlation')\\n            Nu = np.inf\\n    else:\\n        print('Ra is too high, got nothing for you')\\n        Nu = np.inf\\n    return Nu\\n            \")\n",
      "\n",
      "--------------------\n",
      " 1 \n",
      "\n",
      "import pandas\n",
      "\n",
      "features = pandas.read_csv('./features.csv', index_col='match_id')\n",
      "\n",
      "features.head()\n",
      "\n",
      "--------------------\n",
      " 2 \n",
      "\n",
      "row_count = len(X)\n",
      "\n",
      "not_nan_counts = X.count()\n",
      "\n",
      "columns_with_nan = filter((lambda axe: (not_nan_counts[axe] < row_count)), not_nan_counts.axes[0])\n",
      "\n",
      "list(map((lambda column: [column, (row_count - not_nan_counts[column])]), columns_with_nan))\n",
      "\n",
      "--------------------\n",
      " 3 \n",
      "\n",
      "X.fillna(0, inplace=True)\n",
      "\n",
      "--------------------\n",
      " Assignment 5\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from scipy import misc\n",
      "\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import matplotlib\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "matplotlib.style.use('ggplot')\n",
      "\n",
      "--------------------\n",
      " Iris dataset\n",
      "\n",
      "iris = load_iris()\n",
      "\n",
      "pd.DataFrame(iris.data).head()\n",
      "\n",
      "--------------------\n",
      " Train Test Split\n",
      "\n",
      "(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size=0.4, random_state=4)\n",
      "\n",
      "print(('x_train shape: %s' % str(x_train.shape)))\n",
      "\n",
      "print(('x_test shape: %s' % str(x_test.shape)))\n",
      "\n",
      "print(('y_train shape: %s' % str(y_train.shape)))\n",
      "\n",
      "print(('y_test shape: %s' % str(y_test.shape)))\n",
      "\n",
      "--------------------\n",
      " Visualising data using Seaborn\n",
      "\n",
      "data = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv', index_col=0)\n",
      "\n",
      "data.tail()\n",
      "\n",
      "--------------------\n",
      " Seaborn pairplot\n",
      "\n",
      "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data'\n",
      "\n",
      "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
      "\n",
      "pima = pd.read_csv(url, header=None, names=col_names)\n",
      "\n",
      "pima.head(10)\n",
      "\n",
      "--------------------\n",
      " Classification accuracy metrics\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "print(metrics.accuracy_score(y_test, y_pred))\n",
      "\n",
      "--------------------\n",
      " Confusion matrix\n",
      "\n",
      "print(metrics.confusion_matrix(y_test, y_pred))\n",
      "\n",
      "--------------------\n",
      " Classification Accuracy overall how often is the classifier correct \n",
      "\n",
      "print(((TP + TN) / (((TP + TN) + FP) + FN)))\n",
      "\n",
      "print(metrics.accuracy_score(y_test, y_pred))\n",
      "\n",
      "--------------------\n",
      " False positive rate When the actual value is negative how often is the prediction incorrect \n",
      "\n",
      "print((FP / (TN + FP)))\n",
      "\n",
      "--------------------\n",
      " Adjusting the classification threshold\n",
      "\n",
      "knn.predict(x_test)[0:10]\n",
      "\n",
      "--------------------\n",
      " Decrease the threshold for predicting diabetes in order to increase the sensitivity of the classifier\n",
      "\n",
      "from sklearn.preprocessing import binarize\n",
      "\n",
      "y_pred = binarize(y_pred_proba, 0.3)[0]\n",
      "\n",
      "y_pred_proba[:10]\n",
      "\n",
      "--------------------\n",
      " Visulize the data\n",
      "\n",
      "data.hist()\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Prepare the data for classification\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "dataset = data.values\n",
      "\n",
      "X = dataset[:, 0:10].astype(float)\n",
      "\n",
      "Y = dataset[:, 10]\n",
      "\n",
      "features = preprocessing.scale(X)\n",
      "\n",
      "target = Y\n",
      "\n",
      "--------------------\n",
      " Preproccing\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "X_train = preprocessing.normalize(X_train)\n",
      "\n",
      "X_test = preprocessing.normalize(X_test)\n",
      "\n",
      "X_deploy = preprocessing.normalize(X_deploy)\n",
      "\n",
      "X_train = preprocessing.scale(X_train)\n",
      "\n",
      "X_test = preprocessing.scale(X_test)\n",
      "\n",
      "X_deploy = preprocessing.scale(X_deploy)\n",
      "\n",
      "--------------------\n",
      " Feature Selection\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "model = ExtraTreesClassifier()\n",
      "\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "print(model.feature_importances_)\n",
      "\n",
      "--------------------\n",
      " See first step \n",
      "\n",
      "u = ((2 * signal.square((((2 * np.pi) * 10) * t), duty=0.5)) + 23)\n",
      "\n",
      "response = signal.lsim2(tf, U=u, T=t, X0=0.5)\n",
      "\n",
      "--------------------\n",
      " Statistical Analysis\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import collections\n",
      "\n",
      "import sklearn\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "from sklearn import learning_curve\n",
      "\n",
      "from sklearn import ensemble\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from sklearn.ensemble import BaggingClassifier\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "from sklearn.cross_validation import KFold\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn.ensemble import VotingClassifier\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " Correlation Matrix\n",
      "\n",
      "df.corr()\n",
      "\n",
      "plt.matshow(df.corr())\n",
      "\n",
      "plt.yticks(range(len(df.corr().columns)), df.corr().columns)\n",
      "\n",
      "plt.colorbar()\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Preparing Data\n",
      "\n",
      "target = df['shot_made_flag'].copy()\n",
      "\n",
      "nildata = df['shot_made_flag'].isnull()\n",
      "\n",
      "--------------------\n",
      " Feature Engineering\n",
      "\n",
      "df['6secondes_remaining'] = (df['seconds_remaining'] < 6)\n",
      "\n",
      "df['home_play'] = df['matchup'].str.contains('vs').astype('int')\n",
      "\n",
      "df['game_date'] = pd.to_datetime(df['game_date'])\n",
      "\n",
      "df['game_year'] = df['game_date'].dt.year\n",
      "\n",
      "--------------------\n",
      " Transforming categorical columns\n",
      "\n",
      "categorial_cols = ['action_type', 'period', 'season', 'combined_shot_type', 'shot_type', 'game_year', 'shot_zone_area', 'shot_zone_basic', 'shot_zone_range', 'loc_x', 'loc_y']\n",
      "\n",
      "for cc in categorial_cols:\n",
      "    dummies = pd.get_dummies(df[cc])\n",
      "    dummies = dummies.add_prefix('{}#'.format(cc))\n",
      "    df.drop(cc, axis=1, inplace=True)\n",
      "    df = df.join(dummies)\n",
      "\n",
      "--------------------\n",
      " Final Dataset\n",
      "\n",
      "X = df[(~ nildata)]\n",
      "\n",
      "test = df[nildata]\n",
      "\n",
      "Y = target[(~ nildata)]\n",
      "\n",
      "--------------------\n",
      " Machine Learning\n",
      "\n",
      "num_trees = 100\n",
      "\n",
      "model = RandomForestClassifier(n_estimators=50, oob_score=True)\n",
      "\n",
      "results = cross_val_score(model, X, Y)\n",
      "\n",
      "print(results.mean(), '+/-', results.std())\n",
      "\n",
      "--------------------\n",
      " Word dependency entropy\n",
      "\n",
      "wde.sort_values(ascending=True).to_csv((('../data/' + file_prefix) + '.wde.csv'))\n",
      "\n",
      "wde.sort_values(ascending=False)\n",
      "\n",
      "--------------------\n",
      " xgboost \n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "\n",
      "def plot_feature_importances(xgb_model):\n",
      "    plt.figure(figsize=(20, 10))\n",
      "    feat_imp = pd.Series(xgb_model.booster().get_fscore()).sort_values(ascending=False)\n",
      "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
      "    plt.ylabel('Feature Importance Score')\n",
      "\n",
      "--------------------\n",
      " Next week prediction\n",
      "\n",
      "param = {\n",
      "    'learning_rate': 0.3,\n",
      "    'gamma': 0,\n",
      "    'max_depth': 10,\n",
      "    'min_child_weight': 24,\n",
      "    'n_estimators': 100,\n",
      "    'subsample': 0.8,\n",
      "    'colsample_bytree': 0.8,\n",
      "}\n",
      "\n",
      "xgb_model_week9 = xgb.XGBRegressor()\n",
      "\n",
      "xgb_model_week9.set_params(**param)\n",
      "\n",
      "xgb_model_week9.fit(X_train_week9, y_train)\n",
      "\n",
      "--------------------\n",
      " Cross validation\n",
      "\n",
      "param = {\n",
      "    'learning_rate': 0.2,\n",
      "    'gamma': 0,\n",
      "    'max_depth': 10,\n",
      "    'min_child_weight': 22,\n",
      "    'n_estimators': 100,\n",
      "    'subsample': 0.8,\n",
      "    'colsample_bytree': 0.8,\n",
      "}\n",
      "\n",
      "xgtrain = xgb.DMatrix(X_train_week8.values, label=y_train.values)\n",
      "\n",
      "cvresult = xgb.cv(param, xgtrain, num_boost_round=200, nfold=5, metrics='rmse', early_stopping_rounds=10)\n",
      "\n",
      "cvresult\n",
      "\n",
      "--------------------\n",
      " Grid search without cross validation\n",
      "\n",
      "from gridsearch import GridSearch\n",
      "\n",
      "--------------------\n",
      " Week 8\n",
      "\n",
      "param_grid = {\n",
      "    'gamma': [0],\n",
      "}\n",
      "\n",
      "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.3, subsample=0.8, colsample_bytree=0.8, max_depth=10, min_child_weight=22)\n",
      "\n",
      "gs = GridSearch(xgb_model, param_grid, verbose=1)\n",
      "\n",
      "gs.fit(X_train_week8, X_test_week8, y_train, y_test_week8)\n",
      "\n",
      "--------------------\n",
      " Week 9\n",
      "\n",
      "param_grid = {\n",
      "    'max_depth': [7, 10, 13],\n",
      "    'min_child_weight': [19, 22, 25],\n",
      "}\n",
      "\n",
      "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.3, subsample=0.8, colsample_bytree=0.8, gamma=0)\n",
      "\n",
      "gs = GridSearch(xgb_model, param_grid, verbose=1)\n",
      "\n",
      "gs.fit(X_train_week9, X_test_week9, y_train, y_test_week9)\n",
      "\n",
      "--------------------\n",
      " XGBoost GridSearch Experiment\n",
      "\n",
      "from xgboost_grid_search_experiment import XGBoostGridSearchExperiment\n",
      "\n",
      "--------------------\n",
      " Dump xgbmodel for xgbfi\n",
      "\n",
      "param = {\n",
      "    'eta': 0.3,\n",
      "    'gamma': 0,\n",
      "    'max_depth': 10,\n",
      "    'min_child_weight': 22,\n",
      "    'subsample': 0.8,\n",
      "    'colsample_bytree': 0.8,\n",
      "}\n",
      "\n",
      "num_round = 100\n",
      "\n",
      "xgtrain = xgb.DMatrix(X_train_week8.values, label=y_train.values)\n",
      "\n",
      "xgtest = xgb.DMatrix(X_test_week8.values, label=y_test_week8.values)\n",
      "\n",
      "watchlist = [(xgtest, 'eval'), (xgtrain, 'train')]\n",
      "\n",
      "booster = xgb.train(param, xgtrain, num_round, watchlist)\n",
      "\n",
      "--------------------\n",
      " Tested On\n",
      "\n",
      "import sys\n",
      "\n",
      "print(('Python %d.%d.%d' % (sys.version_info.major, sys.version_info.minor, sys.version_info.micro)))\n",
      "\n",
      "--------------------\n",
      " Import Modules\n",
      "\n",
      "import time\n",
      "\n",
      "--------------------\n",
      " Display Settings\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
      "\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "--------------------\n",
      " Get and Plot Data\n",
      "\n",
      "movies = sio.loadmat('ex8_movies.mat')\n",
      "\n",
      "R = movies['R']\n",
      "\n",
      "Y = movies['Y']\n",
      "\n",
      "--------------------\n",
      " Movie List\n",
      "\n",
      "\n",
      "def load_movie_list(filename):\n",
      "    movie_list = []\n",
      "    with open(filename, 'r') as input_fh:\n",
      "        for line in input_fh.readlines():\n",
      "            space_idx = line.find(' ')\n",
      "            if space_idx:\n",
      "                movie_list.append(line[(space_idx + 1):].strip())\n",
      "    return movie_list\n",
      "\n",
      "--------------------\n",
      " Rate Movies\n",
      "\n",
      "(n_m, n_u) = Y.shape\n",
      "\n",
      "--------------------\n",
      " Learn Rating\n",
      "\n",
      "(n_m, n_u) = my_Y.shape\n",
      "\n",
      "n = 100\n",
      "\n",
      "X_init = np.random.rand(n_m, n)\n",
      "\n",
      "Theta_init = np.random.rand(n_u, n)\n",
      "\n",
      "X_Theta_init = np.vstack([X_init, Theta_init]).flatten()\n",
      "\n",
      "Lambda = 1.5\n",
      "\n",
      "args = np.asarray((my_Y_norm, my_R, Lambda, n_m, n_u, n))\n",
      "\n",
      "--------------------\n",
      " numpy\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Load and prepare data following LIGO tutorial \n",
      "\n",
      "(strain, time, chan_dict) = rl.loaddata('H-H1_LOSC_4_V1-1126259446-32.hdf5', 'H1')\n",
      "\n",
      "dt = (time[1] - time[0])\n",
      "\n",
      "(NRtime, NR_H1) = np.genfromtxt('GW150914_4_NR_waveform.txt').transpose()\n",
      "\n",
      "--------------------\n",
      " Import modules\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from matplotlib.patches import Rectangle\n",
      "\n",
      "import matplotlib.image as mpimg\n",
      "\n",
      "from collections import Counter\n",
      "\n",
      "from six.moves import cPickle as pickle\n",
      "\n",
      "from scipy import ndimage\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "import copy\n",
      "\n",
      "from sklearn.utils import shuffle\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "print('Modules loaded.')\n",
      "\n",
      "--------------------\n",
      " Load the data\n",
      "\n",
      "filename = './test_data'\n",
      "\n",
      "with open((filename + '.pickle'), 'rb') as f:\n",
      "    test_data = pickle.load(f)\n",
      "\n",
      "X_test_full = test_data['X_test']\n",
      "\n",
      "y_test_full = test_data['y_test']\n",
      "\n",
      "image_path_test_full = test_data['image_path_test']\n",
      "\n",
      "--------------------\n",
      " Preprocess the data\n",
      "\n",
      "y_test_digit = copy.deepcopy(y_test_full[:, 0:6])\n",
      "\n",
      "y_test_digit[:, 0] = (y_test_digit[:, 0] - 1)\n",
      "\n",
      "y_test_bbox = copy.deepcopy(y_test_full[:, 6:])\n",
      "\n",
      "--------------------\n",
      " Add noise to test images\n",
      "\n",
      "\n",
      "def gaussian_noise(image, sd_factor):\n",
      "    return (image + ((sd_factor * image.std()) * np.random.random(image.shape)))\n",
      "\n",
      "--------------------\n",
      " Defining the graph\n",
      "\n",
      "\n",
      "def accuracy_length(predictions, labels):\n",
      "    ' Compute length accuracy.\\n    Args:\\n        predictions:    (numpy array) predicted values [length,digit1,digit2,digit3,digit4,digit5].\\n        labels:         (numpy array) actual values [length,digit1,digit2,digit3,digit4,digit5].\\n    Returns:\\n        (float) Full sequence accuracy in percentage.\\n    '\n",
      "    return ((100.0 * np.sum(np.equal(predictions[:, 0], labels[:, 0]))) / predictions.shape[0])\n",
      "\n",
      "--------------------\n",
      " Testing my code against sklearn\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "--------------------\n",
      " 1 Tokenization\n",
      "\n",
      "feature_pos = ('NNP', 'NNG', 'NNB', 'NP', 'VV', 'VA', 'MAG')\n",
      "\n",
      "--------------------\n",
      " 2 Modeling\n",
      "\n",
      "cf_doc2vec_model = gensim.models.Doc2Vec(kon_token_tags, size=200)\n",
      "\n",
      "--------------------\n",
      " Libraries\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import sklearn\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "--------------------\n",
      " Versions\n",
      "\n",
      "get_ipython().system('python --version')\n",
      "\n",
      "--------------------\n",
      " Get Data\n",
      "\n",
      "X = pd.read_hdf('/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/data/py27/simulated_raw_data_py27.h5', 'table')\n",
      "\n",
      "--------------------\n",
      " Preprocess Data\n",
      "\n",
      "y = X.pop('hired')\n",
      "\n",
      "--------------------\n",
      " Split Data\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "training = pd.concat([X_train, y_train], axis=1)\n",
      "\n",
      "training.reset_index(drop=True, inplace=True)\n",
      "\n",
      "--------------------\n",
      " Pickle X test y test\n",
      "\n",
      "import pickle\n",
      "\n",
      "path = '/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/pickle_files/py27/'\n",
      "\n",
      "with open((path + 'X_test_py27.pkl'), 'wb') as picklefile:\n",
      "    pickle.dump(X_test, picklefile)\n",
      "\n",
      "with open((path + 'y_test_py27.pkl'), 'wb') as picklefile:\n",
      "    pickle.dump(y_test, picklefile)\n",
      "\n",
      "--------------------\n",
      " Write Training Data To Disk\n",
      "\n",
      "training.to_hdf('/Users/davidziganto/Repositories/Synthetic_Dataset_Generation/data/py27/simulated_raw_training_data_py27.h5', 'table', mode='w', append=True, complevel=9, complib='blosc', fletcher32=True)\n",
      "\n",
      "--------------------\n",
      " Distributions in Pandas\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Hypothesis Testing\n",
      "\n",
      "df = pd.read_csv('grades.csv')\n",
      "\n",
      "--------------------\n",
      " Solving by sklearn\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "C = 100\n",
      "\n",
      "clf = SVC(kernel='linear', C=C)\n",
      "\n",
      "clf.fit(X, y)\n",
      "\n",
      "w_sklearn = clf.coef_.reshape((- 1), 1)\n",
      "\n",
      "b_sklearn = clf.intercept_[0]\n",
      "\n",
      "--------------------\n",
      " Load the data\n",
      "\n",
      "X_train = np.load('/Users/salemameen/Desktop/banditsbook/python_wine/wine/X_train.npy')\n",
      "\n",
      "y_train = np.load('/Users/salemameen/Desktop/banditsbook/python_wine/wine/y_train.npy')\n",
      "\n",
      "X_test = np.load('/Users/salemameen/Desktop/banditsbook/python_wine/wine/X_test.npy')\n",
      "\n",
      "y_test = np.load('/Users/salemameen/Desktop/banditsbook/python_wine/wine/y_test.npy')\n",
      "\n",
      "X_deploy = np.load('/Users/salemameen/Desktop/banditsbook/python_wine/wine/X_deploy.npy')\n",
      "\n",
      "y_deploy = np.load('/Users/salemameen/Desktop/banditsbook/python_wine/wine/y_deploy.npy')\n",
      "\n",
      "print('Number of training examples', len(X_train))\n",
      "\n",
      "print('Number of validation examples', len(X_test))\n",
      "\n",
      "print('Number of testing examples', len(X_deploy))\n",
      "\n",
      "--------------------\n",
      " Run Thompson Sampling pruning Algorithm\n",
      "\n",
      "algo = Thompson_Sampling([], [])\n",
      "\n",
      "Alg_name = 'Thompson_Sampling Algorithm'\n",
      "\n",
      "path = './Thompson_Sampling/'\n",
      "\n",
      "sys.path.append('./Thompson_Sampling')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run UCB1 pruning Algorithm\n",
      "\n",
      "algo = UCB1([], [])\n",
      "\n",
      "Alg_name = 'UCB1 Algorithm'\n",
      "\n",
      "path = './UCB1/'\n",
      "\n",
      "sys.path.append('./UCB1')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run Annealing Epsilon Greedy pruning Algorithm\n",
      "\n",
      "algo = AnnealingEpsilonGreedy([], [])\n",
      "\n",
      "Alg_name = 'Annealing Epsilon Greedy Algorithm'\n",
      "\n",
      "path = './AnnealingEpsilonGreedy/'\n",
      "\n",
      "sys.path.append('./AnnealingEpsilonGreedy')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run Epsilon Greedy pruning Algorithm\n",
      "\n",
      "epsilon = 0.9\n",
      "\n",
      "algo = EpsilonGreedy(epsilon, [], [])\n",
      "\n",
      "Alg_name = 'Epsilon Greedy Algorithm'\n",
      "\n",
      "path = './EpsilonGreedy/'\n",
      "\n",
      "sys.path.append('./AnnealingEpsilonGreedy')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run Exp3 pruning Algorithm\n",
      "\n",
      "exp3_gamma = 0.2\n",
      "\n",
      "algo = Exp3(exp3_gamma, [])\n",
      "\n",
      "Alg_name = 'Exp3 Algorithm'\n",
      "\n",
      "path = './Exp3/'\n",
      "\n",
      "sys.path.append('./EpsilonGreedy')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run Softmax pruning Algorithm\n",
      "\n",
      "temperature = 0.9\n",
      "\n",
      "algo = Softmax(temperature, [], [])\n",
      "\n",
      "Alg_name = 'Softmax Algorithm'\n",
      "\n",
      "path = './Softmax/'\n",
      "\n",
      "sys.path.append('./Softmax')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run Annealing Softmax pruning Algorithm\n",
      "\n",
      "algo = AnnealingSoftmax([], [])\n",
      "\n",
      "Alg_name = 'Annealing Softmax Algorithm'\n",
      "\n",
      "path = './AnnealingSoftmax/'\n",
      "\n",
      "sys.path.append('./AnnealingSoftmax')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Run Hedge pruning Algorithm\n",
      "\n",
      "eta = 0.9\n",
      "\n",
      "algo = Hedge(eta, [], [])\n",
      "\n",
      "Alg_name = 'Hedge Algorithm'\n",
      "\n",
      "path = './Hedge/'\n",
      "\n",
      "sys.path.append('./Hedge')\n",
      "\n",
      "exec(open('mnist_cnnFORTESTING.py').read())\n",
      "\n",
      "--------------------\n",
      " Compare the accuracy of the models\n",
      "\n",
      "ucb1 = np.load('./UCB1/AccuracyAftrerPrune.npy')\n",
      "\n",
      "EpsilonGreedy = np.load('./EpsilonGreedy/AccuracyAftrerPrune.npy')\n",
      "\n",
      "AnnealingEpsilonGreedy = np.load('./AnnealingEpsilonGreedy/AccuracyAftrerPrune.npy')\n",
      "\n",
      "Softmax = np.load('./Softmax/AccuracyAftrerPrune.npy')\n",
      "\n",
      "AnnealingSoftmax = np.load('./AnnealingSoftmax/AccuracyAftrerPrune.npy')\n",
      "\n",
      "Exp3 = np.load('./Exp3/AccuracyAftrerPrune.npy')\n",
      "\n",
      "Hedge = np.load('./Hedge/AccuracyAftrerPrune.npy')\n",
      "\n",
      "ThompsonSampling = np.load('./Thompson_Sampling/AccuracyAftrerPrune.npy')\n",
      "\n",
      "Accuracy = np.load('AccuracyBeforePruning.npy')\n",
      "\n",
      "--------------------\n",
      " Convolutional Neural Networks for Artistic Style Transfer\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import time\n",
      "\n",
      "from PIL import Image\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from keras import backend\n",
      "\n",
      "from keras.models import Model\n",
      "\n",
      "from keras.applications.vgg16 import VGG16\n",
      "\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "\n",
      "from scipy.misc import imsave\n",
      "\n",
      "--------------------\n",
      " 1 Load and preprocess the content and style images\n",
      "\n",
      "height = 256\n",
      "\n",
      "width = 256\n",
      "\n",
      "content_image_path = './base_image.jpg'\n",
      "\n",
      "content_image = Image.open(content_image_path)\n",
      "\n",
      "content_image = content_image.resize((height, width))\n",
      "\n",
      "content_image\n",
      "\n",
      "--------------------\n",
      " 1 1 Preprocess content and style images\n",
      "\n",
      "content_array = np.asarray(content_image, dtype='float32')\n",
      "\n",
      "content_array = np.expand_dims(content_array, axis=0)\n",
      "\n",
      "print(content_array.shape)\n",
      "\n",
      "style_array = np.asarray(style_image, dtype='float32')\n",
      "\n",
      "style_array = np.expand_dims(style_array, axis=0)\n",
      "\n",
      "print(style_array.shape)\n",
      "\n",
      "--------------------\n",
      " 1 2 Define variables in Keras backend TensorFlow graph \n",
      "\n",
      "content_image = backend.variable(content_array)\n",
      "\n",
      "style_image = backend.variable(style_array)\n",
      "\n",
      "combination_image = backend.placeholder((1, height, width, 3))\n",
      "\n",
      "--------------------\n",
      " 2 Reusing a pre trained model for image classification to define loss functions\n",
      "\n",
      "model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
      "\n",
      "--------------------\n",
      " 2 1 Defining scalar weights for content style and total variation in the combination image\n",
      "\n",
      "content_weight = 0.025\n",
      "\n",
      "style_weight = 5.0\n",
      "\n",
      "total_variation_weight = 1.0\n",
      "\n",
      "loss = backend.variable(0.0)\n",
      "\n",
      "--------------------\n",
      " 2 2 The content loss function\n",
      "\n",
      "\n",
      "def content_loss(content, combination):\n",
      "    return backend.sum(backend.square((content - combination)))\n",
      "\n",
      "layer_features = layers['block2_conv2']\n",
      "\n",
      "content_image_features = layer_features[0, :, :, :]\n",
      "\n",
      "combination_image_features = layer_features[2, :, :, :]\n",
      "\n",
      "loss += (content_weight * content_loss(content_image_features, combination_image_features))\n",
      "\n",
      "--------------------\n",
      " 2 3 The style loss function\n",
      "\n",
      "\n",
      "def gram_matrix(x):\n",
      "    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n",
      "    gram = backend.dot(features, backend.transpose(features))\n",
      "    return gram\n",
      "\n",
      "--------------------\n",
      " 3 Define needed gradients and solve the optimization problem\n",
      "\n",
      "grads = backend.gradients(loss, combination_image)\n",
      "\n",
      "--------------------\n",
      " Generating sample\n",
      "\n",
      "\n",
      "def gen(sz, k, b):\n",
      "    x = stats.uniform.rvs(loc=(- 3), scale=6, size=sz)\n",
      "    y = (((k * x) + b) + stats.norm.rvs(scale=0.2, size=sz))\n",
      "    return (x, y)\n",
      "\n",
      "--------------------\n",
      " MSE optimization\n",
      "\n",
      "from scipy import optimize\n",
      "\n",
      "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
      "\n",
      "--------------------\n",
      " Modifying sample\n",
      "\n",
      "(x2, y2) = gen(75, 0, (- 1))\n",
      "\n",
      "x2 = np.append(x, x2)\n",
      "\n",
      "y2 = np.append(y, y2)\n",
      "\n",
      "--------------------\n",
      " MSE optimization on modified sample\n",
      "\n",
      "(k2, b2) = optimize.minimize(mse, [0, 0], args=(x2, y2)).x\n",
      "\n",
      "print(k2, b2)\n",
      "\n",
      "--------------------\n",
      " MAE optimization on modified sample\n",
      "\n",
      "\n",
      "def mae(c, x, y):\n",
      "    return mean_absolute_error(((c[0] * x) + c[1]), y)\n",
      "\n",
      "--------------------\n",
      " Perform the thing on our new data \n",
      "\n",
      "from pickle import load\n",
      "\n",
      "vectors = load(open('./SOMPY/separate_feature_vectors.pkl'))\n",
      "\n",
      "labels = load(open('./SOMPY/separate_feature_labels.pkl'))\n",
      "\n",
      "--------------------\n",
      " Default imports\n",
      "\n",
      "get_ipython().magic(\"config InlineBackend.figure_format = 'retina'\")\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scipy as sp\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import sklearn\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "sns.set_style('white')\n",
      "\n",
      "--------------------\n",
      " Load data\n",
      "\n",
      "filename = 'burrito_current.csv'\n",
      "\n",
      "df = pd.read_csv(filename)\n",
      "\n",
      "N = df.shape[0]\n",
      "\n",
      "--------------------\n",
      " global initializer \n",
      "\n",
      "model.trainable_weights\n",
      "\n",
      "--------------------\n",
      " json \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import json\n",
      "\n",
      "import jpype\n",
      "\n",
      "import glob\n",
      "\n",
      "from random import shuffle\n",
      "\n",
      "from bs4 import BeautifulSoup as bs\n",
      "\n",
      "data_path = 'data(test)'\n",
      "\n",
      "file_list = glob.glob(('%s/*.json' % data_path))\n",
      "\n",
      "json_train = []\n",
      "\n",
      "shuffle(file_list)\n",
      "\n",
      "for json_file_name in file_list:\n",
      "    json_file = json.loads(open(json_file_name).read())\n",
      "    json_train += json_file['articles']\n",
      "\n",
      "--------------------\n",
      " Feature Hasher\n",
      "\n",
      "from sklearn.feature_extraction import FeatureHasher\n",
      "\n",
      "hasher_features = 1000\n",
      "\n",
      "hasher = FeatureHasher(input_type='string', n_features=hasher_features)\n",
      "\n",
      "hashed = hasher.transform(labeled_train['author'])\n",
      "\n",
      "hashed = pd.DataFrame(hashed.toarray())\n",
      "\n",
      "hashed.columns = [('author_%d' % author_num) for author_num in range(1, (hasher_features + 1))]\n",
      "\n",
      "labeled_train = pd.concat([labeled_train, hashed], axis=1)\n",
      "\n",
      "labeled_train\n",
      "\n",
      "--------------------\n",
      " predictor model \n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "label = 'istroll'\n",
      "\n",
      "pre = labeled_train.columns.drop(['author_pos', 'author', 'forumid', label])\n",
      "\n",
      "model = RandomForestClassifier(n_estimators=10, n_jobs=6)\n",
      "\n",
      "--------------------\n",
      " cross validation\n",
      "\n",
      "from sklearn import cross_validation\n",
      "\n",
      "cv_value = 3\n",
      "\n",
      "scores = cross_validation.cross_val_score(model, labeled_train[pre], labeled_train[label], cv=cv_value, scoring='roc_auc')\n",
      "\n",
      "cv_result = scores.mean()\n",
      "\n",
      "print(cv_result)\n",
      "\n",
      "--------------------\n",
      " 1 CSV pandas \n",
      "\n",
      "df = pd.read_csv('bukken_data.csv')\n",
      "\n",
      "df = df[:][(df['pay'] < 300000)]\n",
      "\n",
      "df = df.reset_index(drop=True)\n",
      "\n",
      "--------------------\n",
      " 2 Entrenamiento del modelo\n",
      "\n",
      "BernoulliNB().get_params()\n",
      "\n",
      "--------------------\n",
      " 4 Predicci n de la polaridad\n",
      "\n",
      "pipeline = Pipeline([('vect', CountVectorizer(analyzer='word', tokenizer=tokenize, lowercase=True, stop_words=spanish_stopwords, min_df=0, max_df=26363, max_features=1000)), ('cls', BernoulliNB(alpha=1, fit_prior='True'))])\n",
      "\n",
      "pipeline.fit(tweets_df.content, tweets_df.polarity_bin)\n",
      "\n",
      "tweets['polarity'] = pipeline.predict(tweets.content)\n",
      "\n",
      "--------------------\n",
      " Import packages\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "from tqdm import tqdm, tqdm_notebook, tqdm_pandas\n",
      "\n",
      "tqdm_notebook().pandas()\n",
      "\n",
      "--------------------\n",
      " Remove hyper links within the cleaned text\n",
      "\n",
      "import re\n",
      "\n",
      "\n",
      "def remove_link(text):\n",
      "    text = re.sub('http\\\\S+', '', text)\n",
      "    return text\n",
      "\n",
      "--------------------\n",
      " Count number of words\n",
      "\n",
      "from textstat.textstat import textstat\n",
      "\n",
      "--------------------\n",
      " Count number of sentences\n",
      "\n",
      "combined['no_of_sent'] = combined.cleaned.apply(textstat.sentence_count)\n",
      "\n",
      "--------------------\n",
      " Drop useless columns\n",
      "\n",
      "combined.drop(['Id', 'OwnerUserId', 'CreationDate', 'ParentId'], axis=1, inplace=True)\n",
      "\n",
      "--------------------\n",
      " Drop number of words 2\n",
      "\n",
      "combined = combined[(combined.no_of_words >= 2)]\n",
      "\n",
      "--------------------\n",
      " Drop number of sentences 2\n",
      "\n",
      "combined = combined[(combined.no_of_sent >= 2)]\n",
      "\n",
      "--------------------\n",
      " Get SpaCy object\n",
      "\n",
      "import spacy\n",
      "\n",
      "nlp = spacy.load('en')\n",
      "\n",
      "--------------------\n",
      " Get Textacy object\n",
      "\n",
      "import textacy\n",
      "\n",
      "--------------------\n",
      " Get Summary column which contains all other attributes\n",
      "\n",
      "combined['summary'] = combined.textacy.apply(textacy.text_stats.readability_stats)\n",
      "\n",
      "--------------------\n",
      " Convert Summary from string to dict\n",
      "\n",
      "import ast\n",
      "\n",
      "--------------------\n",
      " Get number of polysyllable words\n",
      "\n",
      "\n",
      "def get_no_of_polysyllable_words(data):\n",
      "    return data.get('n_polysyllable_words')\n",
      "\n",
      "--------------------\n",
      " Get flesch readability\n",
      "\n",
      "\n",
      "def get_flesch_readability(data):\n",
      "    return data.get('flesch_readability_ease')\n",
      "\n",
      "--------------------\n",
      " Get sentiment score by Textblob\n",
      "\n",
      "from textblob import TextBlob\n",
      "\n",
      "\n",
      "def get_textblob_sentiment(data):\n",
      "    score = TextBlob(data)\n",
      "    score = score.sentiment.polarity\n",
      "    return score\n",
      "\n",
      "--------------------\n",
      " Get subjectivity by Textblob\n",
      "\n",
      "\n",
      "def get_textblob_subjectivity(data):\n",
      "    score = TextBlob(data)\n",
      "    score = score.sentiment.subjectivity\n",
      "    return score\n",
      "\n",
      "--------------------\n",
      " by calculating the percentage of NUM and DET words in the sentence\n",
      "\n",
      "\n",
      "def get_quantitative(data):\n",
      "    token_pos = [token.pos_ for token in data]\n",
      "    counter = 0\n",
      "    for i in range(0, len(token_pos)):\n",
      "        if ((token_pos[i] == 'NUM') or (token_pos[i] == 'DET')):\n",
      "            counter += 1\n",
      "    if (len(token_pos) == 0):\n",
      "        return 0\n",
      "    else:\n",
      "        return (counter / len(token_pos))\n",
      "\n",
      "--------------------\n",
      " Transform Score into Good or Bad\n",
      "\n",
      "combined['good_bad'] = 0\n",
      "\n",
      "--------------------\n",
      " Sampling\n",
      "\n",
      "sample = combined[((combined.no_of_sent >= 1) & ((combined.Score > 21) | (combined.Score < 0)))].copy()\n",
      "\n",
      "--------------------\n",
      " Regression\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "from pandas.stats.api import ols\n",
      "\n",
      "--------------------\n",
      " Define a funtion to get the ROC AUC score Logistic Regression\n",
      "\n",
      "\n",
      "def get_model_score(variable_list_input):\n",
      "    X = sample[variable_list_input]\n",
      "    y = sample['good_bad']\n",
      "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, random_state=1)\n",
      "    logistic_model = logistic.fit(X_train, y_train)\n",
      "    y_prob = logistic_model.predict_proba(X_test)[:, 1]\n",
      "    return metrics.roc_auc_score(y_test, y_prob)\n",
      "\n",
      "--------------------\n",
      " Generate different combination of the 9 parameters for comparison later\n",
      "\n",
      "variable_list = ['is_code_present', 'no_of_words', 'no_of_sent', 'no_of_polysyllable_words', 'flesch_readability', 'sentiment', 'subjectivity', 'quantitative', 'descriptive']\n",
      "\n",
      "--------------------\n",
      " Try all possible combination of variables see which one performs the best\n",
      "\n",
      "best_variable_combination = []\n",
      "\n",
      "best_score = 0\n",
      "\n",
      "for subset in combination_list:\n",
      "    score = get_model_score(subset)\n",
      "    if (score > best_score):\n",
      "        best_score = score\n",
      "        best_variable_combination = subset\n",
      "        print(best_score)\n",
      "        print(best_variable_combination)\n",
      "\n",
      "--------------------\n",
      " Sparse Matrices\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from scipy import sparse\n",
      "\n",
      "--------------------\n",
      " Load Data\n",
      "\n",
      "train_full_df = pd.read_csv('train_data.csv')\n",
      "\n",
      "--------------------\n",
      " Majority vote\n",
      "\n",
      "mv_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])\n",
      "\n",
      "clf_labels += ['Majority Voting']\n",
      "\n",
      "all_clf = [pipe1, clf2, pipe3, mv_clf]\n",
      "\n",
      "for (clf, label) in zip(all_clf, clf_labels):\n",
      "    scores = cross_val_score(estimator=clf, X=X_train, y=y_train, cv=10, scoring='roc_auc')\n",
      "    print(('ROC AUC: %0.2f (+/- %0.2f) [%s]' % (scores.mean(), scores.std(), label)))\n",
      "\n",
      "--------------------\n",
      " Plot decision regions\n",
      "\n",
      "sc = StandardScaler()\n",
      "\n",
      "X_train_std = sc.fit_transform(X_train)\n",
      "\n",
      "--------------------\n",
      " Get the parameter names \n",
      "\n",
      "mv_clf.get_params()\n",
      "\n",
      "--------------------\n",
      " Encoding and splitting\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "if (Version(sklearn_version) < '0.18'):\n",
      "    from sklearn.cross_validation import train_test_split\n",
      "else:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "\n",
      "le = LabelEncoder()\n",
      "\n",
      "y = le.fit_transform(y)\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.4, random_state=1)\n",
      "\n",
      "--------------------\n",
      " Bagging classifier\n",
      "\n",
      "from sklearn.ensemble import BaggingClassifier\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "tree = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=1)\n",
      "\n",
      "bag = BaggingClassifier(base_estimator=tree, n_estimators=500, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, n_jobs=1, random_state=1)\n",
      "\n",
      "--------------------\n",
      " AdaBoost code example\n",
      "\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "tree = DecisionTreeClassifier(criterion='entropy', max_depth=1, random_state=0)\n",
      "\n",
      "ada = AdaBoostClassifier(base_estimator=tree, n_estimators=500, learning_rate=0.1, random_state=0)\n",
      "\n",
      "--------------------\n",
      " Lab 7 Text Classification with SVM\n",
      "\n",
      "from sklearn.datasets import load_files\n",
      "\n",
      "movie_reviews_data_folder = 'lab7.data/movie_reviews/txt_sentoken'\n",
      "\n",
      "dataset = load_files(movie_reviews_data_folder, shuffle=False)\n",
      "\n",
      "--------------------\n",
      " Print the classification report\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "print(metrics.classification_report(y_test, y_predicted, target_names=dataset.target_names))\n",
      "\n",
      "--------------------\n",
      " Print and plot the confusion matrix\n",
      "\n",
      "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
      "\n",
      "print(cm)\n",
      "\n",
      "--------------------\n",
      " Setting up the Notebook\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "plt.style.use('notebook')\n",
      "\n",
      "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
      "\n",
      "colors = ['#2078B5', '#FF7F0F', '#2CA12C', '#D72827', '#9467BE', '#8C574B', '#E478C2', '#808080', '#BCBE20', '#17BED0', '#AEC8E9', '#FFBC79', '#98E08B', '#FF9896', '#C6B1D6', '#C59D94', '#F8B7D3', '#C8C8C8', '#DCDC8E', '#9EDAE6']\n",
      "\n",
      "--------------------\n",
      " Step 1 at present f x it not normalized so we need to turn it into a probability distribution \n",
      "\n",
      "from scipy import integrate\n",
      "\n",
      "(xmin, xmax) = ((- 5), 5)\n",
      "\n",
      "f = (lambda x: (1.0 / np.sqrt(np.cosh(x))))\n",
      "\n",
      "A = (1.0 / integrate.quad(f, xmin, xmax)[0])\n",
      "\n",
      "print(A)\n",
      "\n",
      "p = (lambda x: (A * f(x)))\n",
      "\n",
      "--------------------\n",
      " Step 2 determine the maximual value of p x on the interval\n",
      "\n",
      "px = np.linspace(xmin, xmax, 10000)\n",
      "\n",
      "plt.plot(px, p(px), color=colors[0], label=('$\\\\frac{%4.2f}{\\\\sqrt{\\\\cosh(x)}}$' % A))\n",
      "\n",
      "plt.xlabel('x')\n",
      "\n",
      "plt.ylabel('p(x)')\n",
      "\n",
      "plt.xlim((- 5), 5)\n",
      "\n",
      "plt.legend()\n",
      "\n",
      "--------------------\n",
      " Step 3 Generate the two lists of random numbers\n",
      "\n",
      "N = (10 ** 6)\n",
      "\n",
      "x = (xmin + ((xmax - xmin) * np.random.random(N)))\n",
      "\n",
      "y = (p(0) * np.random.random(N))\n",
      "\n",
      "--------------------\n",
      " Step 4 perform the rejection\n",
      "\n",
      "accepted = x[(y < p(x))]\n",
      "\n",
      "--------------------\n",
      " Script settings\n",
      "\n",
      "EXO_File = 'strategy_880131'\n",
      "\n",
      "costs_options = 3.0\n",
      "\n",
      "costs_futures = 3.0\n",
      "\n",
      "NSwarm_Members = 5\n",
      "\n",
      "STRATEGY_PARAMS = [OptParam('SlowMAPeriod', 20, 10, 30, 2), OptParam('FastMAPeriod', 2, 2, 20, 1), OptParam('MedianPeriod', 5, 5, 20, 3)]\n",
      "\n",
      "up_factor = 3.0\n",
      "\n",
      "down_factor = 10.0\n",
      "\n",
      "--------------------\n",
      " Exo data\n",
      "\n",
      "strategyname_global = EXO_File\n",
      "\n",
      "(d, info) = matlab.loaddata((('../mat/' + strategyname_global) + '.mat'))\n",
      "\n",
      "--------------------\n",
      " Checkin SplLevel equality splThreshold 8 \n",
      "\n",
      "figsize(15, 15)\n",
      "\n",
      "g_price.plot()\n",
      "\n",
      "g_splLevel.plot()\n",
      "\n",
      "splLevel.plot()\n",
      "\n",
      "--------------------\n",
      " Even Though I print out correlation digits it s still hard to tell how salaries affect people s mentality\n",
      "\n",
      "df_low = df[(df['salary'] == 'low')]\n",
      "\n",
      "df_medium = df[(df['salary'] == 'medium')]\n",
      "\n",
      "df_high = df[(df['salary'] == 'high')]\n",
      "\n",
      "print('{} with low salary '.format(df_low.size))\n",
      "\n",
      "print('{} with medium salary'.format(df_medium.size))\n",
      "\n",
      "print('{} with high salary'.format(df_high.size))\n",
      "\n",
      "--------------------\n",
      " Salary and Sale feature plot\n",
      "\n",
      "sns.factorplot('sales', col='salary', col_wrap=4, data=df, kind='count', size=10, aspect=0.8)\n",
      "\n",
      "--------------------\n",
      " Satisfaction level by sales\n",
      "\n",
      "df.groupby('sales').mean()['satisfaction_level'].plot(kind='bar', color='r')\n",
      "\n",
      "--------------------\n",
      " Predict left 1 by other features\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.calibration import CalibratedClassifierCV\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "from sklearn.feature_selection import SelectFromModel\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "--------------------\n",
      " RandomForest scores so high Hmmm it actually make sense because we make up mind to quit a job by a serial decision making\n",
      "\n",
      "indices = np.argsort(radm.feature_importances_)[::(- 1)]\n",
      "\n",
      "print('Feature ranking:')\n",
      "\n",
      "for f in range(df1.shape[1]):\n",
      "    print(('%d. feature %d %s (%f)' % ((f + 1), indices[f], df1.columns[indices[f]], radm.feature_importances_[indices[f]])))\n",
      "\n",
      "--------------------\n",
      " Part 1 Model building in scikit learn refresher \n",
      "\n",
      "from sklearn.datasets import load_iris\n",
      "\n",
      "iris = load_iris()\n",
      "\n",
      "--------------------\n",
      " Part 2 Representing text as numerical data\n",
      "\n",
      "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']\n",
      "\n",
      "--------------------\n",
      " Part 3 Reading a text based dataset into pandas\n",
      "\n",
      "path = 'data/sms.tsv'\n",
      "\n",
      "sms = pd.read_table(path, header=None, names=['label', 'message'])\n",
      "\n",
      "--------------------\n",
      " Part 4 Vectorizing our dataset\n",
      "\n",
      "vect = CountVectorizer()\n",
      "\n",
      "--------------------\n",
      " Lab 7 QR 1 \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scipy.linalg\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " Problem 2\n",
      "\n",
      "\n",
      "def absdet(A):\n",
      "    if (A.shape[0] != A.shape[1]):\n",
      "        raise ValueError('Please Enter an nxn matrix')\n",
      "    else:\n",
      "        return np.absolute(gsmod(A)[1].diagonal()).prod()\n",
      "\n",
      "--------------------\n",
      " Problem 1\n",
      "\n",
      "\n",
      "def linsolve2(A, b):\n",
      "    (Q, R) = gsmod(A)\n",
      "    yvec = np.dot(Q.T, b)\n",
      "    return scipy.linalg.solve_triangular(R, yvec)\n",
      "\n",
      "--------------------\n",
      " Problem 2\n",
      "\n",
      "housing = np.load('housing.npy')\n",
      "\n",
      "A_housing = np.column_stack((np.ones_like(housing[:, 0]), housing[:, 0]))\n",
      "\n",
      "b_housing = housing[:, 1]\n",
      "\n",
      "coef = linsolve2(A_housing, b_housing)\n",
      "\n",
      "--------------------\n",
      " Exercise 1\n",
      "\n",
      "from numba import jit\n",
      "\n",
      "--------------------\n",
      " The following gets a summaries of the articles that are inserted\n",
      "\n",
      "from gensim.summarization import summarize\n",
      "\n",
      "from gensim.summarization import keywords\n",
      "\n",
      "--------------------\n",
      " Note only some percent of the full data set which is in total 986 677 rows\n",
      "\n",
      "data.head(n=2)\n",
      "\n",
      "--------------------\n",
      " Are a greater number of providers associated with a lower average cost This could be evidence of local competition \n",
      "\n",
      "data_by_zipcode = data.groupby(by='simple_zip')\n",
      "\n",
      "number_of_providers = data_by_zipcode.size()\n",
      "\n",
      "average_of_average_payment = data_by_zipcode.avg_sbmttd_chrg_amt.mean()\n",
      "\n",
      "--------------------\n",
      " Is a average risk associated with a higher average charge \n",
      "\n",
      "x = np.log(data.avg_sbmttd_chrg_amt)\n",
      "\n",
      "y = data.average_hcc_risk_score_of_beneficiaries\n",
      "\n",
      "plt.scatter(x, y, alpha=0.5)\n",
      "\n",
      "plt.xlabel('(Log) Average submitted charge amount')\n",
      "\n",
      "plt.ylabel('Average HCC Risk Score')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " What about specialty \n",
      "\n",
      "groups = data.groupby('provider_type_of_the_provider')\n",
      "\n",
      "top_6_groups = groups.size().sort_values(ascending=False)[0:6]\n",
      "\n",
      "print(top_6_groups)\n",
      "\n",
      "new_gb = pd.concat([groups.get_group(group_name) for group_name in list(top_6_groups.index)])\n",
      "\n",
      "--------------------\n",
      " load calour\n",
      "\n",
      "import calour as ca\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
      "\n",
      "--------------------\n",
      " Load Data\n",
      "\n",
      "\n",
      "def get_train_data(base_path='./data/image/'):\n",
      "    data = {\n",
      "        'filename': [],\n",
      "        'label': [],\n",
      "    }\n",
      "    files = os.listdir(base_path)\n",
      "    for f in files:\n",
      "        label = f.split('.')[0]\n",
      "        data['filename'].append(f)\n",
      "        data['label'].append(label)\n",
      "    return pd.DataFrame(data)\n",
      "\n",
      "--------------------\n",
      " Keras image Generator\n",
      "\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "--------------------\n",
      " Predict\n",
      "\n",
      "test_path = './data/test/'\n",
      "\n",
      "test_data_gen = ImageDataGenerator(rescale=(1.0 / 255))\n",
      "\n",
      "test_generator = test_data_gen.flow_from_directory(test_path, target_size=(img_width, img_height), batch_size=batch_size)\n",
      "\n",
      "--------------------\n",
      " posts train\n",
      "\n",
      "posts_train.head()\n",
      "\n",
      "--------------------\n",
      " tags\n",
      "\n",
      "vectorizer = CountVectorizer(stop_words='english')\n",
      "\n",
      "X = vectorizer.fit_transform(tags.TagName.values)\n",
      "\n",
      "vectorizer.vocabulary_\n",
      "\n",
      "docs = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
      "\n",
      "--------------------\n",
      " comments train\n",
      "\n",
      "comments_train.head()\n",
      "\n",
      "--------------------\n",
      " users\n",
      "\n",
      "users = pd.read_csv('/Users/nichollejames/Desktop/DSI-SF-2-oboechick/projects/project-07/stack_exchange_travel/users.csv')\n",
      "\n",
      "--------------------\n",
      " Model 1 ENTSOE Only\n",
      "\n",
      "test_results_01 = test_results_01.sort_values('Mean absolute error', ascending=True)\n",
      "\n",
      "best_models['m1'] = [test_results_01.loc[0]['Model name'], ['entsoe']]\n",
      "\n",
      "test_results_01\n",
      "\n",
      "--------------------\n",
      " Model 2 Calendar only\n",
      "\n",
      "test_results_02 = test_results_02.sort_values('Mean absolute error', ascending=True)\n",
      "\n",
      "best_models['m2'] = [test_results_02.loc[0]['Model name'], ['calendar']]\n",
      "\n",
      "test_results_02\n",
      "\n",
      "--------------------\n",
      " Model 3 Weather only\n",
      "\n",
      "test_results_03 = test_results_03.sort_values('Mean absolute error', ascending=True)\n",
      "\n",
      "best_models['m3'] = [test_results_03.loc[0]['Model name'], ['weather']]\n",
      "\n",
      "test_results_03\n",
      "\n",
      "--------------------\n",
      " Model 4 ENTSOE Calendar\n",
      "\n",
      "test_results_04 = test_results_04.sort_values('Mean absolute error', ascending=True)\n",
      "\n",
      "best_models['m4'] = [test_results_04.loc[0]['Model name'], ['entsoe', 'calendar']]\n",
      "\n",
      "test_results_04\n",
      "\n",
      "--------------------\n",
      " Model 6 All available data\n",
      "\n",
      "test_results_06 = test_results_06.sort_values('Mean absolute error', ascending=True)\n",
      "\n",
      "best_models['m6'] = [test_results_06.loc[0]['Model name'], ['all']]\n",
      "\n",
      "test_results_06\n",
      "\n",
      "--------------------\n",
      " Define data folders data and sample name\n",
      "\n",
      "annotation = '/annotation_dir/'\n",
      "\n",
      "tmp = '/input_data/'\n",
      "\n",
      "input_dir = '/output_dir/'\n",
      "\n",
      "output_dir = '/output_dir/'\n",
      "\n",
      "input_fq_1 = 'rnaseq_mesc_1_1M.fq.gz'\n",
      "\n",
      "input_fq_2 = 'rnaseq_mesc_2_1M.fq.gz'\n",
      "\n",
      "treat_fq_1 = 'rnaseq_mesc_1_1M.fq.gz'\n",
      "\n",
      "treat_fq_2 = 'rnaseq_mesc_2_1M.fq.gz'\n",
      "\n",
      "sample_name = 'rnaseq_mesc_1M_wt'\n",
      "\n",
      "treat_name = 'rnaseq_mesc_1M_treat'\n",
      "\n",
      "--------------------\n",
      " Wildtype\n",
      "\n",
      "get_ipython().system('rsem-calculate-expression     --output-genome-bam --star --star-gzipped-read-file     -p 16 --append-names     --paired-end $input_dir$input_fq_1 $input_dir$input_fq_2 $annotation\"/mm9_refseq\" $sample_name')\n",
      "\n",
      "--------------------\n",
      " Treatment condition\n",
      "\n",
      "get_ipython().system('rsem-calculate-expression     --output-genome-bam --star --star-gzipped-read-file     -p 16 --append-names     --paired-end $input_dir$treat_fq_1 $input_dir$treat_fq_2 $annotation\"/mm9_refseq\" $treat_name')\n",
      "\n",
      "--------------------\n",
      " Take all the gene results and put them in a matrix\n",
      "\n",
      "get_ipython().system('rsem-generate-data-matrix $sample_name\".genes.results\" $treat_name\".genes.results\" > wt_treat_counts_genes.matrix')\n",
      "\n",
      "--------------------\n",
      " Visulize the data\n",
      "\n",
      "data.hist()\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Prepare the data for classification\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "dataset = data.values\n",
      "\n",
      "X = dataset[:, 0:11].astype(float)\n",
      "\n",
      "Y = dataset[:, 11]\n",
      "\n",
      "features = preprocessing.scale(X)\n",
      "\n",
      "target = Y\n",
      "\n",
      "--------------------\n",
      " Preproccing\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "X_train = preprocessing.normalize(X_train)\n",
      "\n",
      "X_test = preprocessing.normalize(X_test)\n",
      "\n",
      "X_deploy = preprocessing.normalize(X_deploy)\n",
      "\n",
      "X_train = preprocessing.scale(X_train)\n",
      "\n",
      "X_test = preprocessing.scale(X_test)\n",
      "\n",
      "X_deploy = preprocessing.scale(X_deploy)\n",
      "\n",
      "--------------------\n",
      " Feature Selection\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "model = ExtraTreesClassifier()\n",
      "\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "print(model.feature_importances_)\n",
      "\n",
      "--------------------\n",
      " XGBoost eXtreme Gradient Boosting\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "XG_Boost = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, y_train)\n",
      "\n",
      "y_pred = XG_Boost.predict(X_test)\n",
      "\n",
      "print('\\n===================================================================')\n",
      "\n",
      "print('The accuracy on validation dataset of QDA : \\t', metrics.accuracy_score(y_test, y_pred))\n",
      "\n",
      "print('===================================================================')\n",
      "\n",
      "print(metrics.classification_report(y_test, y_pred, target_names=['3', '4', '5', '6', '7', '8', '9']))\n",
      "\n",
      "--------------------\n",
      " Visulize the data\n",
      "\n",
      "data.hist()\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Prepare the data for classification\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "dataset = data.values\n",
      "\n",
      "X = dataset[:, 0:3].astype(float)\n",
      "\n",
      "Y = dataset[:, 3]\n",
      "\n",
      "features = preprocessing.scale(X)\n",
      "\n",
      "target = Y\n",
      "\n",
      "--------------------\n",
      " Feature Selection\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "\n",
      "model = ExtraTreesClassifier()\n",
      "\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "print(model.feature_importances_)\n",
      "\n",
      "--------------------\n",
      " Seaching for the best hyperparameters \n",
      "\n",
      "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "\n",
      "parameters = {\n",
      "    'solver': ('svd', 'lsqr'),\n",
      "}\n",
      "\n",
      "ld = LinearDiscriminantAnalysis()\n",
      "\n",
      "clf = grid_search.GridSearchCV(ld, parameters)\n",
      "\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "report(clf.grid_scores_)\n",
      "\n",
      "--------------------\n",
      " Test model\n",
      "\n",
      "\n",
      "def get_next(inp):\n",
      "    idxs = [char_indices[c] for c in inp]\n",
      "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
      "    p = model.predict(arrs)\n",
      "    i = np.argmax(p)\n",
      "    return chars[i]\n",
      "\n",
      "--------------------\n",
      " Create and train model\n",
      "\n",
      "\n",
      "def embedding_input(name, n_in, n_out):\n",
      "    inp = Input(shape=(1,), dtype='int64', name=(name + '_in'))\n",
      "    emb = Embedding(n_in, n_out, input_length=1, name=(name + '_emb'))(inp)\n",
      "    return (inp, Flatten()(emb))\n",
      "\n",
      "--------------------\n",
      " Test model\n",
      "\n",
      "\n",
      "def get_next(inp):\n",
      "    idxs = [np.array(char_indices[c])[np.newaxis] for c in inp]\n",
      "    p = model.predict(idxs)\n",
      "    return chars[np.argmax(p)]\n",
      "\n",
      "--------------------\n",
      " Our first RNN with keras \n",
      "\n",
      "(n_hidden, n_fac, cs, vocab_size) = (256, 42, 8, 86)\n",
      "\n",
      "--------------------\n",
      " Create and train model\n",
      "\n",
      "dense_in = Dense(n_hidden, activation='relu')\n",
      "\n",
      "dense_hidden = Dense(n_hidden, activation='relu', init='identity')\n",
      "\n",
      "dense_out = Dense(vocab_size, activation='softmax', name='output')\n",
      "\n",
      "--------------------\n",
      " Sequence model with keras\n",
      "\n",
      "(n_hidden, n_fac, cs, vocab_size)\n",
      "\n",
      "--------------------\n",
      " Stateful model with keras\n",
      "\n",
      "bs = 64\n",
      "\n",
      "--------------------\n",
      " Theano RNN\n",
      "\n",
      "n_input = vocab_size\n",
      "\n",
      "n_output = vocab_size\n",
      "\n",
      "--------------------\n",
      " Train indeces and Test indeces\n",
      "\n",
      "train_indeces = np.random.choice(len(x_vals), int(round((len(x_vals) * 0.8))), replace=False)\n",
      "\n",
      "--------------------\n",
      " normalization\n",
      "\n",
      "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\n",
      "\n",
      "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))\n",
      "\n",
      "--------------------\n",
      " Define the Layer Model\n",
      "\n",
      "batch_size = 50\n",
      "\n",
      "x_data = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
      "\n",
      "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
      "\n",
      "--------------------\n",
      " chi 2 \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from scipy import stats\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "observed_frequences = np.bincount(data)\n",
      "\n",
      "observed_frequences\n",
      "\n",
      "--------------------\n",
      " CNN Transfer Learning with VGG16 Part 1 \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import h5py\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "import keras\n",
      "\n",
      "from keras.applications.vgg16 import preprocess_input\n",
      "\n",
      "from keras.applications.vgg16 import VGG16\n",
      "\n",
      "from keras.preprocessing import image\n",
      "\n",
      "from keras.layers import Input, Flatten, Dense\n",
      "\n",
      "from keras.models import Model\n",
      "\n",
      "--------------------\n",
      " Train the new model \n",
      "\n",
      "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-06)\n",
      "\n",
      "new_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
      "\n",
      "--------------------\n",
      " Compile the Model\n",
      "\n",
      "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "--------------------\n",
      " Load the Model with the Best Validation Loss\n",
      "\n",
      "model.load_weights('saved_models/weights.best.from_scratch.hdf5')\n",
      "\n",
      "--------------------\n",
      " Obtain Bottleneck Features\n",
      "\n",
      "bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\n",
      "\n",
      "train_VGG16 = bottleneck_features['train']\n",
      "\n",
      "valid_VGG16 = bottleneck_features['valid']\n",
      "\n",
      "test_VGG16 = bottleneck_features['test']\n",
      "\n",
      "--------------------\n",
      " Compile the Model\n",
      "\n",
      "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
      "\n",
      "--------------------\n",
      " Train the Model\n",
      "\n",
      "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', verbose=1, save_best_only=True)\n",
      "\n",
      "VGG16_model.fit(train_VGG16, train_targets, validation_data=(valid_VGG16, valid_targets), epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
      "\n",
      "--------------------\n",
      " Load the Model with the Best Validation Loss\n",
      "\n",
      "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')\n",
      "\n",
      "--------------------\n",
      " Predict Dog Breed with the Model\n",
      "\n",
      "from extract_bottleneck_features import *\n",
      "\n",
      "\n",
      "def VGG16_predict_breed(img_path):\n",
      "    bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
      "    predicted_vector = VGG16_model.predict(bottleneck_feature)\n",
      "    return dog_names[np.argmax(predicted_vector)]\n",
      "\n",
      "--------------------\n",
      " IMPLEMENTATION Compile the Model\n",
      "\n",
      "Resnet50_model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
      "\n",
      "--------------------\n",
      " IMPLEMENTATION Load the Model with the Best Validation Loss\n",
      "\n",
      "Resnet50_model.load_weights('saved_models/weights.best.Resnet50.hdf5')\n",
      "\n",
      "--------------------\n",
      " Saprawdzamy za o enie o r wno ci variancii \n",
      "\n",
      "(W, p) = stats.levene(group1, group2, group3)\n",
      "\n",
      "if (p < 0.05):\n",
      "    print('Warning: the p-value of the Levene test is <0.05: p={0}'.format(p))\n",
      "else:\n",
      "    print('OK: the p-value of the Levene test is >0.05: p={0}'.format(p))\n",
      "\n",
      "--------------------\n",
      " Wykonuje anoe jednoczynnikow \n",
      "\n",
      "(F_statistic, pVal) = stats.f_oneway(group1, group2, group3)\n",
      "\n",
      "--------------------\n",
      " DS SF 23 Lab 09 Introduction to Logistic Regression\n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import linear_model, cross_validation\n",
      "\n",
      "pd.set_option('display.max_rows', 10)\n",
      "\n",
      "pd.set_option('display.notebook_repr_html', True)\n",
      "\n",
      "pd.set_option('display.max_columns', 10)\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "plt.style.use('ggplot')\n",
      "\n",
      "--------------------\n",
      " Importing\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Numpy arrays\n",
      "\n",
      "a = np.array([1, 2, 3, 4, 5], float)\n",
      "\n",
      "a\n",
      "\n",
      "--------------------\n",
      " Numpy arrays behave similar to Python arrays\n",
      "\n",
      "print(a[2:])\n",
      "\n",
      "print(a[(- 1)])\n",
      "\n",
      "print(a[2:4])\n",
      "\n",
      "print(a[::2])\n",
      "\n",
      "a[0] = 5\n",
      "\n",
      "print(a)\n",
      "\n",
      "--------------------\n",
      " Multi dimensional arrays\n",
      "\n",
      "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "\n",
      "A\n",
      "\n",
      "--------------------\n",
      " Slicing\n",
      "\n",
      "a = np.array(range(15))\n",
      "\n",
      "print(a[1:10:2])\n",
      "\n",
      "a[1::2] = 0\n",
      "\n",
      "print(a)\n",
      "\n",
      "--------------------\n",
      " Array dimensions\n",
      "\n",
      "print(len(A))\n",
      "\n",
      "print(A.shape)\n",
      "\n",
      "--------------------\n",
      " Check occurrence\n",
      "\n",
      "print((2 in A))\n",
      "\n",
      "print((13 in A))\n",
      "\n",
      "--------------------\n",
      " Changing the shape of an array\n",
      "\n",
      "c = np.array([1, 2, 3, 4, 5, 6])\n",
      "\n",
      "print(c)\n",
      "\n",
      "c.reshape((3, 2))\n",
      "\n",
      "--------------------\n",
      " Attention deep copy vs shallow copy\n",
      "\n",
      "a = np.array([1, 2, 3])\n",
      "\n",
      "b = a\n",
      "\n",
      "c = a.copy()\n",
      "\n",
      "a[0] = 6\n",
      "\n",
      "print(a)\n",
      "\n",
      "print(b)\n",
      "\n",
      "print(c)\n",
      "\n",
      "--------------------\n",
      " Further array functions\n",
      "\n",
      "a.tolist()\n",
      "\n",
      "a.fill(12)\n",
      "\n",
      "print(A)\n",
      "\n",
      "print(A.transpose())\n",
      "\n",
      "print(A.T)\n",
      "\n",
      "--------------------\n",
      " Convenient functions to construct arrays\n",
      "\n",
      "np.arange(0, 5, 0.1)\n",
      "\n",
      "--------------------\n",
      " Linear algebra in numpy\n",
      "\n",
      "A = np.array([[1, 2], [6, 7]])\n",
      "\n",
      "np.linalg.det(A)\n",
      "\n",
      "np.linalg.eig(A)\n",
      "\n",
      "np.linalg.inv(A)\n",
      "\n",
      "np.linalg.svd(A)\n",
      "\n",
      "--------------------\n",
      " All operations on arrays are elementwise per default\n",
      "\n",
      "A = np.array([[1, 2], [3, 4]])\n",
      "\n",
      "B = np.array([[0, 1], [1, 0]])\n",
      "\n",
      "(A + B)\n",
      "\n",
      "(A - B)\n",
      "\n",
      "(A * B)\n",
      "\n",
      "(B / A)\n",
      "\n",
      "(A ** B)\n",
      "\n",
      "--------------------\n",
      " smaller arrays are broadcasted automatically\n",
      "\n",
      "A = np.ones((3, 3))\n",
      "\n",
      "c = np.array([1, 2, 3])\n",
      "\n",
      "(A + c)\n",
      "\n",
      "(A + c[:, np.newaxis])\n",
      "\n",
      "--------------------\n",
      " Matrix multiplication\n",
      "\n",
      "A = np.array([[0, 1], [1, 0]])\n",
      "\n",
      "v = np.array([6, 7])\n",
      "\n",
      "np.dot(A, v)\n",
      "\n",
      "--------------------\n",
      " Advaned array acessing\n",
      "\n",
      "a = np.array([1, 6, 3, 4, 9, 6, 7, 3, 2, 4, 5])\n",
      "\n",
      "a[(a > 4)]\n",
      "\n",
      "a[np.logical_and((a > 4), (a < 12))]\n",
      "\n",
      "indices = [1, 3]\n",
      "\n",
      "a[indices]\n",
      "\n",
      "--------------------\n",
      " Example 1 numerical minimization of a function\n",
      "\n",
      "\n",
      "def myfunc(x):\n",
      "    return (((3 + x) * (3 - x)) * (- 12))\n",
      "\n",
      "sp.optimize.minimize_scalar(myfunc)\n",
      "\n",
      "--------------------\n",
      " Compare exact and numerical solutions\n",
      "\n",
      "exact = (x0 * np.exp((k_g * time)))\n",
      "\n",
      "(exact - result.T)\n",
      "\n",
      "plt.plot(time, (exact - result.T).T)\n",
      "\n",
      "--------------------\n",
      " Corundum\n",
      "\n",
      "corundum_scan = scimap.XRDScan(filename='test-data-xrd/corundum.brml')\n",
      "\n",
      "corundum_scan.plot_diffractogram()\n",
      "\n",
      "--------------------\n",
      " Remove a Peak\n",
      "\n",
      "(q, y) = scimap.remove_peak_from_df(x=corundum_scan.scattering_lengths, y=corundum_scan.intensities, xrange=(2, 3))\n",
      "\n",
      "print(len(q), len(y))\n",
      "\n",
      "plt.plot(q, y, marker='+', linestyle='None')\n",
      "\n",
      "--------------------\n",
      " Peak Fitting\n",
      "\n",
      "celref_peaks = [('012', 3.4746228816945104, 25.637288649553085), ('104', 2.5479680737754244, 35.22223164557721), ('110', 2.375, 37.88141047624646), ('006', 2.1636666666666664, 41.74546075011751), ('113', 2.0820345582756135, 43.46365474219995), ('024', 1.7373114408472552, 52.68443192186963), ('116', 1.5994489779586798, 57.62940019834231)]\n",
      "\n",
      "two_theta = np.array([p[2] for p in celref_peaks])\n",
      "\n",
      "scimap.twotheta_to_q(two_theta, scimap.tubes['Cu'].kalpha.num)\n",
      "\n",
      "--------------------\n",
      " Assignment 1\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import os\n",
      "\n",
      "import sys\n",
      "\n",
      "import tarfile\n",
      "\n",
      "import random\n",
      "\n",
      "from IPython.display import display, Image\n",
      "\n",
      "from scipy import ndimage\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from six.moves.urllib.request import urlretrieve\n",
      "\n",
      "from six.moves import cPickle as pickle\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " Get recipe names into a vector\n",
      "\n",
      "stopwords = nltk.corpus.stopwords.words('english')\n",
      "\n",
      "stemmer = SnowballStemmer('english')\n",
      "\n",
      "--------------------\n",
      " Multinomial Bayes\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "X_train = culled_array[200:]\n",
      "\n",
      "y_train = cholcat[200:]\n",
      "\n",
      "X = X_train\n",
      "\n",
      "y = y_train\n",
      "\n",
      "X_test = culled_array[:200]\n",
      "\n",
      "y_test = cholcat[:200]\n",
      "\n",
      "mnb = MultinomialNB().fit(X, y)\n",
      "\n",
      "--------------------\n",
      " Bernoulli Naive Bayes\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "\n",
      "X_train = culled_array[200:]\n",
      "\n",
      "y_train = cholcat[200:]\n",
      "\n",
      "X = X_train\n",
      "\n",
      "y = y_train\n",
      "\n",
      "X_test = culled_array[:200]\n",
      "\n",
      "y_test = cholcat[:200]\n",
      "\n",
      "bnb = BernoulliNB().fit(X, y)\n",
      "\n",
      "--------------------\n",
      " next is to handle missing values\n",
      "\n",
      "df = df.drop(df.columns[12:18], axis=1)\n",
      "\n",
      "--------------------\n",
      " Imports\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " 3 pedestrians \n",
      "\n",
      "import matplotlib\n",
      "\n",
      "matplotlib.reload(vs)\n",
      "\n",
      "--------------------\n",
      " Uniform Horn\n",
      "\n",
      "x = np.arange(0, 10000, 0.1)\n",
      "\n",
      "Z_L = (Z * ())\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "all = data\n",
      "\n",
      "len(all[:][(all['AbsSignal_s'] > 5000)])\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "param = ['EAS', 'Crit1', 'dt2_n', 'ng_n', 'dt2_s', 'AbsSignal_n', 'SNRatio_s', 'Crit2']\n",
      "\n",
      "features = param[1:]\n",
      "\n",
      "--------------------\n",
      " EAS\n",
      "\n",
      "data.corr(method='pearson')\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "clf.decision_path(X)\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "features = param[1:6]\n",
      "\n",
      "X = data[features]\n",
      "\n",
      "Y = data['EAS']\n",
      "\n",
      "clf = DecisionTreeClassifier(random_state=20, max_leaf_nodes=8, min_samples_leaf=2)\n",
      "\n",
      "clf.fit(X, Y)\n",
      "\n",
      "importances = clf.feature_importances_\n",
      "\n",
      "for i in range(len(importances)):\n",
      "    print(('%20s   %7f' % (features[i], importances[i])))\n",
      "\n",
      "--------------------\n",
      " ESLE\n",
      "\n",
      "clf.score(X, Y)\n",
      "\n",
      "--------------------\n",
      " Imports\n",
      "\n",
      "get_ipython().system('pip install lxml')\n",
      "\n",
      "--------------------\n",
      " Pulling URLs steps\n",
      "\n",
      "import requests\n",
      "\n",
      "response = requests.get(link)\n",
      "\n",
      "HTML = response.text\n",
      "\n",
      "--------------------\n",
      " Test modification of link\n",
      "\n",
      "search_term = 'data source'\n",
      "\n",
      "location = 'Boston, MA'\n",
      "\n",
      "link = (((('https://www.indeed.com/jobs?q=' + search_term) + '&l=') + location) + '&start=')\n",
      "\n",
      "link\n",
      "\n",
      "--------------------\n",
      " Functions\n",
      "\n",
      "\n",
      "def page(link):\n",
      "    response = requests.get(link)\n",
      "    HTML = response.text\n",
      "    return html.fromstring(HTML)\n",
      "\n",
      "--------------------\n",
      " Xpath search term to pull all urls for listings off Indeed com main listing page\n",
      "\n",
      "main_xpath = {\n",
      "    'job_title': \"//div[contains(@class,'result')]//a[@data-tn-element='jobTitle']/@title\",\n",
      "    'job_url': \"//div[contains(@class,'result')]//a[@data-tn-element='jobTitle']/@href\",\n",
      "    'job_id': \"//div[contains(@class,'result')]/@data-jk\",\n",
      "    'job_id2': '//div/@data-jk',\n",
      "    'end': \"//div[@class='pagination']//span[@class='pn']/span[@class='np']/text()\",\n",
      "    'job_count': \"//div[@id='searchCount']/text()\",\n",
      "}\n",
      "\n",
      "--------------------\n",
      " Check it saved\n",
      "\n",
      "get_ipython().system(\"ls './Boston'\")\n",
      "\n",
      "--------------------\n",
      " Breakthrough text \n",
      "\n",
      "desc_xpath = {\n",
      "    'comp_name': \"//div[@data-tn-component='jobHeader']/span[@class='company']/text()\",\n",
      "    'job_title': \"//div[@data-tn-component='jobHeader']/b/font/text()\",\n",
      "    'job_loc': \"//div[@data-tn-component='jobHeader']/span[@class='location']/text()\",\n",
      "    'job_summary': \"//td[@class='snip']/span[@id='job_summary']//text()\",\n",
      "    'job_count': \"//div[@id='searchCount']/text()\",\n",
      "}\n",
      "\n",
      "--------------------\n",
      " Make functions to add these\n",
      "\n",
      "from lxml import html\n",
      "\n",
      "--------------------\n",
      " EDA the job summary text\n",
      "\n",
      "df = df.reset_index()\n",
      "\n",
      "df.drop('index', axis=1, inplace=True)\n",
      "\n",
      "df.drop('html', axis=1, inplace=True)\n",
      "\n",
      "--------------------\n",
      " df job title str contains A \n",
      "\n",
      "link = 'https://www.indeed.com/company/Newton-Colmore-Consulting-Ltd/jobs/Data-Scientist-Deep-Learning-0b97704eee16f3be?fccid=66a59a212fc22e05'\n",
      "\n",
      "print(page(link).xpath(desc_xpath['comp_name']))\n",
      "\n",
      "print(page(link).xpath(desc_xpath['job_title']))\n",
      "\n",
      "print(page(link).xpath(desc_xpath['job_loc']))\n",
      "\n",
      "print(page(link).xpath(desc_xpath['job_summary']))\n",
      "\n",
      "--------------------\n",
      " Import nltk the data is saved on my 2nd harddrive so add path\n",
      "\n",
      "import nltk\n",
      "\n",
      "nltk.data.path.append('/Volumes/Secondary/')\n",
      "\n",
      "--------------------\n",
      " Rolled no duplicates into the html downloading so I didn t waste time\n",
      "\n",
      "df.shape\n",
      "\n",
      "--------------------\n",
      " Set label to numeric get baseline prediction 67\n",
      "\n",
      "df['title_num'] = df['title'].map({\n",
      "    'junior': 0,\n",
      "    'senior': 1,\n",
      "})\n",
      "\n",
      "--------------------\n",
      " Industry df\n",
      "\n",
      "df_gov = pd.read_csv('government.csv', encoding='latin1')\n",
      "\n",
      "df_health = pd.read_csv('healthcare.csv', encoding='latin1')\n",
      "\n",
      "df_bank = pd.read_csv('banking.csv', encoding='latin1')\n",
      "\n",
      "df_ins = pd.read_csv('insurance.csv', encoding='latin1')\n",
      "\n",
      "df_manu = pd.read_csv('manufacturing.csv', encoding='latin1')\n",
      "\n",
      "--------------------\n",
      " Pretty large if want to quicken up subset based on search phrase\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "--------------------\n",
      " Add Lemmantizer to the countvectorizer\n",
      "\n",
      "from nltk import word_tokenize\n",
      "\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "\n",
      "\n",
      "class LemmaTokenizer(object):\n",
      "\n",
      "    def __init__(self):\n",
      "        self.wnl = WordNetLemmatizer()\n",
      "\n",
      "    def __call__(self, doc):\n",
      "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
      "\n",
      "vect = CountVectorizer(tokenizer=LemmaTokenizer())\n",
      "\n",
      "--------------------\n",
      " Try LDA NMF topic modeling with industry data\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Use this in a model \n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "from sklearn.model_selection import ShuffleSplit\n",
      "\n",
      "--------------------\n",
      " NMF investigation to cluster industry jobs \n",
      "\n",
      "df = pd.read_csv('industry_df.csv', encoding='latin1')\n",
      "\n",
      "--------------------\n",
      " Load Libraries\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Define variables\n",
      "\n",
      "l_parse_date_cols = ['dt_prediction_date', 'dt_target_date', 'dt_flight_date']\n",
      "\n",
      "l_target_cols = ['num_pax_000_014_mins_before_sdt', 'num_pax_015_029_mins_before_sdt', 'num_pax_030_044_mins_before_sdt', 'num_pax_045_059_mins_before_sdt', 'num_pax_060_074_mins_before_sdt', 'num_pax_075_089_mins_before_sdt', 'num_pax_090_104_mins_before_sdt', 'num_pax_105_119_mins_before_sdt', 'num_pax_120_134_mins_before_sdt', 'num_pax_135_149_mins_before_sdt', 'num_pax_150_164_mins_before_sdt', 'num_pax_165_179_mins_before_sdt', 'num_pax_180_194_mins_before_sdt', 'num_pax_195_209_mins_before_sdt', 'num_pax_210_224_mins_before_sdt', 'num_pax_225_239_mins_before_sdt', 'num_pax_240plus_mins_before_sdt']\n",
      "\n",
      "--------------------\n",
      " Function to calculate score\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "\n",
      "def calculate_score(df_target_cases, df_predictions):\n",
      "    'Root-mean-squared error is the chosen error metric. This function calculates and returns the root-mean-squared error'\n",
      "    f_rmse = np.sqrt(mean_squared_error(df_target_cases, df_predictions))\n",
      "    return f_rmse\n",
      "\n",
      "--------------------\n",
      " Read in csv file and set index as id\n",
      "\n",
      "train = pd.read_csv('C:\\\\Users\\\\piush\\\\Desktop\\\\Dataset\\\\data_20161116\\\\train.csv')\n",
      "\n",
      "train = train.set_index('id')\n",
      "\n",
      "test = pd.read_csv('C:\\\\Users\\\\piush\\\\Desktop\\\\Dataset\\\\data_20161116\\\\test.csv')\n",
      "\n",
      "test = test.set_index('id')\n",
      "\n",
      "--------------------\n",
      " Do not include the nans in the test\n",
      "\n",
      "test2 = test[pd.isnull(test).any(axis=1)]\n",
      "\n",
      "--------------------\n",
      " Set target columns\n",
      "\n",
      "target = train[l_target_cols]\n",
      "\n",
      "--------------------\n",
      " Drop the target columns from the training and test dataset\n",
      "\n",
      "df1 = train.drop(l_target_cols, axis=1)\n",
      "\n",
      "test2 = test2.drop(l_target_cols, axis=1)\n",
      "\n",
      "--------------------\n",
      " Concatenate the 2 data sets\n",
      "\n",
      "df = df1.append(test2, ignore_index=True)\n",
      "\n",
      "--------------------\n",
      " Normalize\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "normalized_df = preprocessing.normalize(df)\n",
      "\n",
      "--------------------\n",
      " Split the train and test data sets\n",
      "\n",
      "X = normalized_df[:train.shape[0]]\n",
      "\n",
      "test1 = normalized_df[train.shape[0]:]\n",
      "\n",
      "--------------------\n",
      " Split the data set for checking the score\n",
      "\n",
      "offset = int((X.shape[0] * 0.9))\n",
      "\n",
      "(X_train, y_train) = (X[:offset], target[:offset])\n",
      "\n",
      "(X_test, y_test) = (X[offset:], target[offset:])\n",
      "\n",
      "--------------------\n",
      " Fit regression model\n",
      "\n",
      "from sklearn.linear_model import ElasticNet\n",
      "\n",
      "model = ElasticNet(alpha=0.001, random_state=5)\n",
      "\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "prediction_test = clf.predict(X_test)\n",
      "\n",
      "mse = mean_squared_error(y_test, prediction_test)\n",
      "\n",
      "print(('MSE: %.4f' % mse))\n",
      "\n",
      "--------------------\n",
      " Predict the test data set with Elastic Net\n",
      "\n",
      "from sklearn.linear_model import ElasticNet\n",
      "\n",
      "model = ElasticNet(alpha=0.001, random_state=5)\n",
      "\n",
      "model.fit(X, target)\n",
      "\n",
      "predictions_1 = model.predict(test1).astype(int)\n",
      "\n",
      "--------------------\n",
      " Predictions array\n",
      "\n",
      "predictions_1\n",
      "\n",
      "--------------------\n",
      " Reshape the predictions to a dataframe\n",
      "\n",
      "df4 = predictions_1.reshape(((- 1), 1))\n",
      "\n",
      "--------------------\n",
      " Seasonality of all events\n",
      "\n",
      "(fig, ax) = plt.subplots(figsize=(13, 1))\n",
      "\n",
      "sns.heatmap(daily_count.transpose(), xticklabels=365, robust=True, cmap='YlGnBu')\n",
      "\n",
      "--------------------\n",
      " Seasonality of events separated by type\n",
      "\n",
      "(fig, ax) = plt.subplots(figsize=(12, 12))\n",
      "\n",
      "sns.heatmap(daily_count_by_type.transpose(), xticklabels=365, robust=True, cmap='YlGnBu')\n",
      "\n",
      "--------------------\n",
      " Option 2 Component arrows\n",
      "\n",
      "tokens = ['AAA', 'AEE', 'AHH', 'EHH', 'ERR', 'IHH', 'IYY', 'UHH', 'UWW']\n",
      "\n",
      "blocks = [27]\n",
      "\n",
      "[K, anat, stop_times, start_times] = makeD_multi(pth, blocks, tokens, dtype='kin', align_window=window)\n",
      "\n",
      "Ka = [K[d] for d in tokens]\n",
      "\n",
      "stops = [stop_times[d] for d in tokens]\n",
      "\n",
      "starts = [start_times[d] for d in tokens]\n",
      "\n",
      "--------------------\n",
      " Loading data\n",
      "\n",
      "data = pd.read_csv('data/comments_vrn.csv.gz')\n",
      "\n",
      "--------------------\n",
      " Words count\n",
      "\n",
      "lenghts_word = np.array([len(m.split()) for m in data.text.values])\n",
      "\n",
      "--------------------\n",
      " Links\n",
      "\n",
      "links = [m for m in data.text.values if (('http' in m) or ('www' in m) or ('.ru' in m) or ('.com' in m))]\n",
      "\n",
      "print('{:.2f}% of comments contain links'.format(((len(links) / len(data)) * 100)))\n",
      "\n",
      "--------------------\n",
      " Droping outliers\n",
      "\n",
      "from sklearn.ensemble import IsolationForest\n",
      "\n",
      "--------------------\n",
      " Emoji\n",
      "\n",
      "comments_list = comments.text.values\n",
      "\n",
      "--------------------\n",
      " If not done before\n",
      "\n",
      "len(comments_list)\n",
      "\n",
      "--------------------\n",
      " Else load\n",
      "\n",
      "with open('emoji_from_comments_rep_vrn.pkl', 'rb') as f:\n",
      "    emoji_from_comments_rep = pickle.load(f)\n",
      "\n",
      "emoji_from_comments_no_rep = list(map((lambda com: get_emoji(com, False)), comments_list))\n",
      "\n",
      "(len(comments_list), len(emoji_from_comments_rep))\n",
      "\n",
      "--------------------\n",
      " With repetition\n",
      "\n",
      "print((em_proportion_rep > 0.2).sum())\n",
      "\n",
      "comments_list[(em_proportion_rep > 0.2)][:10]\n",
      "\n",
      "--------------------\n",
      " Without repetition\n",
      "\n",
      "print((em_proportion_no_rep > 0.07).sum())\n",
      "\n",
      "comments_list[(em_proportion_no_rep > 0.07)][:10]\n",
      "\n",
      "--------------------\n",
      " Proportion of alphabetical symbols\n",
      "\n",
      "\n",
      "def get_abc_proportion(comments):\n",
      "    abc_proportion = []\n",
      "    for i in range(len(comments)):\n",
      "        com = re.sub(' *', '', comments[i])\n",
      "        abc = re.findall('[а-яёa-z]', com, flags=re.IGNORECASE)\n",
      "        abc_proportion.append((len(abc) / len(com)))\n",
      "    return np.array(abc_proportion)\n",
      "\n",
      "--------------------\n",
      " Filling DataFrame\n",
      "\n",
      "comments['emojis'] = [' '.join(e) for e in emoji_from_comments_rep]\n",
      "\n",
      "comments['em_proportion_rep'] = em_proportion_rep\n",
      "\n",
      "comments['em_proportion_no_rep'] = em_proportion_no_rep\n",
      "\n",
      "comments['abc_proportion'] = abc_proportion\n",
      "\n",
      "--------------------\n",
      " If message repeats more than one time drop spam \n",
      "\n",
      "print('{} different spam comments'.format((comments.text.value_counts() > 1).sum()))\n",
      "\n",
      "--------------------\n",
      " Dropping outlier\n",
      "\n",
      "spam_comments = comments.text.value_counts()[(comments.text.value_counts() > 1)].keys()\n",
      "\n",
      "comments = comments[comments.text.apply((lambda t: (t not in spam_comments)))]\n",
      "\n",
      "--------------------\n",
      " Clearing comments\n",
      "\n",
      "y = comments.is_gum.values\n",
      "\n",
      "adj_proportion = []\n",
      "\n",
      "errors = []\n",
      "\n",
      "--------------------\n",
      " Word\n",
      "\n",
      "get_ipython().run_cell_magic('time', '', 'clear_coms = clear_comments(comments_list, min_word_len=3, with_emoji=True, with_stemmer=False,\\n                            with_lemmer=True, without_names=True, without_stop_words=False)')\n",
      "\n",
      "--------------------\n",
      " Punctuation count in comment\n",
      "\n",
      "\n",
      "def punctuation_counts(comments, pattern='\\\\(+', partion=False):\n",
      "    if partion:\n",
      "        return [(sum((len(p) for p in re.findall(pattern, c))) / len(c)) for c in comments]\n",
      "    else:\n",
      "        return [(1 if (len(re.findall(pattern, c)) > 0) else 0) for c in comments]\n",
      "\n",
      "--------------------\n",
      " Total words\n",
      "\n",
      "\n",
      "def total_words(comments):\n",
      "    return [(len(com.split()) if (len(com.split()) < 25) else 25) for com in comments]\n",
      "\n",
      "--------------------\n",
      " Total chars\n",
      "\n",
      "\n",
      "def total_chars(comments):\n",
      "    return [(len(com) if (len(com) < 100) else 100) for com in comments]\n",
      "\n",
      "--------------------\n",
      " All comments features together\n",
      "\n",
      "from sklearn.feature_selection import VarianceThreshold\n",
      "\n",
      "--------------------\n",
      " Read csv\n",
      "\n",
      "df = pd.read_csv('car_data.csv')\n",
      "\n",
      "--------------------\n",
      " Linear regression equation for mileage vs price\n",
      "\n",
      "x = df[['Mileage']]\n",
      "\n",
      "y = df[['Price']]\n",
      "\n",
      "lm = linear_model.LinearRegression()\n",
      "\n",
      "lm.fit(x, y)\n",
      "\n",
      "--------------------\n",
      " Portion of mileage vs price 604 entries \n",
      "\n",
      "df1 = pd.DataFrame(mileage_x)\n",
      "\n",
      "df1 = df1.join(mileage_y)\n",
      "\n",
      "sns.lmplot('Mileage', 'Price', data=df1, fit_reg=True)\n",
      "\n",
      "--------------------\n",
      " Mileage vs Price Full Data \n",
      "\n",
      "sns.lmplot('Mileage', 'Price', data=df, fit_reg=True)\n",
      "\n",
      "--------------------\n",
      " Create dummy variables for make model and type\n",
      "\n",
      "dummy_make = pd.get_dummies(df['Make'])\n",
      "\n",
      "dummy_model = pd.get_dummies(df['Model'])\n",
      "\n",
      "dummy_type = pd.get_dummies(df['Type'])\n",
      "\n",
      "--------------------\n",
      " Import modules\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "from math import ceil\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from pandas import DataFrame, read_sql_query\n",
      "\n",
      "from datetime import date\n",
      "\n",
      "from IPython.display import HTML, display\n",
      "\n",
      "display(HTML('<p>Last update {0}</p>'.format(date.today())))\n",
      "\n",
      "--------------------\n",
      " Small data sample\n",
      "\n",
      "boats_df.head()\n",
      "\n",
      "--------------------\n",
      " Decision Tree\n",
      "\n",
      "from sklearn import tree\n",
      "\n",
      "MAX_DEPTH = 3\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=MAX_DEPTH)\n",
      "\n",
      "clf = clf.fit(X, y)\n",
      "\n",
      "--------------------\n",
      " Visualize Decision tree\n",
      "\n",
      "from sklearn.externals.six import StringIO\n",
      "\n",
      "with open('boat_tree.dot', 'w') as f:\n",
      "    f = tree.export_graphviz(clf, out_file=f, feature_names=feature)\n",
      "\n",
      "--------------------\n",
      " Cross Validation\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, random_state=0)\n",
      "\n",
      "clf_2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=MAX_DEPTH)\n",
      "\n",
      "clf_2 = clf_2.fit(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " Persist the model\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "joblib.dump(clf, 'decision_tree.pkl')\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "l = []\n",
      "\n",
      "m = []\n",
      "\n",
      "import math\n",
      "\n",
      "for i in range(rental.shape[0]):\n",
      "    for j in range(rental.shape[1]):\n",
      "        if (type(rental[(i, j)]) != str):\n",
      "            if math.isnan(rental[(i, j)]):\n",
      "                m.append(i)\n",
      "\n",
      "--------------------\n",
      " 5 Lease Type \n",
      "\n",
      "np.unique(rental[:, 3])\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "data = np.hstack((rental[:, :2], rental[:, 5:22]))\n",
      "\n",
      "data = data.astype(float)\n",
      "\n",
      "C = np.corrcoef(data.transpose())\n",
      "\n",
      "import PIL.Image\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "im = PIL.Image.fromarray(plt.cm.gist_earth(C, bytes=True)).show()\n",
      "\n",
      "--------------------\n",
      " Space Type \n",
      "\n",
      "Type = np.unique(rental[:, 2])\n",
      "\n",
      "--------------------\n",
      " 20 \n",
      "\n",
      "plt.scatter(list(range(rental[(rental[:, 2] == Type[9])].shape[0])), rental[((rental[:, 2] == Type[9]), 1)])\n",
      "\n",
      "--------------------\n",
      " Linear Kernel SVM varying C parameter \n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn import svm\n",
      "\n",
      "X_norm = np.zeros(X1.shape)\n",
      "\n",
      "for col in range(X1.shape[1]):\n",
      "    col_mean = X1[:, col].mean()\n",
      "    col_sigma = X1[:, col].std()\n",
      "    X_norm[:, col] = ((X1[:, col] - col_mean) / col_sigma)\n",
      "\n",
      "--------------------\n",
      " Gaussian Kernel Dataset2 \n",
      "\n",
      "mat = scipy.io.loadmat('ex6data2.mat')\n",
      "\n",
      "X2 = mat['X']\n",
      "\n",
      "y2 = mat['y']\n",
      "\n",
      "(fig, ax) = plt.subplots()\n",
      "\n",
      "color = ['r', 'b']\n",
      "\n",
      "ax.scatter(X2[:, 0], X2[:, 1], c=y2)\n",
      "\n",
      "--------------------\n",
      " Python imports\n",
      "\n",
      "import scipy as sp\n",
      "\n",
      "from scipy.integrate import odeint\n",
      "\n",
      "import scipy.linalg\n",
      "\n",
      "import scipy.optimize\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from ipywidgets import interact\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "plt.style.use('ggplot')\n",
      "\n",
      "--------------------\n",
      " Extract texts and process them\n",
      "\n",
      "import warnings\n",
      "\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "from cleaner import *\n",
      "\n",
      "get_ipython().run_line_magic('autoreload', '2')\n",
      "\n",
      "cleaner = Cleaner()\n",
      "\n",
      "clean_text_series = cleaner.cleaning_pipeline_series(emails.ExtractedBodyText.dropna())\n",
      "\n",
      "clean_text_series.head(5)\n",
      "\n",
      "--------------------\n",
      " Topics modeling and choosing the number of topics \n",
      "\n",
      "from classifier import Classifier\n",
      "\n",
      "classifier = Classifier()\n",
      "\n",
      "classifier.define_dictionary(clean_text_series)\n",
      "\n",
      "--------------------\n",
      " Visualization\n",
      "\n",
      "classifier.define_model(clean_text_series, 15, iter)\n",
      "\n",
      "--------------------\n",
      " Please change the pkg path and model file to be correct path\n",
      "\n",
      "pkg_path = '../../python-package/'\n",
      "\n",
      "model_file = 's3://my-bucket/xgb-demo/model/0002.model'\n",
      "\n",
      "sys.path.insert(0, pkg_path)\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "--------------------\n",
      " Plot the Feature Importance\n",
      "\n",
      "bst = xgb.Booster(model_file=model_file)\n",
      "\n",
      "xgb.plot_importance(bst)\n",
      "\n",
      "--------------------\n",
      " Plot the First Tree\n",
      "\n",
      "tree_id = 0\n",
      "\n",
      "xgb.to_graphviz(bst, tree_id)\n",
      "\n",
      "--------------------\n",
      " Chisquare test\n",
      "\n",
      "\n",
      "def chisq(model, y, e, dof):\n",
      "    dof = ((len(y) - dof) - 1)\n",
      "    return (sum((((model - y) ** 2) / (e ** 2))) / dof)\n",
      "\n",
      "--------------------\n",
      " Test\n",
      "\n",
      "name = 'Avatar of Hope'\n",
      "\n",
      "card_index = magic_cards[(magic_cards['name'] == name)].index.tolist()\n",
      "\n",
      "card_index = card_index[0]\n",
      "\n",
      "(distances, indices) = knn.kneighbors(combined_df.iloc[card_index, :])\n",
      "\n",
      "index = indices[0]\n",
      "\n",
      "distance = distances[0]\n",
      "\n",
      "card_index\n",
      "\n",
      "--------------------\n",
      " Problem 1 KNN Classifiers\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " You can measure precision of your prediction either by manually computing it or using knn score\n",
      "\n",
      "y_hat = knn.predict(X)\n",
      "\n",
      "Score1 = knn.score(X, y)\n",
      "\n",
      "Score2 = (float(sum((y_hat == y))) / len(AdmissionData))\n",
      "\n",
      "print(Score1)\n",
      "\n",
      "print(Score2)\n",
      "\n",
      "--------------------\n",
      " What would be the result without standardizing your data \n",
      "\n",
      "url = 'https://raw.githubusercontent.com/ga-students/SF-DAT-20/master/HW%20assignments/HW2/admissions.csv'\n",
      "\n",
      "AdmissionData = pd.read_csv(url)\n",
      "\n",
      "AdmissionData.dropna(inplace=True)\n",
      "\n",
      "X = AdmissionData[['gre', 'gpa', 'prestige']]\n",
      "\n",
      "y = AdmissionData['admit']\n",
      "\n",
      "--------------------\n",
      " Problem 2 KNN and Regression Models\n",
      "\n",
      "from numpy import random\n",
      "\n",
      "x = random.uniform((- 10), 10, 100)\n",
      "\n",
      "error = np.random.normal(0, 20, 100)\n",
      "\n",
      "y = (((3 + (1.5 * x)) + (4 * (x ** 2))) + error)\n",
      "\n",
      "df = pd.DataFrame({\n",
      "    'X': x,\n",
      "    'y': y,\n",
      "})\n",
      "\n",
      "df.plot(kind='scatter', x='X', y='y')\n",
      "\n",
      "--------------------\n",
      " Power spectrum of turbulent vertical velocity\n",
      "\n",
      "td = numpy.load('miami_tower.npz')\n",
      "\n",
      "print('keys: ', td.keys())\n",
      "\n",
      "print(td['description'])\n",
      "\n",
      "--------------------\n",
      " start with wvel\n",
      "\n",
      "winspec = do_fft(wvel, window)\n",
      "\n",
      "sampleRate = 20.833\n",
      "\n",
      "nyquistfreq = (sampleRate / 2.0)\n",
      "\n",
      "halfpoint = int((len(winspec) / 2.0))\n",
      "\n",
      "averaged_freq = (np.linspace(0, 1.0, halfpoint) * nyquistfreq)\n",
      "\n",
      "winspec = winspec[0:halfpoint]\n",
      "\n",
      "--------------------\n",
      " Para lista 1\n",
      "\n",
      "fft_l1 = fft(InterList1)\n",
      "\n",
      "fft_l1 /= RangoTot\n",
      "\n",
      "fft_l1_shift = np.fft.fftshift(fft_l1)\n",
      "\n",
      "--------------------\n",
      " Para Lista 2\n",
      "\n",
      "fft_l2 = fft(InterList2)\n",
      "\n",
      "fft_l2 /= RangoTot\n",
      "\n",
      "fft_l2_shift = np.fft.fftshift(fft_l2)\n",
      "\n",
      "--------------------\n",
      " Para Lista 3\n",
      "\n",
      "fft_l3 = fft(InterList3)\n",
      "\n",
      "fft_l3 /= RangoTot\n",
      "\n",
      "fft_l3_shift = np.fft.fftshift(fft_l3)\n",
      "\n",
      "--------------------\n",
      " Espectro de potencia pot l1 \n",
      "\n",
      "plot(freq, pot_l1)\n",
      "\n",
      "--------------------\n",
      " Espectro de potencia pot l2 \n",
      "\n",
      "plot(freq, pot_l2)\n",
      "\n",
      "--------------------\n",
      " Espectro de potencia pot l3 \n",
      "\n",
      "plot(freq, pot_l3)\n",
      "\n",
      "--------------------\n",
      " T inversa de las funciones\n",
      "\n",
      "rta_l1 = ifft(fft_Xk_plus1)\n",
      "\n",
      "rta_l2 = ifft(fft_Xk_plus2)\n",
      "\n",
      "rta_l3 = ifft(fft_Xk_plus3)\n",
      "\n",
      "--------------------\n",
      " Graficas de Interpolacion Constante\n",
      "\n",
      "InterList1 /= np.max(np.abs(InterList1))\n",
      "\n",
      "plot(InterList1)\n",
      "\n",
      "show()\n",
      "\n",
      "rta_l1 /= np.max(np.abs(rta_l1))\n",
      "\n",
      "plot(rta_l1)\n",
      "\n",
      "show()\n",
      "\n",
      "plot(rta_l1, '-', InterList1, '-')\n",
      "\n",
      "show()\n",
      "\n",
      "--------------------\n",
      " Diferencia entre interpolacion y los datos\n",
      "\n",
      "plot((rta_l1 - InterList1))\n",
      "\n",
      "--------------------\n",
      " Graficas de Interpolacion Lineal\n",
      "\n",
      "InterList2 /= np.max(np.abs(InterList2))\n",
      "\n",
      "plot(InterList2)\n",
      "\n",
      "show()\n",
      "\n",
      "rta_l2 /= np.max(np.abs(rta_l2))\n",
      "\n",
      "plot(rta_l2)\n",
      "\n",
      "show()\n",
      "\n",
      "plot(rta_l2, '-', InterList2, '-')\n",
      "\n",
      "show()\n",
      "\n",
      "--------------------\n",
      " Diferencia entre interpolacion y datos\n",
      "\n",
      "plot((rta_l2 - InterList2))\n",
      "\n",
      "--------------------\n",
      " Graficas de Interpolacion Cubica\n",
      "\n",
      "InterList3 /= np.max(np.abs(InterList3))\n",
      "\n",
      "rta_l3 /= np.max(np.abs(rta_l3))\n",
      "\n",
      "plot(InterList3)\n",
      "\n",
      "show()\n",
      "\n",
      "rta_l3 /= np.max(np.abs(rta_l3))\n",
      "\n",
      "plot(rta_l3)\n",
      "\n",
      "show()\n",
      "\n",
      "plot(rta_l3, '-', InterList3, '-')\n",
      "\n",
      "show()\n",
      "\n",
      "--------------------\n",
      " Diferencia entre datos de la interpolacion y originales\n",
      "\n",
      "plot((rta_l3 - InterList3))\n",
      "\n",
      "--------------------\n",
      " Preliminary Analysis\n",
      "\n",
      "clean_hospital_read_df = hospital_read_df[(hospital_read_df['Number of Discharges'] != 'Not Available')]\n",
      "\n",
      "clean_hospital_read_df.loc[:, 'Number of Discharges'] = clean_hospital_read_df['Number of Discharges'].astype(int)\n",
      "\n",
      "clean_hospital_read_df = clean_hospital_read_df.sort_values('Number of Discharges')\n",
      "\n",
      "--------------------\n",
      " Here s a sample of code for how to get variance and bias from an sklearn model\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "regr = linear_model.LinearRegression()\n",
      "\n",
      "regr.fit(X, Y)\n",
      "\n",
      "yhat = regr.predict(X)\n",
      "\n",
      "sse = np.mean(((np.mean(yhat) - Y) ** 2))\n",
      "\n",
      "var = np.var(yhat)\n",
      "\n",
      "bias = ((sse - var) - 0.01)\n",
      "\n",
      "--------------------\n",
      " Inspect the outliers from the linear regression modeling of Hubway data\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "from sklearn import cross_validation\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from pylab import savefig\n",
      "\n",
      "--------------------\n",
      " Get the data and pre process the data\n",
      "\n",
      "df = pd.read_csv('../data/data_ready.csv')\n",
      "\n",
      "df.head()\n",
      "\n",
      "--------------------\n",
      " 4 2 Training Logistic Regression with Scikit\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "lr = LogisticRegression(C=1000.0, random_state=0)\n",
      "\n",
      "lr.fit(X_train_std, y_train)\n",
      "\n",
      "plot_decision_regions(X=X_combined_std, y=y_combined, classifier=lr, test_index=range(105, 150))\n",
      "\n",
      "plt.xlabel('petal length [standardization]')\n",
      "\n",
      "plt.ylabel('petal width [standardization]')\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " 5 Support Vector Machines\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
      "\n",
      "svm.fit(X_train_std, y_train)\n",
      "\n",
      "plot_decision_regions(X_combined_std, y_combined, classifier=svm, test_index=range(105, 150))\n",
      "\n",
      "plt.xlabel('petal length [standardized]')\n",
      "\n",
      "plt.ylabel('petal width [standardized]')\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " 5 1 2 Alternative Implementations of Scikit Learn\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "ppn = SGDClassifier(loss='perceptron')\n",
      "\n",
      "lr = SGDClassifier(loss='log')\n",
      "\n",
      "svm = SGDClassifier(loss='hinge')\n",
      "\n",
      "--------------------\n",
      " 6 2 Random Forests\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "forest = RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=1, n_jobs=2)\n",
      "\n",
      "forest.fit(X_train, y_train)\n",
      "\n",
      "plot_decision_regions(X_combined, y_combined, classifier=forest, test_index=range(105, 150))\n",
      "\n",
      "plt.xlabel('petal length [standardized]')\n",
      "\n",
      "plt.ylabel('petal width [standardized]')\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " 7 K nearest Neighbors\n",
      "\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
      "\n",
      "knn.fit(X_train_std, y_train)\n",
      "\n",
      "plot_decision_regions(X_combined_std, y_combined, classifier=knn, test_index=range(105, 150))\n",
      "\n",
      "plt.xlabel('petal length [standardized]')\n",
      "\n",
      "plt.ylabel('petal width [standardized]')\n",
      "\n",
      "plt.legend(loc='upper left')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " 1 Missing Data\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from io import StringIO\n",
      "\n",
      "csv_data = 'A,B,C,D\\n1.0,2.0,3.0,4.0\\n5.0,6.0,,8.0\\n10.0,11.0,12.0,'\n",
      "\n",
      "df = pd.read_csv(StringIO(csv_data))\n",
      "\n",
      "df\n",
      "\n",
      "--------------------\n",
      " 3 Partitioning the Data into Training and Test Set\n",
      "\n",
      "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
      "\n",
      "df_wine.columns = ['Class label', 'Alcohol', 'Malic Acid', 'Ash', 'Alcalinity of Ash', 'Magnesium', 'Total Phenols', 'Flavanoids', 'Nonflavanoid Phenols', 'Proanthocyanins', 'Color Intensity', 'Hue', 'OD280/OD315 of Dilute Wines', 'Proline']\n",
      "\n",
      "print('Class labels', np.unique(df_wine['Class label']))\n",
      "\n",
      "df_wine.head()\n",
      "\n",
      "--------------------\n",
      " 4 Feature Scaling\n",
      "\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "mms = MinMaxScaler()\n",
      "\n",
      "X_train_norm = mms.fit_transform(X_train)\n",
      "\n",
      "X_test_norm = mms.transform(X_test)\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "stdsc = StandardScaler()\n",
      "\n",
      "X_train_std = stdsc.fit_transform(X_train)\n",
      "\n",
      "X_test_std = stdsc.transform(X_test)\n",
      "\n",
      "--------------------\n",
      " 5 1 L1 Regularization\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "lr = LogisticRegression(penalty='l1', C=0.1)\n",
      "\n",
      "lr.fit(X_train_std, y_train)\n",
      "\n",
      "print('Training Accuracy:', lr.score(X_train_std, y_train))\n",
      "\n",
      "print('Test Accuracy:', lr.score(X_test_std, y_test))\n",
      "\n",
      "print(lr.intercept_)\n",
      "\n",
      "--------------------\n",
      " Charting with a 10 000 row sample\n",
      "\n",
      "train_s = train.sample(n=10000)\n",
      "\n",
      "--------------------\n",
      " Unpickle data\n",
      "\n",
      "\n",
      "def unpickle(f):\n",
      "    fo = open(f, 'rb')\n",
      "    d = cPickle.load(fo)\n",
      "    fo.close()\n",
      "    return d\n",
      "\n",
      "--------------------\n",
      " Import Deep Learning Library\n",
      "\n",
      "from keras.models import Sequential\n",
      "\n",
      "from keras.layers import Dense, Activation, MaxPooling2D, Flatten\n",
      "\n",
      "from keras.layers import Convolution2D\n",
      "\n",
      "from keras.utils import np_utils\n",
      "\n",
      "from keras.optimizers import SGD, Adam\n",
      "\n",
      "from keras import backend as K\n",
      "\n",
      "from IPython.display import SVG\n",
      "\n",
      "from keras.utils.visualize_util import model_to_dot, plot\n",
      "\n",
      "--------------------\n",
      " General parameters for the CNN models\n",
      "\n",
      "batch_size = 32\n",
      "\n",
      "nb_classes = 10\n",
      "\n",
      "nb_epoch = 20\n",
      "\n",
      "nb_filters = 32\n",
      "\n",
      "--------------------\n",
      " Visualization\n",
      "\n",
      "output = model_opti2.predict_classes(X_test, batch_size=batch_size, verbose=1)\n",
      "\n",
      "--------------------\n",
      " Some types of houses are more desireable than others as well Detached single familys and the townhouses on the end of the block have the highest mean price\n",
      "\n",
      "h.groupby('BldgType')['SalePrice'].mean()\n",
      "\n",
      "--------------------\n",
      " Remove commercial properties from the dataset\n",
      "\n",
      "h.groupby(['MSZoning']).size()\n",
      "\n",
      "--------------------\n",
      " Set Id as index\n",
      "\n",
      "h.set_index('Id', inplace=True)\n",
      "\n",
      "--------------------\n",
      " Remove cols with less than 90 data in cols\n",
      "\n",
      "print(((1 - (h.isnull().sum().sort_values(ascending=False) / len(h))) < 0.9).head(10))\n",
      "\n",
      "h.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage'], axis=1, inplace=True)\n",
      "\n",
      "--------------------\n",
      " Convert MSSubClass to cat\n",
      "\n",
      "\n",
      "def MSconvert(num):\n",
      "    MS_dict = {\n",
      "        20: '1STORY1946',\n",
      "        30: '1STORY1945',\n",
      "        40: '1STORYATTIC',\n",
      "        45: '1.5STORYUNFIN',\n",
      "        50: '1.5STORYFIN',\n",
      "        60: '2STORY1946N',\n",
      "        70: '2STORY1945O',\n",
      "        75: '2.5STORY',\n",
      "        80: 'SPLITLEVEL',\n",
      "        85: 'SPLITFOYER',\n",
      "        90: 'DUPLEX',\n",
      "        120: '1STORYPUD',\n",
      "        150: '1.5STORYPUD',\n",
      "        160: '2STORYPUD',\n",
      "        180: 'MULTILEVELPUD',\n",
      "        190: '2FAMILY',\n",
      "    }\n",
      "    return MS_dict[num]\n",
      "\n",
      "MSconvert(orig['MSSubClass'][0])\n",
      "\n",
      "--------------------\n",
      " Take copy\n",
      "\n",
      "hcopy = h.copy()\n",
      "\n",
      "--------------------\n",
      " Take a look at NaNs\n",
      "\n",
      "h.isnull().sum().sort_values(ascending=False).head()\n",
      "\n",
      "--------------------\n",
      " Take a look at distributions looks like a few of the top candidates are not normally distributed\n",
      "\n",
      "from scipy.stats import norm\n",
      "\n",
      "--------------------\n",
      " Save cleaned no transforms dataframe\n",
      "\n",
      "h_no_transforms = h.copy()\n",
      "\n",
      "--------------------\n",
      " Convert 0 s in some numerics to categorical BsmtSq\n",
      "\n",
      "\n",
      "def Zeroconvert(num):\n",
      "    if (num == 0):\n",
      "        out = 1\n",
      "    else:\n",
      "        out = 0\n",
      "    return out\n",
      "\n",
      "Zeroconvert(orig['TotalBsmtSF'][0])\n",
      "\n",
      "--------------------\n",
      " Copy of transformed data without dummies\n",
      "\n",
      "h_no_dummy = h.copy()\n",
      "\n",
      "--------------------\n",
      " Make sure added cols have non Nans\n",
      "\n",
      "h.isnull().sum().sort_values(ascending=False).head()\n",
      "\n",
      "--------------------\n",
      " Create a fixed and non fixed feature dataframes to evaluate separately\n",
      "\n",
      "h_fixed = h_log_dummy.copy()\n",
      "\n",
      "--------------------\n",
      " Remove the target variable\n",
      "\n",
      "y = h['SalePrice']\n",
      "\n",
      "X = h.drop('SalePrice', axis=1)\n",
      "\n",
      "Xn = h.drop('SalePrice', axis=1)\n",
      "\n",
      "--------------------\n",
      " Scale it\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "ss = StandardScaler()\n",
      "\n",
      "X = ss.fit_transform(X)\n",
      "\n",
      "X = pd.DataFrame(X, columns=Xn.columns)\n",
      "\n",
      "--------------------\n",
      " Create Holdouts\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "(X_train, X_hold, y_train, y_hold) = train_test_split(X, y, test_size=0.2)\n",
      "\n",
      "--------------------\n",
      " Create new test train set off the non holdout terms\n",
      "\n",
      "X = X_train.copy()\n",
      "\n",
      "y = y_train.copy()\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2)\n",
      "\n",
      "--------------------\n",
      " Okay our R2 value got hammered But it typically falls when comparing test train to cross val\n",
      "\n",
      "from sklearn.model_selection import cross_val_score\n",
      "\n",
      "from sklearn.model_selection import KFold\n",
      "\n",
      "kfold = KFold(n_splits=10, random_state=4)\n",
      "\n",
      "score = cross_val_score(lr, X, y, scoring='neg_mean_squared_error', cv=kfold)\n",
      "\n",
      "positive_score = (- score)\n",
      "\n",
      "np.sqrt(positive_score).mean()\n",
      "\n",
      "--------------------\n",
      " This looks promising but again we should take a look at the cross val scores to get a more realistic score Lets make a function to put a model into the Kfolds and return RMSE\n",
      "\n",
      "\n",
      "def cv_rmse(estimator):\n",
      "    score = cross_val_score(estimator, X, y, scoring='neg_mean_squared_error', cv=kfold)\n",
      "    positive_score = (- score)\n",
      "    return np.sqrt(positive_score)\n",
      "\n",
      "--------------------\n",
      " Leads to sparsity and simplification of a model which is very good in this case because we want to be able to explain the outcome of salesprice in terms of the coeficients\n",
      "\n",
      "a = [0.0005, 0.0008, 0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.05]\n",
      "\n",
      "Lasso_rmse = []\n",
      "\n",
      "Lasso_std = []\n",
      "\n",
      "for i in a:\n",
      "    Lasso_rmse.append(cv_rmse(linear_model.Lasso(alpha=i)).mean())\n",
      "    Lasso_std.append(cv_rmse(linear_model.Lasso(alpha=i)).std())\n",
      "\n",
      "--------------------\n",
      " Train Lasso model on best hyperparameter alpha\n",
      "\n",
      "lasso = linear_model.Lasso(alpha=0.004)\n",
      "\n",
      "lasso.fit(X, y)\n",
      "\n",
      "Lasso_coef = pd.DataFrame(lasso.coef_, index=Xn.columns)\n",
      "\n",
      "--------------------\n",
      " Lasso strength of top 20 coef out of 53 Lasso selected \n",
      "\n",
      "print(('\\nnum of coefs: ' + str(Lasso_coef[(Lasso_coef[0] > 0)].count())))\n",
      "\n",
      "print('\\n')\n",
      "\n",
      "print((np.e ** lasso.intercept_))\n",
      "\n",
      "--------------------\n",
      " Cr ation des mod les\n",
      "\n",
      "lm = smf.ols(formula='mpg ~ horsepower', data=auto).fit()\n",
      "\n",
      "print(lm.params)\n",
      "\n",
      "print()\n",
      "\n",
      "--------------------\n",
      " Implementing simple majority vote classifier\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "np.argmax(np.bincount([0, 0, 1], weights=[0.2, 0.2, 0.6]))\n",
      "\n",
      "--------------------\n",
      " Combining different algorithms for classification with majority vote\n",
      "\n",
      "from sklearn import datasets\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "(X, y) = (iris.data[50:, [1, 2]], iris.target[50:])\n",
      "\n",
      "le = LabelEncoder()\n",
      "\n",
      "y = le.fit_transform(y)\n",
      "\n",
      "--------------------\n",
      " Bragging building an ensemble of classifiers from bootstrap samples\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
      "\n",
      "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
      "\n",
      "df_wine = df_wine[(df_wine['Class label'] != 1)]\n",
      "\n",
      "y = df_wine['Class label'].values\n",
      "\n",
      "X = df_wine[['Alcohol', 'Hue']].values\n",
      "\n",
      "--------------------\n",
      " load foreground images and labels\n",
      "\n",
      "dir_data\n",
      "\n",
      "--------------------\n",
      " Pass images through VGG to obtain meaningful features\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "import vgg16\n",
      "\n",
      "--------------------\n",
      " split into training and validation randomly\n",
      "\n",
      "data_features.shape\n",
      "\n",
      "--------------------\n",
      " since SVM depends on the distance scale normalize the features dataset before inputting it into SVM \n",
      "\n",
      "X_train_mean = np.mean(X_train, axis=0)\n",
      "\n",
      "X_train_std = np.std(X_train, axis=0)\n",
      "\n",
      "X_train = ((X_train - X_train_mean) / (X_train_std + 0.0001))\n",
      "\n",
      "X_val = ((X_val - X_train_mean) / (X_train_std + 0.0001))\n",
      "\n",
      "--------------------\n",
      " Cross validation scores\n",
      "\n",
      "cv_scores_train = cross_val_score(svm1_best, X_train, Y_train, cv=cv_train)\n",
      "\n",
      "print(('Accuracy: %0.3f (+/- %0.3f)' % (cv_scores_train.mean(), (cv_scores_train.std() * 2))))\n",
      "\n",
      "--------------------\n",
      " train Random Forest on VGG features\n",
      "\n",
      "rf_model = RandomForestClassifier(max_depth=None, class_weight='balanced', min_samples_split=2, n_estimators=1000, max_features=int(np.sqrt(X_train.shape[1])), random_state=0, n_jobs=(- 1), oob_score=True)\n",
      "\n",
      "--------------------\n",
      " Cross validation scores\n",
      "\n",
      "cv_scores_train = cross_val_score(rf1, X_train, Y_train, cv=cv_train)\n",
      "\n",
      "print(('Accuracy: %0.3f (+/- %0.3f)' % (cv_scores_train.mean(), (cv_scores_train.std() * 2))))\n",
      "\n",
      "--------------------\n",
      " Importance of fc8 features from Random forest\n",
      "\n",
      "plt.figure(figsize=(15, 5))\n",
      "\n",
      "plt.plot(rf_model.feature_importances_)\n",
      "\n",
      "plt.xlabel('Feature Number')\n",
      "\n",
      "plt.ylabel('Importance')\n",
      "\n",
      "--------------------\n",
      " Pixel importance on the fc8 layer\n",
      "\n",
      "plt.figure(figsize=(10, 10))\n",
      "\n",
      "io.imshow(np.reshape(rf_model.feature_importances_, (64, 64)))\n",
      "\n",
      "--------------------\n",
      " Visualize intermediate VGG16 layers\n",
      "\n",
      "import keras\n",
      "\n",
      "from keras.models import Sequential, Model\n",
      "\n",
      "from keras.layers import Input, Dense, Flatten, Activation, pooling\n",
      "\n",
      "from keras.layers import Dropout, BatchNormalization, Convolution2D, MaxPooling2D\n",
      "\n",
      "from keras import initializers\n",
      "\n",
      "from keras.optimizers import Adam, RMSprop\n",
      "\n",
      "from keras.layers import Lambda, Input\n",
      "\n",
      "from keras.models import Model\n",
      "\n",
      "from keras.backend import tf as ktf\n",
      "\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "\n",
      "from keras.applications.vgg16 import VGG16, preprocess_input\n",
      "\n",
      "from scipy.misc import imread, imresize\n",
      "\n",
      "--------------------\n",
      " an original binary image\n",
      "\n",
      "plt.figure(figsize=(8, 8))\n",
      "\n",
      "plt.imshow(X_data[0, :, :, 0])\n",
      "\n",
      "--------------------\n",
      " Now display this image at the layer with index1\n",
      "\n",
      "\n",
      "def layer_features(index1, data1):\n",
      "    intermediate_layer_model = Model(inputs=model1.input, outputs=model1.get_layer(index=index1).output)\n",
      "    index_features = intermediate_layer_model.predict(data1)\n",
      "    return index_features\n",
      "\n",
      "--------------------\n",
      " Airline exercise Using seaborn\n",
      "\n",
      "import urllib\n",
      "\n",
      "import os\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "if (not os.path.exists('airfares.txt')):\n",
      "    urllib.urlretrieve('http://www.stat.ufl.edu/~winner/data/airq4.dat', 'airfares.txt')\n",
      "\n",
      "--------------------\n",
      " Random Forest Model\n",
      "\n",
      "model_rf = RandomForestRegressor(n_estimators=5000, oob_score=True, n_jobs=(- 1), random_state=42, max_features='auto', min_samples_leaf=7)\n",
      "\n",
      "model_rf.fit(X, y)\n",
      "\n",
      "roc = roc_auc_score(y, model_rf.oob_prediction_)\n",
      "\n",
      "print('AUC Score: ', roc)\n",
      "\n",
      "--------------------\n",
      " Multi layer Perceptron Classifier\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "scaler = StandardScaler()\n",
      "\n",
      "scaler.fit(X_train)\n",
      "\n",
      "X_train = scaler.transform(X_train)\n",
      "\n",
      "X_test = scaler.transform(X_test)\n",
      "\n",
      "model_mlp = model = MLPClassifier(hidden_layer_sizes=(1000, 5), max_iter=1000, random_state=42)\n",
      "\n",
      "model_mlp.fit(X_test, y_test)\n",
      "\n",
      "--------------------\n",
      " REFRESH DATA \n",
      "\n",
      "for team in teams.keys():\n",
      "    with open((team + '.json'), 'r') as f:\n",
      "        try:\n",
      "            teams[team] = pd.read_json(json.load(f))\n",
      "        except ValueError:\n",
      "            teams[team] = {\n",
      "                \n",
      "            }\n",
      "\n",
      "--------------------\n",
      " Scenario and Problem Statement\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "--------------------\n",
      " Rotten Tomatoes Dataset\n",
      "\n",
      "critics = pd.read_csv('/Users/sowmyamoka/Satish_Python/Machine_Learning/naive_bayes/critics.csv')\n",
      "\n",
      "critics = critics[(~ critics.quote.isnull())]\n",
      "\n",
      "critics.head()\n",
      "\n",
      "--------------------\n",
      " Explore\n",
      "\n",
      "n_reviews = len(critics)\n",
      "\n",
      "n_movies = critics.rtid.unique().size\n",
      "\n",
      "n_critics = critics.critic.unique().size\n",
      "\n",
      "print('Number of reviews: {:d}'.format(n_reviews))\n",
      "\n",
      "print('Number of critics: {:d}'.format(n_critics))\n",
      "\n",
      "print('Number of movies:  {:d}'.format(n_movies))\n",
      "\n",
      "--------------------\n",
      " Import nltk\n",
      "\n",
      "import nltk\n",
      "\n",
      "--------------------\n",
      " Load English stopwords and print some of the words\n",
      "\n",
      "sw = set(nltk.corpus.stopwords.words('english'))\n",
      "\n",
      "print('Stop words:', list(sw)[:7])\n",
      "\n",
      "--------------------\n",
      " Load Gutenberg corpopra and print some of the filenames\n",
      "\n",
      "gb = nltk.corpus.gutenberg\n",
      "\n",
      "print('Gutenberg files:\\n', gb.fileids()[(- 5):])\n",
      "\n",
      "--------------------\n",
      " Extract sentences from milton paradise txt file\n",
      "\n",
      "text_sent = gb.sents('milton-paradise.txt')[:2]\n",
      "\n",
      "print('Unfiltered:', text_sent)\n",
      "\n",
      "--------------------\n",
      " Import scikit learn\n",
      "\n",
      "import sklearn as sk\n",
      "\n",
      "--------------------\n",
      " Load two documents from NLTK Gutenberg corpus\n",
      "\n",
      "hamlet = gb.raw('shakespeare-hamlet.txt')\n",
      "\n",
      "macbeth = gb.raw('shakespeare-macbeth.txt')\n",
      "\n",
      "--------------------\n",
      " Create the feature vector by omitting English stopwords\n",
      "\n",
      "cv = sk.feature_extraction.text.CountVectorizer(stop_words='english')\n",
      "\n",
      "print('Feature vector:\\n', cv.fit_transform([hamlet, macbeth]).toarray())\n",
      "\n",
      "--------------------\n",
      " Print a small selection of the features found\n",
      "\n",
      "print('Features:\\n', cv.get_feature_names()[:5])\n",
      "\n",
      "--------------------\n",
      " Social Network Analysis\n",
      "\n",
      "import networkx as nx\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "print([s for s in dir(nx) if s.endswith('graph')])\n",
      "\n",
      "G = nx.davis_southern_women_graph()\n",
      "\n",
      "plt.hist(list(nx.degree(G).values()))\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Rotten Tomatoes Dataset\n",
      "\n",
      "critics = pd.read_csv('./critics.csv')\n",
      "\n",
      "critics = critics[(~ critics.quote.isnull())]\n",
      "\n",
      "critics['fresh'].value_counts()\n",
      "\n",
      "--------------------\n",
      " Explore\n",
      "\n",
      "n_reviews = len(critics)\n",
      "\n",
      "n_movies = critics.rtid.unique().size\n",
      "\n",
      "n_critics = critics.critic.unique().size\n",
      "\n",
      "print('Number of reviews: {:d}'.format(n_reviews))\n",
      "\n",
      "print('Number of critics: {:d}'.format(n_critics))\n",
      "\n",
      "print('Number of movies:  {:d}'.format(n_movies))\n",
      "\n",
      "--------------------\n",
      " Log likelihood as score means higher the log likelihood the more the chances are of quote being categorized as fresh Higher value of alpha may indicate that the prediction may not be accurate \n",
      "\n",
      "\n",
      "def make_xy(critics, vectorizer=None):\n",
      "    if (vectorizer is None):\n",
      "        vectorizer = CountVectorizer()\n",
      "    X = vectorizer.fit_transform(critics.quote)\n",
      "    X = X.tocsc()\n",
      "    y = (critics.fresh == 'fresh').values.astype(np.int)\n",
      "    return (X, y)\n",
      "\n",
      "(X, y) = make_xy(critics)\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "classification_problem = datasets.make_classification(n_features=2, n_informative=2, n_classes=3, n_redundant=0, n_clusters_per_class=1, random_state=3)\n",
      "\n",
      "--------------------\n",
      " DecisionTreeClassifier\n",
      "\n",
      "clf = tree.DecisionTreeClassifier(random_state=1)\n",
      "\n",
      "clf.fit(train_data, train_labels)\n",
      "\n",
      "--------------------\n",
      " Constants\n",
      "\n",
      "V0 = (800 * const.e)\n",
      "\n",
      "a = 5e-11\n",
      "\n",
      "--------------------\n",
      " Infinite Harmonic Well\n",
      "\n",
      "ihsystem = qmsys1d(np.linspace((- a), a, 1000), (lambda x: ((V0 * np.square((x / a))) if (abs(x) <= a) else 0.0)), [0.0, 1.0], 5, 4e-18, store_ef_values=True)\n",
      "\n",
      "--------------------\n",
      " Finite Square Well\n",
      "\n",
      "fssystem = qmsys1d(np.linspace((- a), a, 1000), (lambda x: (0.0 if (abs(x) <= (a / 2.0)) else V0)), [0.0, 1.0], 3, 1e-17, store_ef_values=True)\n",
      "\n",
      "--------------------\n",
      " Finite Harmonic Well\n",
      "\n",
      "fhsystem = qmsys1d(np.linspace((- a), a, 1000), (lambda x: ((V0 * np.square((x / a))) if (abs(x) <= a) else V0)), [0.0, 1.0], 4, store_ef_values=True)\n",
      "\n",
      "--------------------\n",
      " Finite Square Barrier\n",
      "\n",
      "fhbsystem = qmsys1d(np.linspace((- a), a, 1000), (lambda x: (V0 if (abs(x) <= (a / 5)) else 0.0)), [0.0, 1.0], 4, El=0, store_ef_values=True)\n",
      "\n",
      "--------------------\n",
      " Finite Harmonic Barrier\n",
      "\n",
      "asystem = qmsys1d(np.linspace((- a), a, 1000), (lambda x: ((V0 * (1 - np.square(((4 * x) / a)))) if (abs(x) <= (a / 4)) else 0.0)), [0.0, 1.0], 4, El=0, store_ef_values=True)\n",
      "\n",
      "--------------------\n",
      " Imports\n",
      "\n",
      "import sys\n",
      "\n",
      "import gc\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import sklearn as sk\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
      "\n",
      "--------------------\n",
      " now back to our own task\n",
      "\n",
      "autoclf = autosklearn.classification.AutoSklearnClassifier(ml_memory_limit=2048, time_left_for_this_task=180)\n",
      "\n",
      "autoclf.fit(tr_features, tr_labels, metric='f1_metric')\n",
      "\n",
      "y_hat_intdect = autoclf.predict(test_features)\n",
      "\n",
      "print('F1 score', sklearn.metrics.accuracy_score(test_features, y_hat_intdect))\n",
      "\n",
      "--------------------\n",
      " Built in datasets\n",
      "\n",
      "datasets.load_boston\n",
      "\n",
      "--------------------\n",
      " Regression\n",
      "\n",
      "np.random.seed(123)\n",
      "\n",
      "--------------------\n",
      " Classification\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "--------------------\n",
      " Clustering\n",
      "\n",
      "(X, y) = (iris.data, iris.target)\n",
      "\n",
      "--------------------\n",
      " Versions\n",
      "\n",
      "get_ipython().run_line_magic('reload_ext', 'version_information')\n",
      "\n",
      "--------------------\n",
      " Model\n",
      "\n",
      "model = keras.models.Sequential()\n",
      "\n",
      "model.add(keras.layers.recurrent.GRU(100, input_shape=input_shape))\n",
      "\n",
      "model.add(keras.layers.Dropout(0.3))\n",
      "\n",
      "model.add(keras.layers.Dense(23, activation='softmax'))\n",
      "\n",
      "--------------------\n",
      " Submission\n",
      "\n",
      "(_, target, raw_cats) = helper.load_multiclass_data()\n",
      "\n",
      "--------------------\n",
      " Reconstruct the categories from the one hot encoding\n",
      "\n",
      "yhat = model.predict(submission_vectors)\n",
      "\n",
      "--------------------\n",
      " Python imports\n",
      "\n",
      "import sys\n",
      "\n",
      "sys.path.append('../../artools')\n",
      "\n",
      "import artools\n",
      "\n",
      "artools = reload(artools)\n",
      "\n",
      "import scipy as sp\n",
      "\n",
      "import scipy.integrate\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "plt.style.use('ggplot')\n",
      "\n",
      "import ipywidgets\n",
      "\n",
      "--------------------\n",
      " 1 Load affairs dataset\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Q3 Compute margin of error confidence interval and p value \n",
      "\n",
      "data[['call', 'race']].groupby(['call', 'race']).size()\n",
      "\n",
      "--------------------\n",
      " Escrever a fun o que calcula a derivada de x em t \n",
      "\n",
      "\n",
      "def fun(x, t):\n",
      "    d = 100\n",
      "    a = 200\n",
      "    b = 2000\n",
      "    g = 150\n",
      "    w = 10\n",
      "    (x1, x2) = x\n",
      "    dxdt = [x2, ((((g * sp.cos((w * t))) - (d * x2)) - (a * x1)) - (b * (x1 ** 3)))]\n",
      "    return dxdt\n",
      "\n",
      "--------------------\n",
      " Determinar condi es iniciais e o intervalo de tempo \n",
      "\n",
      "x0 = 0.01\n",
      "\n",
      "v0 = 0.1\n",
      "\n",
      "z0 = [x0, v0]\n",
      "\n",
      "tf = 10\n",
      "\n",
      "t = sp.linspace(0, tf, 1000)\n",
      "\n",
      "--------------------\n",
      " Calcular a solu o\n",
      "\n",
      "sol = odeint(fun, z0, t)\n",
      "\n",
      "--------------------\n",
      " Plotar solu o deslocamento x tempo \n",
      "\n",
      "plt.plot(sol, label='x1(t)')\n",
      "\n",
      "plt.legend()\n",
      "\n",
      "plt.xlabel('t')\n",
      "\n",
      "--------------------\n",
      " Plotar solu o velocidade x tempo \n",
      "\n",
      "plt.plot(sol, label='x2(t)')\n",
      "\n",
      "plt.legend()\n",
      "\n",
      "plt.xlabel('t')\n",
      "\n",
      "--------------------\n",
      " Example clustering random points\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "sns.set_context('notebook')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "np.random.seed(42)\n",
      "\n",
      "(x, y) = np.random.uniform(0, 10, 50).reshape(2, 25)\n",
      "\n",
      "plt.scatter(x, y)\n",
      "\n",
      "--------------------\n",
      " Drawback 1 Need to choose a right number of clusters\n",
      "\n",
      "(X, y) = make_blobs(n_samples=1000, n_features=2, centers=3, random_state=170)\n",
      "\n",
      "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
      "\n",
      "--------------------\n",
      " 4 1 7 1 Test 1 Default LRM on Original data with NO stratified split\n",
      "\n",
      "get_ipython().run_line_magic('pinfo', 'metrics.roc_curve')\n",
      "\n",
      "--------------------\n",
      " Linear Regression\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Predictions\n",
      "\n",
      "predictions = lm.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " Since K means is an unsupervised learning we assume the output 1 is defined as full term here is the result of train error and test error \n",
      "\n",
      "true_classification = np.zeros(len(train_x))\n",
      "\n",
      "true_classification[pre_true_index] = 1\n",
      "\n",
      "true_classification[full_true_index] = 0\n",
      "\n",
      "--------------------\n",
      " Now we assume the output 1 is defined as pre term here is the result of train error and test error \n",
      "\n",
      "train_pre = []\n",
      "\n",
      "train_full = []\n",
      "\n",
      "for i in range(len(estimate_train)):\n",
      "    if (estimate_train[i] == 1):\n",
      "        train_pre.append(birth_train['gestation age'].values[i])\n",
      "    else:\n",
      "        train_full.append(birth_train['gestation age'].values[i])\n",
      "\n",
      "--------------------\n",
      " Compare the results with sklearn s GaussianMixture model\n",
      "\n",
      "from sklearn import mixture\n",
      "\n",
      "gmm = mixture.GaussianMixture(n_components=2, covariance_type='full').fit(train_x)\n",
      "\n",
      "--------------------\n",
      " trace\n",
      "\n",
      "full_trace = trace[(- 5000):]\n",
      "\n",
      "pm.traceplot(full_trace)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " How the Power of a Test Translates into Sample Requirement\n",
      "\n",
      "ro.r('power.prop.test(p1 = .03, p2 = .033, sig.level =0.05, power = .90)')\n",
      "\n",
      "--------------------\n",
      " Imports\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " Config\n",
      "\n",
      "AFM_FOLDER = '../data_vault/AFM/'\n",
      "\n",
      "NLINES = 32\n",
      "\n",
      "SAMPLES_PER_LINE = 16384\n",
      "\n",
      "CMIN = (- 5)\n",
      "\n",
      "CMAX = 5\n",
      "\n",
      "FIGSIZE = (15, 7)\n",
      "\n",
      "SMOOTHNESS = 5\n",
      "\n",
      "MAX_RAD = 30\n",
      "\n",
      "LOW_THRESHOLD = 0.5\n",
      "\n",
      "HBINS = 50\n",
      "\n",
      "HMIN = 0\n",
      "\n",
      "HMAX = 10\n",
      "\n",
      "--------------------\n",
      " Local maximum finder\n",
      "\n",
      "from scipy.ndimage.filters import maximum_filter\n",
      "\n",
      "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
      "\n",
      "\n",
      "def detect_peaks(image):\n",
      "    \"\\n    Takes an image and detect the peaks using the local maximum filter.\\n    Returns a boolean mask of the peaks (i.e. 1 when\\n    the pixel's value is the neighborhood maximum, 0 otherwise)\\n    \"\n",
      "    neighborhood = generate_binary_structure(2, 2)\n",
      "    local_max = (maximum_filter(image, footprint=neighborhood) == image)\n",
      "    background = (image == 0)\n",
      "    eroded_background = binary_erosion(background, structure=neighborhood, border_value=1)\n",
      "    detected_peaks = (local_max - eroded_background)\n",
      "    return detected_peaks\n",
      "\n",
      "--------------------\n",
      " Linear models with CNN features\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import utils\n",
      "\n",
      "reload(utils)\n",
      "\n",
      "from utils import *\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "from sklearn import model_selection, linear_model, metrics\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "raw_data = pd.read_csv('bike_sharing_demand.csv', header=0, sep=',')\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "raw_data.info()\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "train_data = raw_data.iloc[:(- 1000), :]\n",
      "\n",
      "hold_out_test_data = raw_data.iloc[(- 1000):, :]\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "train_labels = train_data['count'].values\n",
      "\n",
      "train_data = train_data.drop(['datetime', 'count'], axis=1)\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "pylab.figure(figsize=(16, 6))\n",
      "\n",
      "pylab.subplot(1, 2, 1)\n",
      "\n",
      "pylab.hist(train_labels)\n",
      "\n",
      "pylab.title('train y')\n",
      "\n",
      "pylab.subplot(1, 2, 2)\n",
      "\n",
      "pylab.hist(test_labels)\n",
      "\n",
      "pylab.title('test y')\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "numeric_columns = ['temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'month', 'hour']\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "regressor = linear_model.SGDRegressor(random_state=0)\n",
      "\n",
      "--------------------\n",
      " Scaling\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "print(*map((lambda x: round(x, 2)), regressor.coef_))\n",
      "\n",
      "--------------------\n",
      " Pipeline\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "pipeline.get_params().keys()\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "metrics.mean_absolute_error(test_labels, grid_cv.best_estimator_.predict(test_data))\n",
      "\n",
      "--------------------\n",
      " export for Keras js tests\n",
      "\n",
      "print(json.dumps(DATA))\n",
      "\n",
      "--------------------\n",
      " Backward selection\n",
      "\n",
      "df_bward_eval = pd.DataFrame({\n",
      "    'k': np.nan,\n",
      "    'Param': np.nan,\n",
      "    'train_score': np.nan,\n",
      "    'cv_score': np.nan,\n",
      "}, index=[0])\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "N = 512\n",
      "\n",
      "dt = 0.01\n",
      "\n",
      "f = 10\n",
      "\n",
      "t = ((np.linspace(1, N, N) * dt) - dt)\n",
      "\n",
      "y = np.sin(((np.pi * f) * t))\n",
      "\n",
      "--------------------\n",
      " Text Chunking for Noun Phrase\n",
      "\n",
      "print(__doc__)\n",
      "\n",
      "'These are remarks about text Chunking of Noun Phrases'\n",
      "\n",
      "--------------------\n",
      " Conversion to n grams\n",
      "\n",
      "NounPhraseList = sorted(list(set(map((lambda x: x.lower()), NPs))))\n",
      "\n",
      "print(NounPhraseList[17000:17020])\n",
      "\n",
      "print(len(NounPhraseList))\n",
      "\n",
      "--------------------\n",
      " Noun Phrase Importance using TextRank\n",
      "\n",
      "import json\n",
      "\n",
      "f = open('NounPhrases.json', 'r')\n",
      "\n",
      "NounPhrases = json.load(f)\n",
      "\n",
      "NounPhrases = [item.lower() for item in NounPhrases]\n",
      "\n",
      "--------------------\n",
      " Junk \n",
      "\n",
      "print(type(SentenceTree))\n",
      "\n",
      "print(SentenceTree)\n",
      "\n",
      "print(NounPhrases)\n",
      "\n",
      "--------------------\n",
      " Create a corpus and conduct analysis\n",
      "\n",
      "\n",
      "def concatCol(col):\n",
      "    text = ''\n",
      "    for n in range(len(col)):\n",
      "        text += (str(col[n]) + ' ')\n",
      "    return text\n",
      "\n",
      "corpus = concatCol(df['PublicRemarks'])\n",
      "\n",
      "file = open('PublicRemarksCorpus.txt', 'w')\n",
      "\n",
      "file.write(corpus)\n",
      "\n",
      "file.close()\n",
      "\n",
      "--------------------\n",
      " Load the Data\n",
      "\n",
      "X_train = np.load('./car/X_train.npy')\n",
      "\n",
      "y_train = np.load('./car/y_train.npy')\n",
      "\n",
      "X_test = np.load('./car/X_test.npy')\n",
      "\n",
      "y_test = np.load('./car/y_test.npy')\n",
      "\n",
      "X_deploy = np.load('./car/X_deploy.npy')\n",
      "\n",
      "y_deploy = np.load('./car/y_deploy.npy')\n",
      "\n",
      "print('Number of training examples', len(X_train))\n",
      "\n",
      "print('Number of validation examples', len(X_test))\n",
      "\n",
      "print('Number of testing examples', len(X_deploy))\n",
      "\n",
      "--------------------\n",
      " UCB1\n",
      "\n",
      "model1 = Sequential()\n",
      "\n",
      "model1.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model1.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model1.load_weights('./UCB1/spam5.hdf5')\n",
      "\n",
      "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " Espsilon Greedy\n",
      "\n",
      "model_EG = Sequential()\n",
      "\n",
      "model_EG.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_EG.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_EG.load_weights('./EpsilonGreedy/spam5.hdf5')\n",
      "\n",
      "model_EG.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " Annealing Epsilon Greedy\n",
      "\n",
      "model_AEG = Sequential()\n",
      "\n",
      "model_AEG.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_AEG.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_AEG.load_weights('./AnnealingEpsilonGreedy/spam5.hdf5')\n",
      "\n",
      "model_AEG.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " SOFTMAX\n",
      "\n",
      "model_SM = Sequential()\n",
      "\n",
      "model_SM.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_SM.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_SM.load_weights('./Softmax/spam5.hdf5')\n",
      "\n",
      "model_SM.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " ANNEELYING SOFTMAX\n",
      "\n",
      "model_ASM = Sequential()\n",
      "\n",
      "model_ASM.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_ASM.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_ASM.load_weights('./AnnealingSoftmax/spam5.hdf5')\n",
      "\n",
      "model_ASM.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " THOMPSON SAMBLING\n",
      "\n",
      "model_TS = Sequential()\n",
      "\n",
      "model_TS.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_TS.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_TS.load_weights('./thompson_sampling/spam5.hdf5')\n",
      "\n",
      "model_TS.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " HEDGE\n",
      "\n",
      "model_HG = Sequential()\n",
      "\n",
      "model_HG.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_HG.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_HG.load_weights('./Hedge/spam5.hdf5')\n",
      "\n",
      "model_HG.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " EXP3\n",
      "\n",
      "model_EXP = Sequential()\n",
      "\n",
      "model_EXP.add(Dense(25, input_shape=(6,), activation='relu', W_regularizer=l2(0.001)))\n",
      "\n",
      "model_EXP.add(Dense(5, activation='softmax'))\n",
      "\n",
      "model_EXP.load_weights('./Exp3/spam5.hdf5')\n",
      "\n",
      "model_EXP.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
      "\n",
      "--------------------\n",
      " Graphics and Equation Typesetting\n",
      "\n",
      "get_ipython().run_line_magic('pylab', 'inline')\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Do not change the function names if you want to use the assert statements \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "--------------------\n",
      " Fun Fact Notice there are functions that have 1 underscore before them for example hypothesis In python programming these are usually considered to be private functions Unlike C C these functions can be called by users so they are not really private The idea behind private functions is that a user would most likely never call this function but you need it in order to perform operations for functions that users will call For example it can be argued that users will never care about what the gradient or hypothesis for a given example will be Thus you can keep these hidden as users will most likely only care about fitting the model and predicting on new values \n",
      "\n",
      "x = np.array([[1, 2], [1, 2], [0, 1], [2, 4]])\n",
      "\n",
      "--------------------\n",
      " Author Anita Ahmed ama908 nyu edu\n",
      "\n",
      "import os\n",
      "\n",
      "import json\n",
      "\n",
      "import csv\n",
      "\n",
      "import urllib2\n",
      "\n",
      "import zipfile\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import geopandas as gp\n",
      "\n",
      "import sklearn\n",
      "\n",
      "import sklearn.cluster\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "get_ipython().run_line_magic('pylab', 'inline')\n",
      "\n",
      "--------------------\n",
      " First Method K Means\n",
      "\n",
      "num_clusters = 8\n",
      "\n",
      "res = sklearn.cluster.KMeans(n_clusters=num_clusters).fit(matrix)\n",
      "\n",
      "--------------------\n",
      " Second Method Affinity Propogration Algorithms\n",
      "\n",
      "res = sklearn.cluster.AffinityPropagation(0.999).fit(matrix)\n",
      "\n",
      "plotClusters(res.cluster_centers_, res.labels_)\n",
      "\n",
      "--------------------\n",
      " Import modules\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from scipy.stats import entropy\n",
      "\n",
      "import os\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "from sklearn import tree\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "import statsmodels.api as sm\n",
      "\n",
      "from patsy import dmatrices\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.datasets import make_classification\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.ensemble import RandomTreesEmbedding, RandomForestClassifier, GradientBoostingClassifier\n",
      "\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "from sklearn.metrics import roc_curve\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Logistic Regression Model Evaluation Using a Validation Set\n",
      "\n",
      "X_LR = df.drop('bot', 1)\n",
      "\n",
      "Y_LR = df['bot']\n",
      "\n",
      "--------------------\n",
      " Traning Models Random Forest Classifier\n",
      "\n",
      "X_train_RF = train_df.drop('bot', 1)\n",
      "\n",
      "Y_train_RF = train_df['bot']\n",
      "\n",
      "X_test_RF = test_df.drop('bot', 1)\n",
      "\n",
      "Y_test_RF = test_df['bot']\n",
      "\n",
      "--------------------\n",
      " HISTOGRAMS\n",
      "\n",
      "plt.hist(bos.CRIM)\n",
      "\n",
      "plt.title('CRIM')\n",
      "\n",
      "plt.xlabel('Crime Rate Per Capita')\n",
      "\n",
      "plt.ylabel('Frequency')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Residual Sum of Squares\n",
      "\n",
      "print((np.sum((bos.PRICE - lm.predict(X))) ** 2))\n",
      "\n",
      "--------------------\n",
      " Mean Sqaured Error\n",
      "\n",
      "mseFull = np.mean(((bos.PRICE - lm.predict(X)) ** 2))\n",
      "\n",
      "print(mseFull)\n",
      "\n",
      "--------------------\n",
      " Residual Plots \n",
      "\n",
      "plt.scatter(lm.predict(X_train), (lm.predict(X_train) - Y_train), c='b', s=40, alpha=0.5)\n",
      "\n",
      "plt.scatter(lm.predict(X_test), (lm.predict(X_test) - Y_test), c='g', s=50)\n",
      "\n",
      "plt.title('Residual Plot using training (blue) and test (green) data')\n",
      "\n",
      "plt.ylabel('Residuals')\n",
      "\n",
      "--------------------\n",
      " where bo 1 constant \n",
      "\n",
      "((resultsW0.params[0] * newX[0]) + (resultsW0.params[1] * newX[1]))\n",
      "\n",
      "--------------------\n",
      " Proper way to predict\n",
      "\n",
      "resultsW0.predict(newX)\n",
      "\n",
      "--------------------\n",
      " Note resultW0 predict X resultW0 fittedvalues\n",
      "\n",
      "plt.scatter(faithful.waiting, faithful.eruptions)\n",
      "\n",
      "plt.xlabel('Waiting time to next eruption (in mins)')\n",
      "\n",
      "plt.ylabel('Eruption time (in mins)')\n",
      "\n",
      "plt.title('Old Faithful Geyser')\n",
      "\n",
      "plt.plot(faithful.waiting, resultsW0.fittedvalues, color='blue', linewidth=3)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Errors \n",
      "\n",
      "resids = (faithful.eruptions - resultsW0.predict(X))\n",
      "\n",
      "--------------------\n",
      " F \n",
      "\n",
      "phase = np.tan((((- f) / (2 * np.pi)) * tau))\n",
      "\n",
      "plt.title('Bode Plot, Phase')\n",
      "\n",
      "plt.xlabel('Frequency (Hz)')\n",
      "\n",
      "plt.ylabel('Phase (radians)')\n",
      "\n",
      "plt.semilogx(f, phase)\n",
      "\n",
      "--------------------\n",
      " B \n",
      "\n",
      "hn = h(t, (0.05 * 80))\n",
      "\n",
      "print(('The area under h[n] is: ' + str(sum(hn))))\n",
      "\n",
      "plt.plot(t, hn)\n",
      "\n",
      "plt.title('Gaussian Filter Kernel (Frequency Domain)')\n",
      "\n",
      "plt.xlabel('time (samples)')\n",
      "\n",
      "plt.ylabel('Amplitude (uV)')\n",
      "\n",
      "--------------------\n",
      " C \n",
      "\n",
      "y = np.real(np.fft.ifft(np.multiply(np.fft.fft(x), np.fft.fft(hn))))\n",
      "\n",
      "--------------------\n",
      " D \n",
      "\n",
      "plt.plot(t, hn, label='h[n]')\n",
      "\n",
      "plt.plot(t, x, label='x[n]')\n",
      "\n",
      "plt.plot(t, y, label='Convolution of x and h')\n",
      "\n",
      "plt.title('Gaussian Filter Result (Frequency Domain)')\n",
      "\n",
      "plt.xlabel('Sample')\n",
      "\n",
      "plt.ylabel('Amplitude (uV)')\n",
      "\n",
      "plt.legend(loc='best')\n",
      "\n",
      "--------------------\n",
      " Naive Clustering\n",
      "\n",
      "plt.hist(**data)\n",
      "\n",
      "plt.title(title)\n",
      "\n",
      "_ = plt.axvline(5.8, color='black', linewidth=4)\n",
      "\n",
      "--------------------\n",
      " Excursis Bag of Words Assumption\n",
      "\n",
      "import collections\n",
      "\n",
      "this = 'beautiful is better than ugly explicit is better than implicit simple is better than complex complex is better than complicated flat is better than nested sparse is better than dense readability counts special cases arent special enough to break the rules although practicality beats purity errors should never pass silently unless explicitly silenced in the face of ambiguity refuse the temptation to guess there should be one and preferably only one obvious way to do it although that way may not be obvious at first unless youre dutch now is better than never although never is often better than right now if the implementation is hard to explain its a bad idea if the implementation is easy to explain it may be a good idea namespaces are one honking great idea lets do more of those'\n",
      "\n",
      "' '.join(sorted(this.split(' ')))\n",
      "\n",
      "--------------------\n",
      " Utility Functions\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "import scipy.stats as stats\n",
      "\n",
      "import time\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "import sklearn.feature_selection as selection\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.model_selection import StratifiedKFold\n",
      "\n",
      "from sklearn.feature_selection import RFECV\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "from collections import defaultdict\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "import multiprocessing as mp\n",
      "\n",
      "from joblib import Parallel, delayed\n",
      "\n",
      "--------------------\n",
      " Missing Values\n",
      "\n",
      "\n",
      "def fill_na(df, d):\n",
      "    '\\n    Inputs:\\n        - d -> dictionary with column name and value to substitute missing values\\n    '\n",
      "    df_copy = df.copy()\n",
      "    for col in d.keys():\n",
      "        df_copy[col] = df_copy[col].fillna(d[col])\n",
      "    return df_copy\n",
      "\n",
      "--------------------\n",
      " Univariate\n",
      "\n",
      "\n",
      "def select_univariate(X_train, y_train, n=None, score_function=selection.chi2):\n",
      "    '\\n    Returns the new X with the best n columns\\n    Inputs:\\n        - n -> number of feature to select (in case of Select K best, otherwise None)\\n        - score_function -> chi-square default (classification) other here:\\n                            http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\\n    '\n",
      "    return selection.SelectKBest(score_func=score_function, k=n).fit_transform(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " Feature importance Decision Trees\n",
      "\n",
      "\n",
      "def feature_importance_trees(X, y, n, model):\n",
      "    '\\n    Input:\\n        - n: number of feature to select\\n    Output:\\n        - X_selected_features: X with the selected features\\n    '\n",
      "    model.fit(X, y)\n",
      "    feature_importance = pd.DataFrame({\n",
      "        'Feature': X.columns,\n",
      "        'Feature_Importance': model.feature_importances_,\n",
      "    })\n",
      "    feature_importance.sort(columns='Feature_Importance', ascending=False, inplace=True)\n",
      "    return X[feature_importance.Feature.tolist()[:n]]\n",
      "\n",
      "--------------------\n",
      " Training Validation Test Set Split\n",
      "\n",
      "\n",
      "def train_test_split_df(df, train_size=0.67, random_state=42):\n",
      "    '\\n    Output:\\n        - df_train, df_test\\n    '\n",
      "    (df_train, df_test) = train_test_split(df, train_size=train_size, random_state=random_state)\n",
      "    return (df_train, df_test)\n",
      "\n",
      "\n",
      "def train_test_split_X_y(X, y, train_size=0.67, random_state=42):\n",
      "    '\\n    Output:\\n        - X_train, X_test, y_train, y_test\\n    '\n",
      "    (X_train, X_test, y_train, y_test) = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
      "    return (X_train, X_test, y_train, y_test)\n",
      "\n",
      "--------------------\n",
      " Step 2 Tune max depth and min child weight\n",
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "param_test1 = {\n",
      "    'max_depth': range(3, 10, 2),\n",
      "    'min_child_weight': range(1, 6, 2),\n",
      "}\n",
      "\n",
      "gs1 = GridSearchCV(xgb1, param_grid=param_test1, scoring='accuracy', n_jobs=4, iid=False, cv=5)\n",
      "\n",
      "gs1.fit(train[features], train[target])\n",
      "\n",
      "(gs1.grid_scores_, gs1.best_params_, gs1.best_score_)\n",
      "\n",
      "--------------------\n",
      " Step 6 Reducing Learning Rate\n",
      "\n",
      "xgb4 = XGBClassifier(learning_rate=0.01, n_estimators=5000, max_depth=9, min_child_weight=1, gamma=0.2, subsample=0.6, colsample_bytree=0.8, reg_alpha=0.05, objective='multi:softmax', nthread=4, scale_pos_weight=1, seed=seed)\n",
      "\n",
      "modelfit(xgb4, train, features)\n",
      "\n",
      "--------------------\n",
      " General Visualisations \n",
      "\n",
      "titanic_df.drop(['PassengerId'], axis=1).hist(figsize=(12, 12), layout=(4, 2))\n",
      "\n",
      "--------------------\n",
      " Pclass \n",
      "\n",
      "basic_plots('Pclass')\n",
      "\n",
      "--------------------\n",
      " Here s a sample of code for how to get variance and bias from an sklearn model\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "regr = linear_model.LinearRegression()\n",
      "\n",
      "regr.fit(X, Y)\n",
      "\n",
      "yhat = regr.predict(X)\n",
      "\n",
      "sse = np.mean(((np.mean(yhat) - Y) ** 2))\n",
      "\n",
      "var = np.var(yhat)\n",
      "\n",
      "bias = ((sse - var) - 0.01)\n",
      "\n",
      "--------------------\n",
      " Validation\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import time\n",
      "\n",
      "import os\n",
      "\n",
      "import sys\n",
      "\n",
      "import sqlite3\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scipy as sp\n",
      "\n",
      "import statsmodels.formula.api as smf\n",
      "\n",
      "import scipy.io\n",
      "\n",
      "import matplotlib as mpl\n",
      "\n",
      "import matplotlib.cm as cm\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "import plotly\n",
      "\n",
      "plotly.offline.init_notebook_mode()\n",
      "\n",
      "--------------------\n",
      " Here the resulting bounding boxes are drawn onto the last frame in the series \n",
      "\n",
      "file = glob.glob('test_images/frame*.jpg')[5]\n",
      "\n",
      "img = cv2.imread(file)\n",
      "\n",
      "img = draw_labeled_bboxes(img, label(heat))\n",
      "\n",
      "plt.title('Bounding boxes')\n",
      "\n",
      "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
      "\n",
      "--------------------\n",
      " Learning with ensembles\n",
      "\n",
      "Image(filename='./images/07_01.png', width=500)\n",
      "\n",
      "--------------------\n",
      " Implementing a simple majority vote classifier \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "np.argmax(np.bincount([0, 0, 1], weights=[0.2, 0.2, 0.6]))\n",
      "\n",
      "--------------------\n",
      " Combining different algorithms for classification with majority vote\n",
      "\n",
      "from sklearn import datasets\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "(X, y) = (iris.data[50:, [1, 2]], iris.target[50:])\n",
      "\n",
      "le = LabelEncoder()\n",
      "\n",
      "y = le.fit_transform(y)\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.5, random_state=1)\n",
      "\n",
      "--------------------\n",
      " Bagging Building an ensemble of classifiers from bootstrap samples\n",
      "\n",
      "Image(filename='./images/07_06.png', width=500)\n",
      "\n",
      "--------------------\n",
      " Leveraging weak learners via adaptive boosting\n",
      "\n",
      "Image(filename='./images/07_09.png', width=400)\n",
      "\n",
      "--------------------\n",
      " Load in the data\n",
      "\n",
      "(x_train, y_train, x_test, y_test) = read_data(data_fname, ntrain)\n",
      "\n",
      "--------------------\n",
      " Test the trained model\n",
      "\n",
      "y_pred = model.predict(x_test, batch_size=100, verbose=0)\n",
      "\n",
      "y_bc = predict_barycenter(x_test)\n",
      "\n",
      "--------------------\n",
      " The molecules\n",
      "\n",
      "np.unique(y_df['molecule'].values)\n",
      "\n",
      "--------------------\n",
      " The concentration\n",
      "\n",
      "plt.hist(concentration, bins=26)\n",
      "\n",
      "plt.xlabel('Concentration')\n",
      "\n",
      "print(('There are %s different values of concentrations.' % np.unique(concentration).size))\n",
      "\n",
      "--------------------\n",
      " Link between molecules and concentrations\n",
      "\n",
      "for mol in np.unique(molecule):\n",
      "    plt.figure()\n",
      "    plt.hist(concentration[(molecule == mol)], bins=20)\n",
      "    plt.title((mol + ('-  %s values of concentrations.' % np.unique(concentration[(molecule == mol)]).size)))\n",
      "    print(np.unique(concentration[(molecule == mol)]))\n",
      "\n",
      "--------------------\n",
      " Explore the Raman Spectra\n",
      "\n",
      "plt.plot(freqs, spectra[100:130].T)\n",
      "\n",
      "plt.xlabel('Freq')\n",
      "\n",
      "plt.ylabel('Intensity')\n",
      "\n",
      "--------------------\n",
      " Link between Raman Spectra and molecules\n",
      "\n",
      "for mol in np.unique(molecule):\n",
      "    plt.plot(np.mean(X[(molecule == mol), :], axis=0), label=('%s' % mol))\n",
      "\n",
      "plt.legend(bbox_to_anchor=(1.2, 1), bbox_transform=plt.gcf().transFigure)\n",
      "\n",
      "--------------------\n",
      " Link between Raman spectrum and concentrations\n",
      "\n",
      "for c in np.unique(concentration):\n",
      "    plt.plot(np.mean(X[(concentration == c), :], axis=0), label=('%s' % c))\n",
      "\n",
      "plt.legend(bbox_to_anchor=(1.2, 1), bbox_transform=plt.gcf().transFigure)\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "X = []\n",
      "\n",
      "y = []\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "model.fit(X, y)\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "place_names = model.classes_\n",
      "\n",
      "print(place_names)\n",
      "\n",
      "--------------------\n",
      " Load data\n",
      "\n",
      "Conf = eclipse_DVH('Prostate_data_C-5/DVH_conf.txt')\n",
      "\n",
      "IMRT = eclipse_DVH('Prostate_data_C-5/DVH_IMRT.txt')\n",
      "\n",
      "--------------------\n",
      " Predicting Arrival Delay\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import time\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "tic = time.time()\n",
      "\n",
      "df = pd.read_csv('../python-introduction-th2669/juneairline_data1.csv')\n",
      "\n",
      "toc = time.time()\n",
      "\n",
      "print((('Finished reading CSV file in ' + str((toc - tic))) + ' seconds'))\n",
      "\n",
      "df.head\n",
      "\n",
      "df.dtypes\n",
      "\n",
      "--------------------\n",
      " Try Logistic Regression Model \n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(df.drop('ARR_DELAY', axis=1), df['ARR_DELAY'], test_size=0.3, random_state=42)\n",
      "\n",
      "--------------------\n",
      " Let s Try Random Forest Model n 50 \n",
      "\n",
      "from sklearn import linear_model, cross_validation, metrics, svm\n",
      "\n",
      "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "randomforest_arr = RandomForestClassifier(n_estimators=50, n_jobs=(- 1))\n",
      "\n",
      "randomforest_arr.fit(X_train, y_train)\n",
      "\n",
      "predictions = randomforest_arr.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " Let s Try Random Forest Model n 100 \n",
      "\n",
      "from sklearn import linear_model, cross_validation, metrics, svm\n",
      "\n",
      "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "randomforest_arr = RandomForestClassifier(n_estimators=100, n_jobs=(- 1))\n",
      "\n",
      "randomforest_arr.fit(X_train, y_train)\n",
      "\n",
      "predictions = randomforest_arr.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " Predicting Departure Delay with same method\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import time\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "tic = time.time()\n",
      "\n",
      "df = pd.read_csv('../python-introduction-th2669/juneairline_data2.csv')\n",
      "\n",
      "toc = time.time()\n",
      "\n",
      "print((('Finished reading CSV file in ' + str((toc - tic))) + ' seconds'))\n",
      "\n",
      "df.head\n",
      "\n",
      "df.dtypes\n",
      "\n",
      "--------------------\n",
      " Logistic Regression Model\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(df.drop('DEP_DELAY', axis=1), df['DEP_DELAY'], test_size=0.3, random_state=101)\n",
      "\n",
      "--------------------\n",
      " Let s Try Random Forest Model n 50 \n",
      "\n",
      "from sklearn import linear_model, cross_validation, metrics, svm\n",
      "\n",
      "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "randomforest_dep = RandomForestClassifier(n_estimators=50, n_jobs=(- 1))\n",
      "\n",
      "randomforest_dep.fit(X_train, y_train)\n",
      "\n",
      "predictions = randomforest_dep.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " Let s Try Random Forest Model n 100 \n",
      "\n",
      "from sklearn import linear_model, cross_validation, metrics, svm\n",
      "\n",
      "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "randomforest_dep = RandomForestClassifier(n_estimators=100, n_jobs=(- 1))\n",
      "\n",
      "randomforest_dep.fit(X_train, y_train)\n",
      "\n",
      "predictions = randomforest_dep.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " Collapses the spectrum in the dispersion direction to get a cross dispersion profile \n",
      "\n",
      "plt.imshow(img, vmin=0, vmax=50, cmap=plt.cm.gray, origin='lower')\n",
      "\n",
      "--------------------\n",
      " Finds all points 2 median smoothed background assume these are spectrum locations \n",
      "\n",
      "specs = np.array((collapsed_img > (2.0 * med_fit)))\n",
      "\n",
      "--------------------\n",
      " Plot results \n",
      "\n",
      "tbdata = pyfits.getdata(ofile, 1)\n",
      "\n",
      "extrlocy = tbdata['extrlocy'][0]\n",
      "\n",
      "--------------------\n",
      " examples\n",
      "\n",
      "a = np.array([[5, 0], [6, 0]])\n",
      "\n",
      "main(a)\n",
      "\n",
      "--------------------\n",
      " Heat maps showing pitch targets for a batter over the season\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " Script starts here\n",
      "\n",
      "batter_name = 'Travis Shaw'\n",
      "\n",
      "year = '2015'\n",
      "\n",
      "--------------------\n",
      " Pitch location with KDE plots\n",
      "\n",
      "sb.set_style('darkgrid')\n",
      "\n",
      "--------------------\n",
      " Pitch location with heat maps \n",
      "\n",
      "sb.set_style('white')\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "from Levenshtein import distance\n",
      "\n",
      "--------------------\n",
      " tf idf\n",
      "\n",
      "ch2 = SelectKBest(chi2, k=5000)\n",
      "\n",
      "X_train_ch = ch2.fit_transform(X_train, y_train)\n",
      "\n",
      "X_test_ch = ch2.transform(X_test)\n",
      "\n",
      "--------------------\n",
      " Linear Regression with scikit learn\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "--------------------\n",
      " Testing for Cointegration\n",
      "\n",
      "adf = statsmodels.tsa.stattools.adfuller(spread['in-sample'], maxlag=1)\n",
      "\n",
      "print('ADF test statistics: {:.03f}').format(adf[0])\n",
      "\n",
      "print('p-value: {:.03f}').format(adf[1])\n",
      "\n",
      "--------------------\n",
      " Out of Sample Test Set\n",
      "\n",
      "data_oos = get_pricing(symbols(tickers), start_date='2008-08-01', end_date='2010-01-01', fields='close_price', frequency='daily')\n",
      "\n",
      "data_oos.columns = [ticker.symbol for ticker in data_oos.columns]\n",
      "\n",
      "data_oos.index.name = 'Date'\n",
      "\n",
      "--------------------\n",
      " Tear Sheet\n",
      "\n",
      "bt = get_backtest('59687abcabb3315736a24c90')\n",
      "\n",
      "--------------------\n",
      " Read Data\n",
      "\n",
      "DATA_ROOT = 'D:/data/hands_on_ML'\n",
      "\n",
      "FILE_PATH = '/C2/housing.csv'\n",
      "\n",
      "raw_d = pd.read_csv((DATA_ROOT + FILE_PATH))\n",
      "\n",
      "--------------------\n",
      " Visualize and explore data\n",
      "\n",
      "training_copy = strat_train_set.copy()\n",
      "\n",
      "--------------------\n",
      " Feature engineering and Data cleaning\n",
      "\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\n",
      "\n",
      "from sklearn.pipeline import Pipeline, FeatureUnion\n",
      "\n",
      "from sklearn.preprocessing import Imputer, StandardScaler, LabelBinarizer\n",
      "\n",
      "--------------------\n",
      " Select and train model\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "from sklearn.tree import DecisionTreeRegressor\n",
      "\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "\n",
      "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
      "\n",
      "--------------------\n",
      " Random forest with grid search\n",
      "\n",
      "param_grid = [{\n",
      "    'n_estimators': [3, 10, 30],\n",
      "    'max_features': [2, 4, 6, 8],\n",
      "}, {\n",
      "    'bootstrap': [False],\n",
      "    'n_estimators': [3, 10],\n",
      "    'max_features': [2, 3, 4],\n",
      "}]\n",
      "\n",
      "forest_reg = RandomForestRegressor()\n",
      "\n",
      "grid_search = GridSearchCV(forest_reg, param_grid, cv=4, scoring='neg_mean_squared_error')\n",
      "\n",
      "grid_search.fit(train_x, train_y)\n",
      "\n",
      "--------------------\n",
      " Classification with Support Vector Machines\n",
      "\n",
      "Image(filename='../images/03_08.png', width=600)\n",
      "\n",
      "--------------------\n",
      " Trials\n",
      "\n",
      "frank = get_data(51, 5)\n",
      "\n",
      "--------------------\n",
      " Loading the dataset\n",
      "\n",
      "import os\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import sklearn as skl\n",
      "\n",
      "import holcrawl.shared\n",
      "\n",
      "--------------------\n",
      " Prediction\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "from sklearn.model_selection import cross_val_score\n",
      "\n",
      "--------------------\n",
      " center Xgboost center \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "get_ipython().run_line_magic('pylab', 'inline')\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
      "\n",
      "--------------------\n",
      " Test outlier on scores\n",
      "\n",
      "import imp\n",
      "\n",
      "import sys\n",
      "\n",
      "sys.path.append('../lib')\n",
      "\n",
      "from outlier import *\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from itertools import groupby\n",
      "\n",
      "from sklearn.linear_model import ElasticNet\n",
      "\n",
      "from sklearn.model_selection import cross_val_score\n",
      "\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "--------------------\n",
      " Import data 2\n",
      "\n",
      "store_cible = pd.HDFStore('../PCA/cible_crossB2B_1.h5')\n",
      "\n",
      "--------------------\n",
      " Score battre avec LogisticRegression\n",
      "\n",
      "np.logspace((- 4), 4, 10)\n",
      "\n",
      "--------------------\n",
      " Score battre avec AdaBoost\n",
      "\n",
      "tuned_parameters = [{\n",
      "    'n_estimators': [50, 100, 200, 300],\n",
      "    'learning_rate': [1, 2],\n",
      "}]\n",
      "\n",
      "clf_ada = GridSearchCV(AdaBoostClassifier(base_estimator=best_log), tuned_parameters, scoring='roc_auc', cv=5, verbose=10)\n",
      "\n",
      "clf_ada.fit(dg_drop_minmax, cible)\n",
      "\n",
      "--------------------\n",
      " Score battre avec gradient boosting \n",
      "\n",
      "tuned_parameters = [{\n",
      "    'loss': ['deviance', 'exponential'],\n",
      "    'max_features': [5, 10, 20],\n",
      "    'max_depth': [5, 10, 30],\n",
      "    'n_estimators': [20, 100],\n",
      "}]\n",
      "\n",
      "clf = GridSearchCV(GradientBoostingClassifier(), tuned_parameters, scoring='roc_auc', cv=5, verbose=10)\n",
      "\n",
      "clf.fit(dg_drop_minmax, cible)\n",
      "\n",
      "--------------------\n",
      " Remove outlier using Mahalanobis\n",
      "\n",
      "outliersMahanalobis = OutlierMahalanobis(support_fraction=0.95, chi2_percentile=0.995)\n",
      "\n",
      "--------------------\n",
      " Remove outlier with Kmeans\n",
      "\n",
      "normalIndex = (dg['fin'] == 1)\n",
      "\n",
      "K = 5\n",
      "\n",
      "kmeans = KMeans(init='k-means++', n_clusters=K, n_init=10, random_state=5)\n",
      "\n",
      "--------------------\n",
      " Remove outliers with robust PCA\n",
      "\n",
      "rpca = R_pca(np.array(dg.transpose()))\n",
      "\n",
      "--------------------\n",
      " DAT NYC 37 Lab 08 Introduction to Classification\n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn import neighbors, metrics, grid_search, cross_validation\n",
      "\n",
      "pd.set_option('display.max_rows', 10)\n",
      "\n",
      "pd.set_option('display.notebook_repr_html', True)\n",
      "\n",
      "pd.set_option('display.max_columns', 10)\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "plt.style.use('ggplot')\n",
      "\n",
      "--------------------\n",
      " Linear models with CNN features\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import utils\n",
      "\n",
      "reload(utils)\n",
      "\n",
      "from utils import *\n",
      "\n",
      "--------------------\n",
      " Generate documents\n",
      "\n",
      "try:\n",
      "    fname = 'AllCards.json.gz'\n",
      "    cards = json.load(gzip.open(fname, 'rt'))\n",
      "except FileNotFoundError:\n",
      "    url = 'https://mtgjson.com/json/AllCards.json.gz'\n",
      "    fname = wget.download(url)\n",
      "    cards = json.load(gzip.open(fname, 'rt'))\n",
      "\n",
      "--------------------\n",
      " Model LSI\n",
      "\n",
      "tfidf = models.TfidfModel(corpus)\n",
      "\n",
      "corpus_tfidf = tfidf[corpus]\n",
      "\n",
      "--------------------\n",
      " Create index\n",
      "\n",
      "index = similarities.MatrixSimilarity(corpus_lsi)\n",
      "\n",
      "index.save('all_cards_lsi.index')\n",
      "\n",
      "--------------------\n",
      " Query similar cards\n",
      "\n",
      "get_similar_cards('Cadaverous Bloom')\n",
      "\n",
      "--------------------\n",
      " Model LDA\n",
      "\n",
      "lda = models.LdaMulticore(corpus, id2word=dictionary, num_topics=100)\n",
      "\n",
      "corpus_lda = lda[corpus]\n",
      "\n",
      "--------------------\n",
      " Model HDP\n",
      "\n",
      "hdp = models.HdpModel(corpus, id2word=dictionary)\n",
      "\n",
      "corpus_hdp = hdp[corpus]\n",
      "\n",
      "--------------------\n",
      " Shlukov n pro na i lohu\n",
      "\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
      "\n",
      "--------------------\n",
      " Jak najdeme odpov di na na i lohu \n",
      "\n",
      "print((- kmeansModelTricka.score(cistaData[['Sirka [cm]', 'Delka [cm]']])))\n",
      "\n",
      "--------------------\n",
      " Predicting Sentiment from Tweet\n",
      "\n",
      "X_test = ['Congrats @ravikiranj, i heard you wrote a new tech post on sentiment analysis']\n",
      "\n",
      "--------------------\n",
      " Additional plots 3D skipped if lack of time\n",
      "\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "ax = plt.axes(projection='3d')\n",
      "\n",
      "(xgrid, ygrid) = np.meshgrid(x, y.ravel())\n",
      "\n",
      "ax.plot_surface(xgrid, ygrid, im, cmap=plt.cm.jet, cstride=2, rstride=2, linewidth=0)\n",
      "\n",
      "--------------------\n",
      " center Martim Jos e Filipe Borba center \n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import json\n",
      "\n",
      "import itertools\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from scipy import stats\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "import matplotlib.patches as mpatches\n",
      "\n",
      "import math\n",
      "\n",
      "--------------------\n",
      " Preliminary analysis\n",
      "\n",
      "clean_hospital_read_df = hospital_read_df[(hospital_read_df['Number of Discharges'] != 'Not Available')]\n",
      "\n",
      "clean_hospital_read_df.loc[:, 'Number of Discharges'] = clean_hospital_read_df['Number of Discharges'].astype(int)\n",
      "\n",
      "clean_hospital_read_df = clean_hospital_read_df.sort('Number of Discharges')\n",
      "\n",
      "--------------------\n",
      " Imports \n",
      "\n",
      "from __future__ import unicode_literals\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "pd.set_option('display.max_columns', 60)\n",
      "\n",
      "import itertools as it\n",
      "\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "xls_writer = pd.ExcelWriter\n",
      "\n",
      "import pybedtools as pbt\n",
      "\n",
      "import scipy\n",
      "\n",
      "import statsmodels.api as sm\n",
      "\n",
      "import statsmodels.stats.multitest as smm\n",
      "\n",
      "import munch\n",
      "\n",
      "from spartan.utils.genome_specific.GfusI1 import GfusI1_0\n",
      "\n",
      "from spartan.utils.fastas import ParseFastA\n",
      "\n",
      "--------------------\n",
      " File paths \n",
      "\n",
      "tx_fasta = '/home/gus/MEGAsync/zim/main/Yale/Collaborations/Hongyu-tsetse/Xiaoqing/transcripts/2016-02-05_comprehensive_Gmm_transcript_set/Gisella2016_Morsitan_transcriptome/transcripts.fa'\n",
      "\n",
      "ortholog_table = '/home/gus/MEGAsync/zim/main/Yale/Collaborations/Hongyu-tsetse/Find_Gff_sequences_from_Gmm_RNA-seq_transcriptome/existing_genes/vectorbase_orthologs_GMOY_GFUI.csv'\n",
      "\n",
      "tx_orthos_out = '/home/gus/MEGAsync/zim/main/Yale/Collaborations/Hongyu-tsetse/Find_Gff_sequences_from_Gmm_RNA-seq_transcriptome/existing_genes/xiaoqing_orthologous_Tx_GMOY_GFUI_comp_Tx_assemb.xls'\n",
      "\n",
      "--------------------\n",
      " Outliers\n",
      "\n",
      "dfs = df_all[(df_all['application'] == 'ScalaSort')].drop('application', axis=1)\n",
      "\n",
      "print('{:d} outliers:'.format(dfs.outlier.sum()))\n",
      "\n",
      "dfs[dfs.outlier].drop('outlier', axis=1).groupby(['input', 'workers']).agg(np.size)\n",
      "\n",
      "--------------------\n",
      " Measurements without outliers\n",
      "\n",
      "df_clean = dfs[(~ dfs.outlier)].drop('outlier', axis=1).groupby(['input', 'workers']).agg([np.mean, np.std, np.size])\n",
      "\n",
      "print('{:g} experiments:'.format(df_clean.seconds['size'].sum()))\n",
      "\n",
      "df_clean\n",
      "\n",
      "--------------------\n",
      " K means Application\n",
      "\n",
      "\n",
      "def input2samples(df):\n",
      "    b2s = {\n",
      "        \n",
      "    }\n",
      "    k_samples = 32\n",
      "    for mb in sorted(df.input.unique()):\n",
      "        b2s[mb] = k_samples\n",
      "        k_samples *= 2\n",
      "    df.input = df.input.apply((lambda mb: b2s[mb]))\n",
      "\n",
      "--------------------\n",
      " Outliers\n",
      "\n",
      "dfk = df_all[df_all.application.str.startswith('DenseKMeans')].drop('application', axis=1)\n",
      "\n",
      "input2samples(dfk)\n",
      "\n",
      "print('{:d} outliers:'.format(dfk.outlier.sum()))\n",
      "\n",
      "dfk[dfk.outlier].drop('outlier', axis=1).groupby(['input', 'workers']).agg(np.size)\n",
      "\n",
      "--------------------\n",
      " Measurements without outliers\n",
      "\n",
      "df_clean = dfk.drop('outlier', axis=1).groupby(['input', 'workers']).agg([np.mean, np.std, np.size])\n",
      "\n",
      "print('{:g} experiments:'.format(df_clean.seconds['size'].sum()))\n",
      "\n",
      "df_clean\n",
      "\n",
      "--------------------\n",
      " Outliers\n",
      "\n",
      "outliers = calc_outliers(df_jobs, 'job 00', ['workers', 'input'], 3)\n",
      "\n",
      "df_jobs[(~ outliers)].groupby(['workers', 'input'])['job 00'].agg(np.size).value_counts()\n",
      "\n",
      "outliers.sum()\n",
      "\n",
      "--------------------\n",
      " Data locality\n",
      "\n",
      "\n",
      "def get_info(task):\n",
      "    method = (None if (not task.metrics) else task.metrics.data_read_method)\n",
      "    return (task.locality, method)\n",
      "\n",
      "types = set((get_info(t) for a in apps for s in a.stages for t in s.tasks))\n",
      "\n",
      "types\n",
      "\n",
      "--------------------\n",
      " Load dataset \n",
      "\n",
      "trains24 = pd.read_csv('../Dataset/articoliS24O.csv', delimiter='\\t')\n",
      "\n",
      "trainRadiocor = pd.read_csv('../Dataset/articoliRadiocor.csv', delimiter='\\t')\n",
      "\n",
      "--------------------\n",
      " Data Exploration \n",
      "\n",
      "dim_init_s24 = colsel_trains24.shape\n",
      "\n",
      "dim_init_s24\n",
      "\n",
      "--------------------\n",
      " First BOW \n",
      "\n",
      "\n",
      "def build_BOW(corpus):\n",
      "    'The corpus to be fed into should be a list!'\n",
      "    all_words = [w for t in corpus for w in t.split()]\n",
      "    freq = nltk.FreqDist(all_words)\n",
      "    return freq\n",
      "\n",
      "--------------------\n",
      " Impact of Stopwords onto the coprus \n",
      "\n",
      "stopw = set(stopwords.words('italian'))\n",
      "\n",
      "puntk = set(string.punctuation)\n",
      "\n",
      "direct = (((set('«') | set('»')) | set('“')) | set('”'))\n",
      "\n",
      "removal = ((stopw | puntk) | direct)\n",
      "\n",
      "print(removal)\n",
      "\n",
      "--------------------\n",
      " Generate verb tokens \n",
      "\n",
      "\n",
      "def clean_tag(tt):\n",
      "    if (len(tt) < 3):\n",
      "        print(tt[0])\n",
      "    if ((tt[2] == '@card@') or (tt[2] == '@ord@')):\n",
      "        return tt[0]\n",
      "    else:\n",
      "        return re.sub('[a-z]+\\\\|', '', tt[2])\n",
      "\n",
      "--------------------\n",
      " WordCloud after Cleaning \n",
      "\n",
      "wc = wordcloud(cleaned_corpus['body'], None)\n",
      "\n",
      "--------------------\n",
      " 2 TensorFlow float32 \n",
      "\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "(x_train, x_test, y_train, y_test) = model_selection.train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)\n",
      "\n",
      "(x_train, x_test) = map(np.float32, [x_train, x_test])\n",
      "\n",
      "--------------------\n",
      " 3 \n",
      "\n",
      "classifier = SKCompat(learn.Estimator(model_fn=my_model, model_dir='Models/model_1'))\n",
      "\n",
      "classifier.fit(x_train, y_train, steps=800)\n",
      "\n",
      "y_predicted = [i for i in classifier.predict(x_test)]\n",
      "\n",
      "score = metrics.accuracy_score(y_test, y_predicted)\n",
      "\n",
      "print(('Accuracy: %.2f%%' % (score * 100)))\n",
      "\n",
      "--------------------\n",
      " Write Distance Matrix\n",
      "\n",
      "get_ipython().system('rm dismat.csv')\n",
      "\n",
      "with open('dismat.csv', 'a') as file:\n",
      "    for hashtag in points:\n",
      "        file.write((hashtag + ';'))\n",
      "        for second in points:\n",
      "            file.write((str(metric(hashtag, second)) + ';'))\n",
      "        file.write('\\n')\n",
      "\n",
      "--------------------\n",
      " HILLARY VS TRUMP\n",
      "\n",
      "(db, conn) = connect()\n",
      "\n",
      "db.execute(\"SELECT (time_stamp,tag) FROM occurs INNER JOIN Tweet ON occurs.id = Tweet.id WHERE tag = '#VoteTrump' OR tag = '#votetrump'\")\n",
      "\n",
      "tags_trump = db.fetchall()\n",
      "\n",
      "db.execute(\"SELECT (time_stamp,tag) FROM occurs INNER JOIN Tweet ON occurs.id = Tweet.id WHERE tag = '#ImWithHer' OR tag = '#Hillary2016'\")\n",
      "\n",
      "tags_hill = db.fetchall()\n",
      "\n",
      "db.close()\n",
      "\n",
      "conn.close()\n",
      "\n",
      "--------------------\n",
      " We ll try 3\n",
      "\n",
      "kmeans_model = KMeans(n_clusters=3, random_state=42)\n",
      "\n",
      "kmeans_model.fit(df_scaled)\n",
      "\n",
      "--------------------\n",
      " Explore flight delay data wrt day of week\n",
      "\n",
      "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scipy as sp\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "sns.set_style('white')\n",
      "\n",
      "--------------------\n",
      " Load data\n",
      "\n",
      "from flightdelay.fld import io as flio\n",
      "\n",
      "(airlines_df, airports_df, flights_df) = flio.load_data()\n",
      "\n",
      "--------------------\n",
      " Departure hour\n",
      "\n",
      "flights_df['HOUR_DEPARTURE'] = np.floor((flights_df['SCHEDULED_DEPARTURE'].values / 100)).astype(int)\n",
      "\n",
      "--------------------\n",
      " Departure hour by airport\n",
      "\n",
      "gb_aph = flights_df[['ORIGIN_AIRPORT', 'HOUR_DEPARTURE', 'DEPARTURE_DELAY']].groupby(['ORIGIN_AIRPORT', 'HOUR_DEPARTURE'])\n",
      "\n",
      "mean_delays = gb_aph.agg(['mean'])\n",
      "\n",
      "--------------------\n",
      " Departure hour for all flights\n",
      "\n",
      "gb_aph = flights_df[['HOUR_DEPARTURE', 'DEPARTURE_DELAY']].groupby(['HOUR_DEPARTURE'])\n",
      "\n",
      "mean_delays = gb_aph.agg(['mean', 'count', 'sem'])\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "\n",
      "((X_train, y_train), (X_test, y_test)) = pickle.load(f, encoding='bytes')\n",
      "\n",
      "f.close()\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "index = 242\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "Image(model_to_dot(model, show_shapes=1).create_png())\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "model.compile(loss='mean_squared_error', optimizer='Adam')\n",
      "\n",
      "--------------------\n",
      " 1 7 \n",
      "\n",
      "(((predict.shape[0] - is_true) / predict.shape[0]) * 100)\n",
      "\n",
      "--------------------\n",
      " Selects the period 1950 2013 and the tropical Pacific domain\n",
      "\n",
      "dsub = dset.sel(time=slice('1950', '2013'), zlev=0, lat=slice((- 40), 40), lon=slice(120, 290))\n",
      "\n",
      "--------------------\n",
      " reshape in 2D time space \n",
      "\n",
      "X = np.reshape(sst, (sst.shape[0], (len(lat) * len(lon))), order='F')\n",
      "\n",
      "--------------------\n",
      " Mask the land points\n",
      "\n",
      "type(X)\n",
      "\n",
      "--------------------\n",
      " keep only oceanic grid points\n",
      "\n",
      "X = X[:, ocean]\n",
      "\n",
      "--------------------\n",
      " Standardize SST using the fit and transform methods of the sklearn preprocessing scaler StandardScaler \n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "scaler = preprocessing.StandardScaler()\n",
      "\n",
      "--------------------\n",
      " Once the scaler object has been trained on the data we can save it as a pickle object\n",
      "\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "--------------------\n",
      " scales use the transform method of the scaler object\n",
      "\n",
      "X = scaler_sst.transform(X)\n",
      "\n",
      "--------------------\n",
      " verify that mean 0 and std 1\n",
      "\n",
      "X.mean()\n",
      "\n",
      "--------------------\n",
      " EOF decomposition \n",
      "\n",
      "from sklearn.decomposition import pca\n",
      "\n",
      "--------------------\n",
      " instantiates the PCA object\n",
      "\n",
      "skpca = pca.PCA()\n",
      "\n",
      "--------------------\n",
      " fit\n",
      "\n",
      "skpca.fit(X)\n",
      "\n",
      "--------------------\n",
      " Now saves the fitted PCA object for reuse in operations\n",
      "\n",
      "joblib.dump(skpca, '../EOF.pkl', compress=9)\n",
      "\n",
      "--------------------\n",
      " keep number of PC sufficient to explain 70 of the original variance \n",
      "\n",
      "ipc = np.where((skpca.explained_variance_ratio_.cumsum() >= 0.7))[0][0]\n",
      "\n",
      "--------------------\n",
      " The Principal Components PCs are obtained by using the transform method of the pca object skpca \n",
      "\n",
      "PCs = skpca.transform(X)\n",
      "\n",
      "--------------------\n",
      " The Empirical Orthogonal Functions EOFs are contained in the components attribute of the pca object skpca \n",
      "\n",
      "EOFs = skpca.components_\n",
      "\n",
      "--------------------\n",
      " we can the reconstruct the 2D fields maps \n",
      "\n",
      "EOF_recons = (np.ones((ipc, (len(lat) * len(lon)))) * (- 999.0))\n",
      "\n",
      "--------------------\n",
      " scale the Principal Components\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "--------------------\n",
      " Import some python modules\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from scipy import signal\n",
      "\n",
      "from scipy.interpolate import interp1d\n",
      "\n",
      "from scipy.signal import butter, filtfilt, iirdesign, zpk2tf, freqz\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "get_ipython().magic(\"config InlineBackend.figure_format = 'retina'\")\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import matplotlib.mlab as mlab\n",
      "\n",
      "import h5py\n",
      "\n",
      "import readligo as rl\n",
      "\n",
      "--------------------\n",
      " Load data\n",
      "\n",
      "(strain, time, chan_dict_H1) = rl.loaddata(filename, 'H1')\n",
      "\n",
      "dt = (time[1] - time[0])\n",
      "\n",
      "fs = int(np.round((1 / dt)))\n",
      "\n",
      "rel_time = (time - t0)\n",
      "\n",
      "print('Got a sample frequency of {0}'.format(fs))\n",
      "\n",
      "print('Found {0} seconds of data'.format((strain.size * dt)))\n",
      "\n",
      "--------------------\n",
      " PSD Whitened Data and Spectrogram\n",
      "\n",
      "fig1\n",
      "\n",
      "--------------------\n",
      " Training doc to vec model\n",
      "\n",
      "num_features = 100\n",
      "\n",
      "min_word_count = 1\n",
      "\n",
      "context_window = 10\n",
      "\n",
      "library_model = doc2vec.Doc2Vec(wiki_docs_data, size=100, window=context_window, min_count=min_word_count, workers=num_workers)\n",
      "\n",
      "library_model.most_similar()\n",
      "\n",
      "--------------------\n",
      " n 100\n",
      "\n",
      "n = 100\n",
      "\n",
      "(x, y) = np.random.multivariate_normal(mean, cov, n).T\n",
      "\n",
      "--------------------\n",
      " n 1000\n",
      "\n",
      "n = 1000\n",
      "\n",
      "(x, y) = np.random.multivariate_normal(mean, cov, n).T\n",
      "\n",
      "--------------------\n",
      " n 10000\n",
      "\n",
      "n = 10000\n",
      "\n",
      "(x, y) = np.random.multivariate_normal(mean, cov, n).T\n",
      "\n",
      "--------------------\n",
      " font color red Corr 0 font \n",
      "\n",
      "muX = 21\n",
      "\n",
      "varX = 4\n",
      "\n",
      "muY = 18.9\n",
      "\n",
      "varY = 2.25\n",
      "\n",
      "corXY = 0\n",
      "\n",
      "covXY = (corXY * ((varX * varY) ** 0.5))\n",
      "\n",
      "mean = [muX, muY]\n",
      "\n",
      "cov = [[varX, covXY], [covXY, varY]]\n",
      "\n",
      "--------------------\n",
      " n 100\n",
      "\n",
      "n = 100\n",
      "\n",
      "(x, y) = np.random.multivariate_normal(mean, cov, n).T\n",
      "\n",
      "--------------------\n",
      " n 1000\n",
      "\n",
      "n = 1000\n",
      "\n",
      "(x, y) = np.random.multivariate_normal(mean, cov, n).T\n",
      "\n",
      "--------------------\n",
      " n 10000\n",
      "\n",
      "n = 10000\n",
      "\n",
      "(x, y) = np.random.multivariate_normal(mean, cov, n).T\n",
      "\n",
      "--------------------\n",
      " Eliminating Missing\n",
      "\n",
      "data_raw.rename(columns={\n",
      "    'Unnamed: 0': 'Index',\n",
      "}, inplace=True)\n",
      "\n",
      "--------------------\n",
      " Graphs and Analysis\n",
      "\n",
      "data_cleaner.describe()\n",
      "\n",
      "--------------------\n",
      " Modeling\n",
      "\n",
      "data_cleaner.columns\n",
      "\n",
      "--------------------\n",
      " however there are a lot of non real values in these DataFrames so running pd scatter matrix allmales asian for example would fail You can try \n",
      "\n",
      "fig = pd.scatter_matrix(allmales['all'][['Total with Income', '$2,500 to $4,999', 'Median income', 'Gini ratio']], linewidth=3, s=500, figsize=(15, 15), diagonal='kde')\n",
      "\n",
      "--------------------\n",
      " FBB missing caption \n",
      "\n",
      "print(allmales['asian'].shape)\n",
      "\n",
      "allmales['asian'].applymap(np.isreal).sum()\n",
      "\n",
      "--------------------\n",
      " FBB good\n",
      "\n",
      "fig = pd.scatter_matrix(allfemales['all'][['Total with Income', '$2,500 to $4,999', 'Median income', 'Gini ratio']], linewidth=3, s=500, figsize=(15, 15), diagonal='kde')\n",
      "\n",
      "--------------------\n",
      " imoprting all modules\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from pandas.tools.plotting import scatter_matrix\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn import linear_model\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LassoCV\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "import plotly\n",
      "\n",
      "from plotly.graph_objs import *\n",
      "\n",
      "import plotly.offline as plot\n",
      "\n",
      "import plotly.graph_objs as go\n",
      "\n",
      "plot.offline.init_notebook_mode(connected=True)\n",
      "\n",
      "import statsmodels.formula.api as sm\n",
      "\n",
      "import statsmodels.stats.diagnostic as sms\n",
      "\n",
      "--------------------\n",
      " importing csv file\n",
      "\n",
      "Classification_Data = pd.read_csv('Ex06_Pizzademand_Classification.csv')\n",
      "\n",
      "Regression_Data = pd.read_csv('Ex06_Pizzademand_Regreesion.csv')\n",
      "\n",
      "--------------------\n",
      " Scaling the data\n",
      "\n",
      "for i in Regression_Data.columns.tolist():\n",
      "    Regression_Data[i] = ((Regression_Data[i] - Regression_Data[i].mean()) / Regression_Data[i].var())\n",
      "\n",
      "--------------------\n",
      " Correlation Plot\n",
      "\n",
      "(f, ax) = plt.subplots(figsize=(7, 7))\n",
      "\n",
      "correlation = Regression_Data.corr()\n",
      "\n",
      "sns.heatmap(correlation, mask=np.zeros_like(correlation, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True, ax=ax)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Linear Regression\n",
      "\n",
      "reg = linear_model.LinearRegression()\n",
      "\n",
      "reg.fit(df_x_train, df_y_train)\n",
      "\n",
      "coefficients = reg.coef_.tolist()\n",
      "\n",
      "intercept = reg.intercept_.tolist()\n",
      "\n",
      "mean_square_error = np.mean(((reg.predict(df_x_test) - df_y_test) ** 2))\n",
      "\n",
      "mean_square_error\n",
      "\n",
      "--------------------\n",
      " Scatter Matrix\n",
      "\n",
      "scatter_matrix(Regression_Data, alpha=0.2, figsize=(10, 10), diagonal='kde', grid=True, marker='*')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Model is by taking PizzaPrice BurgerPrice Income SoftDrinkPrice\n",
      "\n",
      "model = sm.ols(formula='PizzaDemand ~ PizzaPrice + BurgerPrice + Income + softdrinkPrice', data=Regression_Data[:80]).fit()\n",
      "\n",
      "model.summary()\n",
      "\n",
      "--------------------\n",
      " Box Plot\n",
      "\n",
      "residual_new = np.array((y_model - df_y_test.PizzaDemand))\n",
      "\n",
      "plt.boxplot(residual_new)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Get some cats and dogs for samples\n",
      "\n",
      "cats = decode_image(train_cats[:1000], resize_func=resize_func)\n",
      "\n",
      "dogs = decode_image(train_dogs[:1000], resize_func=resize_func)\n",
      "\n",
      "--------------------\n",
      " Now set the size use this to generate resized images \n",
      "\n",
      "WIDTH = 128\n",
      "\n",
      "HEIGHT = 128\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "import pandas\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "from sklearn.metrics import roc_auc_score\n",
      "\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "--------------------\n",
      " xgboost\n",
      "\n",
      "matches['log_heroes'] = logreg_train_preds\n",
      "\n",
      "test_matches['log_heroes'] = logreg_test_preds\n",
      "\n",
      "--------------------\n",
      " Random Forest\n",
      "\n",
      "forest = RandomForestClassifier(n_estimators=100)\n",
      "\n",
      "forest.fit(train, y_train)\n",
      "\n",
      "forest_preds = forest.predict_proba(test)[:, 1]\n",
      "\n",
      "--------------------\n",
      " Problem 1\n",
      "\n",
      "display(Image((test_folders[0] + '/MDEtMDEtMDAudHRm.png')))\n",
      "\n",
      "--------------------\n",
      " Problem 3\n",
      "\n",
      "\n",
      "def show_num_img_per_class(dataset_names):\n",
      "    for dataset in dataset_names:\n",
      "        with open(dataset, 'rb') as f:\n",
      "            data = pickle.load(f)\n",
      "            print((dataset + ' number of samples:'), data.shape[0])\n",
      "\n",
      "show_num_img_per_class(train_datasets)\n",
      "\n",
      "show_num_img_per_class(test_datasets)\n",
      "\n",
      "--------------------\n",
      " Problem 4\n",
      "\n",
      "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
      "\n",
      "print('Testing:', test_dataset.shape, test_labels.shape)\n",
      "\n",
      "random_samples = np.random.permutation(10000)[0]\n",
      "\n",
      "plt.imshow(train_dataset[random_samples, :, :])\n",
      "\n",
      "print('labels', train_labels[random_samples])\n",
      "\n",
      "--------------------\n",
      " Solving for current in R L C circuit\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import scipy as sp\n",
      "\n",
      "from scipy.integrate import odeint, ode\n",
      "\n",
      "import matplotlib as mpl\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from math import *\n",
      "\n",
      "import seaborn\n",
      "\n",
      "from IPython.display import Image\n",
      "\n",
      "from bokeh.plotting import figure, output_file, output_notebook, show\n",
      "\n",
      "--------------------\n",
      " Took help from Henry Lin in the second part of the assignment he helped me understand what code to use and why we use it \n",
      "\n",
      "from __future__ import print_function, division\n",
      "\n",
      "import geopandas as gp\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "import os\n",
      "\n",
      "import json\n",
      "\n",
      "import requests\n",
      "\n",
      "import zipfile\n",
      "\n",
      "import urllib\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import statsmodels.api as sm\n",
      "\n",
      "import statsmodels.formula.api as smf\n",
      "\n",
      "from pandas.tools.plotting import scatter_matrix\n",
      "\n",
      "get_ipython().run_line_magic('pylab', 'inline')\n",
      "\n",
      "pl.style.use('fivethirtyeight')\n",
      "\n",
      "--------------------\n",
      " Data on Energy Consumption\n",
      "\n",
      "url = 'https://data.cityofnewyork.us/api/views/rgfe-8y2z/rows.csv?accessType=DOWNLOAD'\n",
      "\n",
      "((('curl -o ' + PUI2016) + '/energy.csv ') + url)\n",
      "\n",
      "--------------------\n",
      " Reading in the Pluto data for manhattan which will give me the number of units ber building Manhattan MNMapPLUTO shp\n",
      "\n",
      "nrg = pd.DataFrame.from_csv(url)\n",
      "\n",
      "nrg.head()\n",
      "\n",
      "--------------------\n",
      " Scatter Plot without changing any values dropping any columns \n",
      "\n",
      "pd.scatter_matrix(nrg, s=300, figsize=(25, 25))\n",
      "\n",
      "--------------------\n",
      " Dropping Columns that are not needed in the nrg data \n",
      "\n",
      "nrg_main = nrg.drop(['Co-reported BBL Status', 'BBLs Co-reported', 'Reported NYC Building Identificaiton Numbers (BINs)', 'Street Number', 'Street Name', 'Borough', 'Zip Code', 'DOF Benchmarking Submission Status', 'Weather Normalized Site EUI(kBtu/ft2)', 'Source EUI(kBtu/ft2)', 'Weather Normalized Source EUI(kBtu/ft2)', 'Municipally Supplied Potable Water - Indoor Intensity (gal/ft²)', 'Automatic Water Benchmarking Eligible', 'Reported Water Method', 'ENERGY STAR Score', 'Total GHG Emissions(MtCO2e)', 'Direct GHG Emissions(MtCO2e)', 'Indirect GHG Emissions(MtCO2e)', 'DOF Property Floor Area (Buildngs and Parking)(ft2)', 'Primary Property Type - Self Selected', 'DOF Number of Buildings'], 1)\n",
      "\n",
      "nrg_main.head()\n",
      "\n",
      "--------------------\n",
      " Chapter 6 Linear Model Selection and Regularization\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "import glmnet as gln\n",
      "\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "from sklearn import cross_validation\n",
      "\n",
      "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
      "\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "from sklearn.cross_decomposition import PLSRegression\n",
      "\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "pd.set_option('display.notebook_repr_html', False)\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "plt.style.use('seaborn-white')\n",
      "\n",
      "--------------------\n",
      " Lab 2\n",
      "\n",
      "df = pd.read_csv('Data/Hitters.csv', index_col=0).dropna()\n",
      "\n",
      "df.index.name = 'Player'\n",
      "\n",
      "df.info()\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      " I executed the R code and downloaded the exact same training test sets used in the book \n",
      "\n",
      "X_train = pd.read_csv('data/Hitters_X_train.csv', index_col=0)\n",
      "\n",
      "y_train = pd.read_csv('data/Hitters_y_train.csv', index_col=0)\n",
      "\n",
      "X_test = pd.read_csv('data/Hitters_X_test.csv', index_col=0)\n",
      "\n",
      "y_test = pd.read_csv('data/Hitters_y_test.csv', index_col=0)\n",
      "\n",
      "--------------------\n",
      " Alpha 4\n",
      "\n",
      "ridge2 = Ridge(alpha=4)\n",
      "\n",
      "ridge2.fit(scale(X_train), y_train)\n",
      "\n",
      "pred = ridge2.predict(scale(X_test))\n",
      "\n",
      "mean_squared_error(y_test, pred)\n",
      "\n",
      "--------------------\n",
      " Compute the regularization path using RidgeCV\n",
      "\n",
      "ridgecv = RidgeCV(alphas=alphas, scoring='mean_squared_error')\n",
      "\n",
      "ridgecv.fit(scale(X_train), y_train)\n",
      "\n",
      "--------------------\n",
      " Lambda 11498\n",
      "\n",
      "ridge3.lambda_path_[49]\n",
      "\n",
      "--------------------\n",
      " Lambda 705\n",
      "\n",
      "ridge3.lambda_path_[59]\n",
      "\n",
      "--------------------\n",
      " Fit model using just the training set \n",
      "\n",
      "ridge4 = gln.ElasticNet(alpha=0, lambda_path=grid, scoring='mean_squared_error', tol=1e-12)\n",
      "\n",
      "ridge4.fit(X_train, y_train.as_matrix().ravel())\n",
      "\n",
      "--------------------\n",
      " Lambda chosen by cross validation\n",
      "\n",
      "ridge5 = gln.ElasticNet(alpha=0, scoring='mean_squared_error')\n",
      "\n",
      "ridge5.fit(X_train, y_train.as_matrix().ravel())\n",
      "\n",
      "--------------------\n",
      " Fit model to full data set\n",
      "\n",
      "ridge6 = gln.ElasticNet(alpha=0, scoring='mean_squared_error', n_folds=10)\n",
      "\n",
      "ridge6.fit(X, y)\n",
      "\n",
      "--------------------\n",
      " python glmnet\n",
      "\n",
      "lasso2 = gln.ElasticNet(alpha=1, lambda_path=grid, scoring='mean_squared_error', n_folds=10)\n",
      "\n",
      "lasso2.fit(X_train, y_train.as_matrix().ravel())\n",
      "\n",
      "--------------------\n",
      " Let glmnet create a grid to use in CV\n",
      "\n",
      "lasso3 = gln.ElasticNet(alpha=1, scoring='mean_squared_error', n_folds=10)\n",
      "\n",
      "lasso3.fit(X_train, y_train.as_matrix().ravel())\n",
      "\n",
      "--------------------\n",
      " Fit model on full dataset\n",
      "\n",
      "lasso4 = gln.ElasticNet(alpha=1, lambda_path=grid, scoring='mean_squared_error', n_folds=10)\n",
      "\n",
      "lasso4.fit(X, y)\n",
      "\n",
      "--------------------\n",
      " Transform test data with PCA loadings and fit regression on 6 principal components\n",
      "\n",
      "X_reduced_test = pca2.transform(scale(X_test))[:, :7]\n",
      "\n",
      "regr = LinearRegression()\n",
      "\n",
      "regr.fit(X_reduced_train[:, :7], y_train)\n",
      "\n",
      "pred = regr.predict(X_reduced_test)\n",
      "\n",
      "mean_squared_error(y_test, pred)\n",
      "\n",
      "--------------------\n",
      " Load Train and Test Data\n",
      "\n",
      "train_collection = get_collection('data/moving-box/32x32/train')\n",
      "\n",
      "train_collection = augment_reverse_color(train_collection)\n",
      "\n",
      "train_collection = augment_reverse_sequence(train_collection)\n",
      "\n",
      "train_collection = center_collections(train_collection)\n",
      "\n",
      "total_train = sum([x.shape[0] for x in train_collection])\n",
      "\n",
      "print('\\nAfter Augmentation: img_collections has {} collections, {} images in total'.format(len(train_collection), total_train))\n",
      "\n",
      "--------------------\n",
      " Param\n",
      "\n",
      "seq_size = 9\n",
      "\n",
      "feature_size = (1024 * 4)\n",
      "\n",
      "lstm_state_size = feature_size\n",
      "\n",
      "num_iteration = 4000\n",
      "\n",
      "gap = 1\n",
      "\n",
      "batch_size = 4\n",
      "\n",
      "learning_rate = 0.00016\n",
      "\n",
      "beta = 0.9\n",
      "\n",
      "assert ((feature_size % 64) == 0), 'feature_size must be divisable by 64!'\n",
      "\n",
      "feature_channels = int(((feature_size / 8) / 8))\n",
      "\n",
      "model_save_path = 'trained_model/LSTM_box_32x32/{}/'.format(time())\n",
      "\n",
      "--------------------\n",
      " Create Directory for Model to be saved\n",
      "\n",
      "try:\n",
      "    os.mkdir(model_save_path)\n",
      "    print('Model to be saved at {}'.format(model_save_path))\n",
      "except:\n",
      "    assert 'Cannot create save folder!'\n",
      "\n",
      "--------------------\n",
      " Loss\n",
      "\n",
      "\n",
      "def get_loss(gd_imgs, output_imgs):\n",
      "    '\\n    Input:\\n        gd_imgs, output_imgs: [batch_size, seq_size, 8, 8, 1]\\n    Output:\\n        scaler loss\\n    '\n",
      "    (gd_imgs, output_imgs) = (tf.contrib.layers.flatten(gd_imgs), tf.contrib.layers.flatten(output_imgs))\n",
      "    return tf.norm((gd_imgs - output_imgs))\n",
      "\n",
      "--------------------\n",
      " Solver\n",
      "\n",
      "\n",
      "def get_solver(learning_rate=0.001, beta1=0.5):\n",
      "    return tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
      "\n",
      "--------------------\n",
      " Train\n",
      "\n",
      "sess = get_session()\n",
      "\n",
      "sess.run(tf.global_variables_initializer())\n",
      "\n",
      "losses = train(sess, train_step, loss, batch_size, num_iteration, plot_every=40, show_loss_every=40, num_plot=7, save_every=2000)\n",
      "\n",
      "--------------------\n",
      " Plot Learning Curve\n",
      "\n",
      "figsize = (20, 8)\n",
      "\n",
      "plt.figure(figsize=figsize)\n",
      "\n",
      "plt.plot(losses)\n",
      "\n",
      "plt.title('Generator Losses', fontsize=16)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "plt.figure(figsize=figsize)\n",
      "\n",
      "plt.plot(losses[(- 100):])\n",
      "\n",
      "plt.title('Generator Losses - Last 1000', fontsize=16)\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Evaluate on Training Data\n",
      "\n",
      "\n",
      "def eval_train(seq_size=3, gap=3):\n",
      "    show_generations('train', seq_size, gap)\n",
      "    loss = report_loss('train', 100, gap, batch_size, seq_size=seq_size)\n",
      "    print('Training Loss = {}'.format(loss))\n",
      "    return loss\n",
      "\n",
      "train_loss = eval_train(seq_size=seq_size, gap=gap)\n",
      "\n",
      "--------------------\n",
      " Evaluate on Test Data\n",
      "\n",
      "\n",
      "def eval_test(seq_size=3, gap=3):\n",
      "    show_generations('test', seq_size, gap)\n",
      "    loss = report_loss('test', 100, gap, batch_size, seq_size=seq_size)\n",
      "    print('Test Loss = {}'.format(loss))\n",
      "    return loss\n",
      "\n",
      "test_loss = eval_test(seq_size=seq_size, gap=gap)\n",
      "\n",
      "--------------------\n",
      " Facebook stock data \n",
      "\n",
      "facebook = pd.read_csv('./datasets/WIKI-FB.csv')\n",
      "\n",
      "facebook = facebook[['Date', 'Open']]\n",
      "\n",
      "facebook.columns = ['date', 'quantity']\n",
      "\n",
      "facebook.date = pd.to_datetime(facebook.date)\n",
      "\n",
      "facebook.index = facebook.date\n",
      "\n",
      "facebook.sort_index(ascending=True, inplace=True)\n",
      "\n",
      "--------------------\n",
      " Netflix stock data\n",
      "\n",
      "netflix = pd.read_csv('./datasets/WIKI-NFLX.csv')\n",
      "\n",
      "netflix = netflix[['Date', 'Open']]\n",
      "\n",
      "netflix.columns = ['date', 'quantity']\n",
      "\n",
      "netflix.date = pd.to_datetime(netflix.date)\n",
      "\n",
      "netflix.index = netflix.date\n",
      "\n",
      "netflix.sort_index(ascending=True, inplace=True)\n",
      "\n",
      "--------------------\n",
      " pacf left x t n right frac covariance left x t x t n x t 1 x t n 1 right sqrt variance left x t x t 1 x t n 1 right variance left x t n x t 1 x t n 1 right \n",
      "\n",
      "from statsmodels.tsa.stattools import acf, pacf\n",
      "\n",
      "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
      "\n",
      "--------------------\n",
      " Import Data\n",
      "\n",
      "pod_number = 'D8'\n",
      "\n",
      "--------------------\n",
      " Declare whether to process raw or filtered data \n",
      "\n",
      "which_data = 0\n",
      "\n",
      "(ref_column, leave_out_pod, pod_ozone) = declare_filt_or_raw_dataset(which_data)\n",
      "\n",
      "--------------------\n",
      " Call the scaling function and create a dataframe with scaled data \n",
      "\n",
      "(df_scaled, features) = scale_features_and_create_day_column(df_all, ref_column)\n",
      "\n",
      "len(df_scaled)\n",
      "\n",
      "--------------------\n",
      " Declare whether you d like to use holdout dates from a pervious run \n",
      "\n",
      "prev_holdout = 'true'\n",
      "\n",
      "chunks = ['7-14 AM', '7-14 PM', '8-21 AM']\n",
      "\n",
      "--------------------\n",
      " Add a day column to the dataframe and separate the data into training and holdout \n",
      "\n",
      "if (prev_holdout == 'true'):\n",
      "    (df_tr, df_hold, chunks_tr, days_tr) = sep_tr_and_holdout_pre_defined(df_scaled, ref_column, chunks)\n",
      "else:\n",
      "    (df_tr, df_hold, chunks_tr, days_tr) = sep_tr_and_holdout(df_scaled, ref_column)\n",
      "\n",
      "--------------------\n",
      " Declare a cutoff value for high ozone \n",
      "\n",
      "cutoff_value = 50\n",
      "\n",
      "--------------------\n",
      " Plot the training ozone\n",
      "\n",
      "plot_tr_and_holdout(df_tr, pod_number, ref_column, 'Training Data', cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Plot holdout ozone to make sure that the holdout set has some high value ozone measurements \n",
      "\n",
      "plot_tr_and_holdout(df_hold, pod_number, ref_column, 'Holdout Data', cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Declare a multiplication factor for the MSE part of the custom score function \n",
      "\n",
      "cust_mse_fact = 1\n",
      "\n",
      "--------------------\n",
      " Linear Regression with Base Features\n",
      "\n",
      "base_features = [pod_ozone, 'Temp', 'Rh']\n",
      "\n",
      "--------------------\n",
      " Plot the learning curve for a linear regression with the base features \n",
      "\n",
      "plt = plot_learning_curve(lin_regr, 'Learning Curve (Linear Regression- Base Features)', df_tr[base_features].values, df_tr[ref_column].values, (0, 14), days_tr, np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1.0]))\n",
      "\n",
      "--------------------\n",
      " Plot the residuals and comparison curves \n",
      "\n",
      "num_good_feat = len(base_features)\n",
      "\n",
      "fitted_vs_ref_plot(df_cv_lin_base, num_good_feat, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_cv_lin_base, pod_number, 1, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_cv_lin_base, pod_number, 2, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_cv_lin_base, pod_number, 3, ref_column)\n",
      "\n",
      "resid = plot_resid_vs_conc(df_cv_lin_base, ref_column)\n",
      "\n",
      "--------------------\n",
      " Linear Regression with All Features \n",
      "\n",
      "every_feature = list(df_tr.ix[:, 0:len(df_scaled.columns)])\n",
      "\n",
      "leave_out = ['ref_o3_smooth', 'chunk', 'day', 'O3_ppb', 'UnixTime']\n",
      "\n",
      "all_features = [f for f in every_feature if (f not in leave_out)]\n",
      "\n",
      "(MSE_CV, MSE_T, MSE_H, high_MSE_cv, X_pred_cv_all, y_cv, df_cv_lin_all, df_H_lin_all) = cross_validation_by_day(lin_regr, all_features, df_tr, df_hold, days_tr, ref_column, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Plot a learning curve with all features \n",
      "\n",
      "plot_learning_curve(lin_regr, 'Learning Curve (Linear Regression- All Features)', df_tr[all_features].values, df_tr[ref_column].values, (0, 40), 5, np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.925, 0.95, 0.975, 1.0]))\n",
      "\n",
      "--------------------\n",
      " Plot the residuals and comparison curves \n",
      "\n",
      "num_good_feat = len(all_features)\n",
      "\n",
      "fitted_vs_ref_plot(df_cv_lin_all, num_good_feat, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_cv_lin_all, pod_number, 1, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_cv_lin_all, pod_number, 2, ref_column)\n",
      "\n",
      "resid = plot_resid_vs_conc(df_cv_lin_all, ref_column)\n",
      "\n",
      "--------------------\n",
      " Declare rather you want to use MSE or a custom error function \n",
      "\n",
      "features_all = list(df_tr.columns)\n",
      "\n",
      "leave_out = ['Zenith Angle [degrees]', 'UnixTime', 'pod_o3_smooth', 'O3_ppb', 'ref_o3_smooth', ref_column, 'chunk']\n",
      "\n",
      "features = [f for f in features_all if (f not in leave_out)]\n",
      "\n",
      "features_it = [f for f in features if (f not in 'day')]\n",
      "\n",
      "(fs_features, score, RMSE) = forward_selection_lodo(lin_regr, features_it, df_tr[([ref_column] + features)].dropna(), 'custom_mse', ref_column, days_tr, 35, cust_mse_fact, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Enter the chosen number of features and perform a linear regression \n",
      "\n",
      "num_good_feat = 16\n",
      "\n",
      "best_features = fs_features[:num_good_feat]\n",
      "\n",
      "(MSE_CV, MSE_T, MSE_H, high_MSE_cv, X_pred_cv_best, y_cv_best, df_cv_lin_best, df_H_lin_best) = cross_validation_by_day(lin_regr, best_features, df_tr, df_hold, days_tr, ref_column, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Print Best Features\n",
      "\n",
      "best_features\n",
      "\n",
      "--------------------\n",
      " Plot the cross validation data and residuals below \n",
      "\n",
      "(df_lin_regr_best_feat_cv, df_lin_regr_best_feat_H) = find_fitted_cv_values_for_best_features(df_tr, df_hold, fs_features, num_good_feat, linear_model.LinearRegression(), chunks_tr, ref_column)\n",
      "\n",
      "fitted_vs_ref_plot(df_lin_regr_best_feat_cv, num_good_feat, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_lin_regr_best_feat_cv, pod_number, 1, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_lin_regr_best_feat_cv, pod_number, 2, ref_column)\n",
      "\n",
      "plot_fitted_and_ref_vs_time(df_lin_regr_best_feat_cv, pod_number, 3, ref_column)\n",
      "\n",
      "resid = plot_resid_vs_conc(df_lin_regr_best_feat_cv, ref_column)\n",
      "\n",
      "--------------------\n",
      " Ridge Regression All Features\n",
      "\n",
      "fs_features = all_features\n",
      "\n",
      "num_good_feat_ridge = len(all_features)\n",
      "\n",
      "--------------------\n",
      " Find the best lambda value using cross validation\n",
      "\n",
      "(best_lambda_ridge, lambda_ridge, coefs, mean_score_lambda) = find_best_lambda(Ridge, fs_features[:num_good_feat_ridge], df_fits, ref_column, 'custom_mse_scoring_function', days_tr, X, y, 1e-07, 1000000, 3, cust_mse_fact, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Plot the values of lambda versus the coefficients and the custom score \n",
      "\n",
      "plot_lambda(lambda_ridge, coefs, mean_score_lambda)\n",
      "\n",
      "--------------------\n",
      " Use the best lambda value found above to find errors \n",
      "\n",
      "(MSE_CV_ridge, MSE_T_ridge, MSE_H_ridge, high_MSE_cv_ridge, X_pred_cv_ridge, y_cv_ridge, df_cv_ridge, df_H_ridge) = cross_validation_by_day(Ridge(alpha=best_lambda_ridge), all_features, df_tr, df_hold, days_tr, ref_column, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Ridge Regression Best Features\n",
      "\n",
      "df_fits_best = df_tr[((best_features + [ref_column]) + ['day'])].dropna()\n",
      "\n",
      "X = df_scaled[best_features].values\n",
      "\n",
      "y = df_scaled[ref_column].values\n",
      "\n",
      "--------------------\n",
      " Use the best lambda value found above to find errors \n",
      "\n",
      "(MSE_CV_ridge_best, MSE_T_ridge_best, MSE_H_ridge_best, high_MSE_cv_ridge_best, X_pred_cv_ridge_best, y_cv_ridge_best, df_cv_ridge_best, df_H_ridge_best) = cross_validation_by_day(Ridge(alpha=best_lambda_ridge_best), best_features, df_tr, df_hold, days_tr, ref_column, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Lasso All Features\n",
      "\n",
      "(best_lambda_lasso, lambda_lasso, coefs_lasso, mean_score_lambda_lasso) = find_best_lambda(Lasso, fs_features[:num_good_feat_ridge], df_fits, ref_column, 'custom_mse_scoring_function', days_tr, X, y, 1e-06, 100, 3, cust_mse_fact, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Use the best lambda value found above to find holdout values \n",
      "\n",
      "(MSE_CV_lasso, MSE_T_lasso, MSE_H_lasso, high_MSE_cv_lasso, X_pred_cv_lasso, y_cv_lasso, df_cv_lasso, df_H_lasso) = cross_validation_by_day(Lasso(alpha=best_lambda_lasso), all_features, df_tr, df_hold, days_tr, ref_column, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Lasso Best Features\n",
      "\n",
      "(best_lambda_lasso_best, lambda_lasso_best, coefs_lasso_best, mean_score_lambda_lasso_best) = find_best_lambda(Lasso, best_features, df_fits_best, ref_column, 'custom_mse_scoring_function', days_tr, X, y, 1e-13, 100, 3, cust_mse_fact, cutoff_value)\n",
      "\n",
      "--------------------\n",
      " Support Vector Machine Best Features\n",
      "\n",
      "(RMSE_CV_day, df_svm_fit) = fit_svm_and_find_MSE(best_features, df_tr, days_tr, ref_column, cutoff_value, df_hold, cust_mse_fact)\n",
      "\n",
      "--------------------\n",
      " Support Vector Machine All Features\n",
      "\n",
      "(RMSE_CV_day_all, df_svm_fit_all) = fit_svm_and_find_MSE(all_features, df_tr, days_tr, ref_column, cutoff_value, df_hold, cust_mse_fact)\n",
      "\n",
      "--------------------\n",
      " Setting up Data This time tried to label subscriber as 0 \n",
      "\n",
      "d2015 = pd.read_csv('../data/for_predictions/2015_membership_pred.csv')\n",
      "\n",
      "d2016 = pd.read_csv('../data/for_predictions/2016_membership_pred.csv')\n",
      "\n",
      "d2017 = pd.read_csv('../data/for_predictions/2017_membership_pred.csv')\n",
      "\n",
      "--------------------\n",
      " Initial classification with TomekLinks RUS dataset DecisionTree \n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X_res2, y_res2, test_size=0.3)\n",
      "\n",
      "--------------------\n",
      " Reliability Calibration Curves on the best tree\n",
      "\n",
      "get_ipython().run_cell_magic('time', '', \"d = [X_train, X_test, y_train, y_test]\\nmsf.plot_calibration_curve(clf, 'DecisionTree', 1, d)\")\n",
      "\n",
      "--------------------\n",
      " Another classification with TomekLinks RUS dataset RandomForest \n",
      "\n",
      "get_ipython().run_cell_magic('time', '', 'clf2 = RandomForestClassifier()\\nclf2.fit(X_train, y_train)')\n",
      "\n",
      "--------------------\n",
      " RandomForest GridSearchCV on the undersampled dataset\n",
      "\n",
      "get_ipython().run_cell_magic('time', '', \"parameters = {'criterion':['gini', 'entropy'], 'max_depth': [5, 10, 20, 30, 40]}\\ntree = RandomForestClassifier(n_jobs=1, n_estimators=50)\\nclf_gs = GridSearchCV(tree, parameters, n_jobs=4)\\nclf_gs.fit(X_train, y_train)\")\n",
      "\n",
      "--------------------\n",
      " Let s first translate a set of documents articles into a matrix representation with a row per document and a column per feature word or n gram \n",
      "\n",
      "vectorizer = feature_extraction.text.CountVectorizer(stop_words='english')\n",
      "\n",
      "--------------------\n",
      " We want to learn which columns are correlated i e likely to come from the same topic This is the word distribution We can also determine what topics are in each document the topic distribution \n",
      "\n",
      "corpus = matutils.Sparse2Corpus(documents, documents_columns=False)\n",
      "\n",
      "--------------------\n",
      " Word2Vec with gensim \n",
      "\n",
      "sentences = df.review.map((lambda review: review.split()))\n",
      "\n",
      "--------------------\n",
      " Analysis of Edge velocity tuning \n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "import sys\n",
      "\n",
      "sys.path.append('/Users/mmeier/Desktop/new_arena/')\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import seaborn as sb\n",
      "\n",
      "from scipy import stats\n",
      "\n",
      "from os.path import split\n",
      "\n",
      "import pylab\n",
      "\n",
      "import data_analysis.tools as tools\n",
      "\n",
      "import data_analysis.calcium_analysis as calcium_analysis\n",
      "\n",
      "--------------------\n",
      " lets remove Name and create dummmy variables for title\n",
      "\n",
      "dummies = pd.get_dummies(train_df['Title'])\n",
      "\n",
      "train_df = pd.concat([train_df, dummies], axis=1)\n",
      "\n",
      "--------------------\n",
      " lock and load\n",
      "\n",
      "path = '../input/users_2014_actions_combined_device.csv'\n",
      "\n",
      "users = orig.loadAndUpdateFeatures(path)\n",
      "\n",
      "featureList = orig.featureList()\n",
      "\n",
      "featureList.addByRegex(['action_', 'num_of_devices'], users)\n",
      "\n",
      "predictMethod = LogisticRegression()\n",
      "\n",
      "category = 'country_destination'\n",
      "\n",
      "--------------------\n",
      " testing\n",
      "\n",
      "sessions = pd.read_csv('../input/sessions.csv')\n",
      "\n",
      "users = pd.read_csv('../input/train_users.csv')\n",
      "\n",
      "users2014 = pd.read_csv('../input/users_2014_wo_unamed_coloumn.csv')\n",
      "\n",
      "users2014sessions = pd.read_csv('../input/users_2014_in_sessions.csv')\n",
      "\n",
      "--------------------\n",
      " show version\n",
      "\n",
      "import basicLib.category as cat\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import sys\n",
      "\n",
      "print(sys.version)\n",
      "\n",
      "--------------------\n",
      " missing value\n",
      "\n",
      "print(train.isnull().sum())\n",
      "\n",
      "--------------------\n",
      " cabin numbers\n",
      "\n",
      "print(('We know %i of %i Cabin numbers in the training data set and' % (len(train['Cabin'].dropna()), len(train))))\n",
      "\n",
      "print(('we know %i of %i Cabin numbers in the testing data set.' % (len(test['Cabin'].dropna()), len(test))))\n",
      "\n",
      "train.loc[:, ['Survived', 'Cabin']].dropna().head(8)\n",
      "\n",
      "--------------------\n",
      " ticket numbers\n",
      "\n",
      "print(('There are %i unique ticket numbers among the %i tickets.' % (train['Ticket'].nunique(), train['Ticket'].count())))\n",
      "\n",
      "--------------------\n",
      " Imports\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " Set up functions for cross validation\n",
      "\n",
      "seed = 1\n",
      "\n",
      "kfold = cross_validation.StratifiedKFold(train_raw.TARGET, n_folds=5, random_state=seed)\n",
      "\n",
      "--------------------\n",
      " Apply Cross validated Machine Learning\n",
      "\n",
      "from sklearn.feature_selection import SelectKBest, chi2\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "from sklearn import cross_validation\n",
      "\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "from sklearn.model_selection import cross_val_score\n",
      "\n",
      "from sklearn import model_selection\n",
      "\n",
      "from sklearn import metrics\n",
      "\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "from xgboost import XGBClassifier\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "from pandas_ml import ConfusionMatrix\n",
      "\n",
      "--------------------\n",
      " Construct a benchmark null model\n",
      "\n",
      "rand_index = np.random.randint(less_ft.shape[0], size=less_ft.shape[0])\n",
      "\n",
      "randomized = less_ft.iloc[rand_index, :]\n",
      "\n",
      "--------------------\n",
      " Logistic Rression on actual data set\n",
      "\n",
      "print('Logistic Regression\\n mean ROC AUC score: \\n', cv_score(5, less_ft, y, LogisticRegression(C=0.1)))\n",
      "\n",
      "--------------------\n",
      " Test the sensitivity of results to the threshold of unique values for categorical versus numerical variables\n",
      "\n",
      "raw = train_raw.drop(['var3', 'var36', 'TARGET'], axis=1)\n",
      "\n",
      "print('Raw training data\\n scalled Logistic Regression\\n mean ROC AUC score: \\n', cv_score(5, raw, y, pipe_LG_scaled))\n",
      "\n",
      "--------------------\n",
      " Naive Bayes\n",
      "\n",
      "print('Naive Bayes\\n mean ROC AUC score: \\n', cv_score(5, less_ft, y, BernoulliNB()))\n",
      "\n",
      "--------------------\n",
      " Decesion tree based classifiers\n",
      "\n",
      "print('Random Forest on original dataset\\n mean ROC AUC score: \\n', cv_score(5, raw, y, RandomForestClassifier()))\n",
      "\n",
      "print('\\nRandom Forest \\n mean ROC AUC score: \\n', cv_score(5, less_ft, y, RandomForestClassifier()))\n",
      "\n",
      "print('\\nMinMax scalled RandomForestClassifier\\n mean ROC AUC score: \\n', cv_score(5, less_ft, y, Pipeline([('minmax', MinMaxScaler()), ('RF', RandomForestClassifier())])))\n",
      "\n",
      "--------------------\n",
      " Evaluation\n",
      "\n",
      "print()\n",
      "\n",
      "print(('Logistic regression using RBM features:\\n%s\\n' % metrics.classification_report(Y_test, classifier.predict(X_test))))\n",
      "\n",
      "print(('Logistic regression using raw pixel features:\\n%s\\n' % metrics.classification_report(Y_test, logistic_classifier.predict(X_test))))\n",
      "\n",
      "--------------------\n",
      " 1 Format the Data\n",
      "\n",
      "airportdf = pd.read_csv('/Users/samanthafalk/class-GA/week-seven/4.2-lab-hierarchical-clustering/assets/datasets/airport2.csv')\n",
      "\n",
      "--------------------\n",
      " 2 Plot the data\n",
      "\n",
      "airportdf.info()\n",
      "\n",
      "--------------------\n",
      " 3 2 Conduct the k means clustering\n",
      "\n",
      "k = 3\n",
      "\n",
      "--------------------\n",
      " XBox Kinect\n",
      "\n",
      "YouTubeVideo('ECnaCYnQBMQ', height=650, width=900)\n",
      "\n",
      "--------------------\n",
      " Self Driving Cars\n",
      "\n",
      "YouTubeVideo('sIlCR4eG8_o', height=650, width=900)\n",
      "\n",
      "--------------------\n",
      " Facial Recognition\n",
      "\n",
      "YouTubeVideo('Pc2aJxnmzh0', height=650, width=900)\n",
      "\n",
      "--------------------\n",
      " We can see the matrix representation with the following code \n",
      "\n",
      "digits.images[0].shape\n",
      "\n",
      "--------------------\n",
      " Getting started with GraphLab Create\n",
      "\n",
      "import graphlab\n",
      "\n",
      "graphlab.canvas.set_target('ipynb')\n",
      "\n",
      "gl_img = graphlab.SFrame('http://s3.amazonaws.com/dato-datasets/coursera/deep_learning/image_train_data')\n",
      "\n",
      "gl_img\n",
      "\n",
      "--------------------\n",
      " We can look at the first 5 in the dataset\n",
      "\n",
      "graphlab.image_analysis.resize(gl_img['image'][:5], 128, 128).show()\n",
      "\n",
      "--------------------\n",
      " Next we can pull in our own image\n",
      "\n",
      "img = graphlab.Image('https://media.licdn.com/mpr/mpr/shrinknp_200_200/AAEAAQAAAAAAAAiBAAAAJGQzNzFiYTU2LTMwMzAtNGZlZC04OGI4LTAzMGFkYjczNGJiNA.jpg')\n",
      "\n",
      "ppsf = graphlab.SArray([img])\n",
      "\n",
      "ppsf = graphlab.image_analysis.resize(ppsf, 32, 32)\n",
      "\n",
      "graphlab.image_analysis.resize(ppsf, 128, 128).show()\n",
      "\n",
      "--------------------\n",
      " Next we need to extract the deep features from our image\n",
      "\n",
      "extractor = graphlab.feature_engineering.DeepFeatureExtractor(features='image', model='auto')\n",
      "\n",
      "extractor = extractor.fit(ppsf)\n",
      "\n",
      "ppsf['deep_features'] = extractor.transform(ppsf)['deep_features.image']\n",
      "\n",
      "ppsf\n",
      "\n",
      "--------------------\n",
      " Then we append it to our SFrame\n",
      "\n",
      "ppsf['label'] = 'me'\n",
      "\n",
      "gl_img['id'].max()\n",
      "\n",
      "ppsf['id'] = 50000\n",
      "\n",
      "labels = ['id', 'image', 'label', 'deep_features']\n",
      "\n",
      "part_train = gl_img[labels]\n",
      "\n",
      "new_train = part_train.append(ppsf[labels])\n",
      "\n",
      "new_train.tail()\n",
      "\n",
      "--------------------\n",
      " Now we use knn to find our spirit animal\n",
      "\n",
      "knn_model = graphlab.nearest_neighbors.create(new_train, features=['deep_features'], label='id')\n",
      "\n",
      "me_test = new_train[(- 1):]\n",
      "\n",
      "\n",
      "def reveal_my_twin(x):\n",
      "    return gl_img.filter_by(x['reference_label'], 'id')\n",
      "\n",
      "spirit_animal = reveal_my_twin(knn_model.query(me_test))\n",
      "\n",
      "graphlab.image_analysis.resize(spirit_animal['image'], 128, 128).show()\n",
      "\n",
      "--------------------\n",
      " This code loads the dataset\n",
      "\n",
      "print('Loading dataset...')\n",
      "\n",
      "t0 = time()\n",
      "\n",
      "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
      "\n",
      "data_samples = dataset.data[:n_samples]\n",
      "\n",
      "print(('done in %0.3fs.' % (time() - t0)))\n",
      "\n",
      "--------------------\n",
      " 1 Connect to the remote database\n",
      "\n",
      "get_ipython().magic('load_ext sql')\n",
      "\n",
      "--------------------\n",
      " 2 Query the database and aggregate the data\n",
      "\n",
      "data = get_ipython().magic('sql SELECT * FROM train')\n",
      "\n",
      "--------------------\n",
      " 1 Describe the Data\n",
      "\n",
      "data.Age.describe()\n",
      "\n",
      "--------------------\n",
      " 1 Create Dummy Variables for Sex \n",
      "\n",
      "model = pd.DataFrame(data[['Age', 'Sex', 'Pclass', 'Survived']])\n",
      "\n",
      "model.head()\n",
      "\n",
      "--------------------\n",
      " Conduct the logistic regression\n",
      "\n",
      "logreg = LogisticRegression()\n",
      "\n",
      "logreg.fit(X, y)\n",
      "\n",
      "--------------------\n",
      " 4 Examine the coefficients to see our correlations\n",
      "\n",
      "pd.DataFrame(list(zip(X.columns, np.transpose(logreg.coef_))))\n",
      "\n",
      "--------------------\n",
      " 6 Test the Model by introducing a Test or Validaton set \n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.3, random_state=0)\n",
      "\n",
      "logreg2 = LogisticRegression()\n",
      "\n",
      "logreg2.fit(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " 7 Predict the class labels for the Test set\n",
      "\n",
      "predicted = logreg2.predict(X_test)\n",
      "\n",
      "--------------------\n",
      " 8 Predict the class probabilities for the Test set\n",
      "\n",
      "prob = logreg2.predict_proba(X_test)\n",
      "\n",
      "--------------------\n",
      " 9 Evaluate the Test set\n",
      "\n",
      "print(metrics.accuracy_score(y_test, predicted))\n",
      "\n",
      "print(metrics.roc_auc_score(y_test, prob[:, 1]))\n",
      "\n",
      "--------------------\n",
      " 10 Cross validate the test set\n",
      "\n",
      "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
      "\n",
      "print(scores)\n",
      "\n",
      "print(scores.mean())\n",
      "\n",
      "--------------------\n",
      " 11 Check the Classification Report\n",
      "\n",
      "print(metrics.classification_report(y_test, predicted))\n",
      "\n",
      "--------------------\n",
      " 13 Check the Confusion Matrix\n",
      "\n",
      "print(metrics.confusion_matrix(y_test, predicted))\n",
      "\n",
      "--------------------\n",
      " Data Aggregation\n",
      "\n",
      "importer = DatasetImporter('data/testset.csv')\n",
      "\n",
      "X_unnorm = importer.data\n",
      "\n",
      "y = importer.target\n",
      "\n",
      "X = normalize_data(X_unnorm)\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n",
      "\n",
      "X[:5]\n",
      "\n",
      "--------------------\n",
      " Create dict of emails and flag indicating if they re POI or not \n",
      "\n",
      "\n",
      "def load_data():\n",
      "    return pickle.load(open('final_project_dataset.pkl', 'r'))\n",
      "\n",
      "--------------------\n",
      " Classification\n",
      "\n",
      "non_normalized_feature_vectors = [model.docvecs[x] for x in users_on_gender]\n",
      "\n",
      "feature_vectors = preprocessing.normalize(preprocessing.scale(non_normalized_feature_vectors))\n",
      "\n",
      "--------------------\n",
      " t SNE\n",
      "\n",
      "all_xy_vectors = commons.reduce_dim(feature_vectors, 'tsne')\n",
      "\n",
      "--------------------\n",
      " BoW method\n",
      "\n",
      "tf = TfidfVectorizer(analyzer='word', max_features=10000, stop_words='english')\n",
      "\n",
      "--------------------\n",
      " 1 FizzBuzz\n",
      "\n",
      "for i in range(1, 101):\n",
      "    s = ''\n",
      "    if ((i % 3) == 0):\n",
      "        s = 'Fizz'\n",
      "    if ((i % 5) == 0):\n",
      "        s += 'Buzz'\n",
      "    if (not s):\n",
      "        s = i\n",
      "    print(s)\n",
      "\n",
      "--------------------\n",
      " 2 100\n",
      "\n",
      "\n",
      "def fib(n):\n",
      "    a = 0\n",
      "    b = 1\n",
      "    for __ in range(n):\n",
      "        (a, b) = (b, (a + b))\n",
      "    return a\n",
      "\n",
      "print(fib(100))\n",
      "\n",
      "--------------------\n",
      " 1 numpy linspace\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from timeit import timeit\n",
      "\n",
      "(start, stop, num) = (0, 10, 50000)\n",
      "\n",
      "--------------------\n",
      " Raw data\n",
      "\n",
      "background = np.load('background_0.9_K.npz')\n",
      "\n",
      "--------------------\n",
      " SweepArray\n",
      "\n",
      "Q = 30000\n",
      "\n",
      "--------------------\n",
      " Problem 1 \n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "--------------------\n",
      " Problem 4 \n",
      "\n",
      "(year, magnitude, longitude, latitude) = np.load('earthquakes.npy').T\n",
      "\n",
      "plt.plot(year, magnitude, '.', alpha=0.1)\n",
      "\n",
      "plt.xlabel('Year')\n",
      "\n",
      "plt.ylabel('Magnitude')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "--------------------\n",
      " Simulate line profiles for O VII and C V\n",
      "\n",
      "import os\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from scipy import stats\n",
      "\n",
      "from scipy.io import readsav\n",
      "\n",
      "from scipy.ndimage import gaussian_filter\n",
      "\n",
      "import matplotlib as mpl\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import astropy.units as u\n",
      "\n",
      "import astropy.constants as c\n",
      "\n",
      "import spectrum\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "--------------------\n",
      " introduction\n",
      "\n",
      "import keras\n",
      "\n",
      "--------------------\n",
      " 3 \n",
      "\n",
      "model = Sequential()\n",
      "\n",
      "model.add(Dense(32, activation='relu', input_dim=100))\n",
      "\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "--------------------\n",
      " 1 Sequential model API\n",
      "\n",
      "model = Sequential([Dense(10, input_dim=10), Activation('relu'), Dense(10), Activation('softmax')])\n",
      "\n",
      "model.layers\n",
      "\n",
      "--------------------\n",
      " English to French using Neural Machine Translation\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "import importlib\n",
      "\n",
      "from sutils import *\n",
      "\n",
      "import keras\n",
      "\n",
      "import gensim\n",
      "\n",
      "import re\n",
      "\n",
      "import pickle\n",
      "\n",
      "import keras.backend as K\n",
      "\n",
      "from keras_tqdm import TQDMNotebookCallback\n",
      "\n",
      "from keras import initializers\n",
      "\n",
      "from keras.preprocessing.sequence import pad_sequences\n",
      "\n",
      "from keras.models import Model, Sequential\n",
      "\n",
      "from keras.layers import *\n",
      "\n",
      "from keras.optimizers import Adam\n",
      "\n",
      "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau, LearningRateScheduler, EarlyStopping, TensorBoard\n",
      "\n",
      "from keras.callbacks import LambdaCallback\n",
      "\n",
      "from recurrentshop import *\n",
      "\n",
      "import seq2seq\n",
      "\n",
      "from seq2seq.models import AttentionSeq2Seq, SimpleSeq2Seq, Seq2Seq\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "--------------------\n",
      " Set some parameters for the model\n",
      "\n",
      "lr = 0.001\n",
      "\n",
      "maxlen = 30\n",
      "\n",
      "dim_en_vec = 100\n",
      "\n",
      "n_en_vec = 400000\n",
      "\n",
      "dim_fr_vec = 200\n",
      "\n",
      "vocab_size = len(fr_vocab)\n",
      "\n",
      "embedding_size = 100\n",
      "\n",
      "--------------------\n",
      " Testing\n",
      "\n",
      "\n",
      "def sent2ids(sent):\n",
      "    sent = simple_toks(sent)\n",
      "    ids = [en_w2id[t] for t in sent]\n",
      "    return pad_sequences([ids], maxlen, padding='post', truncating='post')\n",
      "\n",
      "--------------------\n",
      " Similarity Matrix\n",
      "\n",
      "submat = sio.loadmat(os.path.join(somatomotor_path, subtype_path))\n",
      "\n",
      "--------------------\n",
      " Loading data\n",
      "\n",
      "import time\n",
      "\n",
      "import sys\n",
      "\n",
      "import xgboost\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " Random Forest\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=120, max_depth=12, warm_start=True, n_jobs=4, verbose=1)\n",
      "\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " SGD\n",
      "\n",
      "clf = SGDClassifier(loss='hinge', penalty='l2', epsilon=1.0, n_jobs=4)\n",
      "\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " XGBoost\n",
      "\n",
      "clf = xgboost.XGBClassifier(max_depth=5, subsample=0.8, colsample_bytree=0.8, n_estimators=175, objective='binary:logistic')\n",
      "\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "print(('E=%s' % gamma.mean()))\n",
      "\n",
      "print(('D=%s' % gamma.var()))\n",
      "\n",
      "--------------------\n",
      " \n",
      "\n",
      "estimate(5, gamma)\n",
      "\n",
      "--------------------\n",
      " 1 Load CIFAR 10 Database\n",
      "\n",
      "import keras\n",
      "\n",
      "from keras.datasets import cifar10\n",
      "\n",
      "((x_train, y_train), (x_test, y_test)) = cifar10.load_data()\n",
      "\n",
      "--------------------\n",
      " 2 Visualize the First 24 Training Images\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().run_line_magic('matplotlib', 'inline')\n",
      "\n",
      "fig = plt.figure(figsize=(20, 5))\n",
      "\n",
      "for i in range(36):\n",
      "    ax = fig.add_subplot(3, 12, (i + 1), xticks=[], yticks=[])\n",
      "    ax.imshow(np.squeeze(x_train[i]))\n",
      "\n",
      "--------------------\n",
      " 3 Rescale the Images by Dividing Every Pixel in Every Image by 255\n",
      "\n",
      "x_train = (x_train.astype('float32') / 255)\n",
      "\n",
      "x_test = (x_test.astype('float32') / 255)\n",
      "\n",
      "--------------------\n",
      " 6 Compile the Model \n",
      "\n",
      "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
      "\n",
      "--------------------\n",
      " 7 Train the Model \n",
      "\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "\n",
      "checkpointer = ModelCheckpoint(filepath='MLP.weights.best.hdf5', verbose=1, save_best_only=True)\n",
      "\n",
      "hist = model.fit(x_train, y_train, batch_size=32, epochs=20, validation_data=(x_valid, y_valid), callbacks=[checkpointer], verbose=2, shuffle=True)\n",
      "\n",
      "--------------------\n",
      " 8 Load the Model with the Best Classification Accuracy on the Validation Set\n",
      "\n",
      "model.load_weights('MLP.weights.best.hdf5')\n",
      "\n",
      "--------------------\n",
      " 9 Calculate Classification Accuracy on Test Set\n",
      "\n",
      "score = model.evaluate(x_test, y_test, verbose=0)\n",
      "\n",
      "print('\\n', 'Test accuracy:', score[1])\n",
      "\n",
      "--------------------\n",
      " 5 Is there a significant difference between males and females in normal temperature \n",
      "\n",
      "temp_F = df.loc[((df['gender'] == 'F'), 'temperature')]\n",
      "\n",
      "temp_M = df.loc[((df['gender'] == 'M'), 'temperature')]\n",
      "\n",
      "--------------------\n",
      " Generating the data set\n",
      "\n",
      "from sklearn.datasets import make_blobs\n",
      "\n",
      "(X, y) = make_blobs(n_features=2, centers=3, n_samples=500, random_state=666)\n",
      "\n",
      "--------------------\n",
      " Anomaly detection with density estimation\n",
      "\n",
      "from sklearn.neighbors.kde import KernelDensity\n",
      "\n",
      "kde = KernelDensity(kernel='gaussian')\n",
      "\n",
      "kde = kde.fit(X)\n",
      "\n",
      "kde\n",
      "\n",
      "--------------------\n",
      " DBSCAN\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "from sklearn.cluster import DBSCAN, KMeans\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn import datasets, linear_model, metrics\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "\n",
      "--------------------\n",
      " 1 2 Standardize X \n",
      "\n",
      "X = StandardScaler().fit_transform(X)\n",
      "\n",
      "--------------------\n",
      " 3 3 Plot the resulting clusters\n",
      "\n",
      "unique_labels = np.unique(labels)\n",
      "\n",
      "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
      "\n",
      "colors\n",
      "\n",
      "--------------------\n",
      " Find epsilon using k distance\n",
      "\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "\n",
      "nn = NearestNeighbors(n_neighbors=len(X)).fit(X)\n",
      "\n",
      "(distances, indices) = nn.kneighbors(X)\n",
      "\n",
      "--------------------\n",
      " Random Forest Model\n",
      "\n",
      "crime_forest = RandomForestClassifier()\n",
      "\n",
      "--------------------\n",
      " Exhaustive Grid Search\n",
      "\n",
      "(X_grid_train, X_grid_cv, y_grid_train, y_grid_cv) = cross_validation.train_test_split(X_train, y_train, test_size=0.5, random_state=1)\n",
      "\n",
      "--------------------\n",
      " SVC Model prediction\n",
      "\n",
      "get_ipython().run_cell_magic('time', '', \"\\n# SUPPORT VECTOR MACHINE\\n\\ncrime_svm = OneVsRestClassifier(SVC(C = 100, gamma = 0.01, kernel='rbf'))\\ncrime_svm.fit(X_train, y_train)\")\n",
      "\n",
      "--------------------\n",
      " Use gender as a confounder\n",
      "\n",
      "data = load_dataset(users_pkl=os.path.join(TWITTER_PATH, 'users_array.pkl'), term_doc_matrix_pkl=os.path.join(TWITTER_PATH, 'term_doc_matrix.pkl'), vectorizer_pkl=os.path.join(TWITTER_PATH, 'vectorizer.pkl'), confounder_key='gender', train_ratio=0.5)\n",
      "\n",
      "--------------------\n",
      " Use location as a confounder\n",
      "\n",
      "data2 = load_dataset(users_pkl=os.path.join(TWITTER_PATH, 'users_array.pkl'), term_doc_matrix_pkl=os.path.join(TWITTER_PATH, 'term_doc_matrix.pkl'), vectorizer_pkl=os.path.join(TWITTER_PATH, 'vectorizer.pkl'), confounder_key='location', train_ratio=0.5)\n",
      "\n",
      "--------------------\n",
      " Load models\n",
      "\n",
      "get_ipython().run_line_magic('run', 'models.py')\n",
      "\n",
      "get_ipython().run_line_magic('run', 'injecting_bias.py')\n",
      "\n",
      "get_ipython().run_line_magic('run', 'confound_plot.py')\n",
      "\n",
      "get_ipython().run_line_magic('run', 'most_changing_coef.py')\n",
      "\n",
      "get_ipython().run_line_magic('run', 'ba_c_study.py')\n",
      "\n",
      "--------------------\n",
      " Accuracy experiment\n",
      "\n",
      "models = [('LR', lr), ('M', matching), ('BA', backdoor_adjustment), ('SO', sumout), ('LRS', lr_subsampling), ('BAZ10', backdoor_adjustment_Z10)]\n",
      "\n",
      "(accuracies, corr_diffs, test_biases) = do_confound_expt(data, ntrials=5, models=models)\n",
      "\n",
      "--------------------\n",
      " Export figures\n",
      "\n",
      "for tr_bias in np.arange(0.1, 1.0, 0.1):\n",
      "    ylabel = ('Accuracy for train bias=%.1f' % tr_bias)\n",
      "    export_plot_accuracy('test', accuracies, test_bias_axis, 2, 2, title='', xlabel='Test bias', train_bias=tr_bias, ylabel=ylabel, xlim=[0.0, 1.0], set_xticks=np.arange(0.1, 1.0, 0.1))\n",
      "\n",
      "--------------------\n",
      " Simpson s paradox\n",
      "\n",
      "get_ipython().run_line_magic('run', 'simpson_paradox.py')\n",
      "\n",
      "--------------------\n",
      " Most changing features\n",
      "\n",
      "get_ipython().run_line_magic('run', 'most_changing_coef.py')\n",
      "\n",
      "--------------------\n",
      " Study effect of C on accuracy\n",
      "\n",
      "c_range = np.logspace((- 3), 4, 15)\n",
      "\n",
      "filter_corr_diff = (lambda x: (np.abs(x) > 1.2))\n",
      "\n",
      "(accuracies_c, coefs_c) = do_c_study(c_range, filter_corr_diff, data, 5, np.random.RandomState(111191), 800, 5)\n",
      "\n",
      "--------------------\n",
      " Top terms table\n",
      "\n",
      "get_ipython().run_line_magic('run', 'top_terms_table.py')\n",
      "\n",
      "--------------------\n",
      " Accuracy experiment\n",
      "\n",
      "models = [('LR', lr), ('M', matching), ('BA', backdoor_adjustment), ('SO', sumout), ('LRS', lr_subsampling), ('BAZ10', backdoor_adjustment_Z10)]\n",
      "\n",
      "(accuracies2, corr_diffs2, test_biases2) = do_confound_expt(data2, ntrials=5, models=models)\n",
      "\n",
      "--------------------\n",
      " Most changing features\n",
      "\n",
      "get_ipython().run_line_magic('run', 'most_changing_coef.py')\n",
      "\n",
      "--------------------\n",
      " Top terms table\n",
      "\n",
      "get_ipython().run_line_magic('run', 'top_terms_table.py')\n",
      "\n",
      "--------------------\n",
      " Create a logistic regression model to predict TP53 mutation from gene expression data in TCGA\n",
      "\n",
      "import os\n",
      "\n",
      "import urllib\n",
      "\n",
      "import random\n",
      "\n",
      "import warnings\n",
      "\n",
      "import resource\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import seaborn as sns\n",
      "\n",
      "from sklearn import preprocessing\n",
      "\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "from sklearn.model_selection import train_test_split, GridSearchCV\n",
      "\n",
      "from sklearn.metrics import roc_auc_score, roc_curve\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
      "\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "from statsmodels.robust.scale import mad\n",
      "\n",
      "--------------------\n",
      " Specify model configuration\n",
      "\n",
      "GENE = 'TP53'\n",
      "\n",
      "--------------------\n",
      " Load Data\n",
      "\n",
      "url_to_path = {\n",
      "    'https://ndownloader.figshare.com/files/5514386': os.path.join('data', 'expression.tsv.bz2'),\n",
      "    'https://ndownloader.figshare.com/files/5514389': os.path.join('data', 'mutation-matrix.tsv.bz2'),\n",
      "}\n",
      "\n",
      "for (url, path) in url_to_path.items():\n",
      "    if (not os.path.exists(path)):\n",
      "        urllib.request.urlretrieve(url, path)\n",
      "\n",
      "--------------------\n",
      " Set aside 10 of the data for testing\n",
      "\n",
      "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.1, random_state=0)\n",
      "\n",
      "'Size: {:,} features, {:,} training samples, {:,} testing samples'.format(len(X.columns), len(X_train), len(X_test))\n",
      "\n",
      "--------------------\n",
      " Reduce the dimensionality via Random Projection\n",
      "\n",
      "transformer = GaussianRandomProjection(random_state=0)\n",
      "\n",
      "--------------------\n",
      " Define pipeline and Cross validation model fitting\n",
      "\n",
      "clf = SGDClassifier(random_state=0, class_weight='balanced', loss=param_fixed['loss'], penalty=param_fixed['penalty'])\n",
      "\n",
      "warnings.filterwarnings('ignore', message='Changing the shape of non-C contiguous array')\n",
      "\n",
      "clf_grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=(- 1), scoring='roc_auc')\n",
      "\n",
      "pipeline = make_pipeline(StandardScaler(), transformer, clf_grid)\n",
      "\n",
      "--------------------\n",
      " NB Uses less data than PCA LDA \n",
      "\n",
      "scaled_X_train = StandardScaler().fit_transform(X_train, y_train)\n",
      "\n",
      "--------------------\n",
      " On auto settings random projection reduces X train to 6935 7580 matrix \n",
      "\n",
      "clf_grid.best_params_\n",
      "\n",
      "--------------------\n",
      " Visualize hyperparameters performance\n",
      "\n",
      "\n",
      "def grid_scores_to_df(grid_scores):\n",
      "    '\\n    Convert a sklearn.grid_search.GridSearchCV.grid_scores_ attribute to \\n    a tidy pandas DataFrame where each row is a hyperparameter-fold combinatination.\\n    '\n",
      "    rows = list()\n",
      "    for grid_score in grid_scores:\n",
      "        for (fold, score) in enumerate(grid_score.cv_validation_scores):\n",
      "            row = grid_score.parameters.copy()\n",
      "            row['fold'] = fold\n",
      "            row['score'] = score\n",
      "            rows.append(row)\n",
      "    df = pd.DataFrame(rows)\n",
      "    return df\n",
      "\n",
      "--------------------\n",
      " Process Mutation Matrix\n",
      "\n",
      "cv_score_df = grid_scores_to_df(clf_grid.grid_scores_)\n",
      "\n",
      "cv_score_df.head(2)\n",
      "\n",
      "--------------------\n",
      " Solution\n",
      "\n",
      "import base64\n",
      "\n",
      "answer = 'Y29sb3VyX25hbWVzID0gWydSZWQnLCdHcmVlbicsJ0JsdWUnXQpkZlsnaGFzX2NvbG91ciddID0gZGYuY29sb3VyLmlzaW4oY29sb3VyX25hbWVzKS5hc3R5cGUoJ2ludCcpCnBkLmNvbmNhdChbZGYsIHBkLmdldF9kdW1taWVzKGRmLmNvbG91cildLCBheGlzPTEp'\n",
      "\n",
      "--------------------\n",
      " With specified timestamps\n",
      "\n",
      "[random_date(start='1/1/2012 1:30 PM', end='1/1/2019 4:50 AM') for _ in range(10)]\n",
      "\n",
      "--------------------\n",
      " Based on pandas datetime objects\n",
      "\n",
      "pd.datetime.now()\n",
      "\n",
      "--------------------\n",
      " Solution\n",
      "\n",
      "answer = 'CnBhcnRzID0gWyd5ZWFyJywnbW9udGgnLCdkYXknXQoKZm9yIHBhcnQgaW4gcGFydHM6CiAgICBkZl9kYXRlW3BhcnRdID0gZ2V0YXR0cihkZl9kYXRlLmRhdGUuZHQsIHBhcnQpCiAgICAKZGZfZGF0ZQo='\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('\\n'.join(headers[:1000]))\n",
    "for i in range(1000):\n",
    "    print('-'*20)\n",
    "    print(headers[i])\n",
    "    print(contexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130968"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-a27fe0a831f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pys' is not defined"
     ]
    }
   ],
   "source": [
    "pys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1345388/1345388 [00:01<00:00, 845929.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32288"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = []\n",
    "for g in tqdm(graphs):\n",
    "    if g[\"header\"]!='':\n",
    "        files.append(g[\"file\"])\n",
    "files = list(set(files))\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/bdata/jupyter/target/nb_303171.py'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/bdata/jupyter/target/nb_161199.py\n"
     ]
    }
   ],
   "source": [
    "py = random.choice(files)\n",
    "# print(os.path.join('/projects/bdata/jupyter/target', py))\n",
    "print(py)\n",
    "# with open(os.path.join('/projects/bdata/jupyter/target', py),'r') as f:\n",
    "with open(py,'r') as f:\n",
    "    content = f.read()\n",
    "    header_lineno, header_lines, header_level = get_header(content)\n",
    "    \n",
    "    \n",
    "#     lines = content.split('\\n')\n",
    "#     print(f.read())\n",
    "#     for l in lines:\n",
    "#         if l.startswith('# #'):\n",
    "#             print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [g for g in graphs if g[\"file\"]==py]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "22\n",
      "37\n",
      "46\n",
      "58\n",
      "122\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "for c in cells:\n",
    "    print(c[\"target_lineno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# coding: utf-8\n",
      "\n",
      "# # K-Means and Elbow Criterion\n",
      "\n",
      "# ## Fitting a K-Means model to our data\n",
      "\n",
      "# ### Import the required libraries\n",
      "\n",
      "# In[1]:\n",
      "\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "from sklearn import datasets\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "\n",
      "# ### We will use the iris dataset for this tutorial. It's one of the most recognizable and popular datasets around; one which most machine learning enthusiasts come across at one point or another.  It can be found at the [UCI ML repository](https://archive.ics.uci.edu/ml/datasets/Iris). It's also provided as a part of the scikit-learn package.\n",
      "\n",
      "# In[2]:\n",
      "\n",
      "\n",
      "# Loads the iris dataset\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "\n",
      "# In[3]:\n",
      "\n",
      "\n",
      "# print(iris)\n",
      "\n",
      "\n",
      "# ### We will need to extract required components from the 'iris' object obtained in the previous step. Namely the features and corresponding flower class. \n",
      "\n",
      "# In[4]:\n",
      "\n",
      "\n",
      "iris_data = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
      "iris_target = pd.DataFrame(iris.target, columns=['target'])\n",
      "\n",
      "\n",
      "# ### The target/class variable obtained in the previous is encoded as integers. We will use some python and pandas trickery to obtain the actual class names.\n",
      "\n",
      "# In[5]:\n",
      "\n",
      "\n",
      "# Map encoded target values to target names\n",
      "def map_target(target_num):\n",
      "    return iris.target_names[int(target_num)]\n",
      "\n",
      "iris_target_name = iris_target.apply(map_target, 1)\n",
      "\n",
      "\n",
      "# ### Now that we have loaded and processed our data, we will go ahead and fit a K-means model to the data. We will use 3 of the 4 features available. This will make it easier for us to visualize the results of the model.\n",
      "\n",
      "# In[6]:\n",
      "\n",
      "\n",
      "# Fit a K-Means model to the data\n",
      "kmeans_3 = KMeans(n_clusters=3)\n",
      "kmeans_iris = kmeans_3.fit(iris_data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']])\n",
      "\n",
      "\n",
      "# ### Below code allows us to visualize our K-Means model's results.\n",
      "# \n",
      "# #### Visualization code adapted from [an example](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html) from scikit-learn documentation.\n",
      "\n",
      "# In[7]:\n",
      "\n",
      "\n",
      "fig = plt.figure(1, figsize=(4, 3))\n",
      "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
      "\n",
      "labels = kmeans_iris.labels_\n",
      "\n",
      "ax.scatter(iris_data.ix[:, 3], iris_data.ix[:, 0], iris_data.ix[:, 2], c=labels.astype(np.float))\n",
      "\n",
      "ax.w_xaxis.set_ticklabels([])\n",
      "ax.w_yaxis.set_ticklabels([])\n",
      "ax.w_zaxis.set_ticklabels([])\n",
      "ax.set_xlabel('Petal width')\n",
      "ax.set_ylabel('Sepal length')\n",
      "ax.set_zlabel('Petal length')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "\n",
      "# ### Below code visualizes actual classes from the iris data.\n",
      "\n",
      "# In[8]:\n",
      "\n",
      "\n",
      "# Plot the ground truth\n",
      "fig = plt.figure(1, figsize=(4, 3))\n",
      "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
      "\n",
      "for name, label in [('Setosa', 0),\n",
      "                    ('Versicolour', 1),\n",
      "                    ('Virginica', 2)]:\n",
      "    ax.text3D(iris_data.ix[iris_target.target == label, 3].mean(),\n",
      "              iris_data.ix[iris_target.target == label, 0].mean() + 1.5,\n",
      "              iris_data.ix[iris_target.target == label, 2].mean(), name,\n",
      "              horizontalalignment='center',\n",
      "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
      "# Reorder the labels to have colors matching the cluster results\n",
      "y = np.choose(iris_target.target, [1, 2, 0]).astype(np.float)\n",
      "ax.scatter(iris_data.ix[:, 3], iris_data.ix[:, 0], iris_data.ix[:, 2], c=y)\n",
      "\n",
      "ax.w_xaxis.set_ticklabels([])\n",
      "ax.w_yaxis.set_ticklabels([])\n",
      "ax.w_zaxis.set_ticklabels([])\n",
      "ax.set_xlabel('Petal width')\n",
      "ax.set_ylabel('Sepal length')\n",
      "ax.set_zlabel('Petal length')\n",
      "plt.show()\n",
      "\n",
      "\n",
      "# ### Next two lines show through summary statistics of actual classes and predicted clusters that how the algorithm clubbed together data points belonging to different classes.\n",
      "\n",
      "# In[9]:\n",
      "\n",
      "\n",
      "print(pd.Series([(iris_target.loc[i][0], kmeans_iris.labels_[i]) for i in range(len(iris.target))]).value_counts())\n",
      "\n",
      "\n",
      "# In[10]:\n",
      "\n",
      "\n",
      "print(pd.Series([(iris_target_name.loc[i][0], kmeans_iris.labels_[i]) for i in range(len(iris.target))]).value_counts())\n",
      "\n",
      "\n",
      "# ### As the above visualizations and statistics show, our simple model has done a decent task of classifying the datapoints into separate clusters. You can see that the two plots resemble each other. When compared with actual classes, the model clustered together some datapoints belonging to different classes. Although the predictions aren’t perfect, they come close. That’s a win for the algorithm.\n",
      "\n",
      "# ## Elbow criterion for finding optimum number of clusters\n",
      "\n",
      "# ### In unsupervised learning, you rarely get an output that’s 100 percent accurate because real-world data is rarely that simple.  \n",
      "# ### Apart from simplicity of the dataset, the reason why above model performed so well was because we knew beforehand the optimum numbers of clusters, i.e. 3. Out in the wild, you won’t know how many clusters to choose (or any initialization parameter for other clustering algorithms). Such parameter-tuning is critical.\n",
      "\n",
      "# ### One of the methods for finding out the optimum number of clusters for K-Means algorithm is the _elbow criterion_. \n",
      "# ### The idea of the elbow method is to run k-means clustering on the dataset for a range of values of k (say, k from 1 to 10 in the examples above), and for each value of k calculate the sum of squared errors (SSE). Then, plot a line chart of the SSE for each value of k. If the line chart looks like an arm, then the \"elbow\" on the arm is the value of k that is the best. \n",
      "# ### The idea is that we want a small SSE, but that the SSE tends to decrease toward 0 as we increase k (the SSE is 0 when k is equal to the number of data points in the dataset, because then each data point is its own cluster, and there is no error between it and the center of its cluster). So our goal is to choose a small value of k that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
      "\n",
      "# In[11]:\n",
      "\n",
      "\n",
      "# Elbow criterion\n",
      "def elbow_plot(data, maxK=10, seed_centroids=None):\n",
      "    \"\"\"\n",
      "        parameters:\n",
      "        - data: pandas DataFrame (data to be fitted)\n",
      "        - maxK (default = 10): integer (maximum number of clusters with which to run k-means)\n",
      "        - seed_centroids (default = None ): float (initial value of centroids for k-means)\n",
      "    \"\"\"\n",
      "    sse = {}\n",
      "    for k in range(1, maxK):\n",
      "        print(\"k: \", k)\n",
      "        if seed_centroids is not None:\n",
      "            seeds = seed_centroids.head(k)\n",
      "            kmeans = KMeans(n_clusters=k, max_iter=500, n_init=100, random_state=0, init=np.reshape(seeds, (k,1))).fit(data)\n",
      "            data[\"clusters\"] = kmeans.labels_\n",
      "        else:\n",
      "            kmeans = KMeans(n_clusters=k, max_iter=300, n_init=100, random_state=0).fit(data)\n",
      "            data[\"clusters\"] = kmeans.labels_\n",
      "        # Inertia: Sum of distances of samples to their closest cluster center\n",
      "        sse[k] = kmeans.inertia_\n",
      "    plt.figure()\n",
      "    plt.plot(list(sse.keys()), list(sse.values()))\n",
      "    plt.show()\n",
      "    return\n",
      "\n",
      "elbow_plot(iris_data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']], maxK=10)\n",
      "\n",
      "\n",
      "# ### As we can see from the above plot, 3 looks like a good choice for number of clusters.\n",
      "# \n",
      "# ### The elbow criterion doesn't always work well.. In cases like this, we might try a different method for determining the optimal k, such as computing silhouette scores, or we might reevaluate whether clustering is the right thing to do on our data.\n",
      "\n",
      "# ## That's all folks!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_annotation_before_index(annotation_info, index):\n",
    "    linenos = annotation_info[\"annotation_lineno\"]\n",
    "    lines = annotation_info[\"annotation_lines\"]\n",
    "    all_ids = []\n",
    "    linenos = [i for i in linenos if i<index][::-1]\n",
    "    lines = lines[:len(linenos)][::-1]\n",
    "#     print(linenos)\n",
    "    n = 0\n",
    "    FLAG = False\n",
    "    for i, l in enumerate(linenos):\n",
    "        if i!=0:\n",
    "            FLAG=True\n",
    "        if i==0 :\n",
    "#             print(l)\n",
    "            if index-l<3:\n",
    "                pass\n",
    "            else:\n",
    "                n=i\n",
    "                break\n",
    "        elif  linenos[i-1]-l < 3:\n",
    "            pass\n",
    "        else:\n",
    "            n=i\n",
    "            break\n",
    "    if n==0 and  FLAG:\n",
    "        n = len(linenos)\n",
    "    linenos = linenos[:n][::-1]\n",
    "    lines = lines[:n][::-1]\n",
    "    return lines\n",
    "#     print(linenos)\n",
    "#     print(lines)\n",
    "#     for l in linenos:\n",
    "#         if l<index:\n",
    "#             all_ids.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "from sklearn import datasets\n",
      "\n",
      "from sklearn.cluster import KMeans\n",
      "\n",
      "[7, 5, 3, 1]\n",
      "[' coding utf 8', ' K Means and Elbow Criterion', ' Fitting a K Means model to our data', ' Import the required libraries']\n",
      "====================\n",
      "\n",
      "iris = datasets.load_iris()\n",
      "\n",
      "[20, 9, 7, 5, 3, 1]\n",
      "[' We will use the iris dataset for this tutorial It s one of the most recognizable and popular datasets around one which most machine learning enthusiasts come across at one point or another It can be found at the UCI ML repository https archive ics uci edu ml datasets Iris It s also provided as a part of the scikit learn package ']\n",
      "====================\n",
      "\n",
      "iris_data = pd.DataFrame(iris.data, columns=iris['feature_names'])\n",
      "\n",
      "iris_target = pd.DataFrame(iris.target, columns=['target'])\n",
      "\n",
      "[35, 32, 29, 25, 22, 20, 9, 7, 5, 3, 1]\n",
      "[' We will need to extract required components from the iris object obtained in the previous step Namely the features and corresponding flower class ']\n",
      "====================\n",
      "\n",
      "\n",
      "def map_target(target_num):\n",
      "    return iris.target_names[int(target_num)]\n",
      "\n",
      "iris_target_name = iris_target.apply(map_target, 1)\n",
      "\n",
      "[44, 37, 35, 32, 29, 25, 22, 20, 9, 7, 5, 3, 1]\n",
      "[' The target class variable obtained in the previous is encoded as integers We will use some python and pandas trickery to obtain the actual class names ']\n",
      "====================\n",
      "\n",
      "kmeans_3 = KMeans(n_clusters=3)\n",
      "\n",
      "kmeans_iris = kmeans_3.fit(iris_data[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']])\n",
      "\n",
      "[56, 49, 46, 44, 37, 35, 32, 29, 25, 22, 20, 9, 7, 5, 3, 1]\n",
      "[' Now that we have loaded and processed our data we will go ahead and fit a K means model to the data We will use 3 of the 4 features available This will make it easier for us to visualize the results of the model ']\n",
      "====================\n",
      "\n",
      "print(pd.Series([(iris_target.loc[i][0], kmeans_iris.labels_[i]) for i in range(len(iris.target))]).value_counts())\n",
      "\n",
      "[120, 107, 95, 92, 90, 70, 68, 67, 66, 61, 58, 56, 49, 46, 44, 37, 35, 32, 29, 25, 22, 20, 9, 7, 5, 3, 1]\n",
      "[' Next two lines show through summary statistics of actual classes and predicted clusters that how the algorithm clubbed together data points belonging to different classes ']\n",
      "====================\n",
      "\n",
      "print(pd.Series([(iris_target_name.loc[i][0], kmeans_iris.labels_[i]) for i in range(len(iris.target))]).value_counts())\n",
      "\n",
      "[122, 120, 107, 95, 92, 90, 70, 68, 67, 66, 61, 58, 56, 49, 46, 44, 37, 35, 32, 29, 25, 22, 20, 9, 7, 5, 3, 1]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for c in cells:\n",
    "    print('='*20)\n",
    "    print(c[\"context\"])\n",
    "    print(find_annotation_before_index(annotation_info, c[\"target_lineno\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "\n",
      "import plotly.offline as pyo\n",
      "\n",
      "from plotly.graph_objs import *\n",
      "\n",
      "import plotly.plotly as py\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "from pandas import DataFrame\n",
      "\n",
      "--------------------\n",
      " \n",
      " We ll then plot the resulting line as a separate trace and add the equation onto our chart as an annotation \n",
      "====================\n",
      "\n",
      "from scipy import stats\n",
      "\n",
      "--------------------\n",
      " \n",
      " We re going to use the code stats code module from the code scipy code library to calculate the regression equation \n",
      "====================\n",
      "\n",
      "pyo.offline.init_notebook_mode()\n",
      "\n",
      "--------------------\n",
      "====================\n",
      "\n",
      "lifeExpectancy = pd.read_csv('http://www.richard-muir.com/data/public/csv/LifeExpectancyCigarettePrices.csv', index_col=0)\n",
      "\n",
      "lifeExpectancy['text'] = lifeExpectancy.apply((lambda x: '<b>{}</b><br>Life expectancy for {}s at 60: {} years<br>Price of cigarettes: ${:.2f}'.format(x['Country'], x['Sex'], x['Years'], float(x['Most sold cigarette brand (US$)']))), axis=1)\n",
      "\n",
      "--------------------\n",
      " We ll create the chart from scratch rather than loading it from the Plotly cloud because we ll need to do the regression calculations on the raw data \n",
      "====================\n",
      "\n",
      "regions = list(lifeExpectancy['Region'].unique())\n",
      "\n",
      "sexes = list(lifeExpectancy['Sex'].unique())\n",
      "\n",
      "markerLookup = {\n",
      "    'Eastern Mediterranean': {\n",
      "        'symbol': 'circle',\n",
      "    },\n",
      "    'Europe': {\n",
      "        'symbol': 'square',\n",
      "    },\n",
      "    'Africa': {\n",
      "        'symbol': 'diamond',\n",
      "    },\n",
      "    'Americas': {\n",
      "        'symbol': 'triangle-up',\n",
      "    },\n",
      "    'Western Pacific': {\n",
      "        'symbol': 'cross',\n",
      "    },\n",
      "    'South-East Asia': {\n",
      "        'symbol': 'x',\n",
      "    },\n",
      "    'Male': {\n",
      "        'color': '#663399',\n",
      "    },\n",
      "    'Female': {\n",
      "        'color': '#FF6347',\n",
      "    },\n",
      "}\n",
      "\n",
      "--------------------\n",
      "====================\n",
      "\n",
      "layout = {\n",
      "    'title': 'Life expectancy against price of most popular brand of cigarettes (2011)',\n",
      "    'xaxis': {\n",
      "        'title': 'Price of most popular brand of cigarettes',\n",
      "        'range': [0, (lifeExpectancy['Most sold cigarette brand (US$)'].max() * 1.05)],\n",
      "        'tickformat': '${:}',\n",
      "    },\n",
      "    'yaxis': {\n",
      "        'title': 'Life expectancy at age 60 (years)',\n",
      "        'range': [(lifeExpectancy['Years'].min() * 0.9), (lifeExpectancy['Years'].max() * 1.05)],\n",
      "    },\n",
      "    'hovermode': 'closest',\n",
      "}\n",
      "\n",
      "fig = Figure(data=traces, layout=layout)\n",
      "\n",
      "pyo.iplot(fig)\n",
      "\n",
      "--------------------\n",
      "====================\n",
      "\n",
      "(slope, intercept, r_value, p_value, std_err) = stats.linregress(lifeExpectancy['Most sold cigarette brand (US$)'], lifeExpectancy['Years'])\n",
      "\n",
      "--------------------\n",
      " \n",
      " For the time being we only need to worry about the slope and the intercept as these are the variables we ll be plotting \n",
      " \n",
      " Let s use this to calculate the regression equation which we can then use to plot the regression line \n",
      "====================\n",
      "\n",
      "(slope, intercept)\n",
      "\n",
      "--------------------\n",
      " Let s see the values for slope and intercept \n",
      "====================\n",
      "\n",
      "((r_value ** 2), p_value, std_err)\n",
      "\n",
      "--------------------\n",
      " What this means is that the regression line crosses the y axis at 17 20 years this is the life expectancy at age 60 when the price of cigarettes is 0 and then for every increase of 1 in the price of cigarettes life expectancy at age 60 increases by 0 84 years \n",
      " \n",
      " Obviously the price of cigarettes does not explain every change in life expectancy and we can evaluate this regression equation by looking at the R 2 p value and std err \n",
      "====================\n",
      "\n",
      "xValRange = [0, lifeExpectancy['Most sold cigarette brand (US$)'].max()]\n",
      "\n",
      "line = [((slope * xValRange[0]) + intercept), ((slope * xValRange[1]) + intercept)]\n",
      "\n",
      "line\n",
      "\n",
      "--------------------\n",
      " \n",
      " Y slope X intercept\n",
      " \n",
      " To plot the line we can calculate the value of y when x 0 and the value of y when x is at its maximum value \n",
      "====================\n",
      "\n",
      "traces.append({\n",
      "    'type': 'scatter',\n",
      "    'mode': 'lines',\n",
      "    'x': xValRange,\n",
      "    'y': line,\n",
      "    'marker': {\n",
      "        'color': '#333',\n",
      "    },\n",
      "    'hoverinfo': 'none',\n",
      "    'showlegend': False,\n",
      "})\n",
      "\n",
      "--------------------\n",
      " We can now add a new trace by plotting another scatter trace but with code mode code set to code lines code We re also going to set the colour of the trace to a dark grey the code showlegend code parameter to code False code and the code hoverinfo code to code none code because we don t want this line to appear on the legend or have any hover interaction \n",
      "====================\n",
      "\n",
      "fig = Figure(data=traces, layout=layout)\n",
      "\n",
      "pyo.iplot(fig)\n",
      "\n",
      "--------------------\n",
      "====================\n",
      "\n",
      "equationAnnotation = {\n",
      "    'text': 'y = {:.2f}x + {:.2f}<br>R<sup>2</sup> = {:.2f}'.format(slope, intercept, (r_value ** 2)),\n",
      "    'xref': 'x',\n",
      "    'yref': 'y',\n",
      "    'x': 10,\n",
      "    'y': 28,\n",
      "    'showarrow': False,\n",
      "}\n",
      "\n",
      "--------------------\n",
      " \n",
      " To do this I ll use the python string formatting which we ve utilised before to create the text column in the DataFrame I ll also use the HTML code lt sup gt lt sup gt code tag to display the R 2 as a superscript \n",
      " \n",
      " I m going to set the x and y coordinates to 10 and 28 respectively this is a good starting point which I ve judged by eye we can always tweak it later \n",
      "====================\n",
      "\n",
      "layout['annotations'] = [equationAnnotation]\n",
      "\n",
      "fig = Figure(data=traces, layout=layout)\n",
      "\n",
      "pyo.iplot(fig)\n",
      "\n",
      "--------------------\n",
      " Let s add this annotation to the layout object remembering to add it as a list refresh the Figure object and plot the chart \n",
      "====================\n",
      "\n",
      "py.plot(fig, filename='Life expectancy against price of cigarettes (Regression)', fileopt='overwrite')\n",
      "\n",
      "--------------------\n",
      " This plot looks great with the added regression line let s push it to the Plotly cloud \n"
     ]
    }
   ],
   "source": [
    "prev_len = 0\n",
    "\n",
    "# create tuple for up/down limit\n",
    "# for c in i(cells):\n",
    "    \n",
    "# lens = [c[\"target_lineno\"] for c in cells]\n",
    "for i, c in enumerate(cells):\n",
    "    print('='*20)\n",
    "    print(c[\"context\"])\n",
    "    print('-'*20)\n",
    "    for lineno, line in zip(annotation_info[\"annotation_lineno\"], annotation_info[\"annotation_lines\"]):\n",
    "        if lineno>=c[\"target_lineno\"]-5 and lineno<c[\"target_lineno\"]:\n",
    "            print(line)\n",
    "    prev_len=c[\"target_lineno\"]\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_annotation_header(content):\n",
    "    lines = content.split('\\n')\n",
    "#     header_lineno = []\n",
    "#     header_lines = []\n",
    "#     header_level = []\n",
    "\n",
    "    annotation_lineno = []\n",
    "    annotation_lines = []\n",
    "\n",
    "    for i, l in enumerate(lines):\n",
    "        if l.startswith(('#', '\\'', '\\\"')):\n",
    "            annotation = re.sub('[^0-9a-zA-Z]+', ' ', l)\n",
    "            annotation_lines.append(annotation)\n",
    "            annotation_lineno.append(i)\n",
    "        else:\n",
    "            pass\n",
    "#     header_info = {\"header_lineno\": header_lineno,\n",
    "#                    \"header_lines\": header_lines,\n",
    "#                    \"header_level\": header_level}\n",
    "    annotation_info = {\"annotation_lineno\": annotation_lineno,\n",
    "                       \"annotation_lines\": annotation_lines}\n",
    "    return  annotation_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# coding: utf-8\n",
      "# # K-Means and Elbow Criterion\n",
      "# ## Fitting a K-Means model to our data\n",
      "# ### Import the required libraries\n",
      "# In[1]:\n",
      "# ### We will use the iris dataset for this tutorial. It's one of the most recognizable and popular datasets around; one which most machine learning enthusiasts come across at one point or another.  It can be found at the [UCI ML repository](https://archive.ics.uci.edu/ml/datasets/Iris). It's also provided as a part of the scikit-learn package.\n",
      "# In[2]:\n",
      "# Loads the iris dataset\n",
      "# In[3]:\n",
      "# print(iris)\n",
      "# ### We will need to extract required components from the 'iris' object obtained in the previous step. Namely the features and corresponding flower class. \n",
      "# In[4]:\n",
      "# ### The target/class variable obtained in the previous is encoded as integers. We will use some python and pandas trickery to obtain the actual class names.\n",
      "# In[5]:\n",
      "# Map encoded target values to target names\n",
      "# ### Now that we have loaded and processed our data, we will go ahead and fit a K-means model to the data. We will use 3 of the 4 features available. This will make it easier for us to visualize the results of the model.\n",
      "# In[6]:\n",
      "# Fit a K-Means model to the data\n",
      "# ### Below code allows us to visualize our K-Means model's results.\n",
      "# \n",
      "# #### Visualization code adapted from [an example](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html) from scikit-learn documentation.\n",
      "# In[7]:\n",
      "# ### Below code visualizes actual classes from the iris data.\n",
      "# In[8]:\n",
      "# Plot the ground truth\n",
      "# Reorder the labels to have colors matching the cluster results\n",
      "# ### Next two lines show through summary statistics of actual classes and predicted clusters that how the algorithm clubbed together data points belonging to different classes.\n",
      "# In[9]:\n",
      "# In[10]:\n",
      "# ### As the above visualizations and statistics show, our simple model has done a decent task of classifying the datapoints into separate clusters. You can see that the two plots resemble each other. When compared with actual classes, the model clustered together some datapoints belonging to different classes. Although the predictions aren’t perfect, they come close. That’s a win for the algorithm.\n",
      "# ## Elbow criterion for finding optimum number of clusters\n",
      "# ### In unsupervised learning, you rarely get an output that’s 100 percent accurate because real-world data is rarely that simple.  \n",
      "# ### Apart from simplicity of the dataset, the reason why above model performed so well was because we knew beforehand the optimum numbers of clusters, i.e. 3. Out in the wild, you won’t know how many clusters to choose (or any initialization parameter for other clustering algorithms). Such parameter-tuning is critical.\n",
      "# ### One of the methods for finding out the optimum number of clusters for K-Means algorithm is the _elbow criterion_. \n",
      "# ### The idea of the elbow method is to run k-means clustering on the dataset for a range of values of k (say, k from 1 to 10 in the examples above), and for each value of k calculate the sum of squared errors (SSE). Then, plot a line chart of the SSE for each value of k. If the line chart looks like an arm, then the \"elbow\" on the arm is the value of k that is the best. \n",
      "# ### The idea is that we want a small SSE, but that the SSE tends to decrease toward 0 as we increase k (the SSE is 0 when k is equal to the number of data points in the dataset, because then each data point is its own cluster, and there is no error between it and the center of its cluster). So our goal is to choose a small value of k that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
      "# In[11]:\n",
      "# Elbow criterion\n",
      "# ### As we can see from the above plot, 3 looks like a good choice for number of clusters.\n",
      "# \n",
      "# ### The elbow criterion doesn't always work well.. In cases like this, we might try a different method for determining the optimal k, such as computing silhouette scores, or we might reevaluate whether clustering is the right thing to do on our data.\n",
      "# ## That's all folks!\n"
     ]
    }
   ],
   "source": [
    "header_info, annotation_info=get_annotation_header(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      " In this lesson we re going to learn how to fit a regression line to the life expectancy data We ll use the code stats code module from the code scipy code library to calculate the regression equation \n",
      "5\n",
      " \n",
      "6\n",
      " We ll then plot the resulting line as a separate trace and add the equation onto our chart as an annotation \n",
      "13\n",
      " plotly offline doesn t push your charts to the clouds\n",
      "15\n",
      " allows us to create the Data and Figure objects\n",
      "17\n",
      " plotly plotly pushes your charts to the cloud \n",
      "20\n",
      " pandas is a data analysis library\n",
      "26\n",
      " \n",
      "27\n",
      " We re going to use the code stats code module from the code scipy code library to calculate the regression equation \n",
      "38\n",
      " lets us see the charts in an iPython Notebook\n",
      "43\n",
      " We ll create the chart from scratch rather than loading it from the Plotly cloud because we ll need to do the regression calculations on the raw data \n",
      "110\n",
      " Now we can use the code stats linregress code function to calculate the regression equation We re going to touch upon some statistics here but I ll keep it light and brief this is a data visualisation course after all Still it s important to know what you re dealing with when plotting a regression line \n",
      "111\n",
      " \n",
      "112\n",
      " code stats linregress code takes two arguments an x value and a y value It returns 5 variables \n",
      "113\n",
      " slope the gradient of the regression line\n",
      "114\n",
      " intercept where the line crosses the y axis\n",
      "115\n",
      " r value the correlation coefficient of the regression R 2 is often used to explain how much variation in the y values is explained by the model \n",
      "116\n",
      " p value a statistical measure of whether or not the line is significantly different from 0 Generally speaking this should be under 0 05 to be considered significant however statistics is a broad subject and the p value is not necessarily the best measure for this \n",
      "117\n",
      " std err the standard error is an estimate of the standard deviation ie how much the data varies \n",
      "118\n",
      " \n",
      "119\n",
      " For the time being we only need to worry about the slope and the intercept as these are the variables we ll be plotting \n",
      "120\n",
      " \n",
      "121\n",
      " Let s use this to calculate the regression equation which we can then use to plot the regression line \n",
      "130\n",
      " Let s see the values for slope and intercept \n",
      "138\n",
      " What this means is that the regression line crosses the y axis at 17 20 years this is the life expectancy at age 60 when the price of cigarettes is 0 and then for every increase of 1 in the price of cigarettes life expectancy at age 60 increases by 0 84 years \n",
      "139\n",
      " \n",
      "140\n",
      " Obviously the price of cigarettes does not explain every change in life expectancy and we can evaluate this regression equation by looking at the R 2 p value and std err \n",
      "148\n",
      " This model only explains 31 of the variation in the y values R 2 0 31 The p value is very small and therefore the result is statistically significant although this can simply mean that we have a lot of data points \n",
      "149\n",
      " \n",
      "150\n",
      " The standard error tells us that the average distance of the data points from the regression line is 0 06 years this is often used to assess the precision of predictions made using the model and is something which we won t cover in this course \n",
      "153\n",
      " \n",
      "154\n",
      " First of all we need to calculate the values for the line The regression equation is of the form \n",
      "155\n",
      " \n",
      "156\n",
      " Y slope X intercept\n",
      "157\n",
      " \n",
      "158\n",
      " To plot the line we can calculate the value of y when x 0 and the value of y when x is at its maximum value \n",
      "169\n",
      " We can now add a new trace by plotting another scatter trace but with code mode code set to code lines code We re also going to set the colour of the trace to a dark grey the code showlegend code parameter to code False code and the code hoverinfo code to code none code because we don t want this line to appear on the legend or have any hover interaction \n",
      "191\n",
      " Adding the regresison equation as an annotaion will allow those who are familiar with statistical regression to evaluate the regression equation \n",
      "192\n",
      " \n",
      "193\n",
      " The Plotly Layout object can contain a list of annotations each showing a different text string \n",
      "194\n",
      " python\n",
      "195\n",
      " layout annotations text Annotation1 \n",
      "196\n",
      " text Annotation2 \n",
      "197\n",
      " \n",
      "198\n",
      " The annotations can be positioned anywhere on the chart area either with respect to the relative coordinates of the plot or as actual data points on the chart We re going to position the annotation for the regression equation based on the data points on the chart \n",
      "199\n",
      " \n",
      "200\n",
      " To do this we must set code xref code and code yref code to code x code and code y code respectively We also need to set the x and y position of the annotation \n",
      "201\n",
      " \n",
      "202\n",
      " python\n",
      "203\n",
      " Annotation1 text Annotation1 \n",
      "204\n",
      " xref x \n",
      "205\n",
      " yref y \n",
      "206\n",
      " x x coordinate normally an integer or float \n",
      "207\n",
      " y y coordinate normally an integer or float \n",
      "208\n",
      " \n",
      "209\n",
      " A default annotation has an arrow which we re going to suppress\n",
      "210\n",
      " python\n",
      "211\n",
      " Annotation1 showarrow False \n",
      "212\n",
      " \n",
      "213\n",
      " I m going to write this annotation as \n",
      "214\n",
      " \n",
      "215\n",
      " y 0 84x 17 2\n",
      "216\n",
      " R 2 0 31\n",
      "217\n",
      " \n",
      "218\n",
      " \n",
      "219\n",
      " To do this I ll use the python string formatting which we ve utilised before to create the text column in the DataFrame I ll also use the HTML code lt sup gt lt sup gt code tag to display the R 2 as a superscript \n",
      "220\n",
      " \n",
      "221\n",
      " I m going to set the x and y coordinates to 10 and 28 respectively this is a good starting point which I ve judged by eye we can always tweak it later \n",
      "234\n",
      " Let s add this annotation to the layout object remembering to add it as a list refresh the Figure object and plot the chart \n",
      "244\n",
      " This plot looks great with the added regression line let s push it to the Plotly cloud \n",
      "254\n",
      " In this lesson we ve learnt how to calculate a regression equation using the code scipy stats linregress code function and we ve had a brief introduction into the output from this function \n",
      "255\n",
      " \n",
      "256\n",
      " We ve learnt how to use the resulting regression equation to calculate the coordinates of a regression line plot this line on the chart and use the code showlegend False code to prevent the trace from appearing as a legend item \n",
      "257\n",
      " \n",
      "258\n",
      " Finally we ve learnt how to add a list of annotations to the layout as well as how to position these annotations using x and y coordinates \n",
      "259\n",
      " \n",
      "260\n",
      " In the next lesson you ll get the opportunity to practise what you ve learnt by fitting a regression line to the data for Males and Females separately \n",
      "262\n",
      " If you have any questions please ask in the comments section or email a href mailto me richard muir com me richard muir com a \n"
     ]
    }
   ],
   "source": [
    "for lineno, line in zip(annotation_info[\"annotation_lineno\"], annotation_info[\"annotation_lines\"]):\n",
    "    print(lineno)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "python2_graphs = []\n",
    "with open('./graphs/test_cells_python2_1_16.txt','r') as f:\n",
    "    for l in f:\n",
    "        python2_graphs.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "/projects/bdata/jupyter/target/nb_952491.py\n",
      "--------------------\n",
      "\n",
      "get_ipython().magic(u'matplotlib inline')\n",
      "\n",
      "import matplotlib\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import pylab as pl\n",
      "\n",
      "import itertools\n",
      "\n",
      "from chdir import chdir\n",
      "\n",
      "from sklearn import decomposition\n",
      "\n",
      "from scipy.stats import zscore\n",
      "\n",
      "from IPython.display import display, HTML, Image\n",
      "\n",
      "pd.options.mode.chained_assignment = None\n",
      "\n",
      "--------------------\n",
      "['get_ipython.magic', 'get_ipython']\n",
      "--------------------\n",
      "[{'type': 'Module', 'children': [1, 8, 10, 13, 16, 19, 22, 24, 26, 28, 30, 34]}, {'type': 'Expr', 'children': [2]}, {'type': 'Call', 'children': [3, 7]}, {'type': 'AttributeLoad', 'children': [4, 6]}, {'type': 'Call', 'children': [5]}, {'type': 'NameLoad', 'value': 'get_ipython'}, {'type': 'attr', 'value': 'magic'}, {'type': 'Str', 'value': 'matplotlib inline'}, {'type': 'Import', 'children': [9]}, {'type': 'alias', 'value': 'matplotlib'}, {'type': 'Import', 'children': [11]}, {'type': 'alias', 'children': [12], 'value': 'matplotlib.pyplot'}, {'type': 'identifier', 'value': 'plt'}, {'type': 'Import', 'children': [14]}, {'type': 'alias', 'children': [15], 'value': 'pandas'}, {'type': 'identifier', 'value': 'pd'}, {'type': 'Import', 'children': [17]}, {'type': 'alias', 'children': [18], 'value': 'numpy'}, {'type': 'identifier', 'value': 'np'}, {'type': 'Import', 'children': [20]}, {'type': 'alias', 'children': [21], 'value': 'pylab'}, {'type': 'identifier', 'value': 'pl'}, {'type': 'Import', 'children': [23]}, {'type': 'alias', 'value': 'itertools'}, {'type': 'ImportFrom', 'children': [25], 'value': 'chdir'}, {'type': 'alias', 'value': 'chdir'}, {'type': 'ImportFrom', 'children': [27], 'value': 'sklearn'}, {'type': 'alias', 'value': 'decomposition'}, {'type': 'ImportFrom', 'children': [29], 'value': 'scipy.stats'}, {'type': 'alias', 'value': 'zscore'}, {'type': 'ImportFrom', 'children': [31, 32, 33], 'value': 'IPython.display'}, {'type': 'alias', 'value': 'display'}, {'type': 'alias', 'value': 'HTML'}, {'type': 'alias', 'value': 'Image'}, {'type': 'Assign', 'children': [35, 42]}, {'type': 'AttributeStore', 'children': [36, 41]}, {'type': 'AttributeLoad', 'children': [37, 40]}, {'type': 'AttributeLoad', 'children': [38, 39]}, {'type': 'NameLoad', 'value': 'pd'}, {'type': 'attr', 'value': 'options'}, {'type': 'attr', 'value': 'mode'}, {'type': 'attr', 'value': 'chained_assignment'}, {'type': 'NameLoad', 'value': 'None'}]\n"
     ]
    }
   ],
   "source": [
    "g = random.choice(python2_train_graphs)\n",
    "print('-'*20)\n",
    "print(g[\"file\"])\n",
    "print('-'*20)\n",
    "print(g[\"context\"])\n",
    "print('-'*20)\n",
    "print(g[\"funcs\"])\n",
    "print('-'*20)\n",
    "print(g[\"nodes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\n",
      "--------------------\n",
      "\n",
      "print x[[0, 2]]\n",
      "\n",
      "--------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "g = random.choice(python2_graphs)\n",
    "print('-'*20)\n",
    "print(g[\"file\"])\n",
    "print('-'*20)\n",
    "print(g[\"context\"])\n",
    "print('-'*20)\n",
    "print(g[\"funcs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "python2_train_graphs = []\n",
    "with open('./graphs/cell_with_func_markdown_1_12.txt','r') as f:\n",
    "    for l in f:\n",
    "        python2_train_graphs.append(json.loads(l))\n",
    "        if len(python2_train_graphs)==10000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(python2_train_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52593"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(python2_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add markdown to graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3172it [00:00, 31718.67it/s]\u001b[A\n",
      "6580it [00:00, 32390.87it/s]\u001b[A\n",
      "9946it [00:00, 32759.40it/s]\u001b[A\n",
      "13354it [00:00, 32970.43it/s]\u001b[A\n",
      "16710it [00:00, 33144.96it/s]\u001b[A\n",
      "20053it [00:00, 33228.08it/s]\u001b[A\n",
      "23500it [00:00, 33585.57it/s]\u001b[A\n",
      "26696it [00:00, 33079.12it/s]\u001b[A\n",
      "30079it [00:00, 33294.42it/s]\u001b[A\n",
      "33381it [00:01, 33211.05it/s]\u001b[A\n",
      "36752it [00:01, 33358.53it/s]\u001b[A\n",
      "40027it [00:01, 33073.43it/s]\u001b[A\n",
      "43406it [00:01, 33284.05it/s]\u001b[A\n",
      "46706it [00:01, 32901.95it/s]\u001b[A\n",
      "50093it [00:01, 33182.86it/s]\u001b[A\n",
      "53495it [00:01, 33428.41it/s]\u001b[A\n",
      "56830it [00:01, 33056.58it/s]\u001b[A\n",
      "60259it [00:01, 33416.82it/s]\u001b[A\n",
      "63598it [00:01, 33314.94it/s]\u001b[A\n",
      "66928it [00:02, 33088.43it/s]\u001b[A\n",
      "70236it [00:02, 32997.41it/s]\u001b[A\n",
      "73558it [00:02, 33063.60it/s]\u001b[A\n",
      "76905it [00:02, 33183.55it/s]\u001b[A\n",
      "80244it [00:02, 33244.89it/s]\u001b[A\n",
      "83569it [00:02, 32854.41it/s]\u001b[A\n",
      "87070it [00:02, 33471.81it/s]\u001b[A\n",
      "90512it [00:02, 33695.45it/s]\u001b[A\n",
      "93885it [00:02, 33352.93it/s]\u001b[A\n",
      "97304it [00:02, 33598.59it/s]\u001b[A\n",
      "100667it [00:03, 33588.67it/s]\u001b[A\n",
      "104028it [00:03, 33329.95it/s]\u001b[A\n",
      "107499it [00:03, 33729.52it/s]\u001b[A\n",
      "110875it [00:03, 33402.38it/s]\u001b[A\n",
      "114330it [00:03, 33738.47it/s]\u001b[A\n",
      "117707it [00:03, 33634.98it/s]\u001b[A\n",
      "121180it [00:03, 33955.30it/s]\u001b[A\n",
      "124578it [00:03, 33831.46it/s]\u001b[A\n",
      "127963it [00:03, 33011.87it/s]\u001b[A\n",
      "131270it [00:03, 32577.44it/s]\u001b[A\n",
      "134533it [00:04, 32323.83it/s]\u001b[A\n",
      "137878it [00:04, 32653.08it/s]\u001b[A\n",
      "141155it [00:04, 32686.70it/s]\u001b[A\n",
      "144427it [00:04, 32659.37it/s]\u001b[A\n",
      "147771it [00:04, 32886.75it/s]\u001b[A\n",
      "151062it [00:04, 32751.65it/s]\u001b[A\n",
      "154416it [00:04, 32982.35it/s]\u001b[A\n",
      "157716it [00:04, 32721.60it/s]\u001b[A\n",
      "161091it [00:04, 33021.38it/s]\u001b[A\n",
      "164487it [00:04, 33297.37it/s]\u001b[A\n",
      "167819it [00:05, 32970.77it/s]\u001b[A\n",
      "171118it [00:05, 32931.22it/s]\u001b[A\n",
      "174461it [00:05, 33079.20it/s]\u001b[A\n",
      "177771it [00:05, 32924.96it/s]\u001b[A\n",
      "181065it [00:05, 32786.78it/s]\u001b[A\n",
      "184345it [00:05, 32699.31it/s]\u001b[A\n",
      "187616it [00:05, 31603.56it/s]\u001b[A\n",
      "190959it [00:05, 32125.82it/s]\u001b[A\n",
      "194290it [00:05, 32471.94it/s]\u001b[A\n",
      "197622it [00:05, 32720.01it/s]\u001b[A\n",
      "200950it [00:06, 32884.91it/s]\u001b[A\n",
      "204243it [00:06, 32767.48it/s]\u001b[A\n",
      "207523it [00:06, 31645.76it/s]\u001b[A\n",
      "210698it [00:06, 30845.74it/s]\u001b[A\n",
      "213795it [00:06, 30781.79it/s]\u001b[A\n",
      "216882it [00:06, 30627.63it/s]\u001b[A\n",
      "219951it [00:06, 30265.46it/s]\u001b[A\n",
      "222983it [00:06, 30264.77it/s]\u001b[A\n",
      "226014it [00:06, 29855.51it/s]\u001b[A\n",
      "229039it [00:07, 29962.70it/s]\u001b[A\n",
      "232038it [00:07, 29872.24it/s]\u001b[A\n",
      "235177it [00:07, 30309.22it/s]\u001b[A\n",
      "238211it [00:07, 30095.24it/s]\u001b[A\n",
      "241223it [00:07, 29503.60it/s]\u001b[A\n",
      "244262it [00:07, 29748.84it/s]\u001b[A\n",
      "247276it [00:07, 29862.86it/s]\u001b[A\n",
      "250265it [00:07, 29725.33it/s]\u001b[A\n",
      "253373it [00:07, 30118.57it/s]\u001b[A\n",
      "256388it [00:07, 29718.88it/s]\u001b[A\n",
      "259415it [00:08, 29880.23it/s]\u001b[A\n",
      "262406it [00:08, 29400.39it/s]\u001b[A\n",
      "265350it [00:08, 29126.59it/s]\u001b[A\n",
      "268266it [00:08, 28808.22it/s]\u001b[A\n",
      "271266it [00:08, 29155.40it/s]\u001b[A\n",
      "274282it [00:08, 29448.41it/s]\u001b[A\n",
      "277340it [00:08, 29777.57it/s]\u001b[A\n",
      "280321it [00:11, 3483.54it/s] \u001b[A\n",
      "284182it [00:11, 4791.22it/s]\u001b[A\n",
      "287859it [00:11, 6482.57it/s]\u001b[A\n",
      "291533it [00:11, 8609.73it/s]\u001b[A\n",
      "295318it [00:11, 11206.97it/s]\u001b[A\n",
      "298983it [00:11, 14154.85it/s]\u001b[A\n",
      "302910it [00:11, 17515.40it/s]\u001b[A\n",
      "306502it [00:11, 20680.89it/s]\u001b[A\n",
      "310095it [00:12, 23680.95it/s]\u001b[A\n",
      "313994it [00:12, 26841.41it/s]\u001b[A\n",
      "317848it [00:12, 29529.95it/s]\u001b[A\n",
      "321602it [00:12, 31547.77it/s]\u001b[A\n",
      "325408it [00:12, 33253.35it/s]\u001b[A\n",
      "329224it [00:12, 34581.97it/s]\u001b[A\n",
      "333046it [00:12, 35597.77it/s]\u001b[A\n",
      "336953it [00:12, 36571.11it/s]\u001b[A\n",
      "340778it [00:12, 37015.80it/s]\u001b[A\n",
      "344681it [00:12, 37595.13it/s]\u001b[A\n",
      "348526it [00:13, 37483.37it/s]\u001b[A\n",
      "352334it [00:15, 4404.60it/s] \u001b[A\n",
      "356150it [00:15, 5995.67it/s]\u001b[A\n",
      "359931it [00:15, 8020.01it/s]\u001b[A\n",
      "363771it [00:16, 10515.76it/s]\u001b[A\n",
      "367613it [00:16, 13445.28it/s]\u001b[A\n",
      "371443it [00:16, 16695.23it/s]\u001b[A\n",
      "375082it [00:16, 19854.87it/s]\u001b[A\n",
      "378915it [00:16, 23210.51it/s]\u001b[A\n",
      "382595it [00:16, 26058.23it/s]\u001b[A\n",
      "386266it [00:16, 28536.85it/s]\u001b[A\n",
      "390000it [00:16, 30706.43it/s]\u001b[A\n",
      "393714it [00:16, 32388.29it/s]\u001b[A\n",
      "397509it [00:16, 33877.17it/s]\u001b[A\n",
      "401235it [00:17, 34404.77it/s]\u001b[A\n",
      "405063it [00:17, 35437.32it/s]\u001b[A\n",
      "408782it [00:17, 35867.53it/s]\u001b[A\n",
      "412539it [00:17, 36361.73it/s]\u001b[A\n",
      "416264it [00:17, 36322.39it/s]\u001b[A\n",
      "420162it [00:17, 37080.43it/s]\u001b[A\n",
      "423960it [00:17, 37343.89it/s]\u001b[A\n",
      "427728it [00:17, 37169.89it/s]\u001b[A\n",
      "431469it [00:17, 37215.38it/s]\u001b[A\n",
      "435208it [00:17, 37025.84it/s]\u001b[A\n",
      "439052it [00:18, 37438.53it/s]\u001b[A\n",
      "442806it [00:21, 3210.37it/s] \u001b[A\n",
      "446371it [00:21, 4415.80it/s]\u001b[A\n",
      "450310it [00:21, 6019.06it/s]\u001b[A\n",
      "454007it [00:21, 8037.73it/s]\u001b[A\n",
      "457559it [00:22, 10467.01it/s]\u001b[A\n",
      "461097it [00:22, 13270.27it/s]\u001b[A\n",
      "464723it [00:22, 16386.91it/s]\u001b[A\n",
      "468499it [00:22, 19738.33it/s]\u001b[A\n",
      "472348it [00:22, 23098.93it/s]\u001b[A\n",
      "476201it [00:22, 26252.70it/s]\u001b[A\n",
      "479921it [00:22, 28653.89it/s]\u001b[A\n",
      "483707it [00:22, 30907.22it/s]\u001b[A\n",
      "487514it [00:22, 32754.33it/s]\u001b[A\n",
      "491404it [00:22, 34379.41it/s]\u001b[A\n",
      "495213it [00:23, 35376.57it/s]\u001b[A\n",
      "499017it [00:23, 36132.15it/s]\u001b[A\n",
      "502812it [00:23, 36446.78it/s]\u001b[A\n",
      "506585it [00:23, 36337.86it/s]\u001b[A\n",
      "510309it [00:23, 36401.25it/s]\u001b[A\n",
      "514012it [00:23, 36023.76it/s]\u001b[A\n",
      "517917it [00:23, 36880.25it/s]\u001b[A\n",
      "521642it [00:23, 36698.14it/s]\u001b[A\n",
      "525425it [00:23, 37026.69it/s]\u001b[A\n",
      "529147it [00:24, 36904.54it/s]\u001b[A\n",
      "533055it [00:24, 37495.76it/s]\u001b[A\n",
      "536817it [00:24, 37307.01it/s]\u001b[A\n",
      "540592it [00:24, 37438.05it/s]\u001b[A\n",
      "544362it [00:24, 37515.84it/s]\u001b[A\n",
      "548118it [00:24, 37158.89it/s]\u001b[A\n",
      "551894it [00:24, 37335.84it/s]\u001b[A\n",
      "555631it [00:29, 2607.55it/s] \u001b[A\n",
      "559413it [00:29, 3618.14it/s]\u001b[A\n",
      "563066it [00:29, 4958.02it/s]\u001b[A\n",
      "566901it [00:29, 6711.05it/s]\u001b[A\n",
      "570702it [00:29, 8912.51it/s]\u001b[A\n",
      "574456it [00:29, 11552.97it/s]\u001b[A\n",
      "578469it [00:29, 14685.49it/s]\u001b[A\n",
      "582390it [00:29, 18077.47it/s]\u001b[A\n",
      "586324it [00:29, 21575.37it/s]\u001b[A\n",
      "590142it [00:30, 24723.45it/s]\u001b[A\n",
      "593939it [00:30, 27504.25it/s]\u001b[A\n",
      "597716it [00:30, 29348.27it/s]\u001b[A\n",
      "601500it [00:30, 31466.59it/s]\u001b[A\n",
      "605257it [00:30, 33078.69it/s]\u001b[A\n",
      "609090it [00:30, 34495.56it/s]\u001b[A\n",
      "612919it [00:30, 35549.87it/s]\u001b[A\n",
      "616700it [00:30, 36059.20it/s]\u001b[A\n",
      "620466it [00:30, 36350.05it/s]\u001b[A\n",
      "624214it [00:30, 36575.32it/s]\u001b[A\n",
      "628078it [00:31, 37171.03it/s]\u001b[A\n",
      "631853it [00:31, 37220.22it/s]\u001b[A\n",
      "635684it [00:31, 37533.99it/s]\u001b[A\n",
      "639467it [00:31, 37514.62it/s]\u001b[A\n",
      "643239it [00:31, 37338.53it/s]\u001b[A\n",
      "647181it [00:31, 37910.80it/s]\u001b[A\n",
      "650985it [00:31, 37673.21it/s]\u001b[A\n",
      "654762it [00:31, 37488.11it/s]\u001b[A\n",
      "658518it [00:31, 37220.50it/s]\u001b[A\n",
      "662245it [00:31, 37132.69it/s]\u001b[A\n",
      "665962it [00:32, 36954.82it/s]\u001b[A\n",
      "669704it [00:32, 37092.61it/s]\u001b[A\n",
      "673416it [00:32, 34082.84it/s]\u001b[A\n",
      "676874it [00:32, 32812.41it/s]\u001b[A\n",
      "680200it [00:32, 31885.74it/s]\u001b[A\n",
      "683426it [00:32, 31622.42it/s]\u001b[A\n",
      "686615it [00:32, 30865.17it/s]\u001b[A\n",
      "689725it [00:32, 30265.96it/s]\u001b[A\n",
      "692770it [00:32, 30133.63it/s]\u001b[A\n",
      "695797it [00:38, 1821.79it/s] \u001b[A\n",
      "699496it [00:38, 2548.55it/s]\u001b[A\n",
      "703312it [00:38, 3539.46it/s]\u001b[A\n",
      "707175it [00:38, 4865.32it/s]\u001b[A\n",
      "710944it [00:38, 6586.07it/s]\u001b[A\n",
      "714693it [00:38, 8749.86it/s]\u001b[A\n",
      "718396it [00:38, 11350.21it/s]\u001b[A\n",
      "722254it [00:38, 14398.43it/s]\u001b[A\n",
      "725904it [00:39, 17582.03it/s]\u001b[A\n",
      "729666it [00:39, 20925.48it/s]\u001b[A\n",
      "733468it [00:39, 24187.66it/s]\u001b[A\n",
      "737185it [00:39, 26877.13it/s]\u001b[A\n",
      "740876it [00:39, 29238.71it/s]\u001b[A\n",
      "744585it [00:39, 31219.73it/s]\u001b[A\n",
      "748279it [00:39, 32504.84it/s]\u001b[A\n",
      "752123it [00:39, 34083.45it/s]\u001b[A\n",
      "755841it [00:39, 34784.29it/s]\u001b[A\n",
      "759540it [00:39, 35176.00it/s]\u001b[A\n",
      "763392it [00:40, 36114.75it/s]\u001b[A\n",
      "767441it [00:40, 37323.94it/s]\u001b[A\n",
      "771265it [00:40, 37588.07it/s]\u001b[A\n",
      "775161it [00:40, 37932.77it/s]\u001b[A\n",
      "779000it [00:40, 38013.20it/s]\u001b[A\n",
      "782834it [00:40, 37744.79it/s]\u001b[A\n",
      "786638it [00:40, 37831.78it/s]\u001b[A\n",
      "790438it [00:40, 37534.55it/s]\u001b[A\n",
      "794204it [00:40, 37327.24it/s]\u001b[A\n",
      "797946it [00:40, 37034.38it/s]\u001b[A\n",
      "801656it [00:41, 37043.15it/s]\u001b[A\n",
      "805526it [00:41, 37522.45it/s]\u001b[A\n",
      "809283it [00:41, 37330.50it/s]\u001b[A\n",
      "813148it [00:41, 37686.92it/s]\u001b[A\n",
      "816960it [00:41, 37815.71it/s]\u001b[A\n",
      "820744it [00:41, 37118.44it/s]\u001b[A\n",
      "824461it [00:41, 36378.98it/s]\u001b[A\n",
      "828106it [00:41, 35903.40it/s]\u001b[A\n",
      "831703it [00:41, 35627.21it/s]\u001b[A\n",
      "835346it [00:42, 35833.23it/s]\u001b[A\n",
      "838940it [00:42, 35863.41it/s]\u001b[A\n",
      "842529it [00:42, 35487.58it/s]\u001b[A\n",
      "846081it [00:42, 34621.45it/s]\u001b[A\n",
      "849550it [00:42, 34620.61it/s]\u001b[A\n",
      "853101it [00:42, 34882.67it/s]\u001b[A\n",
      "856628it [00:42, 34995.43it/s]\u001b[A\n",
      "860131it [00:42, 34988.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "863826it [00:42, 35553.22it/s]\u001b[A\n",
      "867385it [00:42, 35491.02it/s]\u001b[A\n",
      "870937it [00:49, 1650.65it/s] \u001b[A\n",
      "874447it [00:49, 2311.49it/s]\u001b[A\n",
      "877950it [00:50, 3211.26it/s]\u001b[A\n",
      "881500it [00:50, 4416.24it/s]\u001b[A\n",
      "885184it [00:50, 6000.61it/s]\u001b[A\n",
      "888811it [00:50, 8004.59it/s]\u001b[A\n",
      "892236it [00:50, 10393.88it/s]\u001b[A\n",
      "896023it [00:50, 13285.37it/s]\u001b[A\n",
      "899696it [00:50, 16431.72it/s]\u001b[A\n",
      "903395it [00:50, 19719.50it/s]\u001b[A\n",
      "907006it [00:50, 22797.93it/s]\u001b[A\n",
      "910609it [00:50, 25480.41it/s]\u001b[A\n",
      "914185it [00:51, 27196.52it/s]\u001b[A\n",
      "917739it [00:51, 29255.53it/s]\u001b[A\n",
      "921235it [00:51, 30713.07it/s]\u001b[A\n",
      "924804it [00:51, 32053.14it/s]\u001b[A\n",
      "928445it [00:51, 33244.30it/s]\u001b[A\n",
      "931997it [00:51, 33875.25it/s]\u001b[A\n",
      "935547it [00:51, 34119.12it/s]\u001b[A\n",
      "939155it [00:51, 34684.24it/s]\u001b[A\n",
      "942724it [00:51, 34978.89it/s]\u001b[A\n",
      "946280it [00:52, 31978.09it/s]\u001b[A\n",
      "949569it [00:52, 30646.72it/s]\u001b[A\n",
      "952709it [00:52, 29711.14it/s]\u001b[A\n",
      "955739it [00:52, 29254.75it/s]\u001b[A\n",
      "958708it [00:52, 29127.83it/s]\u001b[A\n",
      "961651it [00:52, 28791.86it/s]\u001b[A\n",
      "964553it [00:52, 28455.75it/s]\u001b[A\n",
      "967470it [00:52, 28664.78it/s]\u001b[A\n",
      "970349it [00:52, 28615.01it/s]\u001b[A\n",
      "973219it [00:52, 28433.92it/s]\u001b[A\n",
      "976069it [00:53, 28104.93it/s]\u001b[A\n",
      "978885it [00:53, 27861.51it/s]\u001b[A\n",
      "981860it [00:53, 28400.97it/s]\u001b[A\n",
      "984706it [00:53, 28254.34it/s]\u001b[A\n",
      "987536it [00:53, 28200.15it/s]\u001b[A\n",
      "990359it [00:53, 28094.87it/s]\u001b[A\n",
      "993331it [00:53, 28561.32it/s]\u001b[A\n",
      "996265it [00:53, 28787.97it/s]\u001b[A\n",
      "999147it [00:53, 28562.38it/s]\u001b[A\n",
      "1002045it [00:53, 28685.12it/s]\u001b[A\n",
      "1004916it [00:54, 28533.72it/s]\u001b[A\n",
      "1007827it [00:54, 28703.33it/s]\u001b[A\n",
      "1010762it [00:54, 28893.66it/s]\u001b[A\n",
      "1013696it [00:54, 29024.94it/s]\u001b[A\n",
      "1016600it [00:54, 28983.44it/s]\u001b[A\n",
      "1019500it [00:54, 28983.36it/s]\u001b[A\n",
      "1022399it [00:54, 28714.52it/s]\u001b[A\n",
      "1025272it [00:54, 28562.11it/s]\u001b[A\n",
      "1028170it [00:54, 28683.53it/s]\u001b[A\n",
      "1031048it [00:54, 28711.74it/s]\u001b[A\n",
      "1033971it [00:55, 28863.00it/s]\u001b[A\n",
      "1036858it [00:55, 28452.97it/s]\u001b[A\n",
      "1039705it [00:55, 28200.71it/s]\u001b[A\n",
      "1042584it [00:55, 28371.98it/s]\u001b[A\n",
      "1045467it [00:55, 28506.04it/s]\u001b[A\n",
      "1048319it [00:55, 28388.95it/s]\u001b[A\n",
      "1051249it [00:55, 28615.79it/s]\u001b[A\n",
      "1054120it [00:55, 28638.30it/s]\u001b[A\n",
      "1056985it [00:55, 28193.62it/s]\u001b[A\n",
      "1059902it [00:56, 28478.69it/s]\u001b[A\n",
      "1062787it [00:56, 28537.27it/s]\u001b[A\n",
      "1065643it [00:56, 28370.18it/s]\u001b[A\n",
      "1068564it [00:56, 28614.11it/s]\u001b[A\n",
      "1071427it [00:56, 28057.02it/s]\u001b[A\n",
      "1074261it [00:56, 28136.87it/s]\u001b[A\n",
      "1077164it [00:56, 28398.62it/s]\u001b[A\n",
      "1080007it [00:56, 28349.17it/s]\u001b[A\n",
      "1082844it [00:56, 28025.11it/s]\u001b[A\n",
      "1085649it [00:56, 27777.83it/s]\u001b[A\n",
      "1088429it [01:05, 1060.13it/s] \u001b[A\n",
      "1091906it [01:05, 1494.94it/s]\u001b[A\n",
      "1095429it [01:05, 2097.48it/s]\u001b[A\n",
      "1099058it [01:05, 2923.96it/s]\u001b[A\n",
      "1102720it [01:05, 4038.86it/s]\u001b[A\n",
      "1106378it [01:05, 5508.70it/s]\u001b[A\n",
      "1110066it [01:06, 7395.85it/s]\u001b[A\n",
      "1113729it [01:06, 9723.78it/s]\u001b[A\n",
      "1117361it [01:06, 12461.03it/s]\u001b[A\n",
      "1121082it [01:06, 15566.87it/s]\u001b[A\n",
      "1124680it [01:06, 18682.46it/s]\u001b[A\n",
      "1128268it [01:06, 21819.67it/s]\u001b[A\n",
      "1131967it [01:06, 24879.94it/s]\u001b[A\n",
      "1135592it [01:06, 27463.56it/s]\u001b[A\n",
      "1139208it [01:06, 29514.84it/s]\u001b[A\n",
      "1142812it [01:06, 31129.90it/s]\u001b[A\n",
      "1146406it [01:07, 32103.66it/s]\u001b[A\n",
      "1150074it [01:07, 33351.38it/s]\u001b[A\n",
      "1153741it [01:07, 34281.62it/s]\u001b[A\n",
      "1157564it [01:07, 35373.60it/s]\u001b[A\n",
      "1161239it [01:07, 35416.65it/s]\u001b[A\n",
      "1164958it [01:07, 35930.25it/s]\u001b[A\n",
      "1171184it [01:07, 17296.06it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "with open('./graphs/cell_with_func_markdown_1_12.txt','r') as f:\n",
    "#     for g in tqdm(graphs):\n",
    "    for l in tqdm(f):\n",
    "        graphs.append(json.loads(l))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61028\n",
      "/projects/bdata/jupyter/target/nb_324249.py\n"
     ]
    }
   ],
   "source": [
    "files = [g[\"file\"] for g in graphs]\n",
    "files = list(set(files))\n",
    "print(len(files))\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/projects/bdata/jupyter/target/nb_303171.py','r') as f:\n",
    "    content = f.read()\n",
    "header_info, annotation_info=get_annotation_header(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header_lineno': [], 'header_lines': [], 'header_level': []}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_lineno': [0,\n",
       "  1,\n",
       "  3,\n",
       "  16,\n",
       "  19,\n",
       "  20,\n",
       "  30,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  42,\n",
       "  45,\n",
       "  71,\n",
       "  80,\n",
       "  83,\n",
       "  88,\n",
       "  112,\n",
       "  132,\n",
       "  141,\n",
       "  153,\n",
       "  156,\n",
       "  159,\n",
       "  163,\n",
       "  166,\n",
       "  175,\n",
       "  180,\n",
       "  186],\n",
       " 'annotation_lines': [' usr bin env python',\n",
       "  ' coding utf 8',\n",
       "  ' In 49 ',\n",
       "  ' In 2 ',\n",
       "  ' from operator import mul or mul lambda x y x y',\n",
       "  ' from fractions import Fraction',\n",
       "  ' def nCr n r ',\n",
       "  ' return int reduce mul Fraction n i i 1 for i in range r 1 ',\n",
       "  ' def nCr n r ',\n",
       "  ' f math factorial',\n",
       "  ' return f n f r f n r ',\n",
       "  ' Use python round',\n",
       "  ' def round x n ',\n",
       "  ' return int np rint a 10 n 10 n',\n",
       "  ' In 3 ',\n",
       "  ' 4 3 Hamming Code Reed Solomon Wrap',\n",
       "  ' In 5 ',\n",
       "  ' In 40 ',\n",
       "  ' Table Generation',\n",
       "  ' In 41 ',\n",
       "  ' In 42 ',\n",
       "  ' In 43 ',\n",
       "  ' In 44 ',\n",
       "  ' In 45 ',\n",
       "  ' N num nodes',\n",
       "  ' print psingle psingle pcombo ',\n",
       "  ' In 54 ',\n",
       "  ' Hockey Stick Plot',\n",
       "  ' pprotocol p protocol codetable 0 0 5 0 num nodes SNR 1 0 1 ',\n",
       "  ' In 53 ',\n",
       "  ' In ']}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/61028 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/61028 [00:00<3:32:14,  4.79it/s]\u001b[A\n",
      "  0%|          | 2/61028 [00:00<2:59:18,  5.67it/s]\u001b[A\n",
      "  0%|          | 6/61028 [00:00<2:14:15,  7.58it/s]\u001b[A\n",
      "  0%|          | 10/61028 [00:00<1:42:45,  9.90it/s]\u001b[A\n",
      "  0%|          | 15/61028 [00:00<1:18:20, 12.98it/s]\u001b[A\n",
      "  0%|          | 20/61028 [00:00<1:02:13, 16.34it/s]\u001b[A\n",
      "  0%|          | 24/61028 [00:00<51:43, 19.66it/s]  \u001b[A\n",
      "  0%|          | 29/61028 [00:00<42:28, 23.94it/s]\u001b[A\n",
      "  0%|          | 34/61028 [00:01<36:12, 28.07it/s]\u001b[A\n",
      "  0%|          | 39/61028 [00:01<31:40, 32.10it/s]\u001b[A\n",
      "  0%|          | 44/61028 [00:01<28:52, 35.21it/s]\u001b[A\n",
      "  0%|          | 50/61028 [00:01<26:39, 38.13it/s]\u001b[A\n",
      "  0%|          | 55/61028 [00:01<25:13, 40.29it/s]\u001b[A\n",
      "  0%|          | 62/61028 [00:01<22:30, 45.15it/s]\u001b[A\n",
      "  0%|          | 68/61028 [00:01<21:40, 46.87it/s]\u001b[A\n",
      "  0%|          | 74/61028 [00:01<21:35, 47.05it/s]\u001b[A\n",
      "  0%|          | 82/61028 [00:01<19:02, 53.33it/s]\u001b[A\n",
      "  0%|          | 89/61028 [00:02<18:24, 55.18it/s]\u001b[A\n",
      "  0%|          | 96/61028 [00:02<17:19, 58.60it/s]\u001b[A\n",
      "  0%|          | 103/61028 [00:02<19:46, 51.37it/s]\u001b[A\n",
      "  0%|          | 109/61028 [00:02<20:11, 50.28it/s]\u001b[A\n",
      "  0%|          | 115/61028 [00:02<20:52, 48.64it/s]\u001b[A\n",
      "  0%|          | 121/61028 [00:02<20:09, 50.36it/s]\u001b[A\n",
      "  0%|          | 127/61028 [00:02<19:31, 51.99it/s]\u001b[A\n",
      "  0%|          | 133/61028 [00:02<19:50, 51.16it/s]\u001b[A\n",
      "  0%|          | 140/61028 [00:03<18:57, 53.51it/s]\u001b[A\n",
      "  0%|          | 146/61028 [00:03<30:42, 33.05it/s]\u001b[A\n",
      "  0%|          | 151/61028 [00:03<27:38, 36.71it/s]\u001b[A\n",
      "  0%|          | 156/61028 [00:03<25:34, 39.66it/s]\u001b[A\n",
      "  0%|          | 163/61028 [00:03<22:24, 45.27it/s]\u001b[A\n",
      "  0%|          | 170/61028 [00:03<21:32, 47.09it/s]\u001b[A\n",
      "  0%|          | 176/61028 [00:04<20:51, 48.62it/s]\u001b[A\n",
      "  0%|          | 182/61028 [00:04<20:43, 48.92it/s]\u001b[A\n",
      "  0%|          | 189/61028 [00:04<18:51, 53.77it/s]\u001b[A\n",
      "  0%|          | 196/61028 [00:04<18:24, 55.06it/s]\u001b[A\n",
      "  0%|          | 203/61028 [00:04<18:28, 54.85it/s]\u001b[A\n",
      "  0%|          | 210/61028 [00:04<17:28, 58.03it/s]\u001b[A\n",
      "  0%|          | 216/61028 [00:04<17:42, 57.23it/s]\u001b[A\n",
      "  0%|          | 223/61028 [00:04<16:54, 59.93it/s]\u001b[A\n",
      "  0%|          | 230/61028 [00:04<18:00, 56.28it/s]\u001b[A\n",
      "  0%|          | 236/61028 [00:05<18:59, 53.34it/s]\u001b[A\n",
      "  0%|          | 242/61028 [00:05<20:51, 48.58it/s]\u001b[A\n",
      "  0%|          | 248/61028 [00:05<20:05, 50.40it/s]\u001b[A\n",
      "  0%|          | 254/61028 [00:05<20:22, 49.70it/s]\u001b[A\n",
      "  0%|          | 260/61028 [00:05<20:21, 49.75it/s]\u001b[A\n",
      "  0%|          | 266/61028 [00:05<19:48, 51.14it/s]\u001b[A\n",
      "  0%|          | 272/61028 [00:05<19:00, 53.28it/s]\u001b[A\n",
      "  0%|          | 278/61028 [00:05<18:35, 54.48it/s]\u001b[A\n",
      "  0%|          | 284/61028 [00:05<19:09, 52.85it/s]\u001b[A\n",
      "  0%|          | 292/61028 [00:06<17:36, 57.50it/s]\u001b[A\n",
      "  0%|          | 300/61028 [00:06<17:08, 59.03it/s]\u001b[A\n",
      "  1%|          | 307/61028 [00:06<18:36, 54.41it/s]\u001b[A\n",
      "  1%|          | 314/61028 [00:06<17:39, 57.29it/s]\u001b[A\n",
      "  1%|          | 320/61028 [00:06<17:43, 57.08it/s]\u001b[A\n",
      "  1%|          | 326/61028 [00:06<17:38, 57.36it/s]\u001b[A\n",
      "  1%|          | 332/61028 [00:06<18:58, 53.31it/s]\u001b[A\n",
      "  1%|          | 338/61028 [00:06<20:53, 48.41it/s]\u001b[A\n",
      "  1%|          | 344/61028 [00:07<21:06, 47.92it/s]\u001b[A\n",
      "  1%|          | 350/61028 [00:07<20:27, 49.44it/s]\u001b[A\n",
      "  1%|          | 357/61028 [00:07<18:54, 53.48it/s]\u001b[A\n",
      "  1%|          | 363/61028 [00:07<18:17, 55.28it/s]\u001b[A\n",
      "  1%|          | 369/61028 [00:07<20:00, 50.52it/s]\u001b[A\n",
      "  1%|          | 376/61028 [00:07<19:04, 52.98it/s]\u001b[A\n",
      "  1%|          | 382/61028 [00:07<19:12, 52.62it/s]\u001b[A\n",
      "  1%|          | 388/61028 [00:07<19:36, 51.55it/s]\u001b[A\n",
      "  1%|          | 394/61028 [00:08<18:48, 53.73it/s]\u001b[A\n",
      "  1%|          | 400/61028 [00:08<19:53, 50.80it/s]\u001b[A\n",
      "  1%|          | 407/61028 [00:08<19:26, 51.96it/s]\u001b[A\n",
      "  1%|          | 413/61028 [00:08<30:31, 33.09it/s]\u001b[A\n",
      "  1%|          | 418/61028 [00:08<27:44, 36.40it/s]\u001b[A\n",
      "  1%|          | 423/61028 [00:08<27:54, 36.20it/s]\u001b[A\n",
      "  1%|          | 428/61028 [00:08<26:16, 38.45it/s]\u001b[A\n",
      "  1%|          | 436/61028 [00:09<22:16, 45.32it/s]\u001b[A\n",
      "  1%|          | 443/61028 [00:09<20:05, 50.26it/s]\u001b[A\n",
      "  1%|          | 449/61028 [00:09<21:17, 47.41it/s]\u001b[A\n",
      "  1%|          | 455/61028 [00:09<22:51, 44.18it/s]\u001b[A\n",
      "  1%|          | 461/61028 [00:09<21:32, 46.85it/s]\u001b[A\n",
      "  1%|          | 467/61028 [00:09<21:30, 46.93it/s]\u001b[A\n",
      "  1%|          | 473/61028 [00:09<20:16, 49.80it/s]\u001b[A\n",
      "  1%|          | 479/61028 [00:09<20:00, 50.44it/s]\u001b[A\n",
      "  1%|          | 485/61028 [00:10<19:47, 51.00it/s]\u001b[A\n",
      "  1%|          | 491/61028 [00:10<19:25, 51.96it/s]\u001b[A\n",
      "  1%|          | 497/61028 [00:10<22:24, 45.02it/s]\u001b[A\n",
      "  1%|          | 503/61028 [00:10<21:38, 46.62it/s]\u001b[A\n",
      "  1%|          | 508/61028 [00:10<21:24, 47.10it/s]\u001b[A\n",
      "  1%|          | 515/61028 [00:10<19:55, 50.61it/s]\u001b[A\n",
      "  1%|          | 521/61028 [00:10<20:37, 48.90it/s]\u001b[A\n",
      "  1%|          | 527/61028 [00:10<19:56, 50.57it/s]\u001b[A\n",
      "  1%|          | 533/61028 [00:11<19:14, 52.40it/s]\u001b[A\n",
      "  1%|          | 540/61028 [00:11<18:16, 55.15it/s]\u001b[A\n",
      "  1%|          | 546/61028 [00:11<17:53, 56.34it/s]\u001b[A\n",
      "  1%|          | 552/61028 [00:11<18:11, 55.40it/s]\u001b[A\n",
      "  1%|          | 559/61028 [00:11<17:13, 58.52it/s]\u001b[A\n",
      "  1%|          | 565/61028 [00:11<17:53, 56.32it/s]\u001b[A\n",
      "  1%|          | 572/61028 [00:11<17:40, 57.01it/s]\u001b[A\n",
      "  1%|          | 578/61028 [00:11<18:35, 54.18it/s]\u001b[A\n",
      "  1%|          | 585/61028 [00:11<17:33, 57.37it/s]\u001b[A\n",
      "  1%|          | 591/61028 [00:12<18:53, 53.30it/s]\u001b[A\n",
      "  1%|          | 597/61028 [00:12<21:26, 46.96it/s]\u001b[A\n",
      "  1%|          | 603/61028 [00:12<21:40, 46.48it/s]\u001b[A\n",
      "  1%|          | 609/61028 [00:12<21:13, 47.45it/s]\u001b[A\n",
      "  1%|          | 616/61028 [00:12<19:37, 51.30it/s]\u001b[A\n",
      "  1%|          | 622/61028 [00:12<20:54, 48.14it/s]\u001b[A\n",
      "  1%|          | 627/61028 [00:12<22:21, 45.03it/s]\u001b[A\n",
      "  1%|          | 633/61028 [00:12<20:41, 48.64it/s]\u001b[A\n",
      "  1%|          | 639/61028 [00:13<20:32, 49.00it/s]\u001b[A\n",
      "  1%|          | 645/61028 [00:13<19:56, 50.45it/s]\u001b[A\n",
      "  1%|          | 653/61028 [00:13<18:24, 54.67it/s]\u001b[A\n",
      "  1%|          | 660/61028 [00:13<18:24, 54.65it/s]\u001b[A\n",
      "  1%|          | 666/61028 [00:13<30:10, 33.33it/s]\u001b[A\n",
      "  1%|          | 671/61028 [00:13<28:59, 34.69it/s]\u001b[A\n",
      "  1%|          | 677/61028 [00:13<25:30, 39.43it/s]\u001b[A\n",
      "  1%|          | 682/61028 [00:14<24:07, 41.70it/s]\u001b[A\n",
      "  1%|          | 687/61028 [00:14<24:18, 41.36it/s]\u001b[A\n",
      "  1%|          | 693/61028 [00:14<22:13, 45.23it/s]\u001b[A\n",
      "  1%|          | 699/61028 [00:14<20:39, 48.67it/s]\u001b[A\n",
      "  1%|          | 706/61028 [00:14<18:51, 53.32it/s]\u001b[A\n",
      "  1%|          | 713/61028 [00:14<18:14, 55.10it/s]\u001b[A\n",
      "  1%|          | 719/61028 [00:14<18:54, 53.14it/s]\u001b[A\n",
      "  1%|          | 725/61028 [00:14<18:37, 53.97it/s]\u001b[A\n",
      "  1%|          | 733/61028 [00:14<17:22, 57.86it/s]\u001b[A\n",
      "  1%|          | 741/61028 [00:15<15:59, 62.86it/s]\u001b[A\n",
      "  1%|          | 748/61028 [00:15<16:28, 60.98it/s]\u001b[A\n",
      "  1%|          | 756/61028 [00:15<15:53, 63.19it/s]\u001b[A\n",
      "  1%|▏         | 763/61028 [00:15<17:19, 57.96it/s]\u001b[A\n",
      "  1%|▏         | 770/61028 [00:15<17:08, 58.57it/s]\u001b[A\n",
      "  1%|▏         | 777/61028 [00:15<16:42, 60.11it/s]\u001b[A\n",
      "  1%|▏         | 784/61028 [00:15<16:01, 62.66it/s]\u001b[A\n",
      "  1%|▏         | 791/61028 [00:15<17:02, 58.94it/s]\u001b[A\n",
      "  1%|▏         | 798/61028 [00:16<16:29, 60.89it/s]\u001b[A\n",
      "  1%|▏         | 805/61028 [00:16<17:22, 57.76it/s]\u001b[A\n",
      "  1%|▏         | 811/61028 [00:16<17:56, 55.92it/s]\u001b[A\n",
      "  1%|▏         | 817/61028 [00:16<18:32, 54.11it/s]\u001b[A\n",
      "  1%|▏         | 823/61028 [00:16<18:35, 53.98it/s]\u001b[A\n",
      "  1%|▏         | 829/61028 [00:16<18:32, 54.11it/s]\u001b[A\n",
      "  1%|▏         | 835/61028 [00:16<18:15, 54.96it/s]\u001b[A\n",
      "  1%|▏         | 841/61028 [00:16<20:12, 49.65it/s]\u001b[A\n",
      "  1%|▏         | 847/61028 [00:16<19:17, 52.01it/s]\u001b[A\n",
      "  1%|▏         | 853/61028 [00:17<20:43, 48.41it/s]\u001b[A\n",
      "  1%|▏         | 858/61028 [00:17<21:21, 46.95it/s]\u001b[A\n",
      "  1%|▏         | 863/61028 [00:17<21:27, 46.72it/s]\u001b[A\n",
      "  1%|▏         | 868/61028 [00:17<21:14, 47.20it/s]\u001b[A\n",
      "  1%|▏         | 875/61028 [00:17<19:58, 50.21it/s]\u001b[A\n",
      "  1%|▏         | 882/61028 [00:17<18:21, 54.60it/s]\u001b[A\n",
      "  1%|▏         | 888/61028 [00:17<18:10, 55.16it/s]\u001b[A\n",
      "  1%|▏         | 894/61028 [00:17<17:49, 56.23it/s]\u001b[A\n",
      "  1%|▏         | 900/61028 [00:17<17:47, 56.30it/s]\u001b[A\n",
      "  1%|▏         | 906/61028 [00:18<18:01, 55.59it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 912/61028 [00:18<19:20, 51.79it/s]\u001b[A\n",
      "  2%|▏         | 918/61028 [00:18<19:07, 52.39it/s]\u001b[A\n",
      "  2%|▏         | 925/61028 [00:18<17:47, 56.29it/s]\u001b[A\n",
      "  2%|▏         | 931/61028 [00:18<28:21, 35.32it/s]\u001b[A\n",
      "  2%|▏         | 936/61028 [00:18<28:49, 34.75it/s]\u001b[A\n",
      "  2%|▏         | 942/61028 [00:19<25:38, 39.04it/s]\u001b[A\n",
      "  2%|▏         | 948/61028 [00:19<23:53, 41.90it/s]\u001b[A\n",
      "  2%|▏         | 955/61028 [00:19<21:15, 47.11it/s]\u001b[A\n",
      "  2%|▏         | 964/61028 [00:19<18:49, 53.16it/s]\u001b[A\n",
      "  2%|▏         | 970/61028 [00:19<18:23, 54.44it/s]\u001b[A\n",
      "  2%|▏         | 979/61028 [00:19<16:21, 61.17it/s]\u001b[A\n",
      "  2%|▏         | 987/61028 [00:19<15:27, 64.76it/s]\u001b[A\n",
      "  2%|▏         | 994/61028 [00:19<16:33, 60.40it/s]\u001b[A\n",
      "  2%|▏         | 1002/61028 [00:19<15:40, 63.83it/s]\u001b[A\n",
      "  2%|▏         | 1011/61028 [00:20<14:45, 67.76it/s]\u001b[A\n",
      "  2%|▏         | 1019/61028 [00:20<15:08, 66.06it/s]\u001b[A\n",
      "  2%|▏         | 1026/61028 [00:20<15:17, 65.36it/s]\u001b[A\n",
      "  2%|▏         | 1033/61028 [00:20<16:40, 59.98it/s]\u001b[A\n",
      "  2%|▏         | 1040/61028 [00:20<16:27, 60.74it/s]\u001b[A\n",
      "  2%|▏         | 1047/61028 [00:20<17:28, 57.23it/s]\u001b[A\n",
      "  2%|▏         | 1055/61028 [00:20<16:46, 59.60it/s]\u001b[A\n",
      "  2%|▏         | 1062/61028 [00:20<16:39, 59.99it/s]\u001b[A\n",
      "  2%|▏         | 1069/61028 [00:21<16:51, 59.29it/s]\u001b[A\n",
      "  2%|▏         | 1075/61028 [00:21<17:30, 57.08it/s]\u001b[A\n",
      "  2%|▏         | 1082/61028 [00:21<16:48, 59.46it/s]\u001b[A\n",
      "  2%|▏         | 1089/61028 [00:21<16:14, 61.54it/s]\u001b[A\n",
      "  2%|▏         | 1096/61028 [00:21<16:28, 60.65it/s]\u001b[A\n",
      "  2%|▏         | 1103/61028 [00:21<16:50, 59.30it/s]\u001b[A\n",
      "  2%|▏         | 1109/61028 [00:21<17:14, 57.91it/s]\u001b[A\n",
      "  2%|▏         | 1116/61028 [00:21<16:34, 60.24it/s]\u001b[A\n",
      "  2%|▏         | 1123/61028 [00:21<19:24, 51.44it/s]\u001b[A\n",
      "  2%|▏         | 1129/61028 [00:22<19:37, 50.89it/s]\u001b[A\n",
      "  2%|▏         | 1137/61028 [00:22<18:35, 53.68it/s]\u001b[A\n",
      "  2%|▏         | 1144/61028 [00:22<17:20, 57.57it/s]\u001b[A\n",
      "  2%|▏         | 1150/61028 [00:22<18:18, 54.51it/s]\u001b[A\n",
      "  2%|▏         | 1156/61028 [00:22<18:52, 52.86it/s]\u001b[A\n",
      "  2%|▏         | 1162/61028 [00:22<18:42, 53.32it/s]\u001b[A\n",
      "  2%|▏         | 1168/61028 [00:22<19:41, 50.67it/s]\u001b[A\n",
      "  2%|▏         | 1175/61028 [00:22<18:35, 53.65it/s]\u001b[A\n",
      "  2%|▏         | 1183/61028 [00:23<16:51, 59.17it/s]\u001b[A\n",
      "  2%|▏         | 1190/61028 [00:23<17:14, 57.83it/s]\u001b[A\n",
      "  2%|▏         | 1196/61028 [00:23<17:03, 58.43it/s]\u001b[A\n",
      "  2%|▏         | 1203/61028 [00:23<17:23, 57.35it/s]\u001b[A\n",
      "  2%|▏         | 1210/61028 [00:23<16:38, 59.94it/s]\u001b[A\n",
      "  2%|▏         | 1217/61028 [00:23<27:38, 36.06it/s]\u001b[A\n",
      "  2%|▏         | 1222/61028 [00:24<27:36, 36.10it/s]\u001b[A\n",
      "  2%|▏         | 1229/61028 [00:24<23:45, 41.94it/s]\u001b[A\n",
      "  2%|▏         | 1236/61028 [00:24<21:19, 46.73it/s]\u001b[A\n",
      "  2%|▏         | 1243/61028 [00:24<19:25, 51.30it/s]\u001b[A\n",
      "  2%|▏         | 1251/61028 [00:24<17:40, 56.36it/s]\u001b[A\n",
      "  2%|▏         | 1258/61028 [00:24<17:26, 57.09it/s]\u001b[A\n",
      "  2%|▏         | 1265/61028 [00:24<18:23, 54.14it/s]\u001b[A\n",
      "  2%|▏         | 1272/61028 [00:24<17:18, 57.57it/s]\u001b[A\n",
      "  2%|▏         | 1279/61028 [00:24<16:46, 59.38it/s]\u001b[A\n",
      "  2%|▏         | 1286/61028 [00:25<16:32, 60.18it/s]\u001b[A\n",
      "  2%|▏         | 1293/61028 [00:25<16:34, 60.07it/s]\u001b[A\n",
      "  2%|▏         | 1301/61028 [00:25<15:23, 64.67it/s]\u001b[A\n",
      "  2%|▏         | 1308/61028 [00:25<15:14, 65.31it/s]\u001b[A\n",
      "  2%|▏         | 1315/61028 [00:25<15:17, 65.07it/s]\u001b[A\n",
      "  2%|▏         | 1322/61028 [00:25<15:20, 64.86it/s]\u001b[A\n",
      "  2%|▏         | 1330/61028 [00:25<14:47, 67.25it/s]\u001b[A\n",
      "  2%|▏         | 1337/61028 [00:25<16:50, 59.04it/s]\u001b[A\n",
      "  2%|▏         | 1344/61028 [00:25<16:37, 59.81it/s]\u001b[A\n",
      "  2%|▏         | 1351/61028 [00:26<17:59, 55.30it/s]\u001b[A\n",
      "  2%|▏         | 1359/61028 [00:26<17:14, 57.69it/s]\u001b[A\n",
      "  2%|▏         | 1367/61028 [00:26<16:52, 58.92it/s]\u001b[A\n",
      "  2%|▏         | 1374/61028 [00:26<16:16, 61.08it/s]\u001b[A\n",
      "  2%|▏         | 1381/61028 [00:26<16:48, 59.17it/s]\u001b[A\n",
      "  2%|▏         | 1387/61028 [00:26<16:54, 58.77it/s]\u001b[A\n",
      "  2%|▏         | 1394/61028 [00:26<16:23, 60.63it/s]\u001b[A\n",
      "  2%|▏         | 1402/61028 [00:26<15:45, 63.09it/s]\u001b[A\n",
      "  2%|▏         | 1409/61028 [00:27<16:16, 61.03it/s]\u001b[A\n",
      "  2%|▏         | 1416/61028 [00:27<16:14, 61.20it/s]\u001b[A\n",
      "  2%|▏         | 1423/61028 [00:27<17:42, 56.07it/s]\u001b[A\n",
      "  2%|▏         | 1430/61028 [00:27<16:51, 58.90it/s]\u001b[A\n",
      "  2%|▏         | 1437/61028 [00:27<16:39, 59.63it/s]\u001b[A\n",
      "  2%|▏         | 1444/61028 [00:27<17:53, 55.52it/s]\u001b[A\n",
      "  2%|▏         | 1450/61028 [00:27<18:18, 54.26it/s]\u001b[A\n",
      "  2%|▏         | 1457/61028 [00:27<18:07, 54.78it/s]\u001b[A\n",
      "  2%|▏         | 1463/61028 [00:28<19:30, 50.89it/s]\u001b[A\n",
      "  2%|▏         | 1470/61028 [00:28<18:20, 54.12it/s]\u001b[A\n",
      "  2%|▏         | 1477/61028 [00:28<17:35, 56.42it/s]\u001b[A\n",
      "  2%|▏         | 1484/61028 [00:28<16:36, 59.74it/s]\u001b[A\n",
      "  2%|▏         | 1491/61028 [00:28<17:00, 58.36it/s]\u001b[A\n",
      "  2%|▏         | 1497/61028 [00:28<17:58, 55.22it/s]\u001b[A\n",
      "  2%|▏         | 1508/61028 [00:28<15:50, 62.63it/s]\u001b[A\n",
      "  2%|▏         | 1515/61028 [00:29<29:13, 33.93it/s]\u001b[A\n",
      "  2%|▏         | 1522/61028 [00:29<25:50, 38.38it/s]\u001b[A\n",
      "  3%|▎         | 1529/61028 [00:29<23:13, 42.69it/s]\u001b[A\n",
      "  3%|▎         | 1535/61028 [00:29<21:37, 45.86it/s]\u001b[A\n",
      "  3%|▎         | 1542/61028 [00:29<19:42, 50.32it/s]\u001b[A\n",
      "  3%|▎         | 1549/61028 [00:29<18:53, 52.49it/s]\u001b[A\n",
      "  3%|▎         | 1556/61028 [00:29<17:36, 56.27it/s]\u001b[A\n",
      "  3%|▎         | 1564/61028 [00:29<16:28, 60.13it/s]\u001b[A\n",
      "  3%|▎         | 1571/61028 [00:30<16:28, 60.12it/s]\u001b[A\n",
      "  3%|▎         | 1578/61028 [00:30<16:22, 60.51it/s]\u001b[A\n",
      "  3%|▎         | 1585/61028 [00:30<16:50, 58.83it/s]\u001b[A\n",
      "  3%|▎         | 1592/61028 [00:30<16:21, 60.57it/s]\u001b[A\n",
      "  3%|▎         | 1599/61028 [00:30<16:03, 61.66it/s]\u001b[A\n",
      "  3%|▎         | 1606/61028 [00:30<15:37, 63.40it/s]\u001b[A\n",
      "  3%|▎         | 1613/61028 [00:30<15:41, 63.13it/s]\u001b[A\n",
      "  3%|▎         | 1621/61028 [00:30<15:30, 63.83it/s]\u001b[A\n",
      "  3%|▎         | 1630/61028 [00:30<14:41, 67.39it/s]\u001b[A\n",
      "  3%|▎         | 1637/61028 [00:31<15:29, 63.90it/s]\u001b[A\n",
      "  3%|▎         | 1644/61028 [00:31<17:24, 56.84it/s]\u001b[A\n",
      "  3%|▎         | 1653/61028 [00:31<15:48, 62.58it/s]\u001b[A\n",
      "  3%|▎         | 1661/61028 [00:31<14:57, 66.16it/s]\u001b[A\n",
      "  3%|▎         | 1668/61028 [00:31<15:13, 64.96it/s]\u001b[A\n",
      "  3%|▎         | 1675/61028 [00:31<15:04, 65.65it/s]\u001b[A\n",
      "  3%|▎         | 1683/61028 [00:31<14:26, 68.45it/s]\u001b[A\n",
      "  3%|▎         | 1690/61028 [00:31<14:53, 66.41it/s]\u001b[A\n",
      "  3%|▎         | 1698/61028 [00:32<14:16, 69.28it/s]\u001b[A\n",
      "  3%|▎         | 1706/61028 [00:32<15:55, 62.06it/s]\u001b[A\n",
      "  3%|▎         | 1713/61028 [00:32<15:26, 64.05it/s]\u001b[A\n",
      "  3%|▎         | 1720/61028 [00:32<16:34, 59.63it/s]\u001b[A\n",
      "  3%|▎         | 1727/61028 [00:32<17:06, 57.75it/s]\u001b[A\n",
      "  3%|▎         | 1733/61028 [00:32<17:53, 55.25it/s]\u001b[A\n",
      "  3%|▎         | 1739/61028 [00:32<18:57, 52.11it/s]\u001b[A\n",
      "  3%|▎         | 1746/61028 [00:32<17:36, 56.12it/s]\u001b[A\n",
      "  3%|▎         | 1755/61028 [00:33<15:38, 63.14it/s]\u001b[A\n",
      "  3%|▎         | 1763/61028 [00:33<14:43, 67.07it/s]\u001b[A\n",
      "  3%|▎         | 1771/61028 [00:33<15:29, 63.77it/s]\u001b[A\n",
      "  3%|▎         | 1778/61028 [00:33<16:35, 59.52it/s]\u001b[A\n",
      "  3%|▎         | 1786/61028 [00:33<15:25, 64.00it/s]\u001b[A\n",
      "  3%|▎         | 1793/61028 [00:33<17:18, 57.06it/s]\u001b[A\n",
      "  3%|▎         | 1802/61028 [00:33<15:41, 62.91it/s]\u001b[A\n",
      "  3%|▎         | 1809/61028 [00:33<17:45, 55.59it/s]\u001b[A\n",
      "  3%|▎         | 1816/61028 [00:34<26:20, 37.46it/s]\u001b[A\n",
      "  3%|▎         | 1826/61028 [00:34<21:25, 46.04it/s]\u001b[A\n",
      "  3%|▎         | 1833/61028 [00:34<20:52, 47.26it/s]\u001b[A\n",
      "  3%|▎         | 1839/61028 [00:34<20:17, 48.60it/s]\u001b[A\n",
      "  3%|▎         | 1846/61028 [00:34<18:52, 52.26it/s]\u001b[A\n",
      "  3%|▎         | 1852/61028 [00:34<18:11, 54.20it/s]\u001b[A\n",
      "  3%|▎         | 1858/61028 [00:34<18:09, 54.30it/s]\u001b[A\n",
      "  3%|▎         | 1864/61028 [00:35<17:42, 55.69it/s]\u001b[A\n",
      "  3%|▎         | 1872/61028 [00:35<16:24, 60.07it/s]\u001b[A\n",
      "  3%|▎         | 1879/61028 [00:35<16:14, 60.71it/s]\u001b[A\n",
      "  3%|▎         | 1887/61028 [00:35<16:04, 61.35it/s]\u001b[A\n",
      "  3%|▎         | 1894/61028 [00:35<16:37, 59.26it/s]\u001b[A\n",
      "  3%|▎         | 1901/61028 [00:35<17:26, 56.50it/s]\u001b[A\n",
      "  3%|▎         | 1908/61028 [00:35<16:38, 59.18it/s]\u001b[A\n",
      "  3%|▎         | 1917/61028 [00:35<15:38, 62.99it/s]\u001b[A\n",
      "  3%|▎         | 1924/61028 [00:35<16:43, 58.88it/s]\u001b[A\n",
      "  3%|▎         | 1931/61028 [00:36<17:52, 55.10it/s]\u001b[A\n",
      "  3%|▎         | 1940/61028 [00:36<15:50, 62.14it/s]\u001b[A\n",
      "  3%|▎         | 1947/61028 [00:36<16:11, 60.79it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1954/61028 [00:36<15:56, 61.76it/s]\u001b[A\n",
      "  3%|▎         | 1961/61028 [00:36<15:32, 63.32it/s]\u001b[A\n",
      "  3%|▎         | 1968/61028 [00:36<15:36, 63.05it/s]\u001b[A\n",
      "  3%|▎         | 1975/61028 [00:36<15:10, 64.83it/s]\u001b[A\n",
      "  3%|▎         | 1983/61028 [00:36<14:21, 68.56it/s]\u001b[A\n",
      "  3%|▎         | 1991/61028 [00:36<13:52, 70.93it/s]\u001b[A\n",
      "  3%|▎         | 1999/61028 [00:37<14:38, 67.19it/s]\u001b[A\n",
      "  3%|▎         | 2006/61028 [00:37<15:15, 64.49it/s]\u001b[A\n",
      "  3%|▎         | 2014/61028 [00:37<14:50, 66.27it/s]\u001b[A\n",
      "  3%|▎         | 2021/61028 [00:37<15:03, 65.29it/s]\u001b[A\n",
      "  3%|▎         | 2028/61028 [00:37<15:48, 62.22it/s]\u001b[A\n",
      "  3%|▎         | 2035/61028 [00:37<16:27, 59.74it/s]\u001b[A\n",
      "  3%|▎         | 2042/61028 [00:37<15:49, 62.13it/s]\u001b[A\n",
      "  3%|▎         | 2049/61028 [00:37<15:53, 61.88it/s]\u001b[A\n",
      "  3%|▎         | 2056/61028 [00:38<15:38, 62.85it/s]\u001b[A\n",
      "  3%|▎         | 2063/61028 [00:38<15:43, 62.52it/s]\u001b[A\n",
      "  3%|▎         | 2071/61028 [00:38<14:49, 66.25it/s]\u001b[A\n",
      "  3%|▎         | 2080/61028 [00:38<13:44, 71.52it/s]\u001b[A\n",
      "  3%|▎         | 2088/61028 [00:38<14:41, 66.86it/s]\u001b[A\n",
      "  3%|▎         | 2097/61028 [00:38<13:53, 70.74it/s]\u001b[A\n",
      "  3%|▎         | 2105/61028 [00:38<14:02, 69.94it/s]\u001b[A\n",
      "  3%|▎         | 2113/61028 [00:38<15:23, 63.77it/s]\u001b[A\n",
      "  3%|▎         | 2120/61028 [00:39<17:58, 54.61it/s]\u001b[A\n",
      "  3%|▎         | 2126/61028 [00:39<26:49, 36.60it/s]\u001b[A\n",
      "  3%|▎         | 2132/61028 [00:39<23:50, 41.17it/s]\u001b[A\n",
      "  4%|▎         | 2140/61028 [00:39<20:51, 47.06it/s]\u001b[A\n",
      "  4%|▎         | 2148/61028 [00:39<18:33, 52.86it/s]\u001b[A\n",
      "  4%|▎         | 2155/61028 [00:39<17:25, 56.29it/s]\u001b[A\n",
      "  4%|▎         | 2164/61028 [00:39<15:39, 62.65it/s]\u001b[A\n",
      "  4%|▎         | 2171/61028 [00:39<15:09, 64.68it/s]\u001b[A\n",
      "  4%|▎         | 2178/61028 [00:40<15:29, 63.32it/s]\u001b[A\n",
      "  4%|▎         | 2186/61028 [00:40<14:46, 66.38it/s]\u001b[A\n",
      "  4%|▎         | 2195/61028 [00:40<13:46, 71.18it/s]\u001b[A\n",
      "  4%|▎         | 2203/61028 [00:40<13:34, 72.19it/s]\u001b[A\n",
      "  4%|▎         | 2211/61028 [00:40<13:32, 72.42it/s]\u001b[A\n",
      "  4%|▎         | 2219/61028 [00:40<14:14, 68.82it/s]\u001b[A\n",
      "  4%|▎         | 2227/61028 [00:40<14:36, 67.09it/s]\u001b[A\n",
      "  4%|▎         | 2234/61028 [00:40<14:28, 67.67it/s]\u001b[A\n",
      "  4%|▎         | 2241/61028 [00:40<14:40, 66.78it/s]\u001b[A\n",
      "  4%|▎         | 2249/61028 [00:41<14:15, 68.70it/s]\u001b[A\n",
      "  4%|▎         | 2258/61028 [00:41<14:01, 69.84it/s]\u001b[A\n",
      "  4%|▎         | 2266/61028 [00:41<14:36, 67.00it/s]\u001b[A\n",
      "  4%|▎         | 2274/61028 [00:41<13:58, 70.04it/s]\u001b[A\n",
      "  4%|▎         | 2282/61028 [00:41<14:01, 69.79it/s]\u001b[A\n",
      "  4%|▍         | 2290/61028 [00:41<14:26, 67.79it/s]\u001b[A\n",
      "  4%|▍         | 2297/61028 [00:41<15:26, 63.37it/s]\u001b[A\n",
      "  4%|▍         | 2304/61028 [00:41<16:04, 60.88it/s]\u001b[A\n",
      "  4%|▍         | 2311/61028 [00:42<15:51, 61.72it/s]\u001b[A\n",
      "  4%|▍         | 2318/61028 [00:42<15:48, 61.87it/s]\u001b[A\n",
      "  4%|▍         | 2325/61028 [00:42<15:34, 62.79it/s]\u001b[A\n",
      "  4%|▍         | 2332/61028 [00:42<15:28, 63.19it/s]\u001b[A\n",
      "  4%|▍         | 2339/61028 [00:42<16:03, 60.90it/s]\u001b[A\n",
      "  4%|▍         | 2346/61028 [00:42<17:15, 56.69it/s]\u001b[A\n",
      "  4%|▍         | 2352/61028 [00:42<17:37, 55.46it/s]\u001b[A\n",
      "  4%|▍         | 2359/61028 [00:42<17:14, 56.73it/s]\u001b[A\n",
      "  4%|▍         | 2365/61028 [00:42<17:34, 55.62it/s]\u001b[A\n",
      "  4%|▍         | 2371/61028 [00:43<17:46, 55.01it/s]\u001b[A\n",
      "  4%|▍         | 2377/61028 [00:43<18:18, 53.37it/s]\u001b[A\n",
      "  4%|▍         | 2383/61028 [00:43<18:00, 54.29it/s]\u001b[A\n",
      "  4%|▍         | 2390/61028 [00:43<17:51, 54.73it/s]\u001b[A\n",
      "  4%|▍         | 2396/61028 [00:43<19:00, 51.43it/s]\u001b[A\n",
      "  4%|▍         | 2403/61028 [00:43<17:36, 55.50it/s]\u001b[A\n",
      "  4%|▍         | 2410/61028 [00:43<17:20, 56.34it/s]\u001b[A\n",
      "  4%|▍         | 2416/61028 [00:43<18:06, 53.93it/s]\u001b[A\n",
      "  4%|▍         | 2422/61028 [00:44<19:22, 50.42it/s]\u001b[A\n",
      "  4%|▍         | 2428/61028 [00:44<32:20, 30.20it/s]\u001b[A\n",
      "  4%|▍         | 2434/61028 [00:44<27:49, 35.10it/s]\u001b[A\n",
      "  4%|▍         | 2440/61028 [00:44<24:42, 39.52it/s]\u001b[A\n",
      "  4%|▍         | 2448/61028 [00:44<21:13, 45.98it/s]\u001b[A\n",
      "  4%|▍         | 2458/61028 [00:44<18:25, 52.97it/s]\u001b[A\n",
      "  4%|▍         | 2466/61028 [00:45<17:00, 57.38it/s]\u001b[A\n",
      "  4%|▍         | 2473/61028 [00:45<16:13, 60.14it/s]\u001b[A\n",
      "  4%|▍         | 2480/61028 [00:45<16:01, 60.91it/s]\u001b[A\n",
      "  4%|▍         | 2487/61028 [00:45<17:28, 55.85it/s]\u001b[A\n",
      "  4%|▍         | 2493/61028 [00:45<18:50, 51.79it/s]\u001b[A\n",
      "  4%|▍         | 2502/61028 [00:45<16:33, 58.91it/s]\u001b[A\n",
      "  4%|▍         | 2509/61028 [00:45<16:13, 60.13it/s]\u001b[A\n",
      "  4%|▍         | 2517/61028 [00:45<15:15, 63.93it/s]\u001b[A\n",
      "  4%|▍         | 2525/61028 [00:45<14:28, 67.35it/s]\u001b[A\n",
      "  4%|▍         | 2533/61028 [00:46<14:43, 66.18it/s]\u001b[A\n",
      "  4%|▍         | 2541/61028 [00:46<14:49, 65.79it/s]\u001b[A\n",
      "  4%|▍         | 2549/61028 [00:46<14:27, 67.40it/s]\u001b[A\n",
      "  4%|▍         | 2556/61028 [00:46<14:32, 67.02it/s]\u001b[A\n",
      "  4%|▍         | 2564/61028 [00:46<14:44, 66.13it/s]\u001b[A\n",
      "  4%|▍         | 2571/61028 [00:46<14:39, 66.45it/s]\u001b[A\n",
      "  4%|▍         | 2580/61028 [00:46<13:31, 72.02it/s]\u001b[A\n",
      "  4%|▍         | 2588/61028 [00:46<13:28, 72.24it/s]\u001b[A\n",
      "  4%|▍         | 2596/61028 [00:46<13:07, 74.24it/s]\u001b[A\n",
      "  4%|▍         | 2604/61028 [00:47<13:15, 73.49it/s]\u001b[A\n",
      "  4%|▍         | 2612/61028 [00:47<14:03, 69.26it/s]\u001b[A\n",
      "  4%|▍         | 2620/61028 [00:47<13:31, 71.98it/s]\u001b[A\n",
      "  4%|▍         | 2631/61028 [00:47<12:59, 74.90it/s]\u001b[A\n",
      "  4%|▍         | 2639/61028 [00:47<13:18, 73.10it/s]\u001b[A\n",
      "  4%|▍         | 2647/61028 [00:47<14:06, 69.00it/s]\u001b[A\n",
      "  4%|▍         | 2655/61028 [00:47<13:54, 69.98it/s]\u001b[A\n",
      "  4%|▍         | 2663/61028 [00:47<13:33, 71.78it/s]\u001b[A\n",
      "  4%|▍         | 2671/61028 [00:48<14:06, 68.97it/s]\u001b[A\n",
      "  4%|▍         | 2679/61028 [00:48<13:43, 70.87it/s]\u001b[A\n",
      "  4%|▍         | 2687/61028 [00:48<13:52, 70.11it/s]\u001b[A\n",
      "  4%|▍         | 2695/61028 [00:48<15:01, 64.67it/s]\u001b[A\n",
      "  4%|▍         | 2703/61028 [00:48<14:18, 67.94it/s]\u001b[A\n",
      "  4%|▍         | 2711/61028 [00:48<14:10, 68.59it/s]\u001b[A\n",
      "  4%|▍         | 2720/61028 [00:48<13:18, 73.01it/s]\u001b[A\n",
      "  4%|▍         | 2728/61028 [00:48<13:32, 71.76it/s]\u001b[A\n",
      "  4%|▍         | 2736/61028 [00:48<14:24, 67.42it/s]\u001b[A\n",
      "  4%|▍         | 2744/61028 [00:49<14:53, 65.24it/s]\u001b[A\n",
      "  5%|▍         | 2751/61028 [00:49<15:24, 63.04it/s]\u001b[A\n",
      "  5%|▍         | 2758/61028 [00:49<26:32, 36.58it/s]\u001b[A\n",
      "  5%|▍         | 2764/61028 [00:49<24:10, 40.17it/s]\u001b[A\n",
      "  5%|▍         | 2772/61028 [00:49<20:37, 47.08it/s]\u001b[A\n",
      "  5%|▍         | 2779/61028 [00:49<18:47, 51.65it/s]\u001b[A\n",
      "  5%|▍         | 2787/61028 [00:50<17:14, 56.32it/s]\u001b[A\n",
      "  5%|▍         | 2795/61028 [00:50<15:47, 61.43it/s]\u001b[A\n",
      "  5%|▍         | 2802/61028 [00:50<16:03, 60.45it/s]\u001b[A\n",
      "  5%|▍         | 2809/61028 [00:50<16:49, 57.68it/s]\u001b[A\n",
      "  5%|▍         | 2816/61028 [00:50<16:59, 57.11it/s]\u001b[A\n",
      "  5%|▍         | 2824/61028 [00:50<15:38, 62.03it/s]\u001b[A\n",
      "  5%|▍         | 2832/61028 [00:50<15:12, 63.74it/s]\u001b[A\n",
      "  5%|▍         | 2840/61028 [00:50<14:26, 67.14it/s]\u001b[A\n",
      "  5%|▍         | 2847/61028 [00:50<14:47, 65.58it/s]\u001b[A\n",
      "  5%|▍         | 2855/61028 [00:51<14:34, 66.51it/s]\u001b[A\n",
      "  5%|▍         | 2864/61028 [00:51<13:59, 69.26it/s]\u001b[A\n",
      "  5%|▍         | 2872/61028 [00:51<13:47, 70.24it/s]\u001b[A\n",
      "  5%|▍         | 2880/61028 [00:51<13:38, 71.02it/s]\u001b[A\n",
      "  5%|▍         | 2888/61028 [00:51<13:45, 70.45it/s]\u001b[A\n",
      "  5%|▍         | 2896/61028 [00:51<13:41, 70.81it/s]\u001b[A\n",
      "  5%|▍         | 2904/61028 [00:51<14:09, 68.46it/s]\u001b[A\n",
      "  5%|▍         | 2911/61028 [00:51<14:30, 66.73it/s]\u001b[A\n",
      "  5%|▍         | 2918/61028 [00:51<14:52, 65.14it/s]\u001b[A\n",
      "  5%|▍         | 2928/61028 [00:52<13:28, 71.87it/s]\u001b[A\n",
      "  5%|▍         | 2936/61028 [00:52<14:21, 67.47it/s]\u001b[A\n",
      "  5%|▍         | 2943/61028 [00:52<15:00, 64.53it/s]\u001b[A\n",
      "  5%|▍         | 2952/61028 [00:52<13:46, 70.28it/s]\u001b[A\n",
      "  5%|▍         | 2960/61028 [00:52<13:22, 72.40it/s]\u001b[A\n",
      "  5%|▍         | 2968/61028 [00:52<14:03, 68.82it/s]\u001b[A\n",
      "  5%|▍         | 2976/61028 [00:52<14:44, 65.60it/s]\u001b[A\n",
      "  5%|▍         | 2984/61028 [00:52<14:24, 67.12it/s]\u001b[A\n",
      "  5%|▍         | 2994/61028 [00:53<13:10, 73.41it/s]\u001b[A\n",
      "  5%|▍         | 3002/61028 [00:53<14:12, 68.06it/s]\u001b[A\n",
      "  5%|▍         | 3010/61028 [00:53<14:01, 68.93it/s]\u001b[A\n",
      "  5%|▍         | 3021/61028 [00:53<12:45, 75.80it/s]\u001b[A\n",
      "  5%|▍         | 3030/61028 [00:53<12:25, 77.75it/s]\u001b[A\n",
      "  5%|▍         | 3039/61028 [00:53<13:58, 69.12it/s]\u001b[A\n",
      "  5%|▍         | 3047/61028 [00:53<14:37, 66.10it/s]\u001b[A\n",
      "  5%|▌         | 3055/61028 [00:53<14:00, 68.98it/s]\u001b[A\n",
      "  5%|▌         | 3064/61028 [00:54<14:15, 67.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3071/61028 [00:54<14:51, 65.00it/s]\u001b[A\n",
      "  5%|▌         | 3078/61028 [00:54<15:05, 63.98it/s]\u001b[A\n",
      "  5%|▌         | 3085/61028 [00:54<15:53, 60.78it/s]\u001b[A\n",
      "  5%|▌         | 3092/61028 [00:54<24:46, 38.96it/s]\u001b[A\n",
      "  5%|▌         | 3100/61028 [00:54<21:01, 45.91it/s]\u001b[A\n",
      "  5%|▌         | 3107/61028 [00:54<19:11, 50.28it/s]\u001b[A\n",
      "  5%|▌         | 3114/61028 [00:55<17:46, 54.31it/s]\u001b[A\n",
      "  5%|▌         | 3122/61028 [00:55<16:04, 60.02it/s]\u001b[A\n",
      "  5%|▌         | 3129/61028 [00:55<16:00, 60.27it/s]\u001b[A\n",
      "  5%|▌         | 3137/61028 [00:55<15:18, 63.01it/s]\u001b[A\n",
      "  5%|▌         | 3145/61028 [00:55<14:23, 67.01it/s]\u001b[A\n",
      "  5%|▌         | 3153/61028 [00:55<14:12, 67.87it/s]\u001b[A\n",
      "  5%|▌         | 3161/61028 [00:55<14:08, 68.19it/s]\u001b[A\n",
      "  5%|▌         | 3168/61028 [00:55<14:13, 67.78it/s]\u001b[A\n",
      "  5%|▌         | 3176/61028 [00:55<13:34, 71.03it/s]\u001b[A\n",
      "  5%|▌         | 3184/61028 [00:56<13:09, 73.25it/s]\u001b[A\n",
      "  5%|▌         | 3192/61028 [00:56<13:50, 69.60it/s]\u001b[A\n",
      "  5%|▌         | 3200/61028 [00:56<15:05, 63.88it/s]\u001b[A\n",
      "  5%|▌         | 3207/61028 [00:56<15:38, 61.60it/s]\u001b[A\n",
      "  5%|▌         | 3216/61028 [00:56<14:24, 66.88it/s]\u001b[A\n",
      "  5%|▌         | 3226/61028 [00:56<13:20, 72.22it/s]\u001b[A\n",
      "  5%|▌         | 3234/61028 [00:56<13:26, 71.68it/s]\u001b[A\n",
      "  5%|▌         | 3242/61028 [00:56<14:21, 67.05it/s]\u001b[A\n",
      "  5%|▌         | 3250/61028 [00:56<13:43, 70.16it/s]\u001b[A\n",
      "  5%|▌         | 3258/61028 [00:57<13:25, 71.68it/s]\u001b[A\n",
      "  5%|▌         | 3266/61028 [00:57<14:13, 67.66it/s]\u001b[A\n",
      "  5%|▌         | 3275/61028 [00:57<13:50, 69.56it/s]\u001b[A\n",
      "  5%|▌         | 3283/61028 [00:57<14:03, 68.46it/s]\u001b[A\n",
      "  5%|▌         | 3291/61028 [00:57<13:51, 69.46it/s]\u001b[A\n",
      "  5%|▌         | 3299/61028 [00:57<13:37, 70.58it/s]\u001b[A\n",
      "  5%|▌         | 3307/61028 [00:57<14:28, 66.48it/s]\u001b[A\n",
      "  5%|▌         | 3316/61028 [00:57<13:46, 69.83it/s]\u001b[A\n",
      "  5%|▌         | 3325/61028 [00:58<13:04, 73.55it/s]\u001b[A\n",
      "  5%|▌         | 3334/61028 [00:58<12:43, 75.53it/s]\u001b[A\n",
      "  5%|▌         | 3344/61028 [00:58<11:59, 80.13it/s]\u001b[A\n",
      "  5%|▌         | 3353/61028 [00:58<11:53, 80.87it/s]\u001b[A\n",
      "  6%|▌         | 3362/61028 [00:58<11:36, 82.75it/s]\u001b[A\n",
      "  6%|▌         | 3371/61028 [00:58<11:57, 80.35it/s]\u001b[A\n",
      "  6%|▌         | 3380/61028 [00:58<12:24, 77.39it/s]\u001b[A\n",
      "  6%|▌         | 3388/61028 [00:58<13:35, 70.65it/s]\u001b[A\n",
      "  6%|▌         | 3396/61028 [00:58<14:09, 67.87it/s]\u001b[A\n",
      "  6%|▌         | 3403/61028 [00:59<14:40, 65.43it/s]\u001b[A\n",
      "  6%|▌         | 3410/61028 [00:59<15:42, 61.11it/s]\u001b[A\n",
      "  6%|▌         | 3418/61028 [00:59<14:43, 65.18it/s]\u001b[A\n",
      "  6%|▌         | 3426/61028 [00:59<14:25, 66.52it/s]\u001b[A\n",
      "  6%|▌         | 3433/61028 [00:59<24:01, 39.95it/s]\u001b[A\n",
      "  6%|▌         | 3439/61028 [00:59<21:41, 44.24it/s]\u001b[A\n",
      "  6%|▌         | 3448/61028 [00:59<18:25, 52.09it/s]\u001b[A\n",
      "  6%|▌         | 3457/61028 [01:00<16:22, 58.60it/s]\u001b[A\n",
      "  6%|▌         | 3465/61028 [01:00<16:08, 59.41it/s]\u001b[A\n",
      "  6%|▌         | 3472/61028 [01:00<15:28, 61.98it/s]\u001b[A\n",
      "  6%|▌         | 3480/61028 [01:00<15:11, 63.17it/s]\u001b[A\n",
      "  6%|▌         | 3487/61028 [01:00<15:19, 62.57it/s]\u001b[A\n",
      "  6%|▌         | 3496/61028 [01:00<14:01, 68.35it/s]\u001b[A\n",
      "  6%|▌         | 3504/61028 [01:00<13:35, 70.55it/s]\u001b[A\n",
      "  6%|▌         | 3512/61028 [01:00<13:18, 72.06it/s]\u001b[A\n",
      "  6%|▌         | 3520/61028 [01:01<14:15, 67.21it/s]\u001b[A\n",
      "  6%|▌         | 3527/61028 [01:01<15:09, 63.23it/s]\u001b[A\n",
      "  6%|▌         | 3534/61028 [01:01<15:12, 63.03it/s]\u001b[A\n",
      "  6%|▌         | 3541/61028 [01:01<16:35, 57.73it/s]\u001b[A\n",
      "  6%|▌         | 3548/61028 [01:01<16:05, 59.55it/s]\u001b[A\n",
      "  6%|▌         | 3557/61028 [01:01<14:34, 65.73it/s]\u001b[A\n",
      "  6%|▌         | 3567/61028 [01:01<13:10, 72.69it/s]\u001b[A\n",
      "  6%|▌         | 3576/61028 [01:01<12:28, 76.72it/s]\u001b[A\n",
      "  6%|▌         | 3585/61028 [01:01<14:11, 67.46it/s]\u001b[A\n",
      "  6%|▌         | 3594/61028 [01:02<13:23, 71.50it/s]\u001b[A\n",
      "  6%|▌         | 3604/61028 [01:02<12:58, 73.78it/s]\u001b[A\n",
      "  6%|▌         | 3612/61028 [01:02<12:58, 73.78it/s]\u001b[A\n",
      "  6%|▌         | 3621/61028 [01:02<12:22, 77.27it/s]\u001b[A\n",
      "  6%|▌         | 3630/61028 [01:02<11:59, 79.81it/s]\u001b[A\n",
      "  6%|▌         | 3639/61028 [01:02<13:05, 73.03it/s]\u001b[A\n",
      "  6%|▌         | 3647/61028 [01:02<13:54, 68.79it/s]\u001b[A\n",
      "  6%|▌         | 3655/61028 [01:02<14:58, 63.87it/s]\u001b[A\n",
      "  6%|▌         | 3663/61028 [01:03<14:53, 64.20it/s]\u001b[A\n",
      "  6%|▌         | 3671/61028 [01:03<14:03, 68.02it/s]\u001b[A\n",
      "  6%|▌         | 3678/61028 [01:03<14:05, 67.81it/s]\u001b[A\n",
      "  6%|▌         | 3686/61028 [01:03<13:40, 69.93it/s]\u001b[A\n",
      "  6%|▌         | 3694/61028 [01:03<13:54, 68.68it/s]\u001b[A\n",
      "  6%|▌         | 3704/61028 [01:03<12:36, 75.79it/s]\u001b[A\n",
      "  6%|▌         | 3712/61028 [01:03<13:24, 71.28it/s]\u001b[A\n",
      "  6%|▌         | 3720/61028 [01:03<13:13, 72.18it/s]\u001b[A\n",
      "  6%|▌         | 3729/61028 [01:03<13:43, 69.58it/s]\u001b[A\n",
      "  6%|▌         | 3737/61028 [01:04<14:50, 64.35it/s]\u001b[A\n",
      "  6%|▌         | 3745/61028 [01:04<14:35, 65.44it/s]\u001b[A\n",
      "  6%|▌         | 3753/61028 [01:04<13:54, 68.64it/s]\u001b[A\n",
      "  6%|▌         | 3760/61028 [01:04<14:11, 67.22it/s]\u001b[A\n",
      "  6%|▌         | 3767/61028 [01:04<16:02, 59.51it/s]\u001b[A\n",
      "  6%|▌         | 3774/61028 [01:04<24:19, 39.22it/s]\u001b[A\n",
      "  6%|▌         | 3782/61028 [01:05<20:53, 45.66it/s]\u001b[A\n",
      "  6%|▌         | 3793/61028 [01:05<17:35, 54.24it/s]\u001b[A\n",
      "  6%|▌         | 3803/61028 [01:05<15:46, 60.45it/s]\u001b[A\n",
      "  6%|▌         | 3811/61028 [01:05<15:19, 62.23it/s]\u001b[A\n",
      "  6%|▋         | 3819/61028 [01:05<15:56, 59.82it/s]\u001b[A\n",
      "  6%|▋         | 3826/61028 [01:05<15:16, 62.45it/s]\u001b[A\n",
      "  6%|▋         | 3834/61028 [01:05<14:31, 65.62it/s]\u001b[A\n",
      "  6%|▋         | 3841/61028 [01:05<15:01, 63.43it/s]\u001b[A\n",
      "  6%|▋         | 3848/61028 [01:06<16:37, 57.35it/s]\u001b[A\n",
      "  6%|▋         | 3855/61028 [01:06<15:55, 59.82it/s]\u001b[A\n",
      "  6%|▋         | 3862/61028 [01:06<16:50, 56.56it/s]\u001b[A\n",
      "  6%|▋         | 3869/61028 [01:06<16:31, 57.66it/s]\u001b[A\n",
      "  6%|▋         | 3876/61028 [01:06<15:57, 59.68it/s]\u001b[A\n",
      "  6%|▋         | 3885/61028 [01:06<14:35, 65.24it/s]\u001b[A\n",
      "  6%|▋         | 3892/61028 [01:06<15:44, 60.50it/s]\u001b[A\n",
      "  6%|▋         | 3899/61028 [01:06<15:31, 61.35it/s]\u001b[A\n",
      "  6%|▋         | 3906/61028 [01:06<15:42, 60.60it/s]\u001b[A\n",
      "  6%|▋         | 3913/61028 [01:07<15:28, 61.48it/s]\u001b[A\n",
      "  6%|▋         | 3920/61028 [01:07<15:14, 62.46it/s]\u001b[A\n",
      "  6%|▋         | 3927/61028 [01:07<15:26, 61.62it/s]\u001b[A\n",
      "  6%|▋         | 3934/61028 [01:07<15:36, 60.97it/s]\u001b[A\n",
      "  6%|▋         | 3941/61028 [01:07<15:48, 60.16it/s]\u001b[A\n",
      "  6%|▋         | 3948/61028 [01:07<16:54, 56.27it/s]\u001b[A\n",
      "  6%|▋         | 3956/61028 [01:07<15:39, 60.74it/s]\u001b[A\n",
      "  6%|▋         | 3963/61028 [01:07<15:35, 61.03it/s]\u001b[A\n",
      "  7%|▋         | 3972/61028 [01:08<14:20, 66.34it/s]\u001b[A\n",
      "  7%|▋         | 3979/61028 [01:08<14:09, 67.18it/s]\u001b[A\n",
      "  7%|▋         | 3986/61028 [01:08<15:03, 63.15it/s]\u001b[A\n",
      "  7%|▋         | 3993/61028 [01:08<14:49, 64.14it/s]\u001b[A\n",
      "  7%|▋         | 4000/61028 [01:08<15:26, 61.53it/s]\u001b[A\n",
      "  7%|▋         | 4009/61028 [01:08<14:54, 63.76it/s]\u001b[A\n",
      "  7%|▋         | 4016/61028 [01:08<15:12, 62.50it/s]\u001b[A\n",
      "  7%|▋         | 4023/61028 [01:08<17:10, 55.34it/s]\u001b[A\n",
      "  7%|▋         | 4029/61028 [01:08<16:58, 55.94it/s]\u001b[A\n",
      "  7%|▋         | 4036/61028 [01:09<16:22, 57.99it/s]\u001b[A\n",
      "  7%|▋         | 4042/61028 [01:09<16:13, 58.53it/s]\u001b[A\n",
      "  7%|▋         | 4050/61028 [01:09<15:05, 62.90it/s]\u001b[A\n",
      "  7%|▋         | 4060/61028 [01:09<13:35, 69.84it/s]\u001b[A\n",
      "  7%|▋         | 4068/61028 [01:09<14:12, 66.84it/s]\u001b[A\n",
      "  7%|▋         | 4075/61028 [01:09<15:58, 59.45it/s]\u001b[A\n",
      "  7%|▋         | 4082/61028 [01:10<26:16, 36.12it/s]\u001b[A\n",
      "  7%|▋         | 4089/61028 [01:10<22:44, 41.72it/s]\u001b[A\n",
      "  7%|▋         | 4095/61028 [01:10<20:53, 45.43it/s]\u001b[A\n",
      "  7%|▋         | 4103/61028 [01:10<18:28, 51.35it/s]\u001b[A\n",
      "  7%|▋         | 4114/61028 [01:10<15:55, 59.57it/s]\u001b[A\n",
      "  7%|▋         | 4122/61028 [01:10<16:26, 57.71it/s]\u001b[A\n",
      "  7%|▋         | 4132/61028 [01:10<14:47, 64.11it/s]\u001b[A\n",
      "  7%|▋         | 4140/61028 [01:10<14:58, 63.30it/s]\u001b[A\n",
      "  7%|▋         | 4147/61028 [01:10<14:42, 64.43it/s]\u001b[A\n",
      "  7%|▋         | 4154/61028 [01:11<15:50, 59.82it/s]\u001b[A\n",
      "  7%|▋         | 4161/61028 [01:11<16:28, 57.52it/s]\u001b[A\n",
      "  7%|▋         | 4169/61028 [01:11<15:28, 61.25it/s]\u001b[A\n",
      "  7%|▋         | 4176/61028 [01:11<15:32, 60.94it/s]\u001b[A\n",
      "  7%|▋         | 4183/61028 [01:11<14:58, 63.28it/s]\u001b[A\n",
      "  7%|▋         | 4192/61028 [01:11<14:21, 65.95it/s]\u001b[A\n",
      "  7%|▋         | 4201/61028 [01:11<13:50, 68.44it/s]\u001b[A\n",
      "  7%|▋         | 4208/61028 [01:11<14:30, 65.31it/s]\u001b[A\n",
      "  7%|▋         | 4217/61028 [01:12<13:26, 70.42it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4225/61028 [01:12<13:46, 68.74it/s]\u001b[A\n",
      "  7%|▋         | 4234/61028 [01:12<12:55, 73.27it/s]\u001b[A\n",
      "  7%|▋         | 4242/61028 [01:12<13:34, 69.70it/s]\u001b[A\n",
      "  7%|▋         | 4250/61028 [01:12<14:45, 64.10it/s]\u001b[A\n",
      "  7%|▋         | 4258/61028 [01:12<14:33, 65.02it/s]\u001b[A\n",
      "  7%|▋         | 4267/61028 [01:12<13:23, 70.61it/s]\u001b[A\n",
      "  7%|▋         | 4275/61028 [01:12<12:57, 72.98it/s]\u001b[A\n",
      "  7%|▋         | 4284/61028 [01:12<12:26, 76.00it/s]\u001b[A\n",
      "  7%|▋         | 4292/61028 [01:13<14:29, 65.26it/s]\u001b[A\n",
      "  7%|▋         | 4299/61028 [01:13<14:40, 64.44it/s]\u001b[A\n",
      "  7%|▋         | 4306/61028 [01:13<14:34, 64.87it/s]\u001b[A\n",
      "  7%|▋         | 4315/61028 [01:13<13:28, 70.12it/s]\u001b[A\n",
      "  7%|▋         | 4323/61028 [01:13<14:14, 66.36it/s]\u001b[A\n",
      "  7%|▋         | 4332/61028 [01:13<13:49, 68.36it/s]\u001b[A\n",
      "  7%|▋         | 4340/61028 [01:13<14:15, 66.26it/s]\u001b[A\n",
      "  7%|▋         | 4348/61028 [01:13<14:00, 67.46it/s]\u001b[A\n",
      "  7%|▋         | 4355/61028 [01:14<15:43, 60.06it/s]\u001b[A\n",
      "  7%|▋         | 4362/61028 [01:14<16:16, 58.03it/s]\u001b[A\n",
      "  7%|▋         | 4370/61028 [01:14<14:57, 63.16it/s]\u001b[A\n",
      "  7%|▋         | 4380/61028 [01:14<13:36, 69.39it/s]\u001b[A\n",
      "  7%|▋         | 4388/61028 [01:14<14:28, 65.25it/s]\u001b[A\n",
      "  7%|▋         | 4397/61028 [01:14<13:23, 70.46it/s]\u001b[A\n",
      "  7%|▋         | 4405/61028 [01:14<12:55, 73.02it/s]\u001b[A\n",
      "  7%|▋         | 4413/61028 [01:15<21:58, 42.95it/s]\u001b[A\n",
      "  7%|▋         | 4422/61028 [01:15<18:41, 50.48it/s]\u001b[A\n",
      "  7%|▋         | 4431/61028 [01:15<17:00, 55.44it/s]\u001b[A\n",
      "  7%|▋         | 4438/61028 [01:15<16:33, 56.95it/s]\u001b[A\n",
      "  7%|▋         | 4445/61028 [01:15<16:18, 57.83it/s]\u001b[A\n",
      "  7%|▋         | 4455/61028 [01:15<14:24, 65.41it/s]\u001b[A\n",
      "  7%|▋         | 4463/61028 [01:15<14:24, 65.44it/s]\u001b[A\n",
      "  7%|▋         | 4471/61028 [01:15<14:23, 65.50it/s]\u001b[A\n",
      "  7%|▋         | 4479/61028 [01:16<14:06, 66.81it/s]\u001b[A\n",
      "  7%|▋         | 4487/61028 [01:16<13:28, 69.91it/s]\u001b[A\n",
      "  7%|▋         | 4495/61028 [01:16<14:57, 62.97it/s]\u001b[A\n",
      "  7%|▋         | 4504/61028 [01:16<14:19, 65.76it/s]\u001b[A\n",
      "  7%|▋         | 4511/61028 [01:16<14:35, 64.53it/s]\u001b[A\n",
      "  7%|▋         | 4518/61028 [01:16<14:50, 63.43it/s]\u001b[A\n",
      "  7%|▋         | 4527/61028 [01:16<13:46, 68.39it/s]\u001b[A\n",
      "  7%|▋         | 4535/61028 [01:16<14:24, 65.37it/s]\u001b[A\n",
      "  7%|▋         | 4542/61028 [01:17<15:06, 62.34it/s]\u001b[A\n",
      "  7%|▋         | 4549/61028 [01:17<15:29, 60.75it/s]\u001b[A\n",
      "  7%|▋         | 4557/61028 [01:17<14:36, 64.43it/s]\u001b[A\n",
      "  7%|▋         | 4564/61028 [01:17<15:19, 61.42it/s]\u001b[A\n",
      "  7%|▋         | 4572/61028 [01:17<14:24, 65.28it/s]\u001b[A\n",
      "  8%|▊         | 4579/61028 [01:17<16:01, 58.73it/s]\u001b[A\n",
      "  8%|▊         | 4587/61028 [01:17<15:00, 62.70it/s]\u001b[A\n",
      "  8%|▊         | 4595/61028 [01:17<14:28, 64.98it/s]\u001b[A\n",
      "  8%|▊         | 4604/61028 [01:17<13:16, 70.86it/s]\u001b[A\n",
      "  8%|▊         | 4613/61028 [01:18<12:45, 73.67it/s]\u001b[A\n",
      "  8%|▊         | 4621/61028 [01:18<12:52, 72.98it/s]\u001b[A\n",
      "  8%|▊         | 4631/61028 [01:18<12:04, 77.82it/s]\u001b[A\n",
      "  8%|▊         | 4639/61028 [01:18<12:27, 75.48it/s]\u001b[A\n",
      "  8%|▊         | 4647/61028 [01:18<13:50, 67.93it/s]\u001b[A\n",
      "  8%|▊         | 4655/61028 [01:18<13:16, 70.75it/s]\u001b[A\n",
      "  8%|▊         | 4663/61028 [01:18<13:21, 70.29it/s]\u001b[A\n",
      "  8%|▊         | 4671/61028 [01:18<14:28, 64.89it/s]\u001b[A\n",
      "  8%|▊         | 4678/61028 [01:19<14:20, 65.49it/s]\u001b[A\n",
      "  8%|▊         | 4685/61028 [01:19<14:35, 64.38it/s]\u001b[A\n",
      "  8%|▊         | 4693/61028 [01:19<13:59, 67.13it/s]\u001b[A\n",
      "  8%|▊         | 4703/61028 [01:19<12:55, 72.62it/s]\u001b[A\n",
      "  8%|▊         | 4711/61028 [01:19<13:46, 68.16it/s]\u001b[A\n",
      "  8%|▊         | 4719/61028 [01:19<13:45, 68.24it/s]\u001b[A\n",
      "  8%|▊         | 4726/61028 [01:19<13:53, 67.59it/s]\u001b[A\n",
      "  8%|▊         | 4734/61028 [01:19<13:31, 69.38it/s]\u001b[A\n",
      "  8%|▊         | 4742/61028 [01:19<13:51, 67.68it/s]\u001b[A\n",
      "  8%|▊         | 4749/61028 [01:20<25:29, 36.80it/s]\u001b[A\n",
      "  8%|▊         | 4757/61028 [01:20<21:49, 42.96it/s]\u001b[A\n",
      "  8%|▊         | 4763/61028 [01:20<20:51, 44.94it/s]\u001b[A\n",
      "  8%|▊         | 4771/61028 [01:20<18:21, 51.09it/s]\u001b[A\n",
      "  8%|▊         | 4778/61028 [01:20<17:54, 52.33it/s]\u001b[A\n",
      "  8%|▊         | 4785/61028 [01:20<16:33, 56.60it/s]\u001b[A\n",
      "  8%|▊         | 4793/61028 [01:21<15:37, 59.97it/s]\u001b[A\n",
      "  8%|▊         | 4800/61028 [01:21<15:21, 61.03it/s]\u001b[A\n",
      "  8%|▊         | 4808/61028 [01:21<14:34, 64.32it/s]\u001b[A\n",
      "  8%|▊         | 4816/61028 [01:21<13:52, 67.48it/s]\u001b[A\n",
      "  8%|▊         | 4823/61028 [01:21<14:48, 63.29it/s]\u001b[A\n",
      "  8%|▊         | 4831/61028 [01:21<14:09, 66.16it/s]\u001b[A\n",
      "  8%|▊         | 4839/61028 [01:21<14:05, 66.43it/s]\u001b[A\n",
      "  8%|▊         | 4846/61028 [01:21<13:54, 67.31it/s]\u001b[A\n",
      "  8%|▊         | 4854/61028 [01:21<13:37, 68.75it/s]\u001b[A\n",
      "  8%|▊         | 4864/61028 [01:22<12:42, 73.65it/s]\u001b[A\n",
      "  8%|▊         | 4872/61028 [01:22<12:52, 72.72it/s]\u001b[A\n",
      "  8%|▊         | 4880/61028 [01:22<13:12, 70.83it/s]\u001b[A\n",
      "  8%|▊         | 4888/61028 [01:22<13:21, 70.06it/s]\u001b[A\n",
      "  8%|▊         | 4897/61028 [01:22<12:36, 74.18it/s]\u001b[A\n",
      "  8%|▊         | 4905/61028 [01:22<12:43, 73.48it/s]\u001b[A\n",
      "  8%|▊         | 4913/61028 [01:22<13:50, 67.54it/s]\u001b[A\n",
      "  8%|▊         | 4921/61028 [01:22<13:24, 69.71it/s]\u001b[A\n",
      "  8%|▊         | 4929/61028 [01:22<13:32, 69.04it/s]\u001b[A\n",
      "  8%|▊         | 4936/61028 [01:23<13:32, 69.05it/s]\u001b[A\n",
      "  8%|▊         | 4944/61028 [01:23<13:10, 70.93it/s]\u001b[A\n",
      "  8%|▊         | 4955/61028 [01:23<11:55, 78.34it/s]\u001b[A\n",
      "  8%|▊         | 4965/61028 [01:23<11:39, 80.10it/s]\u001b[A\n",
      "  8%|▊         | 4974/61028 [01:23<11:28, 81.39it/s]\u001b[A\n",
      "  8%|▊         | 4983/61028 [01:23<11:12, 83.32it/s]\u001b[A\n",
      "  8%|▊         | 4992/61028 [01:23<11:54, 78.43it/s]\u001b[A\n",
      "  8%|▊         | 5000/61028 [01:23<13:09, 70.98it/s]\u001b[A\n",
      "  8%|▊         | 5010/61028 [01:23<12:18, 75.84it/s]\u001b[A\n",
      "  8%|▊         | 5018/61028 [01:24<12:32, 74.46it/s]\u001b[A\n",
      "  8%|▊         | 5026/61028 [01:24<13:07, 71.10it/s]\u001b[A\n",
      "  8%|▊         | 5034/61028 [01:24<12:43, 73.34it/s]\u001b[A\n",
      "  8%|▊         | 5042/61028 [01:24<13:45, 67.79it/s]\u001b[A\n",
      "  8%|▊         | 5051/61028 [01:24<12:55, 72.16it/s]\u001b[A\n",
      "  8%|▊         | 5059/61028 [01:24<13:34, 68.69it/s]\u001b[A\n",
      "  8%|▊         | 5067/61028 [01:24<13:55, 66.98it/s]\u001b[A\n",
      "  8%|▊         | 5074/61028 [01:24<14:09, 65.85it/s]\u001b[A\n",
      "  8%|▊         | 5081/61028 [01:25<13:58, 66.69it/s]\u001b[A\n",
      "  8%|▊         | 5088/61028 [01:25<24:22, 38.24it/s]\u001b[A\n",
      "  8%|▊         | 5098/61028 [01:25<20:02, 46.50it/s]\u001b[A\n",
      "  8%|▊         | 5105/61028 [01:25<18:18, 50.90it/s]\u001b[A\n",
      "  8%|▊         | 5112/61028 [01:25<16:51, 55.29it/s]\u001b[A\n",
      "  8%|▊         | 5120/61028 [01:25<15:21, 60.65it/s]\u001b[A\n",
      "  8%|▊         | 5129/61028 [01:25<13:55, 66.90it/s]\u001b[A\n",
      "  8%|▊         | 5137/61028 [01:26<13:33, 68.68it/s]\u001b[A\n",
      "  8%|▊         | 5145/61028 [01:26<14:12, 65.54it/s]\u001b[A\n",
      "  8%|▊         | 5153/61028 [01:26<14:45, 63.12it/s]\u001b[A\n",
      "  8%|▊         | 5160/61028 [01:26<15:11, 61.29it/s]\u001b[A\n",
      "  8%|▊         | 5167/61028 [01:26<14:44, 63.17it/s]\u001b[A\n",
      "  8%|▊         | 5174/61028 [01:26<15:04, 61.77it/s]\u001b[A\n",
      "  8%|▊         | 5181/61028 [01:26<14:39, 63.49it/s]\u001b[A\n",
      "  9%|▊         | 5189/61028 [01:26<13:51, 67.11it/s]\u001b[A\n",
      "  9%|▊         | 5197/61028 [01:26<13:15, 70.20it/s]\u001b[A\n",
      "  9%|▊         | 5205/61028 [01:27<13:27, 69.10it/s]\u001b[A\n",
      "  9%|▊         | 5214/61028 [01:27<12:40, 73.40it/s]\u001b[A\n",
      "  9%|▊         | 5223/61028 [01:27<12:22, 75.17it/s]\u001b[A\n",
      "  9%|▊         | 5231/61028 [01:27<12:55, 71.95it/s]\u001b[A\n",
      "  9%|▊         | 5239/61028 [01:27<15:06, 61.55it/s]\u001b[A\n",
      "  9%|▊         | 5249/61028 [01:27<13:34, 68.46it/s]\u001b[A\n",
      "  9%|▊         | 5257/61028 [01:27<13:03, 71.20it/s]\u001b[A\n",
      "  9%|▊         | 5266/61028 [01:27<12:17, 75.56it/s]\u001b[A\n",
      "  9%|▊         | 5274/61028 [01:28<13:15, 70.10it/s]\u001b[A\n",
      "  9%|▊         | 5284/61028 [01:28<12:14, 75.93it/s]\u001b[A\n",
      "  9%|▊         | 5292/61028 [01:28<12:08, 76.51it/s]\u001b[A\n",
      "  9%|▊         | 5302/61028 [01:28<11:34, 80.19it/s]\u001b[A\n",
      "  9%|▊         | 5311/61028 [01:28<12:10, 76.23it/s]\u001b[A\n",
      "  9%|▊         | 5319/61028 [01:28<12:24, 74.86it/s]\u001b[A\n",
      "  9%|▊         | 5327/61028 [01:28<12:27, 74.53it/s]\u001b[A\n",
      "  9%|▊         | 5335/61028 [01:28<12:45, 72.79it/s]\u001b[A\n",
      "  9%|▉         | 5343/61028 [01:28<13:29, 68.83it/s]\u001b[A\n",
      "  9%|▉         | 5351/61028 [01:29<13:43, 67.60it/s]\u001b[A\n",
      "  9%|▉         | 5359/61028 [01:29<13:21, 69.47it/s]\u001b[A\n",
      "  9%|▉         | 5367/61028 [01:29<13:05, 70.85it/s]\u001b[A\n",
      "  9%|▉         | 5375/61028 [01:29<13:43, 67.56it/s]\u001b[A\n",
      "  9%|▉         | 5382/61028 [01:29<13:53, 66.72it/s]\u001b[A\n",
      "  9%|▉         | 5389/61028 [01:29<14:23, 64.43it/s]\u001b[A\n",
      "  9%|▉         | 5397/61028 [01:29<13:51, 66.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5406/61028 [01:29<13:01, 71.15it/s]\u001b[A\n",
      "  9%|▉         | 5416/61028 [01:29<11:57, 77.46it/s]\u001b[A\n",
      "  9%|▉         | 5424/61028 [01:30<12:51, 72.11it/s]\u001b[A\n",
      "  9%|▉         | 5432/61028 [01:30<13:41, 67.65it/s]\u001b[A\n",
      "  9%|▉         | 5439/61028 [01:30<21:31, 43.06it/s]\u001b[A\n",
      "  9%|▉         | 5445/61028 [01:30<19:43, 46.98it/s]\u001b[A\n",
      "  9%|▉         | 5455/61028 [01:30<16:43, 55.39it/s]\u001b[A\n",
      "  9%|▉         | 5465/61028 [01:30<14:34, 63.55it/s]\u001b[A\n",
      "  9%|▉         | 5474/61028 [01:30<13:24, 69.04it/s]\u001b[A\n",
      "  9%|▉         | 5482/61028 [01:31<13:26, 68.91it/s]\u001b[A\n",
      "  9%|▉         | 5490/61028 [01:31<13:08, 70.42it/s]\u001b[A\n",
      "  9%|▉         | 5498/61028 [01:31<13:05, 70.68it/s]\u001b[A\n",
      "  9%|▉         | 5506/61028 [01:31<13:08, 70.39it/s]\u001b[A\n",
      "  9%|▉         | 5516/61028 [01:31<12:03, 76.74it/s]\u001b[A\n",
      "  9%|▉         | 5525/61028 [01:31<12:52, 71.87it/s]\u001b[A\n",
      "  9%|▉         | 5534/61028 [01:31<12:11, 75.89it/s]\u001b[A\n",
      "  9%|▉         | 5542/61028 [01:31<12:25, 74.41it/s]\u001b[A\n",
      "  9%|▉         | 5550/61028 [01:31<13:12, 70.02it/s]\u001b[A\n",
      "  9%|▉         | 5558/61028 [01:32<13:26, 68.75it/s]\u001b[A\n",
      "  9%|▉         | 5566/61028 [01:32<13:18, 69.44it/s]\u001b[A\n",
      "  9%|▉         | 5575/61028 [01:32<12:32, 73.68it/s]\u001b[A\n",
      "  9%|▉         | 5583/61028 [01:32<12:23, 74.61it/s]\u001b[A\n",
      "  9%|▉         | 5591/61028 [01:32<13:45, 67.14it/s]\u001b[A\n",
      "  9%|▉         | 5598/61028 [01:32<14:37, 63.20it/s]\u001b[A\n",
      "  9%|▉         | 5606/61028 [01:32<13:57, 66.20it/s]\u001b[A\n",
      "  9%|▉         | 5614/61028 [01:32<13:18, 69.37it/s]\u001b[A\n",
      "  9%|▉         | 5622/61028 [01:33<13:24, 68.88it/s]\u001b[A\n",
      "  9%|▉         | 5630/61028 [01:33<13:16, 69.51it/s]\u001b[A\n",
      "  9%|▉         | 5638/61028 [01:33<13:04, 70.61it/s]\u001b[A\n",
      "  9%|▉         | 5647/61028 [01:33<12:25, 74.24it/s]\u001b[A\n",
      "  9%|▉         | 5655/61028 [01:33<12:55, 71.36it/s]\u001b[A\n",
      "  9%|▉         | 5663/61028 [01:33<13:29, 68.43it/s]\u001b[A\n",
      "  9%|▉         | 5670/61028 [01:33<13:53, 66.41it/s]\u001b[A\n",
      "  9%|▉         | 5678/61028 [01:33<13:28, 68.46it/s]\u001b[A\n",
      "  9%|▉         | 5686/61028 [01:33<13:20, 69.13it/s]\u001b[A\n",
      "  9%|▉         | 5694/61028 [01:34<12:59, 70.94it/s]\u001b[A\n",
      "  9%|▉         | 5702/61028 [01:34<13:33, 68.05it/s]\u001b[A\n",
      "  9%|▉         | 5709/61028 [01:34<15:15, 60.45it/s]\u001b[A\n",
      "  9%|▉         | 5718/61028 [01:34<13:48, 66.73it/s]\u001b[A\n",
      "  9%|▉         | 5726/61028 [01:34<13:07, 70.19it/s]\u001b[A\n",
      "  9%|▉         | 5735/61028 [01:34<12:39, 72.80it/s]\u001b[A\n",
      "  9%|▉         | 5744/61028 [01:34<12:09, 75.81it/s]\u001b[A\n",
      "  9%|▉         | 5754/61028 [01:34<11:49, 77.91it/s]\u001b[A\n",
      "  9%|▉         | 5762/61028 [01:34<11:52, 77.55it/s]\u001b[A\n",
      "  9%|▉         | 5770/61028 [01:35<12:55, 71.30it/s]\u001b[A\n",
      "  9%|▉         | 5778/61028 [01:35<13:11, 69.84it/s]\u001b[A\n",
      "  9%|▉         | 5786/61028 [01:35<24:05, 38.21it/s]\u001b[A\n",
      "  9%|▉         | 5793/61028 [01:35<21:03, 43.72it/s]\u001b[A\n",
      " 10%|▉         | 5800/61028 [01:35<18:46, 49.01it/s]\u001b[A\n",
      " 10%|▉         | 5807/61028 [01:35<17:48, 51.66it/s]\u001b[A\n",
      " 10%|▉         | 5815/61028 [01:36<16:14, 56.65it/s]\u001b[A\n",
      " 10%|▉         | 5824/61028 [01:36<14:30, 63.40it/s]\u001b[A\n",
      " 10%|▉         | 5832/61028 [01:36<14:08, 65.07it/s]\u001b[A\n",
      " 10%|▉         | 5840/61028 [01:36<14:31, 63.32it/s]\u001b[A\n",
      " 10%|▉         | 5848/61028 [01:36<13:46, 66.73it/s]\u001b[A\n",
      " 10%|▉         | 5856/61028 [01:36<13:50, 66.40it/s]\u001b[A\n",
      " 10%|▉         | 5863/61028 [01:36<14:32, 63.20it/s]\u001b[A\n",
      " 10%|▉         | 5873/61028 [01:36<12:59, 70.79it/s]\u001b[A\n",
      " 10%|▉         | 5881/61028 [01:37<13:07, 69.99it/s]\u001b[A\n",
      " 10%|▉         | 5889/61028 [01:37<12:46, 71.89it/s]\u001b[A\n",
      " 10%|▉         | 5899/61028 [01:37<12:22, 74.27it/s]\u001b[A\n",
      " 10%|▉         | 5907/61028 [01:37<12:54, 71.16it/s]\u001b[A\n",
      " 10%|▉         | 5915/61028 [01:37<12:34, 73.03it/s]\u001b[A\n",
      " 10%|▉         | 5923/61028 [01:37<13:05, 70.17it/s]\u001b[A\n",
      " 10%|▉         | 5931/61028 [01:37<13:10, 69.68it/s]\u001b[A\n",
      " 10%|▉         | 5940/61028 [01:37<12:26, 73.81it/s]\u001b[A\n",
      " 10%|▉         | 5948/61028 [01:37<12:25, 73.89it/s]\u001b[A\n",
      " 10%|▉         | 5956/61028 [01:38<12:23, 74.09it/s]\u001b[A\n",
      " 10%|▉         | 5965/61028 [01:38<12:37, 72.70it/s]\u001b[A\n",
      " 10%|▉         | 5975/61028 [01:38<11:46, 77.90it/s]\u001b[A\n",
      " 10%|▉         | 5984/61028 [01:38<11:29, 79.83it/s]\u001b[A\n",
      " 10%|▉         | 5993/61028 [01:38<11:17, 81.17it/s]\u001b[A\n",
      " 10%|▉         | 6003/61028 [01:38<10:58, 83.52it/s]\u001b[A\n",
      " 10%|▉         | 6012/61028 [01:38<11:32, 79.41it/s]\u001b[A\n",
      " 10%|▉         | 6021/61028 [01:38<11:26, 80.13it/s]\u001b[A\n",
      " 10%|▉         | 6030/61028 [01:38<11:25, 80.26it/s]\u001b[A\n",
      " 10%|▉         | 6039/61028 [01:39<11:13, 81.70it/s]\u001b[A\n",
      " 10%|▉         | 6048/61028 [01:39<12:12, 75.06it/s]\u001b[A\n",
      " 10%|▉         | 6056/61028 [01:39<12:27, 73.54it/s]\u001b[A\n",
      " 10%|▉         | 6065/61028 [01:39<11:57, 76.57it/s]\u001b[A\n",
      " 10%|▉         | 6073/61028 [01:39<12:12, 75.01it/s]\u001b[A\n",
      " 10%|▉         | 6082/61028 [01:39<11:38, 78.66it/s]\u001b[A\n",
      " 10%|▉         | 6091/61028 [01:39<11:20, 80.69it/s]\u001b[A\n",
      " 10%|▉         | 6100/61028 [01:39<12:01, 76.14it/s]\u001b[A\n",
      " 10%|█         | 6108/61028 [01:40<13:11, 69.37it/s]\u001b[A\n",
      " 10%|█         | 6118/61028 [01:40<12:14, 74.74it/s]\u001b[A\n",
      " 10%|█         | 6126/61028 [01:40<12:36, 72.56it/s]\u001b[A\n",
      " 10%|█         | 6134/61028 [01:40<12:15, 74.64it/s]\u001b[A\n",
      " 10%|█         | 6142/61028 [01:40<13:53, 65.88it/s]\u001b[A\n",
      " 10%|█         | 6149/61028 [01:40<22:04, 41.42it/s]\u001b[A\n",
      " 10%|█         | 6157/61028 [01:40<18:59, 48.13it/s]\u001b[A\n",
      " 10%|█         | 6164/61028 [01:41<17:40, 51.74it/s]\u001b[A\n",
      " 10%|█         | 6171/61028 [01:41<16:29, 55.46it/s]\u001b[A\n",
      " 10%|█         | 6179/61028 [01:41<15:12, 60.11it/s]\u001b[A\n",
      " 10%|█         | 6189/61028 [01:41<13:41, 66.72it/s]\u001b[A\n",
      " 10%|█         | 6197/61028 [01:41<13:11, 69.29it/s]\u001b[A\n",
      " 10%|█         | 6205/61028 [01:41<12:47, 71.43it/s]\u001b[A\n",
      " 10%|█         | 6214/61028 [01:41<12:07, 75.39it/s]\u001b[A\n",
      " 10%|█         | 6224/61028 [01:41<11:14, 81.30it/s]\u001b[A\n",
      " 10%|█         | 6235/61028 [01:41<10:27, 87.33it/s]\u001b[A\n",
      " 10%|█         | 6245/61028 [01:42<11:38, 78.41it/s]\u001b[A\n",
      " 10%|█         | 6254/61028 [01:42<12:19, 74.08it/s]\u001b[A\n",
      " 10%|█         | 6263/61028 [01:42<11:49, 77.22it/s]\u001b[A\n",
      " 10%|█         | 6272/61028 [01:42<11:32, 79.11it/s]\u001b[A\n",
      " 10%|█         | 6281/61028 [01:42<12:07, 75.26it/s]\u001b[A\n",
      " 10%|█         | 6289/61028 [01:42<12:25, 73.46it/s]\u001b[A\n",
      " 10%|█         | 6297/61028 [01:42<12:35, 72.47it/s]\u001b[A\n",
      " 10%|█         | 6308/61028 [01:42<11:47, 77.33it/s]\u001b[A\n",
      " 10%|█         | 6316/61028 [01:42<12:49, 71.10it/s]\u001b[A\n",
      " 10%|█         | 6324/61028 [01:43<12:41, 71.79it/s]\u001b[A\n",
      " 10%|█         | 6333/61028 [01:43<12:30, 72.89it/s]\u001b[A\n",
      " 10%|█         | 6342/61028 [01:43<11:55, 76.41it/s]\u001b[A\n",
      " 10%|█         | 6350/61028 [01:43<12:02, 75.67it/s]\u001b[A\n",
      " 10%|█         | 6358/61028 [01:43<12:56, 70.42it/s]\u001b[A\n",
      " 10%|█         | 6367/61028 [01:43<12:09, 74.97it/s]\u001b[A\n",
      " 10%|█         | 6375/61028 [01:43<12:12, 74.65it/s]\u001b[A\n",
      " 10%|█         | 6383/61028 [01:43<12:52, 70.72it/s]\u001b[A\n",
      " 10%|█         | 6391/61028 [01:43<12:31, 72.68it/s]\u001b[A\n",
      " 10%|█         | 6399/61028 [01:44<12:20, 73.77it/s]\u001b[A\n",
      " 11%|█         | 6408/61028 [01:44<11:56, 76.26it/s]\u001b[A\n",
      " 11%|█         | 6416/61028 [01:44<12:08, 74.98it/s]\u001b[A\n",
      " 11%|█         | 6425/61028 [01:44<11:59, 75.90it/s]\u001b[A\n",
      " 11%|█         | 6433/61028 [01:44<12:01, 75.66it/s]\u001b[A\n",
      " 11%|█         | 6441/61028 [01:44<11:52, 76.57it/s]\u001b[A\n",
      " 11%|█         | 6451/61028 [01:44<11:25, 79.62it/s]\u001b[A\n",
      " 11%|█         | 6460/61028 [01:44<11:33, 78.64it/s]\u001b[A\n",
      " 11%|█         | 6468/61028 [01:44<11:34, 78.54it/s]\u001b[A\n",
      " 11%|█         | 6476/61028 [01:45<12:40, 71.69it/s]\u001b[A\n",
      " 11%|█         | 6484/61028 [01:45<12:29, 72.73it/s]\u001b[A\n",
      " 11%|█         | 6492/61028 [01:45<13:19, 68.23it/s]\u001b[A\n",
      " 11%|█         | 6500/61028 [01:45<12:50, 70.73it/s]\u001b[A\n",
      " 11%|█         | 6508/61028 [01:45<14:49, 61.29it/s]\u001b[A\n",
      " 11%|█         | 6515/61028 [01:45<20:31, 44.25it/s]\u001b[A\n",
      " 11%|█         | 6523/61028 [01:45<17:53, 50.77it/s]\u001b[A\n",
      " 11%|█         | 6533/61028 [01:46<15:16, 59.47it/s]\u001b[A\n",
      " 11%|█         | 6541/61028 [01:46<14:34, 62.31it/s]\u001b[A\n",
      " 11%|█         | 6549/61028 [01:46<14:03, 64.55it/s]\u001b[A\n",
      " 11%|█         | 6559/61028 [01:46<12:37, 71.86it/s]\u001b[A\n",
      " 11%|█         | 6568/61028 [01:46<12:00, 75.54it/s]\u001b[A\n",
      " 11%|█         | 6578/61028 [01:46<11:21, 79.94it/s]\u001b[A\n",
      " 11%|█         | 6587/61028 [01:46<11:08, 81.43it/s]\u001b[A\n",
      " 11%|█         | 6596/61028 [01:46<11:08, 81.39it/s]\u001b[A\n",
      " 11%|█         | 6607/61028 [01:46<10:29, 86.52it/s]\u001b[A\n",
      " 11%|█         | 6617/61028 [01:47<10:07, 89.59it/s]\u001b[A\n",
      " 11%|█         | 6627/61028 [01:47<11:34, 78.37it/s]\u001b[A\n",
      " 11%|█         | 6636/61028 [01:47<12:00, 75.48it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6645/61028 [01:47<11:44, 77.14it/s]\u001b[A\n",
      " 11%|█         | 6654/61028 [01:47<11:21, 79.83it/s]\u001b[A\n",
      " 11%|█         | 6663/61028 [01:47<12:38, 71.64it/s]\u001b[A\n",
      " 11%|█         | 6671/61028 [01:47<12:21, 73.35it/s]\u001b[A\n",
      " 11%|█         | 6680/61028 [01:47<11:47, 76.79it/s]\u001b[A\n",
      " 11%|█         | 6690/61028 [01:48<11:01, 82.08it/s]\u001b[A\n",
      " 11%|█         | 6702/61028 [01:48<10:02, 90.21it/s]\u001b[A\n",
      " 11%|█         | 6712/61028 [01:48<10:31, 86.01it/s]\u001b[A\n",
      " 11%|█         | 6722/61028 [01:48<10:05, 89.69it/s]\u001b[A\n",
      " 11%|█         | 6732/61028 [01:48<10:41, 84.67it/s]\u001b[A\n",
      " 11%|█         | 6742/61028 [01:48<10:33, 85.65it/s]\u001b[A\n",
      " 11%|█         | 6751/61028 [01:48<11:46, 76.77it/s]\u001b[A\n",
      " 11%|█         | 6759/61028 [01:48<11:44, 77.06it/s]\u001b[A\n",
      " 11%|█         | 6767/61028 [01:48<12:19, 73.35it/s]\u001b[A\n",
      " 11%|█         | 6775/61028 [01:49<12:14, 73.91it/s]\u001b[A\n",
      " 11%|█         | 6783/61028 [01:49<12:11, 74.18it/s]\u001b[A\n",
      " 11%|█         | 6791/61028 [01:49<11:56, 75.74it/s]\u001b[A\n",
      " 11%|█         | 6800/61028 [01:49<11:25, 79.11it/s]\u001b[A\n",
      " 11%|█         | 6809/61028 [01:49<11:28, 78.75it/s]\u001b[A\n",
      " 11%|█         | 6817/61028 [01:49<12:22, 73.01it/s]\u001b[A\n",
      " 11%|█         | 6827/61028 [01:49<11:39, 77.44it/s]\u001b[A\n",
      " 11%|█         | 6837/61028 [01:49<11:30, 78.51it/s]\u001b[A\n",
      " 11%|█         | 6847/61028 [01:49<11:02, 81.75it/s]\u001b[A\n",
      " 11%|█         | 6856/61028 [01:50<11:33, 78.06it/s]\u001b[A\n",
      " 11%|█         | 6864/61028 [01:50<12:27, 72.42it/s]\u001b[A\n",
      " 11%|█▏        | 6874/61028 [01:50<11:46, 76.66it/s]\u001b[A\n",
      " 11%|█▏        | 6882/61028 [01:50<12:20, 73.15it/s]\u001b[A\n",
      " 11%|█▏        | 6890/61028 [01:50<12:16, 73.53it/s]\u001b[A\n",
      " 11%|█▏        | 6899/61028 [01:50<11:58, 75.37it/s]\u001b[A\n",
      " 11%|█▏        | 6907/61028 [01:51<21:18, 42.33it/s]\u001b[A\n",
      " 11%|█▏        | 6918/61028 [01:51<17:33, 51.37it/s]\u001b[A\n",
      " 11%|█▏        | 6926/61028 [01:51<15:44, 57.29it/s]\u001b[A\n",
      " 11%|█▏        | 6934/61028 [01:51<14:37, 61.64it/s]\u001b[A\n",
      " 11%|█▏        | 6943/61028 [01:51<13:22, 67.41it/s]\u001b[A\n",
      " 11%|█▏        | 6952/61028 [01:51<12:30, 72.09it/s]\u001b[A\n",
      " 11%|█▏        | 6961/61028 [01:51<13:14, 68.04it/s]\u001b[A\n",
      " 11%|█▏        | 6969/61028 [01:51<12:40, 71.05it/s]\u001b[A\n",
      " 11%|█▏        | 6978/61028 [01:51<12:04, 74.57it/s]\u001b[A\n",
      " 11%|█▏        | 6987/61028 [01:52<11:54, 75.63it/s]\u001b[A\n",
      " 11%|█▏        | 6995/61028 [01:52<12:35, 71.56it/s]\u001b[A\n",
      " 11%|█▏        | 7003/61028 [01:52<12:18, 73.14it/s]\u001b[A\n",
      " 11%|█▏        | 7011/61028 [01:52<12:07, 74.28it/s]\u001b[A\n",
      " 12%|█▏        | 7020/61028 [01:52<11:35, 77.63it/s]\u001b[A\n",
      " 12%|█▏        | 7028/61028 [01:52<11:45, 76.58it/s]\u001b[A\n",
      " 12%|█▏        | 7038/61028 [01:52<11:02, 81.51it/s]\u001b[A\n",
      " 12%|█▏        | 7049/61028 [01:52<10:23, 86.50it/s]\u001b[A\n",
      " 12%|█▏        | 7058/61028 [01:52<11:28, 78.39it/s]\u001b[A\n",
      " 12%|█▏        | 7068/61028 [01:53<10:55, 82.37it/s]\u001b[A\n",
      " 12%|█▏        | 7078/61028 [01:53<10:22, 86.72it/s]\u001b[A\n",
      " 12%|█▏        | 7087/61028 [01:53<11:13, 80.11it/s]\u001b[A\n",
      " 12%|█▏        | 7096/61028 [01:53<10:54, 82.44it/s]\u001b[A\n",
      " 12%|█▏        | 7105/61028 [01:53<11:03, 81.33it/s]\u001b[A\n",
      " 12%|█▏        | 7114/61028 [01:53<11:07, 80.72it/s]\u001b[A\n",
      " 12%|█▏        | 7123/61028 [01:53<10:51, 82.79it/s]\u001b[A\n",
      " 12%|█▏        | 7133/61028 [01:53<10:40, 84.18it/s]\u001b[A\n",
      " 12%|█▏        | 7142/61028 [01:54<11:51, 75.68it/s]\u001b[A\n",
      " 12%|█▏        | 7150/61028 [01:54<11:53, 75.48it/s]\u001b[A\n",
      " 12%|█▏        | 7158/61028 [01:54<12:23, 72.48it/s]\u001b[A\n",
      " 12%|█▏        | 7166/61028 [01:54<12:04, 74.32it/s]\u001b[A\n",
      " 12%|█▏        | 7174/61028 [01:54<11:57, 75.06it/s]\u001b[A\n",
      " 12%|█▏        | 7184/61028 [01:54<11:04, 81.01it/s]\u001b[A\n",
      " 12%|█▏        | 7193/61028 [01:54<11:06, 80.72it/s]\u001b[A\n",
      " 12%|█▏        | 7204/61028 [01:54<10:22, 86.46it/s]\u001b[A\n",
      " 12%|█▏        | 7213/61028 [01:54<11:17, 79.48it/s]\u001b[A\n",
      " 12%|█▏        | 7222/61028 [01:55<11:16, 79.56it/s]\u001b[A\n",
      " 12%|█▏        | 7232/61028 [01:55<10:47, 83.07it/s]\u001b[A\n",
      " 12%|█▏        | 7241/61028 [01:55<11:39, 76.89it/s]\u001b[A\n",
      " 12%|█▏        | 7249/61028 [01:55<11:50, 75.66it/s]\u001b[A\n",
      " 12%|█▏        | 7258/61028 [01:55<11:23, 78.66it/s]\u001b[A\n",
      " 12%|█▏        | 7267/61028 [01:55<11:13, 79.79it/s]\u001b[A\n",
      " 12%|█▏        | 7278/61028 [01:55<10:32, 85.04it/s]\u001b[A\n",
      " 12%|█▏        | 7287/61028 [01:55<11:52, 75.39it/s]\u001b[A\n",
      " 12%|█▏        | 7295/61028 [01:56<18:32, 48.29it/s]\u001b[A\n",
      " 12%|█▏        | 7305/61028 [01:56<15:48, 56.63it/s]\u001b[A\n",
      " 12%|█▏        | 7314/61028 [01:56<14:23, 62.18it/s]\u001b[A\n",
      " 12%|█▏        | 7322/61028 [01:56<13:50, 64.70it/s]\u001b[A\n",
      " 12%|█▏        | 7330/61028 [01:56<13:17, 67.31it/s]\u001b[A\n",
      " 12%|█▏        | 7338/61028 [01:56<13:07, 68.20it/s]\u001b[A\n",
      " 12%|█▏        | 7347/61028 [01:56<12:40, 70.55it/s]\u001b[A\n",
      " 12%|█▏        | 7355/61028 [01:56<12:36, 70.98it/s]\u001b[A\n",
      " 12%|█▏        | 7363/61028 [01:57<12:11, 73.35it/s]\u001b[A\n",
      " 12%|█▏        | 7371/61028 [01:57<12:10, 73.44it/s]\u001b[A\n",
      " 12%|█▏        | 7380/61028 [01:57<11:42, 76.34it/s]\u001b[A\n",
      " 12%|█▏        | 7388/61028 [01:57<11:35, 77.09it/s]\u001b[A\n",
      " 12%|█▏        | 7397/61028 [01:57<11:20, 78.79it/s]\u001b[A\n",
      " 12%|█▏        | 7406/61028 [01:57<11:03, 80.86it/s]\u001b[A\n",
      " 12%|█▏        | 7415/61028 [01:57<12:16, 72.82it/s]\u001b[A\n",
      " 12%|█▏        | 7425/61028 [01:57<11:39, 76.66it/s]\u001b[A\n",
      " 12%|█▏        | 7433/61028 [01:57<11:37, 76.80it/s]\u001b[A\n",
      " 12%|█▏        | 7441/61028 [01:58<12:05, 73.86it/s]\u001b[A\n",
      " 12%|█▏        | 7449/61028 [01:58<12:30, 71.42it/s]\u001b[A\n",
      " 12%|█▏        | 7458/61028 [01:58<12:00, 74.37it/s]\u001b[A\n",
      " 12%|█▏        | 7468/61028 [01:58<11:21, 78.61it/s]\u001b[A\n",
      " 12%|█▏        | 7476/61028 [01:58<13:02, 68.48it/s]\u001b[A\n",
      " 12%|█▏        | 7484/61028 [01:58<12:28, 71.52it/s]\u001b[A\n",
      " 12%|█▏        | 7492/61028 [01:58<12:29, 71.42it/s]\u001b[A\n",
      " 12%|█▏        | 7500/61028 [01:58<12:05, 73.76it/s]\u001b[A\n",
      " 12%|█▏        | 7508/61028 [01:58<12:19, 72.38it/s]\u001b[A\n",
      " 12%|█▏        | 7518/61028 [01:59<11:19, 78.78it/s]\u001b[A\n",
      " 12%|█▏        | 7527/61028 [01:59<11:24, 78.15it/s]\u001b[A\n",
      " 12%|█▏        | 7535/61028 [01:59<12:47, 69.72it/s]\u001b[A\n",
      " 12%|█▏        | 7543/61028 [01:59<12:23, 71.95it/s]\u001b[A\n",
      " 12%|█▏        | 7552/61028 [01:59<11:38, 76.53it/s]\u001b[A\n",
      " 12%|█▏        | 7561/61028 [01:59<11:20, 78.62it/s]\u001b[A\n",
      " 12%|█▏        | 7570/61028 [01:59<11:44, 75.92it/s]\u001b[A\n",
      " 12%|█▏        | 7578/61028 [01:59<12:38, 70.47it/s]\u001b[A\n",
      " 12%|█▏        | 7586/61028 [02:00<12:33, 70.90it/s]\u001b[A\n",
      " 12%|█▏        | 7595/61028 [02:00<12:04, 73.70it/s]\u001b[A\n",
      " 12%|█▏        | 7606/61028 [02:00<10:55, 81.54it/s]\u001b[A\n",
      " 12%|█▏        | 7615/61028 [02:00<12:02, 73.90it/s]\u001b[A\n",
      " 12%|█▏        | 7623/61028 [02:00<11:47, 75.54it/s]\u001b[A\n",
      " 13%|█▎        | 7631/61028 [02:00<11:58, 74.31it/s]\u001b[A\n",
      " 13%|█▎        | 7640/61028 [02:00<12:01, 73.97it/s]\u001b[A\n",
      " 13%|█▎        | 7649/61028 [02:00<11:29, 77.37it/s]\u001b[A\n",
      " 13%|█▎        | 7658/61028 [02:00<12:06, 73.45it/s]\u001b[A\n",
      " 13%|█▎        | 7666/61028 [02:01<20:33, 43.26it/s]\u001b[A\n",
      " 13%|█▎        | 7673/61028 [02:01<18:21, 48.44it/s]\u001b[A\n",
      " 13%|█▎        | 7684/61028 [02:01<15:24, 57.68it/s]\u001b[A\n",
      " 13%|█▎        | 7694/61028 [02:01<13:52, 64.10it/s]\u001b[A\n",
      " 13%|█▎        | 7705/61028 [02:01<12:22, 71.80it/s]\u001b[A\n",
      " 13%|█▎        | 7714/61028 [02:01<12:16, 72.36it/s]\u001b[A\n",
      " 13%|█▎        | 7723/61028 [02:01<11:52, 74.84it/s]\u001b[A\n",
      " 13%|█▎        | 7732/61028 [02:02<12:13, 72.63it/s]\u001b[A\n",
      " 13%|█▎        | 7741/61028 [02:02<11:50, 74.99it/s]\u001b[A\n",
      " 13%|█▎        | 7749/61028 [02:02<12:28, 71.14it/s]\u001b[A\n",
      " 13%|█▎        | 7757/61028 [02:02<12:23, 71.68it/s]\u001b[A\n",
      " 13%|█▎        | 7768/61028 [02:02<11:10, 79.40it/s]\u001b[A\n",
      " 13%|█▎        | 7777/61028 [02:02<12:09, 72.95it/s]\u001b[A\n",
      " 13%|█▎        | 7786/61028 [02:02<11:36, 76.47it/s]\u001b[A\n",
      " 13%|█▎        | 7796/61028 [02:02<10:47, 82.22it/s]\u001b[A\n",
      " 13%|█▎        | 7805/61028 [02:03<11:32, 76.83it/s]\u001b[A\n",
      " 13%|█▎        | 7813/61028 [02:03<11:26, 77.47it/s]\u001b[A\n",
      " 13%|█▎        | 7821/61028 [02:03<11:55, 74.37it/s]\u001b[A\n",
      " 13%|█▎        | 7829/61028 [02:03<11:54, 74.43it/s]\u001b[A\n",
      " 13%|█▎        | 7838/61028 [02:03<11:19, 78.32it/s]\u001b[A\n",
      " 13%|█▎        | 7846/61028 [02:03<11:41, 75.80it/s]\u001b[A\n",
      " 13%|█▎        | 7855/61028 [02:03<11:40, 75.86it/s]\u001b[A\n",
      " 13%|█▎        | 7867/61028 [02:03<10:35, 83.67it/s]\u001b[A\n",
      " 13%|█▎        | 7876/61028 [02:03<11:09, 79.41it/s]\u001b[A\n",
      " 13%|█▎        | 7885/61028 [02:04<11:36, 76.30it/s]\u001b[A\n",
      " 13%|█▎        | 7893/61028 [02:04<11:49, 74.93it/s]\u001b[A\n",
      " 13%|█▎        | 7901/61028 [02:04<13:04, 67.69it/s]\u001b[A\n",
      " 13%|█▎        | 7909/61028 [02:04<12:57, 68.31it/s]\u001b[A\n",
      " 13%|█▎        | 7919/61028 [02:04<11:56, 74.17it/s]\u001b[A\n",
      " 13%|█▎        | 7927/61028 [02:04<12:09, 72.78it/s]\u001b[A\n",
      " 13%|█▎        | 7935/61028 [02:04<12:06, 73.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 7943/61028 [02:04<13:00, 68.06it/s]\u001b[A\n",
      " 13%|█▎        | 7953/61028 [02:05<11:55, 74.19it/s]\u001b[A\n",
      " 13%|█▎        | 7963/61028 [02:05<11:00, 80.31it/s]\u001b[A\n",
      " 13%|█▎        | 7972/61028 [02:05<10:41, 82.73it/s]\u001b[A\n",
      " 13%|█▎        | 7982/61028 [02:05<10:21, 85.33it/s]\u001b[A\n",
      " 13%|█▎        | 7991/61028 [02:05<10:38, 83.10it/s]\u001b[A\n",
      " 13%|█▎        | 8000/61028 [02:05<10:37, 83.13it/s]\u001b[A\n",
      " 13%|█▎        | 8009/61028 [02:05<10:59, 80.36it/s]\u001b[A\n",
      " 13%|█▎        | 8018/61028 [02:05<11:12, 78.82it/s]\u001b[A\n",
      " 13%|█▎        | 8028/61028 [02:05<10:43, 82.30it/s]\u001b[A\n",
      " 13%|█▎        | 8037/61028 [02:06<11:06, 79.52it/s]\u001b[A\n",
      " 13%|█▎        | 8046/61028 [02:06<18:30, 47.69it/s]\u001b[A\n",
      " 13%|█▎        | 8053/61028 [02:06<17:47, 49.62it/s]\u001b[A\n",
      " 13%|█▎        | 8061/61028 [02:06<15:51, 55.67it/s]\u001b[A\n",
      " 13%|█▎        | 8071/61028 [02:06<13:54, 63.42it/s]\u001b[A\n",
      " 13%|█▎        | 8079/61028 [02:06<13:26, 65.69it/s]\u001b[A\n",
      " 13%|█▎        | 8087/61028 [02:06<12:53, 68.49it/s]\u001b[A\n",
      " 13%|█▎        | 8095/61028 [02:07<12:34, 70.18it/s]\u001b[A\n",
      " 13%|█▎        | 8103/61028 [02:07<12:49, 68.74it/s]\u001b[A\n",
      " 13%|█▎        | 8114/61028 [02:07<11:45, 75.03it/s]\u001b[A\n",
      " 13%|█▎        | 8122/61028 [02:07<11:38, 75.75it/s]\u001b[A\n",
      " 13%|█▎        | 8130/61028 [02:07<12:02, 73.22it/s]\u001b[A\n",
      " 13%|█▎        | 8140/61028 [02:07<11:17, 78.12it/s]\u001b[A\n",
      " 13%|█▎        | 8150/61028 [02:07<10:36, 83.11it/s]\u001b[A\n",
      " 13%|█▎        | 8161/61028 [02:07<09:53, 89.15it/s]\u001b[A\n",
      " 13%|█▎        | 8171/61028 [02:07<09:38, 91.44it/s]\u001b[A\n",
      " 13%|█▎        | 8181/61028 [02:08<10:15, 85.85it/s]\u001b[A\n",
      " 13%|█▎        | 8191/61028 [02:08<10:09, 86.70it/s]\u001b[A\n",
      " 13%|█▎        | 8200/61028 [02:08<10:37, 82.81it/s]\u001b[A\n",
      " 13%|█▎        | 8209/61028 [02:08<11:29, 76.56it/s]\u001b[A\n",
      " 13%|█▎        | 8217/61028 [02:08<12:25, 70.83it/s]\u001b[A\n",
      " 13%|█▎        | 8225/61028 [02:08<12:02, 73.13it/s]\u001b[A\n",
      " 13%|█▎        | 8233/61028 [02:08<11:43, 75.06it/s]\u001b[A\n",
      " 14%|█▎        | 8241/61028 [02:08<11:34, 76.06it/s]\u001b[A\n",
      " 14%|█▎        | 8249/61028 [02:08<11:46, 74.68it/s]\u001b[A\n",
      " 14%|█▎        | 8259/61028 [02:09<11:05, 79.34it/s]\u001b[A\n",
      " 14%|█▎        | 8268/61028 [02:09<11:17, 77.90it/s]\u001b[A\n",
      " 14%|█▎        | 8279/61028 [02:09<10:39, 82.49it/s]\u001b[A\n",
      " 14%|█▎        | 8289/61028 [02:09<10:09, 86.49it/s]\u001b[A\n",
      " 14%|█▎        | 8298/61028 [02:09<10:22, 84.67it/s]\u001b[A\n",
      " 14%|█▎        | 8307/61028 [02:09<10:25, 84.23it/s]\u001b[A\n",
      " 14%|█▎        | 8318/61028 [02:09<09:42, 90.45it/s]\u001b[A\n",
      " 14%|█▎        | 8328/61028 [02:09<10:12, 86.04it/s]\u001b[A\n",
      " 14%|█▎        | 8337/61028 [02:09<10:44, 81.77it/s]\u001b[A\n",
      " 14%|█▎        | 8346/61028 [02:10<10:44, 81.80it/s]\u001b[A\n",
      " 14%|█▎        | 8355/61028 [02:10<10:37, 82.68it/s]\u001b[A\n",
      " 14%|█▎        | 8364/61028 [02:10<10:21, 84.68it/s]\u001b[A\n",
      " 14%|█▎        | 8373/61028 [02:10<11:30, 76.30it/s]\u001b[A\n",
      " 14%|█▎        | 8382/61028 [02:10<11:14, 78.08it/s]\u001b[A\n",
      " 14%|█▎        | 8391/61028 [02:10<10:53, 80.60it/s]\u001b[A\n",
      " 14%|█▍        | 8400/61028 [02:10<11:44, 74.72it/s]\u001b[A\n",
      " 14%|█▍        | 8410/61028 [02:10<11:17, 77.72it/s]\u001b[A\n",
      " 14%|█▍        | 8419/61028 [02:11<11:03, 79.27it/s]\u001b[A\n",
      " 14%|█▍        | 8428/61028 [02:11<10:41, 82.02it/s]\u001b[A\n",
      " 14%|█▍        | 8437/61028 [02:11<19:25, 45.11it/s]\u001b[A\n",
      " 14%|█▍        | 8446/61028 [02:11<16:37, 52.70it/s]\u001b[A\n",
      " 14%|█▍        | 8458/61028 [02:11<14:02, 62.36it/s]\u001b[A\n",
      " 14%|█▍        | 8467/61028 [02:11<12:53, 67.92it/s]\u001b[A\n",
      " 14%|█▍        | 8476/61028 [02:12<14:09, 61.83it/s]\u001b[A\n",
      " 14%|█▍        | 8484/61028 [02:12<13:41, 63.98it/s]\u001b[A\n",
      " 14%|█▍        | 8493/61028 [02:12<12:46, 68.56it/s]\u001b[A\n",
      " 14%|█▍        | 8502/61028 [02:12<12:14, 71.50it/s]\u001b[A\n",
      " 14%|█▍        | 8513/61028 [02:12<11:03, 79.11it/s]\u001b[A\n",
      " 14%|█▍        | 8522/61028 [02:12<10:48, 81.00it/s]\u001b[A\n",
      " 14%|█▍        | 8531/61028 [02:12<10:32, 83.05it/s]\u001b[A\n",
      " 14%|█▍        | 8540/61028 [02:12<10:26, 83.72it/s]\u001b[A\n",
      " 14%|█▍        | 8550/61028 [02:12<10:00, 87.35it/s]\u001b[A\n",
      " 14%|█▍        | 8559/61028 [02:12<10:03, 86.99it/s]\u001b[A\n",
      " 14%|█▍        | 8568/61028 [02:13<10:17, 85.00it/s]\u001b[A\n",
      " 14%|█▍        | 8577/61028 [02:13<10:37, 82.32it/s]\u001b[A\n",
      " 14%|█▍        | 8588/61028 [02:13<09:59, 87.50it/s]\u001b[A\n",
      " 14%|█▍        | 8597/61028 [02:13<10:05, 86.59it/s]\u001b[A\n",
      " 14%|█▍        | 8607/61028 [02:13<10:12, 85.59it/s]\u001b[A\n",
      " 14%|█▍        | 8616/61028 [02:13<10:16, 85.08it/s]\u001b[A\n",
      " 14%|█▍        | 8626/61028 [02:13<10:12, 85.52it/s]\u001b[A\n",
      " 14%|█▍        | 8636/61028 [02:13<09:46, 89.29it/s]\u001b[A\n",
      " 14%|█▍        | 8645/61028 [02:13<09:58, 87.56it/s]\u001b[A\n",
      " 14%|█▍        | 8655/61028 [02:14<09:52, 88.35it/s]\u001b[A\n",
      " 14%|█▍        | 8664/61028 [02:14<10:32, 82.79it/s]\u001b[A\n",
      " 14%|█▍        | 8673/61028 [02:14<10:22, 84.09it/s]\u001b[A\n",
      " 14%|█▍        | 8682/61028 [02:14<12:54, 67.62it/s]\u001b[A\n",
      " 14%|█▍        | 8691/61028 [02:14<12:16, 71.08it/s]\u001b[A\n",
      " 14%|█▍        | 8699/61028 [02:14<12:05, 72.10it/s]\u001b[A\n",
      " 14%|█▍        | 8708/61028 [02:14<12:07, 71.94it/s]\u001b[A\n",
      " 14%|█▍        | 8719/61028 [02:14<10:52, 80.18it/s]\u001b[A\n",
      " 14%|█▍        | 8731/61028 [02:15<10:00, 87.10it/s]\u001b[A\n",
      " 14%|█▍        | 8741/61028 [02:15<09:52, 88.30it/s]\u001b[A\n",
      " 14%|█▍        | 8751/61028 [02:15<10:14, 85.13it/s]\u001b[A\n",
      " 14%|█▍        | 8760/61028 [02:15<10:23, 83.79it/s]\u001b[A\n",
      " 14%|█▍        | 8770/61028 [02:15<10:07, 85.98it/s]\u001b[A\n",
      " 14%|█▍        | 8780/61028 [02:15<09:57, 87.39it/s]\u001b[A\n",
      " 14%|█▍        | 8789/61028 [02:15<10:06, 86.07it/s]\u001b[A\n",
      " 14%|█▍        | 8798/61028 [02:15<10:10, 85.49it/s]\u001b[A\n",
      " 14%|█▍        | 8807/61028 [02:15<10:37, 81.95it/s]\u001b[A\n",
      " 14%|█▍        | 8817/61028 [02:16<10:12, 85.24it/s]\u001b[A\n",
      " 14%|█▍        | 8826/61028 [02:16<11:29, 75.68it/s]\u001b[A\n",
      " 14%|█▍        | 8834/61028 [02:16<12:54, 67.43it/s]\u001b[A\n",
      " 14%|█▍        | 8842/61028 [02:16<20:32, 42.34it/s]\u001b[A\n",
      " 14%|█▍        | 8849/61028 [02:16<18:15, 47.61it/s]\u001b[A\n",
      " 15%|█▍        | 8859/61028 [02:16<15:35, 55.79it/s]\u001b[A\n",
      " 15%|█▍        | 8868/61028 [02:17<13:54, 62.52it/s]\u001b[A\n",
      " 15%|█▍        | 8878/61028 [02:17<12:30, 69.44it/s]\u001b[A\n",
      " 15%|█▍        | 8887/61028 [02:17<12:02, 72.17it/s]\u001b[A\n",
      " 15%|█▍        | 8896/61028 [02:17<11:29, 75.64it/s]\u001b[A\n",
      " 15%|█▍        | 8905/61028 [02:17<11:53, 73.07it/s]\u001b[A\n",
      " 15%|█▍        | 8914/61028 [02:17<11:15, 77.14it/s]\u001b[A\n",
      " 15%|█▍        | 8923/61028 [02:17<11:01, 78.76it/s]\u001b[A\n",
      " 15%|█▍        | 8932/61028 [02:17<10:40, 81.28it/s]\u001b[A\n",
      " 15%|█▍        | 8941/61028 [02:17<10:59, 79.00it/s]\u001b[A\n",
      " 15%|█▍        | 8950/61028 [02:18<11:08, 77.86it/s]\u001b[A\n",
      " 15%|█▍        | 8958/61028 [02:18<11:04, 78.33it/s]\u001b[A\n",
      " 15%|█▍        | 8968/61028 [02:18<10:33, 82.15it/s]\u001b[A\n",
      " 15%|█▍        | 8977/61028 [02:18<11:13, 77.32it/s]\u001b[A\n",
      " 15%|█▍        | 8987/61028 [02:18<10:32, 82.28it/s]\u001b[A\n",
      " 15%|█▍        | 8996/61028 [02:18<10:52, 79.74it/s]\u001b[A\n",
      " 15%|█▍        | 9007/61028 [02:18<10:05, 85.96it/s]\u001b[A\n",
      " 15%|█▍        | 9018/61028 [02:18<09:33, 90.73it/s]\u001b[A\n",
      " 15%|█▍        | 9028/61028 [02:18<10:07, 85.60it/s]\u001b[A\n",
      " 15%|█▍        | 9040/61028 [02:19<09:27, 91.53it/s]\u001b[A\n",
      " 15%|█▍        | 9050/61028 [02:19<09:18, 93.00it/s]\u001b[A\n",
      " 15%|█▍        | 9060/61028 [02:19<09:50, 87.96it/s]\u001b[A\n",
      " 15%|█▍        | 9069/61028 [02:19<11:28, 75.46it/s]\u001b[A\n",
      " 15%|█▍        | 9078/61028 [02:19<10:55, 79.27it/s]\u001b[A\n",
      " 15%|█▍        | 9087/61028 [02:19<10:36, 81.55it/s]\u001b[A\n",
      " 15%|█▍        | 9096/61028 [02:19<10:44, 80.63it/s]\u001b[A\n",
      " 15%|█▍        | 9105/61028 [02:19<10:32, 82.14it/s]\u001b[A\n",
      " 15%|█▍        | 9115/61028 [02:19<10:00, 86.45it/s]\u001b[A\n",
      " 15%|█▍        | 9124/61028 [02:20<09:59, 86.61it/s]\u001b[A\n",
      " 15%|█▍        | 9133/61028 [02:20<11:18, 76.52it/s]\u001b[A\n",
      " 15%|█▍        | 9143/61028 [02:20<10:55, 79.21it/s]\u001b[A\n",
      " 15%|█▍        | 9153/61028 [02:20<10:30, 82.25it/s]\u001b[A\n",
      " 15%|█▌        | 9162/61028 [02:20<10:37, 81.42it/s]\u001b[A\n",
      " 15%|█▌        | 9171/61028 [02:20<10:48, 79.91it/s]\u001b[A\n",
      " 15%|█▌        | 9180/61028 [02:20<10:43, 80.61it/s]\u001b[A\n",
      " 15%|█▌        | 9189/61028 [02:20<11:07, 77.68it/s]\u001b[A\n",
      " 15%|█▌        | 9199/61028 [02:21<10:35, 81.52it/s]\u001b[A\n",
      " 15%|█▌        | 9208/61028 [02:21<10:21, 83.43it/s]\u001b[A\n",
      " 15%|█▌        | 9217/61028 [02:21<10:53, 79.32it/s]\u001b[A\n",
      " 15%|█▌        | 9226/61028 [02:21<17:17, 49.95it/s]\u001b[A\n",
      " 15%|█▌        | 9233/61028 [02:21<18:24, 46.90it/s]\u001b[A\n",
      " 15%|█▌        | 9240/61028 [02:21<16:46, 51.46it/s]\u001b[A\n",
      " 15%|█▌        | 9247/61028 [02:22<16:15, 53.10it/s]\u001b[A\n",
      " 15%|█▌        | 9257/61028 [02:22<14:01, 61.52it/s]\u001b[A\n",
      " 15%|█▌        | 9265/61028 [02:22<13:41, 63.01it/s]\u001b[A\n",
      " 15%|█▌        | 9273/61028 [02:22<13:16, 64.98it/s]\u001b[A\n",
      " 15%|█▌        | 9282/61028 [02:22<12:22, 69.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9290/61028 [02:22<12:38, 68.23it/s]\u001b[A\n",
      " 15%|█▌        | 9300/61028 [02:22<11:48, 72.99it/s]\u001b[A\n",
      " 15%|█▌        | 9310/61028 [02:22<11:15, 76.53it/s]\u001b[A\n",
      " 15%|█▌        | 9318/61028 [02:22<11:58, 71.93it/s]\u001b[A\n",
      " 15%|█▌        | 9326/61028 [02:23<12:15, 70.30it/s]\u001b[A\n",
      " 15%|█▌        | 9334/61028 [02:23<11:58, 71.95it/s]\u001b[A\n",
      " 15%|█▌        | 9344/61028 [02:23<11:13, 76.69it/s]\u001b[A\n",
      " 15%|█▌        | 9353/61028 [02:23<10:51, 79.29it/s]\u001b[A\n",
      " 15%|█▌        | 9362/61028 [02:23<11:02, 77.94it/s]\u001b[A\n",
      " 15%|█▌        | 9371/61028 [02:23<11:07, 77.43it/s]\u001b[A\n",
      " 15%|█▌        | 9379/61028 [02:23<11:37, 74.09it/s]\u001b[A\n",
      " 15%|█▌        | 9390/61028 [02:23<10:41, 80.54it/s]\u001b[A\n",
      " 15%|█▌        | 9399/61028 [02:23<10:56, 78.69it/s]\u001b[A\n",
      " 15%|█▌        | 9408/61028 [02:24<11:31, 74.63it/s]\u001b[A\n",
      " 15%|█▌        | 9418/61028 [02:24<10:47, 79.74it/s]\u001b[A\n",
      " 15%|█▌        | 9427/61028 [02:24<10:29, 81.92it/s]\u001b[A\n",
      " 15%|█▌        | 9436/61028 [02:24<11:19, 75.87it/s]\u001b[A\n",
      " 15%|█▌        | 9445/61028 [02:24<10:58, 78.37it/s]\u001b[A\n",
      " 15%|█▌        | 9453/61028 [02:24<11:03, 77.70it/s]\u001b[A\n",
      " 16%|█▌        | 9462/61028 [02:24<10:52, 78.97it/s]\u001b[A\n",
      " 16%|█▌        | 9471/61028 [02:24<10:36, 80.96it/s]\u001b[A\n",
      " 16%|█▌        | 9480/61028 [02:24<10:18, 83.34it/s]\u001b[A\n",
      " 16%|█▌        | 9489/61028 [02:25<10:50, 79.28it/s]\u001b[A\n",
      " 16%|█▌        | 9498/61028 [02:25<11:41, 73.46it/s]\u001b[A\n",
      " 16%|█▌        | 9506/61028 [02:25<11:54, 72.09it/s]\u001b[A\n",
      " 16%|█▌        | 9517/61028 [02:25<10:50, 79.20it/s]\u001b[A\n",
      " 16%|█▌        | 9527/61028 [02:25<10:15, 83.64it/s]\u001b[A\n",
      " 16%|█▌        | 9539/61028 [02:25<09:30, 90.32it/s]\u001b[A\n",
      " 16%|█▌        | 9549/61028 [02:25<10:18, 83.28it/s]\u001b[A\n",
      " 16%|█▌        | 9560/61028 [02:25<09:33, 89.77it/s]\u001b[A\n",
      " 16%|█▌        | 9570/61028 [02:26<09:27, 90.74it/s]\u001b[A\n",
      " 16%|█▌        | 9580/61028 [02:26<10:04, 85.12it/s]\u001b[A\n",
      " 16%|█▌        | 9589/61028 [02:26<10:03, 85.23it/s]\u001b[A\n",
      " 16%|█▌        | 9598/61028 [02:26<10:02, 85.34it/s]\u001b[A\n",
      " 16%|█▌        | 9607/61028 [02:26<10:04, 85.01it/s]\u001b[A\n",
      " 16%|█▌        | 9616/61028 [02:26<12:07, 70.68it/s]\u001b[A\n",
      " 16%|█▌        | 9624/61028 [02:26<18:46, 45.62it/s]\u001b[A\n",
      " 16%|█▌        | 9634/61028 [02:27<15:50, 54.07it/s]\u001b[A\n",
      " 16%|█▌        | 9646/61028 [02:27<13:22, 64.00it/s]\u001b[A\n",
      " 16%|█▌        | 9655/61028 [02:27<12:37, 67.81it/s]\u001b[A\n",
      " 16%|█▌        | 9664/61028 [02:27<11:48, 72.52it/s]\u001b[A\n",
      " 16%|█▌        | 9673/61028 [02:27<11:31, 74.24it/s]\u001b[A\n",
      " 16%|█▌        | 9682/61028 [02:27<11:23, 75.17it/s]\u001b[A\n",
      " 16%|█▌        | 9691/61028 [02:27<11:07, 76.88it/s]\u001b[A\n",
      " 16%|█▌        | 9700/61028 [02:27<11:09, 76.61it/s]\u001b[A\n",
      " 16%|█▌        | 9708/61028 [02:27<11:03, 77.33it/s]\u001b[A\n",
      " 16%|█▌        | 9716/61028 [02:28<11:12, 76.27it/s]\u001b[A\n",
      " 16%|█▌        | 9725/61028 [02:28<10:53, 78.48it/s]\u001b[A\n",
      " 16%|█▌        | 9734/61028 [02:28<10:52, 78.66it/s]\u001b[A\n",
      " 16%|█▌        | 9743/61028 [02:28<10:31, 81.27it/s]\u001b[A\n",
      " 16%|█▌        | 9752/61028 [02:28<10:23, 82.18it/s]\u001b[A\n",
      " 16%|█▌        | 9762/61028 [02:28<09:54, 86.17it/s]\u001b[A\n",
      " 16%|█▌        | 9771/61028 [02:28<09:54, 86.29it/s]\u001b[A\n",
      " 16%|█▌        | 9780/61028 [02:28<09:50, 86.78it/s]\u001b[A\n",
      " 16%|█▌        | 9789/61028 [02:28<10:44, 79.56it/s]\u001b[A\n",
      " 16%|█▌        | 9798/61028 [02:29<11:04, 77.13it/s]\u001b[A\n",
      " 16%|█▌        | 9807/61028 [02:29<10:51, 78.58it/s]\u001b[A\n",
      " 16%|█▌        | 9816/61028 [02:29<10:28, 81.50it/s]\u001b[A\n",
      " 16%|█▌        | 9825/61028 [02:29<10:34, 80.70it/s]\u001b[A\n",
      " 16%|█▌        | 9834/61028 [02:29<12:01, 70.94it/s]\u001b[A\n",
      " 16%|█▌        | 9843/61028 [02:29<11:47, 72.33it/s]\u001b[A\n",
      " 16%|█▌        | 9851/61028 [02:29<11:28, 74.38it/s]\u001b[A\n",
      " 16%|█▌        | 9861/61028 [02:29<11:06, 76.75it/s]\u001b[A\n",
      " 16%|█▌        | 9870/61028 [02:29<10:42, 79.66it/s]\u001b[A\n",
      " 16%|█▌        | 9880/61028 [02:30<10:09, 83.89it/s]\u001b[A\n",
      " 16%|█▌        | 9890/61028 [02:30<09:56, 85.79it/s]\u001b[A\n",
      " 16%|█▌        | 9899/61028 [02:30<09:55, 85.82it/s]\u001b[A\n",
      " 16%|█▌        | 9909/61028 [02:30<09:32, 89.31it/s]\u001b[A\n",
      " 16%|█▋        | 9919/61028 [02:30<09:25, 90.46it/s]\u001b[A\n",
      " 16%|█▋        | 9929/61028 [02:30<09:29, 89.75it/s]\u001b[A\n",
      " 16%|█▋        | 9939/61028 [02:30<09:59, 85.16it/s]\u001b[A\n",
      " 16%|█▋        | 9948/61028 [02:30<10:43, 79.36it/s]\u001b[A\n",
      " 16%|█▋        | 9957/61028 [02:31<10:20, 82.25it/s]\u001b[A\n",
      " 16%|█▋        | 9968/61028 [02:31<09:34, 88.89it/s]\u001b[A\n",
      " 16%|█▋        | 9979/61028 [02:31<09:07, 93.20it/s]\u001b[A\n",
      " 16%|█▋        | 9989/61028 [02:31<10:05, 84.29it/s]\u001b[A\n",
      " 16%|█▋        | 9998/61028 [02:31<09:56, 85.54it/s]\u001b[A\n",
      " 16%|█▋        | 10009/61028 [02:31<09:18, 91.30it/s]\u001b[A\n",
      " 16%|█▋        | 10019/61028 [02:31<16:55, 50.23it/s]\u001b[A\n",
      " 16%|█▋        | 10028/61028 [02:32<14:45, 57.59it/s]\u001b[A\n",
      " 16%|█▋        | 10036/61028 [02:32<15:01, 56.58it/s]\u001b[A\n",
      " 16%|█▋        | 10046/61028 [02:32<13:17, 63.93it/s]\u001b[A\n",
      " 16%|█▋        | 10056/61028 [02:32<11:52, 71.57it/s]\u001b[A\n",
      " 16%|█▋        | 10066/61028 [02:32<11:03, 76.85it/s]\u001b[A\n",
      " 17%|█▋        | 10075/61028 [02:32<10:59, 77.21it/s]\u001b[A\n",
      " 17%|█▋        | 10085/61028 [02:32<10:22, 81.87it/s]\u001b[A\n",
      " 17%|█▋        | 10094/61028 [02:32<10:47, 78.66it/s]\u001b[A\n",
      " 17%|█▋        | 10103/61028 [02:32<10:28, 81.03it/s]\u001b[A\n",
      " 17%|█▋        | 10112/61028 [02:33<10:19, 82.21it/s]\u001b[A\n",
      " 17%|█▋        | 10122/61028 [02:33<09:59, 84.91it/s]\u001b[A\n",
      " 17%|█▋        | 10131/61028 [02:33<10:17, 82.43it/s]\u001b[A\n",
      " 17%|█▋        | 10140/61028 [02:33<10:54, 77.73it/s]\u001b[A\n",
      " 17%|█▋        | 10149/61028 [02:33<10:34, 80.15it/s]\u001b[A\n",
      " 17%|█▋        | 10158/61028 [02:33<10:27, 81.10it/s]\u001b[A\n",
      " 17%|█▋        | 10167/61028 [02:33<10:44, 78.90it/s]\u001b[A\n",
      " 17%|█▋        | 10175/61028 [02:33<11:26, 74.09it/s]\u001b[A\n",
      " 17%|█▋        | 10184/61028 [02:34<11:21, 74.64it/s]\u001b[A\n",
      " 17%|█▋        | 10194/61028 [02:34<10:29, 80.79it/s]\u001b[A\n",
      " 17%|█▋        | 10204/61028 [02:34<09:59, 84.72it/s]\u001b[A\n",
      " 17%|█▋        | 10213/61028 [02:34<09:59, 84.80it/s]\u001b[A\n",
      " 17%|█▋        | 10222/61028 [02:34<10:37, 79.68it/s]\u001b[A\n",
      " 17%|█▋        | 10231/61028 [02:34<11:08, 75.94it/s]\u001b[A\n",
      " 17%|█▋        | 10242/61028 [02:34<10:20, 81.85it/s]\u001b[A\n",
      " 17%|█▋        | 10252/61028 [02:34<09:50, 86.06it/s]\u001b[A\n",
      " 17%|█▋        | 10261/61028 [02:34<10:22, 81.51it/s]\u001b[A\n",
      " 17%|█▋        | 10270/61028 [02:35<10:17, 82.21it/s]\u001b[A\n",
      " 17%|█▋        | 10281/61028 [02:35<09:32, 88.63it/s]\u001b[A\n",
      " 17%|█▋        | 10292/61028 [02:35<09:06, 92.89it/s]\u001b[A\n",
      " 17%|█▋        | 10303/61028 [02:35<08:48, 96.06it/s]\u001b[A\n",
      " 17%|█▋        | 10313/61028 [02:35<09:36, 87.94it/s]\u001b[A\n",
      " 17%|█▋        | 10323/61028 [02:35<10:02, 84.10it/s]\u001b[A\n",
      " 17%|█▋        | 10332/61028 [02:35<10:35, 79.83it/s]\u001b[A\n",
      " 17%|█▋        | 10341/61028 [02:35<10:19, 81.79it/s]\u001b[A\n",
      " 17%|█▋        | 10351/61028 [02:35<09:50, 85.82it/s]\u001b[A\n",
      " 17%|█▋        | 10361/61028 [02:36<09:55, 85.13it/s]\u001b[A\n",
      " 17%|█▋        | 10370/61028 [02:36<10:17, 82.06it/s]\u001b[A\n",
      " 17%|█▋        | 10381/61028 [02:36<09:30, 88.82it/s]\u001b[A\n",
      " 17%|█▋        | 10391/61028 [02:36<09:41, 87.01it/s]\u001b[A\n",
      " 17%|█▋        | 10403/61028 [02:36<09:03, 93.20it/s]\u001b[A\n",
      " 17%|█▋        | 10413/61028 [02:36<09:07, 92.44it/s]\u001b[A\n",
      " 17%|█▋        | 10423/61028 [02:36<09:57, 84.72it/s]\u001b[A\n",
      " 17%|█▋        | 10432/61028 [02:37<17:00, 49.56it/s]\u001b[A\n",
      " 17%|█▋        | 10441/61028 [02:37<14:54, 56.54it/s]\u001b[A\n",
      " 17%|█▋        | 10451/61028 [02:37<13:14, 63.62it/s]\u001b[A\n",
      " 17%|█▋        | 10460/61028 [02:37<12:11, 69.10it/s]\u001b[A\n",
      " 17%|█▋        | 10470/61028 [02:37<11:20, 74.30it/s]\u001b[A\n",
      " 17%|█▋        | 10479/61028 [02:37<11:08, 75.64it/s]\u001b[A\n",
      " 17%|█▋        | 10488/61028 [02:37<11:08, 75.57it/s]\u001b[A\n",
      " 17%|█▋        | 10497/61028 [02:37<11:03, 76.18it/s]\u001b[A\n",
      " 17%|█▋        | 10508/61028 [02:38<10:14, 82.18it/s]\u001b[A\n",
      " 17%|█▋        | 10518/61028 [02:38<09:53, 85.10it/s]\u001b[A\n",
      " 17%|█▋        | 10527/61028 [02:38<10:42, 78.56it/s]\u001b[A\n",
      " 17%|█▋        | 10536/61028 [02:38<10:40, 78.77it/s]\u001b[A\n",
      " 17%|█▋        | 10545/61028 [02:38<10:20, 81.41it/s]\u001b[A\n",
      " 17%|█▋        | 10555/61028 [02:38<09:46, 86.11it/s]\u001b[A\n",
      " 17%|█▋        | 10564/61028 [02:38<10:30, 80.04it/s]\u001b[A\n",
      " 17%|█▋        | 10576/61028 [02:38<09:28, 88.80it/s]\u001b[A\n",
      " 17%|█▋        | 10586/61028 [02:38<09:13, 91.13it/s]\u001b[A\n",
      " 17%|█▋        | 10596/61028 [02:39<09:27, 88.90it/s]\u001b[A\n",
      " 17%|█▋        | 10606/61028 [02:39<09:31, 88.18it/s]\u001b[A\n",
      " 17%|█▋        | 10615/61028 [02:39<09:48, 85.71it/s]\u001b[A\n",
      " 17%|█▋        | 10624/61028 [02:39<09:49, 85.56it/s]\u001b[A\n",
      " 17%|█▋        | 10633/61028 [02:39<09:49, 85.43it/s]\u001b[A\n",
      " 17%|█▋        | 10642/61028 [02:39<10:05, 83.15it/s]\u001b[A\n",
      " 17%|█▋        | 10651/61028 [02:39<10:11, 82.34it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10661/61028 [02:39<09:43, 86.37it/s]\u001b[A\n",
      " 17%|█▋        | 10671/61028 [02:39<09:35, 87.46it/s]\u001b[A\n",
      " 18%|█▊        | 10680/61028 [02:40<09:53, 84.84it/s]\u001b[A\n",
      " 18%|█▊        | 10689/61028 [02:40<09:58, 84.09it/s]\u001b[A\n",
      " 18%|█▊        | 10698/61028 [02:40<10:15, 81.74it/s]\u001b[A\n",
      " 18%|█▊        | 10707/61028 [02:40<10:51, 77.25it/s]\u001b[A\n",
      " 18%|█▊        | 10717/61028 [02:40<10:15, 81.69it/s]\u001b[A\n",
      " 18%|█▊        | 10727/61028 [02:40<09:44, 86.00it/s]\u001b[A\n",
      " 18%|█▊        | 10737/61028 [02:40<09:34, 87.48it/s]\u001b[A\n",
      " 18%|█▊        | 10746/61028 [02:40<09:40, 86.64it/s]\u001b[A\n",
      " 18%|█▊        | 10755/61028 [02:40<10:14, 81.83it/s]\u001b[A\n",
      " 18%|█▊        | 10764/61028 [02:41<10:21, 80.87it/s]\u001b[A\n",
      " 18%|█▊        | 10776/61028 [02:41<09:29, 88.24it/s]\u001b[A\n",
      " 18%|█▊        | 10786/61028 [02:41<09:36, 87.22it/s]\u001b[A\n",
      " 18%|█▊        | 10795/61028 [02:41<10:02, 83.41it/s]\u001b[A\n",
      " 18%|█▊        | 10804/61028 [02:41<10:33, 79.25it/s]\u001b[A\n",
      " 18%|█▊        | 10813/61028 [02:41<11:43, 71.34it/s]\u001b[A\n",
      " 18%|█▊        | 10822/61028 [02:41<11:10, 74.91it/s]\u001b[A\n",
      " 18%|█▊        | 10831/61028 [02:41<11:29, 72.80it/s]\u001b[A\n",
      " 18%|█▊        | 10839/61028 [02:42<18:07, 46.17it/s]\u001b[A\n",
      " 18%|█▊        | 10846/61028 [02:42<16:19, 51.24it/s]\u001b[A\n",
      " 18%|█▊        | 10853/61028 [02:42<15:08, 55.21it/s]\u001b[A\n",
      " 18%|█▊        | 10862/61028 [02:42<13:33, 61.70it/s]\u001b[A\n",
      " 18%|█▊        | 10871/61028 [02:42<12:24, 67.35it/s]\u001b[A\n",
      " 18%|█▊        | 10879/61028 [02:42<12:12, 68.43it/s]\u001b[A\n",
      " 18%|█▊        | 10889/61028 [02:42<11:17, 74.01it/s]\u001b[A\n",
      " 18%|█▊        | 10899/61028 [02:42<10:36, 78.81it/s]\u001b[A\n",
      " 18%|█▊        | 10908/61028 [02:43<11:11, 74.61it/s]\u001b[A\n",
      " 18%|█▊        | 10917/61028 [02:43<10:44, 77.73it/s]\u001b[A\n",
      " 18%|█▊        | 10926/61028 [02:43<11:34, 72.18it/s]\u001b[A\n",
      " 18%|█▊        | 10937/61028 [02:43<10:48, 77.30it/s]\u001b[A\n",
      " 18%|█▊        | 10946/61028 [02:43<10:46, 77.51it/s]\u001b[A\n",
      " 18%|█▊        | 10955/61028 [02:43<10:21, 80.52it/s]\u001b[A\n",
      " 18%|█▊        | 10966/61028 [02:43<09:36, 86.90it/s]\u001b[A\n",
      " 18%|█▊        | 10975/61028 [02:43<09:46, 85.33it/s]\u001b[A\n",
      " 18%|█▊        | 10986/61028 [02:44<09:10, 90.87it/s]\u001b[A\n",
      " 18%|█▊        | 10996/61028 [02:44<09:15, 90.00it/s]\u001b[A\n",
      " 18%|█▊        | 11006/61028 [02:44<09:30, 87.72it/s]\u001b[A\n",
      " 18%|█▊        | 11017/61028 [02:44<09:01, 92.43it/s]\u001b[A\n",
      " 18%|█▊        | 11027/61028 [02:44<09:44, 85.50it/s]\u001b[A\n",
      " 18%|█▊        | 11036/61028 [02:44<09:57, 83.71it/s]\u001b[A\n",
      " 18%|█▊        | 11045/61028 [02:44<10:28, 79.50it/s]\u001b[A\n",
      " 18%|█▊        | 11056/61028 [02:44<09:37, 86.47it/s]\u001b[A\n",
      " 18%|█▊        | 11065/61028 [02:44<09:41, 85.93it/s]\u001b[A\n",
      " 18%|█▊        | 11076/61028 [02:45<09:09, 90.90it/s]\u001b[A\n",
      " 18%|█▊        | 11086/61028 [02:45<09:13, 90.20it/s]\u001b[A\n",
      " 18%|█▊        | 11096/61028 [02:45<09:50, 84.57it/s]\u001b[A\n",
      " 18%|█▊        | 11107/61028 [02:45<09:15, 89.83it/s]\u001b[A\n",
      " 18%|█▊        | 11117/61028 [02:45<09:14, 89.99it/s]\u001b[A\n",
      " 18%|█▊        | 11127/61028 [02:45<09:28, 87.81it/s]\u001b[A\n",
      " 18%|█▊        | 11136/61028 [02:45<09:33, 86.97it/s]\u001b[A\n",
      " 18%|█▊        | 11146/61028 [02:45<09:15, 89.78it/s]\u001b[A\n",
      " 18%|█▊        | 11156/61028 [02:45<09:45, 85.25it/s]\u001b[A\n",
      " 18%|█▊        | 11165/61028 [02:46<10:38, 78.12it/s]\u001b[A\n",
      " 18%|█▊        | 11175/61028 [02:46<10:07, 82.11it/s]\u001b[A\n",
      " 18%|█▊        | 11184/61028 [02:46<09:53, 83.95it/s]\u001b[A\n",
      " 18%|█▊        | 11195/61028 [02:46<09:19, 89.04it/s]\u001b[A\n",
      " 18%|█▊        | 11205/61028 [02:46<10:08, 81.87it/s]\u001b[A\n",
      " 18%|█▊        | 11214/61028 [02:46<10:07, 81.94it/s]\u001b[A\n",
      " 18%|█▊        | 11223/61028 [02:46<10:50, 76.58it/s]\u001b[A\n",
      " 18%|█▊        | 11236/61028 [02:46<09:34, 86.68it/s]\u001b[A\n",
      " 18%|█▊        | 11246/61028 [02:47<09:46, 84.95it/s]\u001b[A\n",
      " 18%|█▊        | 11255/61028 [02:47<17:11, 48.23it/s]\u001b[A\n",
      " 18%|█▊        | 11267/61028 [02:47<14:20, 57.83it/s]\u001b[A\n",
      " 18%|█▊        | 11276/61028 [02:47<12:51, 64.47it/s]\u001b[A\n",
      " 18%|█▊        | 11285/61028 [02:47<12:23, 66.88it/s]\u001b[A\n",
      " 19%|█▊        | 11295/61028 [02:47<11:11, 74.09it/s]\u001b[A\n",
      " 19%|█▊        | 11305/61028 [02:47<10:31, 78.75it/s]\u001b[A\n",
      " 19%|█▊        | 11316/61028 [02:48<09:39, 85.78it/s]\u001b[A\n",
      " 19%|█▊        | 11326/61028 [02:48<09:22, 88.30it/s]\u001b[A\n",
      " 19%|█▊        | 11336/61028 [02:48<09:32, 86.74it/s]\u001b[A\n",
      " 19%|█▊        | 11346/61028 [02:48<09:33, 86.56it/s]\u001b[A\n",
      " 19%|█▊        | 11357/61028 [02:48<09:08, 90.63it/s]\u001b[A\n",
      " 19%|█▊        | 11367/61028 [02:48<09:49, 84.24it/s]\u001b[A\n",
      " 19%|█▊        | 11376/61028 [02:48<10:20, 80.04it/s]\u001b[A\n",
      " 19%|█▊        | 11388/61028 [02:48<09:24, 87.97it/s]\u001b[A\n",
      " 19%|█▊        | 11398/61028 [02:48<09:11, 89.95it/s]\u001b[A\n",
      " 19%|█▊        | 11408/61028 [02:49<09:20, 88.57it/s]\u001b[A\n",
      " 19%|█▊        | 11418/61028 [02:49<09:08, 90.52it/s]\u001b[A\n",
      " 19%|█▊        | 11428/61028 [02:49<09:45, 84.69it/s]\u001b[A\n",
      " 19%|█▊        | 11438/61028 [02:49<09:21, 88.24it/s]\u001b[A\n",
      " 19%|█▉        | 11447/61028 [02:49<10:13, 80.82it/s]\u001b[A\n",
      " 19%|█▉        | 11456/61028 [02:49<10:20, 79.84it/s]\u001b[A\n",
      " 19%|█▉        | 11465/61028 [02:49<10:44, 76.90it/s]\u001b[A\n",
      " 19%|█▉        | 11473/61028 [02:50<17:17, 47.79it/s]\u001b[A\n",
      " 19%|█▉        | 11480/61028 [02:50<16:48, 49.14it/s]\u001b[A\n",
      " 19%|█▉        | 11488/61028 [02:50<14:59, 55.10it/s]\u001b[A\n",
      " 19%|█▉        | 11495/61028 [02:50<14:26, 57.15it/s]\u001b[A\n",
      " 19%|█▉        | 11504/61028 [02:50<13:01, 63.39it/s]\u001b[A\n",
      " 19%|█▉        | 11512/61028 [02:50<12:45, 64.65it/s]\u001b[A\n",
      " 19%|█▉        | 11519/61028 [02:50<12:28, 66.14it/s]\u001b[A\n",
      " 19%|█▉        | 11529/61028 [02:50<11:14, 73.36it/s]\u001b[A\n",
      " 19%|█▉        | 11537/61028 [02:51<11:37, 70.99it/s]\u001b[A\n",
      " 19%|█▉        | 11548/61028 [02:51<10:27, 78.79it/s]\u001b[A\n",
      " 19%|█▉        | 11557/61028 [02:51<10:37, 77.61it/s]\u001b[A\n",
      " 19%|█▉        | 11567/61028 [02:51<10:21, 79.53it/s]\u001b[A\n",
      " 19%|█▉        | 11578/61028 [02:51<09:31, 86.56it/s]\u001b[A\n",
      " 19%|█▉        | 11588/61028 [02:51<09:31, 86.47it/s]\u001b[A\n",
      " 19%|█▉        | 11597/61028 [02:51<09:28, 87.03it/s]\u001b[A\n",
      " 19%|█▉        | 11606/61028 [02:51<09:58, 82.62it/s]\u001b[A\n",
      " 19%|█▉        | 11615/61028 [02:51<09:54, 83.10it/s]\u001b[A\n",
      " 19%|█▉        | 11624/61028 [02:52<09:52, 83.43it/s]\u001b[A\n",
      " 19%|█▉        | 11633/61028 [02:52<10:39, 77.25it/s]\u001b[A\n",
      " 19%|█▉        | 11641/61028 [02:52<17:23, 47.35it/s]\u001b[A\n",
      " 19%|█▉        | 11650/61028 [02:52<15:04, 54.58it/s]\u001b[A\n",
      " 19%|█▉        | 11662/61028 [02:52<12:43, 64.67it/s]\u001b[A\n",
      " 19%|█▉        | 11671/61028 [02:52<12:22, 66.51it/s]\u001b[A\n",
      " 19%|█▉        | 11681/61028 [02:52<11:12, 73.43it/s]\u001b[A\n",
      " 19%|█▉        | 11691/61028 [02:53<10:48, 76.09it/s]\u001b[A\n",
      " 19%|█▉        | 11700/61028 [02:53<10:24, 79.03it/s]\u001b[A\n",
      " 19%|█▉        | 11709/61028 [02:53<10:28, 78.43it/s]\u001b[A\n",
      " 19%|█▉        | 11718/61028 [02:53<10:36, 77.45it/s]\u001b[A\n",
      " 19%|█▉        | 11731/61028 [02:53<09:28, 86.77it/s]\u001b[A\n",
      " 19%|█▉        | 11741/61028 [02:53<10:03, 81.65it/s]\u001b[A\n",
      " 19%|█▉        | 11750/61028 [02:53<10:14, 80.23it/s]\u001b[A\n",
      " 19%|█▉        | 11759/61028 [02:53<10:19, 79.51it/s]\u001b[A\n",
      " 19%|█▉        | 11768/61028 [02:53<10:37, 77.25it/s]\u001b[A\n",
      " 19%|█▉        | 11779/61028 [02:54<09:50, 83.35it/s]\u001b[A\n",
      " 19%|█▉        | 11790/61028 [02:54<09:24, 87.27it/s]\u001b[A\n",
      " 19%|█▉        | 11799/61028 [02:54<10:30, 78.03it/s]\u001b[A\n",
      " 19%|█▉        | 11809/61028 [02:54<10:05, 81.31it/s]\u001b[A\n",
      " 19%|█▉        | 11818/61028 [02:54<10:44, 76.40it/s]\u001b[A\n",
      " 19%|█▉        | 11826/61028 [02:54<11:54, 68.89it/s]\u001b[A\n",
      " 19%|█▉        | 11834/61028 [02:54<11:40, 70.19it/s]\u001b[A\n",
      " 19%|█▉        | 11843/61028 [02:54<11:46, 69.65it/s]\u001b[A\n",
      " 19%|█▉        | 11852/61028 [02:55<11:07, 73.69it/s]\u001b[A\n",
      " 19%|█▉        | 11860/61028 [02:55<11:25, 71.69it/s]\u001b[A\n",
      " 19%|█▉        | 11869/61028 [02:55<10:45, 76.19it/s]\u001b[A\n",
      " 19%|█▉        | 11877/61028 [02:55<10:39, 76.81it/s]\u001b[A\n",
      " 19%|█▉        | 11888/61028 [02:55<09:56, 82.35it/s]\u001b[A\n",
      " 19%|█▉        | 11897/61028 [02:55<10:02, 81.52it/s]\u001b[A\n",
      " 20%|█▉        | 11906/61028 [02:55<10:12, 80.26it/s]\u001b[A\n",
      " 20%|█▉        | 11917/61028 [02:55<09:40, 84.59it/s]\u001b[A\n",
      " 20%|█▉        | 11927/61028 [02:55<09:20, 87.67it/s]\u001b[A\n",
      " 20%|█▉        | 11939/61028 [02:56<08:49, 92.65it/s]\u001b[A\n",
      " 20%|█▉        | 11949/61028 [02:56<09:09, 89.36it/s]\u001b[A\n",
      " 20%|█▉        | 11961/61028 [02:56<08:53, 91.93it/s]\u001b[A\n",
      " 20%|█▉        | 11971/61028 [02:56<08:58, 91.09it/s]\u001b[A\n",
      " 20%|█▉        | 11983/61028 [02:56<08:31, 95.97it/s]\u001b[A\n",
      " 20%|█▉        | 11996/61028 [02:56<08:01, 101.83it/s]\u001b[A\n",
      " 20%|█▉        | 12007/61028 [02:56<08:45, 93.32it/s] \u001b[A\n",
      " 20%|█▉        | 12017/61028 [02:56<09:07, 89.45it/s]\u001b[A\n",
      " 20%|█▉        | 12027/61028 [02:57<10:05, 80.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 12036/61028 [02:57<10:15, 79.55it/s]\u001b[A\n",
      " 20%|█▉        | 12045/61028 [02:57<18:02, 45.25it/s]\u001b[A\n",
      " 20%|█▉        | 12053/61028 [02:57<15:41, 52.02it/s]\u001b[A\n",
      " 20%|█▉        | 12062/61028 [02:57<13:45, 59.31it/s]\u001b[A\n",
      " 20%|█▉        | 12074/61028 [02:57<11:40, 69.88it/s]\u001b[A\n",
      " 20%|█▉        | 12085/61028 [02:57<10:31, 77.52it/s]\u001b[A\n",
      " 20%|█▉        | 12095/61028 [02:58<10:45, 75.83it/s]\u001b[A\n",
      " 20%|█▉        | 12106/61028 [02:58<10:09, 80.26it/s]\u001b[A\n",
      " 20%|█▉        | 12115/61028 [02:58<10:10, 80.17it/s]\u001b[A\n",
      " 20%|█▉        | 12126/61028 [02:58<09:38, 84.55it/s]\u001b[A\n",
      " 20%|█▉        | 12135/61028 [02:58<10:36, 76.85it/s]\u001b[A\n",
      " 20%|█▉        | 12146/61028 [02:58<09:49, 82.88it/s]\u001b[A\n",
      " 20%|█▉        | 12155/61028 [02:58<09:41, 84.11it/s]\u001b[A\n",
      " 20%|█▉        | 12167/61028 [02:58<08:53, 91.53it/s]\u001b[A\n",
      " 20%|█▉        | 12179/61028 [02:59<08:24, 96.91it/s]\u001b[A\n",
      " 20%|█▉        | 12190/61028 [02:59<08:30, 95.64it/s]\u001b[A\n",
      " 20%|█▉        | 12200/61028 [02:59<08:53, 91.45it/s]\u001b[A\n",
      " 20%|██        | 12210/61028 [02:59<08:48, 92.33it/s]\u001b[A\n",
      " 20%|██        | 12220/61028 [02:59<09:00, 90.23it/s]\u001b[A\n",
      " 20%|██        | 12230/61028 [02:59<10:09, 80.07it/s]\u001b[A\n",
      " 20%|██        | 12239/61028 [02:59<11:09, 72.88it/s]\u001b[A\n",
      " 20%|██        | 12249/61028 [02:59<10:20, 78.56it/s]\u001b[A\n",
      " 20%|██        | 12259/61028 [03:00<09:50, 82.58it/s]\u001b[A\n",
      " 20%|██        | 12269/61028 [03:00<09:30, 85.41it/s]\u001b[A\n",
      " 20%|██        | 12278/61028 [03:00<09:44, 83.47it/s]\u001b[A\n",
      " 20%|██        | 12288/61028 [03:00<09:22, 86.64it/s]\u001b[A\n",
      " 20%|██        | 12298/61028 [03:00<08:59, 90.26it/s]\u001b[A\n",
      " 20%|██        | 12308/61028 [03:00<08:58, 90.52it/s]\u001b[A\n",
      " 20%|██        | 12318/61028 [03:00<08:51, 91.60it/s]\u001b[A\n",
      " 20%|██        | 12328/61028 [03:00<09:21, 86.68it/s]\u001b[A\n",
      " 20%|██        | 12338/61028 [03:00<09:00, 90.06it/s]\u001b[A\n",
      " 20%|██        | 12348/61028 [03:01<09:31, 85.21it/s]\u001b[A\n",
      " 20%|██        | 12357/61028 [03:01<10:31, 77.04it/s]\u001b[A\n",
      " 20%|██        | 12367/61028 [03:01<09:52, 82.08it/s]\u001b[A\n",
      " 20%|██        | 12377/61028 [03:01<09:22, 86.48it/s]\u001b[A\n",
      " 20%|██        | 12386/61028 [03:01<09:58, 81.30it/s]\u001b[A\n",
      " 20%|██        | 12395/61028 [03:01<09:53, 81.99it/s]\u001b[A\n",
      " 20%|██        | 12404/61028 [03:01<10:02, 80.74it/s]\u001b[A\n",
      " 20%|██        | 12413/61028 [03:01<10:00, 80.91it/s]\u001b[A\n",
      " 20%|██        | 12423/61028 [03:01<09:39, 83.88it/s]\u001b[A\n",
      " 20%|██        | 12432/61028 [03:02<09:56, 81.44it/s]\u001b[A\n",
      " 20%|██        | 12443/61028 [03:02<09:16, 87.37it/s]\u001b[A\n",
      " 20%|██        | 12452/61028 [03:02<09:38, 83.97it/s]\u001b[A\n",
      " 20%|██        | 12461/61028 [03:02<16:00, 50.59it/s]\u001b[A\n",
      " 20%|██        | 12468/61028 [03:02<15:39, 51.68it/s]\u001b[A\n",
      " 20%|██        | 12477/61028 [03:02<13:46, 58.71it/s]\u001b[A\n",
      " 20%|██        | 12487/61028 [03:02<12:22, 65.39it/s]\u001b[A\n",
      " 20%|██        | 12497/61028 [03:03<11:12, 72.17it/s]\u001b[A\n",
      " 20%|██        | 12507/61028 [03:03<10:41, 75.59it/s]\u001b[A\n",
      " 21%|██        | 12518/61028 [03:03<09:48, 82.49it/s]\u001b[A\n",
      " 21%|██        | 12527/61028 [03:03<10:04, 80.24it/s]\u001b[A\n",
      " 21%|██        | 12539/61028 [03:03<09:18, 86.75it/s]\u001b[A\n",
      " 21%|██        | 12549/61028 [03:03<09:02, 89.30it/s]\u001b[A\n",
      " 21%|██        | 12559/61028 [03:03<09:13, 87.50it/s]\u001b[A\n",
      " 21%|██        | 12570/61028 [03:03<09:03, 89.22it/s]\u001b[A\n",
      " 21%|██        | 12580/61028 [03:03<09:13, 87.54it/s]\u001b[A\n",
      " 21%|██        | 12591/61028 [03:04<08:57, 90.15it/s]\u001b[A\n",
      " 21%|██        | 12601/61028 [03:04<09:48, 82.32it/s]\u001b[A\n",
      " 21%|██        | 12612/61028 [03:04<09:04, 88.97it/s]\u001b[A\n",
      " 21%|██        | 12622/61028 [03:04<10:04, 80.08it/s]\u001b[A\n",
      " 21%|██        | 12631/61028 [03:04<11:13, 71.84it/s]\u001b[A\n",
      " 21%|██        | 12641/61028 [03:04<10:33, 76.38it/s]\u001b[A\n",
      " 21%|██        | 12651/61028 [03:04<09:49, 82.08it/s]\u001b[A\n",
      " 21%|██        | 12661/61028 [03:04<09:27, 85.28it/s]\u001b[A\n",
      " 21%|██        | 12670/61028 [03:05<09:22, 85.94it/s]\u001b[A\n",
      " 21%|██        | 12679/61028 [03:05<10:09, 79.37it/s]\u001b[A\n",
      " 21%|██        | 12689/61028 [03:05<09:39, 83.48it/s]\u001b[A\n",
      " 21%|██        | 12698/61028 [03:05<10:02, 80.23it/s]\u001b[A\n",
      " 21%|██        | 12709/61028 [03:05<09:23, 85.70it/s]\u001b[A\n",
      " 21%|██        | 12718/61028 [03:05<09:19, 86.33it/s]\u001b[A\n",
      " 21%|██        | 12728/61028 [03:05<08:57, 89.81it/s]\u001b[A\n",
      " 21%|██        | 12738/61028 [03:05<08:45, 91.86it/s]\u001b[A\n",
      " 21%|██        | 12748/61028 [03:05<09:11, 87.59it/s]\u001b[A\n",
      " 21%|██        | 12759/61028 [03:06<08:49, 91.21it/s]\u001b[A\n",
      " 21%|██        | 12769/61028 [03:06<09:13, 87.22it/s]\u001b[A\n",
      " 21%|██        | 12778/61028 [03:06<09:15, 86.85it/s]\u001b[A\n",
      " 21%|██        | 12788/61028 [03:06<09:06, 88.34it/s]\u001b[A\n",
      " 21%|██        | 12800/61028 [03:06<08:26, 95.28it/s]\u001b[A\n",
      " 21%|██        | 12810/61028 [03:06<08:26, 95.20it/s]\u001b[A\n",
      " 21%|██        | 12820/61028 [03:06<08:43, 92.06it/s]\u001b[A\n",
      " 21%|██        | 12830/61028 [03:06<09:03, 88.67it/s]\u001b[A\n",
      " 21%|██        | 12840/61028 [03:06<08:59, 89.24it/s]\u001b[A\n",
      " 21%|██        | 12852/61028 [03:07<08:33, 93.91it/s]\u001b[A\n",
      " 21%|██        | 12862/61028 [03:07<09:02, 88.75it/s]\u001b[A\n",
      " 21%|██        | 12872/61028 [03:07<09:13, 86.94it/s]\u001b[A\n",
      " 21%|██        | 12881/61028 [03:07<09:36, 83.55it/s]\u001b[A\n",
      " 21%|██        | 12890/61028 [03:07<17:05, 46.92it/s]\u001b[A\n",
      " 21%|██        | 12898/61028 [03:07<15:32, 51.61it/s]\u001b[A\n",
      " 21%|██        | 12908/61028 [03:08<13:21, 60.03it/s]\u001b[A\n",
      " 21%|██        | 12918/61028 [03:08<11:57, 67.06it/s]\u001b[A\n",
      " 21%|██        | 12928/61028 [03:08<10:58, 73.02it/s]\u001b[A\n",
      " 21%|██        | 12938/61028 [03:08<10:21, 77.35it/s]\u001b[A\n",
      " 21%|██        | 12948/61028 [03:08<09:42, 82.58it/s]\u001b[A\n",
      " 21%|██        | 12957/61028 [03:08<10:34, 75.77it/s]\u001b[A\n",
      " 21%|██        | 12967/61028 [03:08<09:53, 80.93it/s]\u001b[A\n",
      " 21%|██▏       | 12976/61028 [03:08<09:52, 81.14it/s]\u001b[A\n",
      " 21%|██▏       | 12986/61028 [03:08<09:22, 85.38it/s]\u001b[A\n",
      " 21%|██▏       | 12995/61028 [03:09<09:15, 86.51it/s]\u001b[A\n",
      " 21%|██▏       | 13004/61028 [03:09<09:13, 86.71it/s]\u001b[A\n",
      " 21%|██▏       | 13013/61028 [03:09<09:26, 84.75it/s]\u001b[A\n",
      " 21%|██▏       | 13023/61028 [03:09<09:11, 87.11it/s]\u001b[A\n",
      " 21%|██▏       | 13034/61028 [03:09<08:46, 91.12it/s]\u001b[A\n",
      " 21%|██▏       | 13045/61028 [03:09<08:24, 95.02it/s]\u001b[A\n",
      " 21%|██▏       | 13055/61028 [03:09<09:05, 87.96it/s]\u001b[A\n",
      " 21%|██▏       | 13067/61028 [03:09<08:23, 95.19it/s]\u001b[A\n",
      " 21%|██▏       | 13077/61028 [03:09<08:45, 91.33it/s]\u001b[A\n",
      " 21%|██▏       | 13087/61028 [03:10<08:45, 91.16it/s]\u001b[A\n",
      " 21%|██▏       | 13097/61028 [03:10<09:24, 84.95it/s]\u001b[A\n",
      " 21%|██▏       | 13106/61028 [03:10<09:25, 84.80it/s]\u001b[A\n",
      " 21%|██▏       | 13115/61028 [03:10<09:49, 81.28it/s]\u001b[A\n",
      " 22%|██▏       | 13125/61028 [03:10<09:37, 82.99it/s]\u001b[A\n",
      " 22%|██▏       | 13135/61028 [03:10<09:20, 85.47it/s]\u001b[A\n",
      " 22%|██▏       | 13144/61028 [03:10<09:59, 79.82it/s]\u001b[A\n",
      " 22%|██▏       | 13153/61028 [03:10<09:42, 82.23it/s]\u001b[A\n",
      " 22%|██▏       | 13162/61028 [03:10<09:27, 84.29it/s]\u001b[A\n",
      " 22%|██▏       | 13171/61028 [03:11<09:23, 84.94it/s]\u001b[A\n",
      " 22%|██▏       | 13180/61028 [03:11<09:33, 83.47it/s]\u001b[A\n",
      " 22%|██▏       | 13189/61028 [03:11<09:41, 82.27it/s]\u001b[A\n",
      " 22%|██▏       | 13199/61028 [03:11<09:21, 85.23it/s]\u001b[A\n",
      " 22%|██▏       | 13210/61028 [03:11<09:02, 88.09it/s]\u001b[A\n",
      " 22%|██▏       | 13219/61028 [03:11<09:09, 86.93it/s]\u001b[A\n",
      " 22%|██▏       | 13228/61028 [03:11<09:07, 87.38it/s]\u001b[A\n",
      " 22%|██▏       | 13239/61028 [03:11<08:35, 92.74it/s]\u001b[A\n",
      " 22%|██▏       | 13249/61028 [03:11<08:59, 88.52it/s]\u001b[A\n",
      " 22%|██▏       | 13258/61028 [03:12<09:23, 84.85it/s]\u001b[A\n",
      " 22%|██▏       | 13268/61028 [03:12<09:14, 86.15it/s]\u001b[A\n",
      " 22%|██▏       | 13278/61028 [03:12<09:03, 87.82it/s]\u001b[A\n",
      " 22%|██▏       | 13287/61028 [03:12<08:59, 88.42it/s]\u001b[A\n",
      " 22%|██▏       | 13298/61028 [03:12<08:32, 93.11it/s]\u001b[A\n",
      " 22%|██▏       | 13308/61028 [03:12<09:30, 83.60it/s]\u001b[A\n",
      " 22%|██▏       | 13317/61028 [03:12<15:35, 51.00it/s]\u001b[A\n",
      " 22%|██▏       | 13326/61028 [03:13<13:38, 58.31it/s]\u001b[A\n",
      " 22%|██▏       | 13336/61028 [03:13<11:56, 66.58it/s]\u001b[A\n",
      " 22%|██▏       | 13346/61028 [03:13<10:55, 72.71it/s]\u001b[A\n",
      " 22%|██▏       | 13357/61028 [03:13<10:02, 79.07it/s]\u001b[A\n",
      " 22%|██▏       | 13366/61028 [03:13<10:17, 77.17it/s]\u001b[A\n",
      " 22%|██▏       | 13375/61028 [03:13<10:46, 73.74it/s]\u001b[A\n",
      " 22%|██▏       | 13384/61028 [03:13<10:54, 72.83it/s]\u001b[A\n",
      " 22%|██▏       | 13393/61028 [03:13<10:26, 76.00it/s]\u001b[A\n",
      " 22%|██▏       | 13404/61028 [03:14<09:47, 81.00it/s]\u001b[A\n",
      " 22%|██▏       | 13413/61028 [03:14<09:35, 82.70it/s]\u001b[A\n",
      " 22%|██▏       | 13426/61028 [03:14<08:43, 90.97it/s]\u001b[A\n",
      " 22%|██▏       | 13436/61028 [03:14<09:21, 84.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 13445/61028 [03:14<09:29, 83.57it/s]\u001b[A\n",
      " 22%|██▏       | 13454/61028 [03:14<10:05, 78.52it/s]\u001b[A\n",
      " 22%|██▏       | 13463/61028 [03:14<10:00, 79.27it/s]\u001b[A\n",
      " 22%|██▏       | 13473/61028 [03:14<09:29, 83.48it/s]\u001b[A\n",
      " 22%|██▏       | 13482/61028 [03:14<09:34, 82.78it/s]\u001b[A\n",
      " 22%|██▏       | 13491/61028 [03:15<09:32, 83.01it/s]\u001b[A\n",
      " 22%|██▏       | 13500/61028 [03:15<09:42, 81.57it/s]\u001b[A\n",
      " 22%|██▏       | 13510/61028 [03:15<09:15, 85.61it/s]\u001b[A\n",
      " 22%|██▏       | 13519/61028 [03:15<09:27, 83.70it/s]\u001b[A\n",
      " 22%|██▏       | 13528/61028 [03:15<09:15, 85.48it/s]\u001b[A\n",
      " 22%|██▏       | 13538/61028 [03:15<09:05, 87.00it/s]\u001b[A\n",
      " 22%|██▏       | 13548/61028 [03:15<08:58, 88.14it/s]\u001b[A\n",
      " 22%|██▏       | 13558/61028 [03:15<08:50, 89.40it/s]\u001b[A\n",
      " 22%|██▏       | 13567/61028 [03:15<09:05, 87.02it/s]\u001b[A\n",
      " 22%|██▏       | 13577/61028 [03:16<08:50, 89.49it/s]\u001b[A\n",
      " 22%|██▏       | 13586/61028 [03:16<09:10, 86.13it/s]\u001b[A\n",
      " 22%|██▏       | 13596/61028 [03:16<09:07, 86.69it/s]\u001b[A\n",
      " 22%|██▏       | 13605/61028 [03:16<09:04, 87.07it/s]\u001b[A\n",
      " 22%|██▏       | 13614/61028 [03:16<09:15, 85.31it/s]\u001b[A\n",
      " 22%|██▏       | 13623/61028 [03:16<09:30, 83.08it/s]\u001b[A\n",
      " 22%|██▏       | 13633/61028 [03:16<09:03, 87.14it/s]\u001b[A\n",
      " 22%|██▏       | 13643/61028 [03:16<08:55, 88.44it/s]\u001b[A\n",
      " 22%|██▏       | 13652/61028 [03:16<09:13, 85.53it/s]\u001b[A\n",
      " 22%|██▏       | 13665/61028 [03:17<08:29, 93.05it/s]\u001b[A\n",
      " 22%|██▏       | 13675/61028 [03:17<08:18, 94.93it/s]\u001b[A\n",
      " 22%|██▏       | 13685/61028 [03:17<08:15, 95.64it/s]\u001b[A\n",
      " 22%|██▏       | 13695/61028 [03:17<08:11, 96.26it/s]\u001b[A\n",
      " 22%|██▏       | 13705/61028 [03:17<08:21, 94.46it/s]\u001b[A\n",
      " 22%|██▏       | 13715/61028 [03:17<08:16, 95.20it/s]\u001b[A\n",
      " 22%|██▏       | 13725/61028 [03:17<08:30, 92.73it/s]\u001b[A\n",
      " 23%|██▎       | 13735/61028 [03:17<13:04, 60.27it/s]\u001b[A\n",
      " 23%|██▎       | 13743/61028 [03:18<13:36, 57.89it/s]\u001b[A\n",
      " 23%|██▎       | 13753/61028 [03:18<12:08, 64.87it/s]\u001b[A\n",
      " 23%|██▎       | 13762/61028 [03:18<11:09, 70.59it/s]\u001b[A\n",
      " 23%|██▎       | 13771/61028 [03:18<10:28, 75.18it/s]\u001b[A\n",
      " 23%|██▎       | 13780/61028 [03:18<10:02, 78.42it/s]\u001b[A\n",
      " 23%|██▎       | 13789/61028 [03:18<09:52, 79.68it/s]\u001b[A\n",
      " 23%|██▎       | 13800/61028 [03:18<09:14, 85.18it/s]\u001b[A\n",
      " 23%|██▎       | 13809/61028 [03:18<09:14, 85.21it/s]\u001b[A\n",
      " 23%|██▎       | 13821/61028 [03:18<08:31, 92.29it/s]\u001b[A\n",
      " 23%|██▎       | 13831/61028 [03:19<09:04, 86.61it/s]\u001b[A\n",
      " 23%|██▎       | 13841/61028 [03:19<09:04, 86.73it/s]\u001b[A\n",
      " 23%|██▎       | 13850/61028 [03:19<09:00, 87.32it/s]\u001b[A\n",
      " 23%|██▎       | 13860/61028 [03:19<08:53, 88.38it/s]\u001b[A\n",
      " 23%|██▎       | 13869/61028 [03:19<09:07, 86.12it/s]\u001b[A\n",
      " 23%|██▎       | 13878/61028 [03:19<09:09, 85.75it/s]\u001b[A\n",
      " 23%|██▎       | 13887/61028 [03:19<09:30, 82.64it/s]\u001b[A\n",
      " 23%|██▎       | 13898/61028 [03:19<09:10, 85.65it/s]\u001b[A\n",
      " 23%|██▎       | 13907/61028 [03:19<09:13, 85.12it/s]\u001b[A\n",
      " 23%|██▎       | 13917/61028 [03:20<09:12, 85.33it/s]\u001b[A\n",
      " 23%|██▎       | 13926/61028 [03:20<09:41, 80.94it/s]\u001b[A\n",
      " 23%|██▎       | 13935/61028 [03:20<09:25, 83.27it/s]\u001b[A\n",
      " 23%|██▎       | 13944/61028 [03:20<09:32, 82.23it/s]\u001b[A\n",
      " 23%|██▎       | 13953/61028 [03:20<09:39, 81.19it/s]\u001b[A\n",
      " 23%|██▎       | 13965/61028 [03:20<08:53, 88.13it/s]\u001b[A\n",
      " 23%|██▎       | 13975/61028 [03:20<08:38, 90.77it/s]\u001b[A\n",
      " 23%|██▎       | 13985/61028 [03:20<08:30, 92.16it/s]\u001b[A\n",
      " 23%|██▎       | 13995/61028 [03:20<08:26, 92.88it/s]\u001b[A\n",
      " 23%|██▎       | 14005/61028 [03:21<08:31, 91.96it/s]\u001b[A\n",
      " 23%|██▎       | 14016/61028 [03:21<08:17, 94.43it/s]\u001b[A\n",
      " 23%|██▎       | 14028/61028 [03:21<07:59, 97.98it/s]\u001b[A\n",
      " 23%|██▎       | 14038/61028 [03:21<08:14, 94.97it/s]\u001b[A\n",
      " 23%|██▎       | 14048/61028 [03:21<08:23, 93.25it/s]\u001b[A\n",
      " 23%|██▎       | 14059/61028 [03:21<08:06, 96.53it/s]\u001b[A\n",
      " 23%|██▎       | 14069/61028 [03:21<08:20, 93.80it/s]\u001b[A\n",
      " 23%|██▎       | 14079/61028 [03:21<08:24, 92.97it/s]\u001b[A\n",
      " 23%|██▎       | 14089/61028 [03:21<08:26, 92.65it/s]\u001b[A\n",
      " 23%|██▎       | 14101/61028 [03:22<08:04, 96.82it/s]\u001b[A\n",
      " 23%|██▎       | 14111/61028 [03:22<08:15, 94.68it/s]\u001b[A\n",
      " 23%|██▎       | 14122/61028 [03:22<08:06, 96.35it/s]\u001b[A\n",
      " 23%|██▎       | 14133/61028 [03:22<08:01, 97.47it/s]\u001b[A\n",
      " 23%|██▎       | 14144/61028 [03:22<07:55, 98.54it/s]\u001b[A\n",
      " 23%|██▎       | 14154/61028 [03:22<08:14, 94.79it/s]\u001b[A\n",
      " 23%|██▎       | 14164/61028 [03:22<08:34, 91.11it/s]\u001b[A\n",
      " 23%|██▎       | 14175/61028 [03:22<08:46, 88.99it/s]\u001b[A\n",
      " 23%|██▎       | 14184/61028 [03:23<15:34, 50.14it/s]\u001b[A\n",
      " 23%|██▎       | 14194/61028 [03:23<13:15, 58.89it/s]\u001b[A\n",
      " 23%|██▎       | 14202/61028 [03:23<12:24, 62.88it/s]\u001b[A\n",
      " 23%|██▎       | 14214/61028 [03:23<10:47, 72.29it/s]\u001b[A\n",
      " 23%|██▎       | 14224/61028 [03:23<10:05, 77.36it/s]\u001b[A\n",
      " 23%|██▎       | 14233/61028 [03:23<09:40, 80.62it/s]\u001b[A\n",
      " 23%|██▎       | 14242/61028 [03:23<09:44, 80.02it/s]\u001b[A\n",
      " 23%|██▎       | 14251/61028 [03:23<10:02, 77.62it/s]\u001b[A\n",
      " 23%|██▎       | 14260/61028 [03:24<09:52, 78.94it/s]\u001b[A\n",
      " 23%|██▎       | 14273/61028 [03:24<08:54, 87.54it/s]\u001b[A\n",
      " 23%|██▎       | 14283/61028 [03:24<08:41, 89.69it/s]\u001b[A\n",
      " 23%|██▎       | 14293/61028 [03:24<08:45, 88.90it/s]\u001b[A\n",
      " 23%|██▎       | 14303/61028 [03:24<09:35, 81.17it/s]\u001b[A\n",
      " 23%|██▎       | 14312/61028 [03:24<10:01, 77.65it/s]\u001b[A\n",
      " 23%|██▎       | 14321/61028 [03:24<09:53, 78.69it/s]\u001b[A\n",
      " 23%|██▎       | 14331/61028 [03:24<09:32, 81.58it/s]\u001b[A\n",
      " 23%|██▎       | 14341/61028 [03:25<09:13, 84.40it/s]\u001b[A\n",
      " 24%|██▎       | 14351/61028 [03:25<08:52, 87.66it/s]\u001b[A\n",
      " 24%|██▎       | 14362/61028 [03:25<08:24, 92.43it/s]\u001b[A\n",
      " 24%|██▎       | 14374/61028 [03:25<07:51, 98.92it/s]\u001b[A\n",
      " 24%|██▎       | 14385/61028 [03:25<08:19, 93.30it/s]\u001b[A\n",
      " 24%|██▎       | 14395/61028 [03:25<08:42, 89.26it/s]\u001b[A\n",
      " 24%|██▎       | 14405/61028 [03:25<08:32, 90.97it/s]\u001b[A\n",
      " 24%|██▎       | 14416/61028 [03:25<08:12, 94.64it/s]\u001b[A\n",
      " 24%|██▎       | 14426/61028 [03:25<08:11, 94.74it/s]\u001b[A\n",
      " 24%|██▎       | 14436/61028 [03:26<08:04, 96.20it/s]\u001b[A\n",
      " 24%|██▎       | 14446/61028 [03:26<08:06, 95.79it/s]\u001b[A\n",
      " 24%|██▎       | 14456/61028 [03:26<08:12, 94.56it/s]\u001b[A\n",
      " 24%|██▎       | 14466/61028 [03:26<08:18, 93.41it/s]\u001b[A\n",
      " 24%|██▎       | 14476/61028 [03:26<08:58, 86.48it/s]\u001b[A\n",
      " 24%|██▎       | 14486/61028 [03:26<08:43, 88.95it/s]\u001b[A\n",
      " 24%|██▍       | 14495/61028 [03:26<08:42, 89.00it/s]\u001b[A\n",
      " 24%|██▍       | 14506/61028 [03:26<08:26, 91.78it/s]\u001b[A\n",
      " 24%|██▍       | 14516/61028 [03:26<08:49, 87.92it/s]\u001b[A\n",
      " 24%|██▍       | 14528/61028 [03:27<08:27, 91.58it/s]\u001b[A\n",
      " 24%|██▍       | 14538/61028 [03:27<08:22, 92.51it/s]\u001b[A\n",
      " 24%|██▍       | 14548/61028 [03:27<08:31, 90.80it/s]\u001b[A\n",
      " 24%|██▍       | 14558/61028 [03:27<08:32, 90.69it/s]\u001b[A\n",
      " 24%|██▍       | 14568/61028 [03:27<08:37, 89.76it/s]\u001b[A\n",
      " 24%|██▍       | 14578/61028 [03:27<08:42, 88.91it/s]\u001b[A\n",
      " 24%|██▍       | 14589/61028 [03:27<08:20, 92.72it/s]\u001b[A\n",
      " 24%|██▍       | 14599/61028 [03:27<08:39, 89.40it/s]\u001b[A\n",
      " 24%|██▍       | 14609/61028 [03:27<08:22, 92.32it/s]\u001b[A\n",
      " 24%|██▍       | 14619/61028 [03:28<14:22, 53.78it/s]\u001b[A\n",
      " 24%|██▍       | 14627/61028 [03:28<13:40, 56.53it/s]\u001b[A\n",
      " 24%|██▍       | 14636/61028 [03:28<12:22, 62.44it/s]\u001b[A\n",
      " 24%|██▍       | 14646/61028 [03:28<11:11, 69.02it/s]\u001b[A\n",
      " 24%|██▍       | 14655/61028 [03:28<10:31, 73.48it/s]\u001b[A\n",
      " 24%|██▍       | 14664/61028 [03:28<10:04, 76.71it/s]\u001b[A\n",
      " 24%|██▍       | 14674/61028 [03:28<09:35, 80.57it/s]\u001b[A\n",
      " 24%|██▍       | 14683/61028 [03:29<09:27, 81.66it/s]\u001b[A\n",
      " 24%|██▍       | 14693/61028 [03:29<09:22, 82.43it/s]\u001b[A\n",
      " 24%|██▍       | 14702/61028 [03:29<09:12, 83.91it/s]\u001b[A\n",
      " 24%|██▍       | 14711/61028 [03:29<09:06, 84.81it/s]\u001b[A\n",
      " 24%|██▍       | 14721/61028 [03:29<08:45, 88.16it/s]\u001b[A\n",
      " 24%|██▍       | 14730/61028 [03:29<10:03, 76.73it/s]\u001b[A\n",
      " 24%|██▍       | 14739/61028 [03:29<09:54, 77.89it/s]\u001b[A\n",
      " 24%|██▍       | 14751/61028 [03:29<08:53, 86.71it/s]\u001b[A\n",
      " 24%|██▍       | 14761/61028 [03:29<08:33, 90.10it/s]\u001b[A\n",
      " 24%|██▍       | 14772/61028 [03:30<08:17, 93.05it/s]\u001b[A\n",
      " 24%|██▍       | 14782/61028 [03:30<08:35, 89.79it/s]\u001b[A\n",
      " 24%|██▍       | 14793/61028 [03:30<08:11, 94.12it/s]\u001b[A\n",
      " 24%|██▍       | 14803/61028 [03:30<08:36, 89.55it/s]\u001b[A\n",
      " 24%|██▍       | 14813/61028 [03:30<09:03, 84.99it/s]\u001b[A\n",
      " 24%|██▍       | 14823/61028 [03:30<08:41, 88.62it/s]\u001b[A\n",
      " 24%|██▍       | 14834/61028 [03:30<08:14, 93.44it/s]\u001b[A\n",
      " 24%|██▍       | 14845/61028 [03:30<07:52, 97.74it/s]\u001b[A\n",
      " 24%|██▍       | 14855/61028 [03:30<07:55, 97.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 14866/61028 [03:31<07:46, 98.86it/s]\u001b[A\n",
      " 24%|██▍       | 14877/61028 [03:31<07:34, 101.57it/s]\u001b[A\n",
      " 24%|██▍       | 14888/61028 [03:31<07:41, 99.97it/s] \u001b[A\n",
      " 24%|██▍       | 14899/61028 [03:31<07:51, 97.77it/s]\u001b[A\n",
      " 24%|██▍       | 14909/61028 [03:31<07:50, 98.12it/s]\u001b[A\n",
      " 24%|██▍       | 14919/61028 [03:31<08:05, 95.03it/s]\u001b[A\n",
      " 24%|██▍       | 14930/61028 [03:31<07:45, 98.99it/s]\u001b[A\n",
      " 24%|██▍       | 14940/61028 [03:31<08:39, 88.65it/s]\u001b[A\n",
      " 24%|██▍       | 14950/61028 [03:31<08:45, 87.71it/s]\u001b[A\n",
      " 25%|██▍       | 14959/61028 [03:32<08:47, 87.32it/s]\u001b[A\n",
      " 25%|██▍       | 14970/61028 [03:32<08:19, 92.29it/s]\u001b[A\n",
      " 25%|██▍       | 14980/61028 [03:32<08:29, 90.44it/s]\u001b[A\n",
      " 25%|██▍       | 14990/61028 [03:32<08:46, 87.47it/s]\u001b[A\n",
      " 25%|██▍       | 14999/61028 [03:32<08:52, 86.50it/s]\u001b[A\n",
      " 25%|██▍       | 15008/61028 [03:32<08:48, 87.06it/s]\u001b[A\n",
      " 25%|██▍       | 15019/61028 [03:32<08:23, 91.40it/s]\u001b[A\n",
      " 25%|██▍       | 15029/61028 [03:32<08:29, 90.28it/s]\u001b[A\n",
      " 25%|██▍       | 15040/61028 [03:32<08:05, 94.67it/s]\u001b[A\n",
      " 25%|██▍       | 15051/61028 [03:33<07:57, 96.31it/s]\u001b[A\n",
      " 25%|██▍       | 15061/61028 [03:33<13:52, 55.22it/s]\u001b[A\n",
      " 25%|██▍       | 15070/61028 [03:33<12:21, 62.01it/s]\u001b[A\n",
      " 25%|██▍       | 15080/61028 [03:33<11:05, 69.01it/s]\u001b[A\n",
      " 25%|██▍       | 15089/61028 [03:33<11:30, 66.51it/s]\u001b[A\n",
      " 25%|██▍       | 15099/61028 [03:33<10:22, 73.73it/s]\u001b[A\n",
      " 25%|██▍       | 15111/61028 [03:33<09:14, 82.87it/s]\u001b[A\n",
      " 25%|██▍       | 15121/61028 [03:34<09:19, 81.98it/s]\u001b[A\n",
      " 25%|██▍       | 15130/61028 [03:34<09:21, 81.79it/s]\u001b[A\n",
      " 25%|██▍       | 15139/61028 [03:34<09:25, 81.15it/s]\u001b[A\n",
      " 25%|██▍       | 15152/61028 [03:34<08:23, 91.03it/s]\u001b[A\n",
      " 25%|██▍       | 15164/61028 [03:34<07:47, 98.08it/s]\u001b[A\n",
      " 25%|██▍       | 15175/61028 [03:34<07:53, 96.92it/s]\u001b[A\n",
      " 25%|██▍       | 15186/61028 [03:34<08:44, 87.41it/s]\u001b[A\n",
      " 25%|██▍       | 15196/61028 [03:34<08:43, 87.49it/s]\u001b[A\n",
      " 25%|██▍       | 15208/61028 [03:35<08:10, 93.48it/s]\u001b[A\n",
      " 25%|██▍       | 15218/61028 [03:35<08:14, 92.57it/s]\u001b[A\n",
      " 25%|██▍       | 15228/61028 [03:35<08:52, 85.98it/s]\u001b[A\n",
      " 25%|██▍       | 15238/61028 [03:35<08:34, 88.93it/s]\u001b[A\n",
      " 25%|██▍       | 15248/61028 [03:35<08:47, 86.83it/s]\u001b[A\n",
      " 25%|██▌       | 15259/61028 [03:35<08:23, 90.86it/s]\u001b[A\n",
      " 25%|██▌       | 15269/61028 [03:35<08:15, 92.29it/s]\u001b[A\n",
      " 25%|██▌       | 15279/61028 [03:35<08:15, 92.37it/s]\u001b[A\n",
      " 25%|██▌       | 15289/61028 [03:35<08:19, 91.62it/s]\u001b[A\n",
      " 25%|██▌       | 15299/61028 [03:36<08:42, 87.46it/s]\u001b[A\n",
      " 25%|██▌       | 15308/61028 [03:36<09:12, 82.73it/s]\u001b[A\n",
      " 25%|██▌       | 15317/61028 [03:36<09:04, 83.97it/s]\u001b[A\n",
      " 25%|██▌       | 15326/61028 [03:36<09:03, 84.05it/s]\u001b[A\n",
      " 25%|██▌       | 15336/61028 [03:36<08:51, 85.91it/s]\u001b[A\n",
      " 25%|██▌       | 15345/61028 [03:36<08:58, 84.86it/s]\u001b[A\n",
      " 25%|██▌       | 15354/61028 [03:36<08:53, 85.68it/s]\u001b[A\n",
      " 25%|██▌       | 15365/61028 [03:36<08:27, 90.01it/s]\u001b[A\n",
      " 25%|██▌       | 15375/61028 [03:36<08:23, 90.64it/s]\u001b[A\n",
      " 25%|██▌       | 15386/61028 [03:37<08:08, 93.51it/s]\u001b[A\n",
      " 25%|██▌       | 15396/61028 [03:37<08:25, 90.25it/s]\u001b[A\n",
      " 25%|██▌       | 15407/61028 [03:37<08:04, 94.07it/s]\u001b[A\n",
      " 25%|██▌       | 15417/61028 [03:37<08:07, 93.54it/s]\u001b[A\n",
      " 25%|██▌       | 15427/61028 [03:37<08:16, 91.88it/s]\u001b[A\n",
      " 25%|██▌       | 15437/61028 [03:37<08:06, 93.69it/s]\u001b[A\n",
      " 25%|██▌       | 15447/61028 [03:37<08:08, 93.37it/s]\u001b[A\n",
      " 25%|██▌       | 15457/61028 [03:37<08:00, 94.78it/s]\u001b[A\n",
      " 25%|██▌       | 15467/61028 [03:37<07:58, 95.24it/s]\u001b[A\n",
      " 25%|██▌       | 15477/61028 [03:37<08:15, 91.98it/s]\u001b[A\n",
      " 25%|██▌       | 15488/61028 [03:38<07:52, 96.48it/s]\u001b[A\n",
      " 25%|██▌       | 15498/61028 [03:38<09:20, 81.21it/s]\u001b[A\n",
      " 25%|██▌       | 15507/61028 [03:38<15:19, 49.49it/s]\u001b[A\n",
      " 25%|██▌       | 15519/61028 [03:38<12:38, 59.97it/s]\u001b[A\n",
      " 25%|██▌       | 15528/61028 [03:38<12:53, 58.85it/s]\u001b[A\n",
      " 25%|██▌       | 15538/61028 [03:38<11:31, 65.81it/s]\u001b[A\n",
      " 25%|██▌       | 15549/61028 [03:39<10:09, 74.58it/s]\u001b[A\n",
      " 25%|██▌       | 15558/61028 [03:39<09:43, 77.98it/s]\u001b[A\n",
      " 26%|██▌       | 15570/61028 [03:39<08:49, 85.79it/s]\u001b[A\n",
      " 26%|██▌       | 15580/61028 [03:39<08:41, 87.11it/s]\u001b[A\n",
      " 26%|██▌       | 15590/61028 [03:39<08:27, 89.49it/s]\u001b[A\n",
      " 26%|██▌       | 15601/61028 [03:39<08:15, 91.71it/s]\u001b[A\n",
      " 26%|██▌       | 15611/61028 [03:39<08:24, 90.03it/s]\u001b[A\n",
      " 26%|██▌       | 15621/61028 [03:39<08:33, 88.51it/s]\u001b[A\n",
      " 26%|██▌       | 15633/61028 [03:39<08:03, 93.84it/s]\u001b[A\n",
      " 26%|██▌       | 15643/61028 [03:40<07:59, 94.73it/s]\u001b[A\n",
      " 26%|██▌       | 15653/61028 [03:40<08:15, 91.63it/s]\u001b[A\n",
      " 26%|██▌       | 15663/61028 [03:40<08:06, 93.33it/s]\u001b[A\n",
      " 26%|██▌       | 15673/61028 [03:40<08:20, 90.64it/s]\u001b[A\n",
      " 26%|██▌       | 15683/61028 [03:40<08:22, 90.25it/s]\u001b[A\n",
      " 26%|██▌       | 15693/61028 [03:40<08:23, 90.03it/s]\u001b[A\n",
      " 26%|██▌       | 15704/61028 [03:40<08:00, 94.24it/s]\u001b[A\n",
      " 26%|██▌       | 15714/61028 [03:40<08:18, 90.84it/s]\u001b[A\n",
      " 26%|██▌       | 15724/61028 [03:40<08:11, 92.17it/s]\u001b[A\n",
      " 26%|██▌       | 15735/61028 [03:41<07:47, 96.88it/s]\u001b[A\n",
      " 26%|██▌       | 15745/61028 [03:41<08:52, 85.00it/s]\u001b[A\n",
      " 26%|██▌       | 15756/61028 [03:41<08:24, 89.81it/s]\u001b[A\n",
      " 26%|██▌       | 15766/61028 [03:41<08:34, 87.90it/s]\u001b[A\n",
      " 26%|██▌       | 15777/61028 [03:41<08:11, 92.13it/s]\u001b[A\n",
      " 26%|██▌       | 15787/61028 [03:41<08:12, 91.91it/s]\u001b[A\n",
      " 26%|██▌       | 15797/61028 [03:41<08:19, 90.59it/s]\u001b[A\n",
      " 26%|██▌       | 15807/61028 [03:41<08:20, 90.34it/s]\u001b[A\n",
      " 26%|██▌       | 15817/61028 [03:41<08:25, 89.43it/s]\u001b[A\n",
      " 26%|██▌       | 15829/61028 [03:42<07:53, 95.39it/s]\u001b[A\n",
      " 26%|██▌       | 15839/61028 [03:42<07:55, 94.94it/s]\u001b[A\n",
      " 26%|██▌       | 15850/61028 [03:42<07:39, 98.34it/s]\u001b[A\n",
      " 26%|██▌       | 15860/61028 [03:42<07:53, 95.41it/s]\u001b[A\n",
      " 26%|██▌       | 15870/61028 [03:42<08:11, 91.86it/s]\u001b[A\n",
      " 26%|██▌       | 15881/61028 [03:42<07:52, 95.45it/s]\u001b[A\n",
      " 26%|██▌       | 15892/61028 [03:42<07:59, 94.21it/s]\u001b[A\n",
      " 26%|██▌       | 15902/61028 [03:42<08:13, 91.53it/s]\u001b[A\n",
      " 26%|██▌       | 15913/61028 [03:42<07:57, 94.45it/s]\u001b[A\n",
      " 26%|██▌       | 15924/61028 [03:43<07:50, 95.84it/s]\u001b[A\n",
      " 26%|██▌       | 15934/61028 [03:43<07:50, 95.74it/s]\u001b[A\n",
      " 26%|██▌       | 15944/61028 [03:43<07:57, 94.34it/s]\u001b[A\n",
      " 26%|██▌       | 15954/61028 [03:43<14:06, 53.23it/s]\u001b[A\n",
      " 26%|██▌       | 15964/61028 [03:43<12:13, 61.47it/s]\u001b[A\n",
      " 26%|██▌       | 15974/61028 [03:43<11:01, 68.14it/s]\u001b[A\n",
      " 26%|██▌       | 15983/61028 [03:44<10:50, 69.28it/s]\u001b[A\n",
      " 26%|██▌       | 15993/61028 [03:44<10:00, 75.02it/s]\u001b[A\n",
      " 26%|██▌       | 16005/61028 [03:44<09:02, 83.06it/s]\u001b[A\n",
      " 26%|██▌       | 16015/61028 [03:44<08:49, 84.99it/s]\u001b[A\n",
      " 26%|██▋       | 16026/61028 [03:44<08:21, 89.72it/s]\u001b[A\n",
      " 26%|██▋       | 16037/61028 [03:44<07:59, 93.90it/s]\u001b[A\n",
      " 26%|██▋       | 16050/61028 [03:44<07:26, 100.67it/s]\u001b[A\n",
      " 26%|██▋       | 16061/61028 [03:44<08:08, 92.08it/s] \u001b[A\n",
      " 26%|██▋       | 16071/61028 [03:44<08:28, 88.48it/s]\u001b[A\n",
      " 26%|██▋       | 16082/61028 [03:45<08:11, 91.40it/s]\u001b[A\n",
      " 26%|██▋       | 16092/61028 [03:45<08:06, 92.35it/s]\u001b[A\n",
      " 26%|██▋       | 16102/61028 [03:45<07:59, 93.78it/s]\u001b[A\n",
      " 26%|██▋       | 16112/61028 [03:45<08:00, 93.42it/s]\u001b[A\n",
      " 26%|██▋       | 16122/61028 [03:45<07:58, 93.80it/s]\u001b[A\n",
      " 26%|██▋       | 16132/61028 [03:45<09:08, 81.80it/s]\u001b[A\n",
      " 26%|██▋       | 16142/61028 [03:45<09:04, 82.49it/s]\u001b[A\n",
      " 26%|██▋       | 16152/61028 [03:45<08:44, 85.62it/s]\u001b[A\n",
      " 26%|██▋       | 16163/61028 [03:45<08:22, 89.21it/s]\u001b[A\n",
      " 27%|██▋       | 16173/61028 [03:46<08:08, 91.75it/s]\u001b[A\n",
      " 27%|██▋       | 16183/61028 [03:46<08:05, 92.31it/s]\u001b[A\n",
      " 27%|██▋       | 16193/61028 [03:46<08:12, 90.96it/s]\u001b[A\n",
      " 27%|██▋       | 16203/61028 [03:46<08:05, 92.42it/s]\u001b[A\n",
      " 27%|██▋       | 16213/61028 [03:46<08:24, 88.90it/s]\u001b[A\n",
      " 27%|██▋       | 16225/61028 [03:46<07:52, 94.83it/s]\u001b[A\n",
      " 27%|██▋       | 16236/61028 [03:46<07:43, 96.55it/s]\u001b[A\n",
      " 27%|██▋       | 16246/61028 [03:46<08:05, 92.29it/s]\u001b[A\n",
      " 27%|██▋       | 16256/61028 [03:46<08:32, 87.32it/s]\u001b[A\n",
      " 27%|██▋       | 16268/61028 [03:47<07:58, 93.60it/s]\u001b[A\n",
      " 27%|██▋       | 16278/61028 [03:47<08:07, 91.71it/s]\u001b[A\n",
      " 27%|██▋       | 16290/61028 [03:47<07:34, 98.43it/s]\u001b[A\n",
      " 27%|██▋       | 16301/61028 [03:47<08:12, 90.83it/s]\u001b[A\n",
      " 27%|██▋       | 16313/61028 [03:47<08:08, 91.51it/s]\u001b[A\n",
      " 27%|██▋       | 16324/61028 [03:47<07:45, 96.07it/s]\u001b[A\n",
      " 27%|██▋       | 16335/61028 [03:47<07:38, 97.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16345/61028 [03:47<07:59, 93.15it/s]\u001b[A\n",
      " 27%|██▋       | 16355/61028 [03:48<08:02, 92.64it/s]\u001b[A\n",
      " 27%|██▋       | 16365/61028 [03:48<08:03, 92.36it/s]\u001b[A\n",
      " 27%|██▋       | 16375/61028 [03:48<08:22, 88.82it/s]\u001b[A\n",
      " 27%|██▋       | 16384/61028 [03:48<08:52, 83.91it/s]\u001b[A\n",
      " 27%|██▋       | 16393/61028 [03:48<14:59, 49.62it/s]\u001b[A\n",
      " 27%|██▋       | 16401/61028 [03:48<13:22, 55.59it/s]\u001b[A\n",
      " 27%|██▋       | 16409/61028 [03:48<12:20, 60.24it/s]\u001b[A\n",
      " 27%|██▋       | 16419/61028 [03:49<10:55, 68.01it/s]\u001b[A\n",
      " 27%|██▋       | 16429/61028 [03:49<09:56, 74.72it/s]\u001b[A\n",
      " 27%|██▋       | 16440/61028 [03:49<09:09, 81.09it/s]\u001b[A\n",
      " 27%|██▋       | 16450/61028 [03:49<08:47, 84.55it/s]\u001b[A\n",
      " 27%|██▋       | 16461/61028 [03:49<08:14, 90.10it/s]\u001b[A\n",
      " 27%|██▋       | 16471/61028 [03:49<08:08, 91.25it/s]\u001b[A\n",
      " 27%|██▋       | 16482/61028 [03:49<07:49, 94.79it/s]\u001b[A\n",
      " 27%|██▋       | 16492/61028 [03:49<08:02, 92.27it/s]\u001b[A\n",
      " 27%|██▋       | 16502/61028 [03:49<08:53, 83.47it/s]\u001b[A\n",
      " 27%|██▋       | 16511/61028 [03:50<08:56, 82.96it/s]\u001b[A\n",
      " 27%|██▋       | 16520/61028 [03:50<08:45, 84.73it/s]\u001b[A\n",
      " 27%|██▋       | 16530/61028 [03:50<08:44, 84.85it/s]\u001b[A\n",
      " 27%|██▋       | 16539/61028 [03:50<08:44, 84.83it/s]\u001b[A\n",
      " 27%|██▋       | 16550/61028 [03:50<08:10, 90.67it/s]\u001b[A\n",
      " 27%|██▋       | 16560/61028 [03:50<08:19, 89.02it/s]\u001b[A\n",
      " 27%|██▋       | 16570/61028 [03:50<08:19, 88.97it/s]\u001b[A\n",
      " 27%|██▋       | 16579/61028 [03:50<08:22, 88.40it/s]\u001b[A\n",
      " 27%|██▋       | 16589/61028 [03:50<08:05, 91.47it/s]\u001b[A\n",
      " 27%|██▋       | 16600/61028 [03:51<07:45, 95.36it/s]\u001b[A\n",
      " 27%|██▋       | 16610/61028 [03:51<07:43, 95.77it/s]\u001b[A\n",
      " 27%|██▋       | 16621/61028 [03:51<07:26, 99.43it/s]\u001b[A\n",
      " 27%|██▋       | 16632/61028 [03:51<07:47, 94.91it/s]\u001b[A\n",
      " 27%|██▋       | 16642/61028 [03:51<07:54, 93.47it/s]\u001b[A\n",
      " 27%|██▋       | 16652/61028 [03:51<08:11, 90.38it/s]\u001b[A\n",
      " 27%|██▋       | 16662/61028 [03:51<08:05, 91.36it/s]\u001b[A\n",
      " 27%|██▋       | 16672/61028 [03:51<08:06, 91.16it/s]\u001b[A\n",
      " 27%|██▋       | 16682/61028 [03:51<07:59, 92.43it/s]\u001b[A\n",
      " 27%|██▋       | 16692/61028 [03:52<08:02, 91.82it/s]\u001b[A\n",
      " 27%|██▋       | 16702/61028 [03:52<08:06, 91.14it/s]\u001b[A\n",
      " 27%|██▋       | 16715/61028 [03:52<07:26, 99.19it/s]\u001b[A\n",
      " 27%|██▋       | 16726/61028 [03:52<07:56, 92.91it/s]\u001b[A\n",
      " 27%|██▋       | 16736/61028 [03:52<08:00, 92.19it/s]\u001b[A\n",
      " 27%|██▋       | 16747/61028 [03:52<07:46, 94.90it/s]\u001b[A\n",
      " 27%|██▋       | 16757/61028 [03:52<07:54, 93.33it/s]\u001b[A\n",
      " 27%|██▋       | 16769/61028 [03:52<07:27, 98.90it/s]\u001b[A\n",
      " 27%|██▋       | 16780/61028 [03:52<07:52, 93.66it/s]\u001b[A\n",
      " 28%|██▊       | 16791/61028 [03:53<07:38, 96.51it/s]\u001b[A\n",
      " 28%|██▊       | 16803/61028 [03:53<07:22, 99.96it/s]\u001b[A\n",
      " 28%|██▊       | 16814/61028 [03:53<07:39, 96.29it/s]\u001b[A\n",
      " 28%|██▊       | 16824/61028 [03:53<08:25, 87.51it/s]\u001b[A\n",
      " 28%|██▊       | 16834/61028 [03:53<08:08, 90.44it/s]\u001b[A\n",
      " 28%|██▊       | 16844/61028 [03:53<12:35, 58.48it/s]\u001b[A\n",
      " 28%|██▊       | 16852/61028 [03:53<12:46, 57.66it/s]\u001b[A\n",
      " 28%|██▊       | 16862/61028 [03:54<11:21, 64.78it/s]\u001b[A\n",
      " 28%|██▊       | 16871/61028 [03:54<10:38, 69.11it/s]\u001b[A\n",
      " 28%|██▊       | 16882/61028 [03:54<09:34, 76.79it/s]\u001b[A\n",
      " 28%|██▊       | 16891/61028 [03:54<09:12, 79.84it/s]\u001b[A\n",
      " 28%|██▊       | 16900/61028 [03:54<08:59, 81.84it/s]\u001b[A\n",
      " 28%|██▊       | 16911/61028 [03:54<08:24, 87.52it/s]\u001b[A\n",
      " 28%|██▊       | 16922/61028 [03:54<07:59, 91.99it/s]\u001b[A\n",
      " 28%|██▊       | 16932/61028 [03:54<08:16, 88.77it/s]\u001b[A\n",
      " 28%|██▊       | 16942/61028 [03:54<08:48, 83.39it/s]\u001b[A\n",
      " 28%|██▊       | 16952/61028 [03:55<08:31, 86.20it/s]\u001b[A\n",
      " 28%|██▊       | 16962/61028 [03:55<08:12, 89.54it/s]\u001b[A\n",
      " 28%|██▊       | 16972/61028 [03:55<08:02, 91.29it/s]\u001b[A\n",
      " 28%|██▊       | 16984/61028 [03:55<07:39, 95.78it/s]\u001b[A\n",
      " 28%|██▊       | 16997/61028 [03:55<07:13, 101.54it/s]\u001b[A\n",
      " 28%|██▊       | 17008/61028 [03:55<07:10, 102.19it/s]\u001b[A\n",
      " 28%|██▊       | 17019/61028 [03:55<07:31, 97.41it/s] \u001b[A\n",
      " 28%|██▊       | 17029/61028 [03:55<07:33, 97.04it/s]\u001b[A\n",
      " 28%|██▊       | 17039/61028 [03:55<08:06, 90.43it/s]\u001b[A\n",
      " 28%|██▊       | 17051/61028 [03:56<07:30, 97.57it/s]\u001b[A\n",
      " 28%|██▊       | 17062/61028 [03:56<07:28, 98.09it/s]\u001b[A\n",
      " 28%|██▊       | 17073/61028 [03:56<07:21, 99.47it/s]\u001b[A\n",
      " 28%|██▊       | 17084/61028 [03:56<07:41, 95.27it/s]\u001b[A\n",
      " 28%|██▊       | 17094/61028 [03:56<07:38, 95.81it/s]\u001b[A\n",
      " 28%|██▊       | 17105/61028 [03:56<07:33, 96.90it/s]\u001b[A\n",
      " 28%|██▊       | 17115/61028 [03:56<07:32, 96.98it/s]\u001b[A\n",
      " 28%|██▊       | 17125/61028 [03:56<07:36, 96.10it/s]\u001b[A\n",
      " 28%|██▊       | 17136/61028 [03:56<07:26, 98.29it/s]\u001b[A\n",
      " 28%|██▊       | 17146/61028 [03:57<07:36, 96.21it/s]\u001b[A\n",
      " 28%|██▊       | 17158/61028 [03:57<07:16, 100.44it/s]\u001b[A\n",
      " 28%|██▊       | 17169/61028 [03:57<07:33, 96.66it/s] \u001b[A\n",
      " 28%|██▊       | 17179/61028 [03:57<07:33, 96.78it/s]\u001b[A\n",
      " 28%|██▊       | 17190/61028 [03:57<07:20, 99.62it/s]\u001b[A\n",
      " 28%|██▊       | 17201/61028 [03:57<07:31, 97.04it/s]\u001b[A\n",
      " 28%|██▊       | 17211/61028 [03:57<07:46, 93.89it/s]\u001b[A\n",
      " 28%|██▊       | 17221/61028 [03:57<07:45, 94.12it/s]\u001b[A\n",
      " 28%|██▊       | 17232/61028 [03:57<07:32, 96.87it/s]\u001b[A\n",
      " 28%|██▊       | 17242/61028 [03:58<07:39, 95.30it/s]\u001b[A\n",
      " 28%|██▊       | 17253/61028 [03:58<07:25, 98.27it/s]\u001b[A\n",
      " 28%|██▊       | 17263/61028 [03:58<07:38, 95.41it/s]\u001b[A\n",
      " 28%|██▊       | 17274/61028 [03:58<07:25, 98.23it/s]\u001b[A\n",
      " 28%|██▊       | 17286/61028 [03:58<07:08, 102.01it/s]\u001b[A\n",
      " 28%|██▊       | 17297/61028 [03:58<07:17, 99.92it/s] \u001b[A\n",
      " 28%|██▊       | 17308/61028 [03:58<07:37, 95.61it/s]\u001b[A\n",
      " 28%|██▊       | 17318/61028 [03:59<12:37, 57.74it/s]\u001b[A\n",
      " 28%|██▊       | 17326/61028 [03:59<11:59, 60.77it/s]\u001b[A\n",
      " 28%|██▊       | 17335/61028 [03:59<10:52, 67.01it/s]\u001b[A\n",
      " 28%|██▊       | 17344/61028 [03:59<10:07, 71.93it/s]\u001b[A\n",
      " 28%|██▊       | 17355/61028 [03:59<09:04, 80.15it/s]\u001b[A\n",
      " 28%|██▊       | 17366/61028 [03:59<08:28, 85.84it/s]\u001b[A\n",
      " 28%|██▊       | 17376/61028 [03:59<08:22, 86.94it/s]\u001b[A\n",
      " 28%|██▊       | 17386/61028 [03:59<09:26, 77.02it/s]\u001b[A\n",
      " 29%|██▊       | 17397/61028 [03:59<08:51, 82.09it/s]\u001b[A\n",
      " 29%|██▊       | 17408/61028 [04:00<08:23, 86.63it/s]\u001b[A\n",
      " 29%|██▊       | 17418/61028 [04:00<08:05, 89.80it/s]\u001b[A\n",
      " 29%|██▊       | 17430/61028 [04:00<07:49, 92.76it/s]\u001b[A\n",
      " 29%|██▊       | 17441/61028 [04:00<07:38, 95.02it/s]\u001b[A\n",
      " 29%|██▊       | 17451/61028 [04:00<07:53, 92.13it/s]\u001b[A\n",
      " 29%|██▊       | 17461/61028 [04:00<08:03, 90.13it/s]\u001b[A\n",
      " 29%|██▊       | 17471/61028 [04:00<07:53, 91.99it/s]\u001b[A\n",
      " 29%|██▊       | 17481/61028 [04:00<08:27, 85.73it/s]\u001b[A\n",
      " 29%|██▊       | 17490/61028 [04:00<08:41, 83.55it/s]\u001b[A\n",
      " 29%|██▊       | 17501/61028 [04:01<08:07, 89.35it/s]\u001b[A\n",
      " 29%|██▊       | 17511/61028 [04:01<07:51, 92.26it/s]\u001b[A\n",
      " 29%|██▊       | 17521/61028 [04:01<08:08, 89.06it/s]\u001b[A\n",
      " 29%|██▊       | 17531/61028 [04:01<08:31, 84.97it/s]\u001b[A\n",
      " 29%|██▊       | 17542/61028 [04:01<08:01, 90.32it/s]\u001b[A\n",
      " 29%|██▉       | 17553/61028 [04:01<07:41, 94.14it/s]\u001b[A\n",
      " 29%|██▉       | 17563/61028 [04:01<07:50, 92.39it/s]\u001b[A\n",
      " 29%|██▉       | 17574/61028 [04:01<07:36, 95.19it/s]\u001b[A\n",
      " 29%|██▉       | 17585/61028 [04:01<07:27, 97.14it/s]\u001b[A\n",
      " 29%|██▉       | 17595/61028 [04:02<07:25, 97.55it/s]\u001b[A\n",
      " 29%|██▉       | 17605/61028 [04:02<07:59, 90.55it/s]\u001b[A\n",
      " 29%|██▉       | 17616/61028 [04:02<07:38, 94.74it/s]\u001b[A\n",
      " 29%|██▉       | 17626/61028 [04:02<07:41, 94.09it/s]\u001b[A\n",
      " 29%|██▉       | 17636/61028 [04:02<07:32, 95.79it/s]\u001b[A\n",
      " 29%|██▉       | 17646/61028 [04:02<07:31, 96.00it/s]\u001b[A\n",
      " 29%|██▉       | 17657/61028 [04:02<07:18, 98.80it/s]\u001b[A\n",
      " 29%|██▉       | 17667/61028 [04:02<07:19, 98.63it/s]\u001b[A\n",
      " 29%|██▉       | 17677/61028 [04:02<07:21, 98.22it/s]\u001b[A\n",
      " 29%|██▉       | 17688/61028 [04:03<07:19, 98.54it/s]\u001b[A\n",
      " 29%|██▉       | 17698/61028 [04:03<07:25, 97.34it/s]\u001b[A\n",
      " 29%|██▉       | 17709/61028 [04:03<07:11, 100.32it/s]\u001b[A\n",
      " 29%|██▉       | 17720/61028 [04:03<07:14, 99.71it/s] \u001b[A\n",
      " 29%|██▉       | 17730/61028 [04:03<07:19, 98.56it/s]\u001b[A\n",
      " 29%|██▉       | 17741/61028 [04:03<07:07, 101.31it/s]\u001b[A\n",
      " 29%|██▉       | 17752/61028 [04:03<07:34, 95.14it/s] \u001b[A\n",
      " 29%|██▉       | 17762/61028 [04:04<13:51, 52.01it/s]\u001b[A\n",
      " 29%|██▉       | 17773/61028 [04:04<11:40, 61.75it/s]\u001b[A\n",
      " 29%|██▉       | 17784/61028 [04:04<10:10, 70.84it/s]\u001b[A\n",
      " 29%|██▉       | 17794/61028 [04:04<09:34, 75.28it/s]\u001b[A\n",
      " 29%|██▉       | 17805/61028 [04:04<08:50, 81.46it/s]\u001b[A\n",
      " 29%|██▉       | 17817/61028 [04:04<08:04, 89.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 17829/61028 [04:04<07:27, 96.43it/s]\u001b[A\n",
      " 29%|██▉       | 17840/61028 [04:04<07:34, 94.97it/s]\u001b[A\n",
      " 29%|██▉       | 17851/61028 [04:04<08:14, 87.31it/s]\u001b[A\n",
      " 29%|██▉       | 17861/61028 [04:05<08:20, 86.20it/s]\u001b[A\n",
      " 29%|██▉       | 17871/61028 [04:05<08:09, 88.09it/s]\u001b[A\n",
      " 29%|██▉       | 17881/61028 [04:05<08:05, 88.86it/s]\u001b[A\n",
      " 29%|██▉       | 17891/61028 [04:05<07:57, 90.41it/s]\u001b[A\n",
      " 29%|██▉       | 17901/61028 [04:05<08:12, 87.60it/s]\u001b[A\n",
      " 29%|██▉       | 17911/61028 [04:05<08:07, 88.50it/s]\u001b[A\n",
      " 29%|██▉       | 17921/61028 [04:05<07:50, 91.53it/s]\u001b[A\n",
      " 29%|██▉       | 17932/61028 [04:05<07:31, 95.43it/s]\u001b[A\n",
      " 29%|██▉       | 17943/61028 [04:05<07:17, 98.39it/s]\u001b[A\n",
      " 29%|██▉       | 17953/61028 [04:06<07:33, 95.04it/s]\u001b[A\n",
      " 29%|██▉       | 17963/61028 [04:06<07:50, 91.46it/s]\u001b[A\n",
      " 29%|██▉       | 17973/61028 [04:06<08:00, 89.59it/s]\u001b[A\n",
      " 29%|██▉       | 17984/61028 [04:06<07:43, 92.80it/s]\u001b[A\n",
      " 29%|██▉       | 17994/61028 [04:06<07:59, 89.80it/s]\u001b[A\n",
      " 30%|██▉       | 18004/61028 [04:06<08:03, 88.91it/s]\u001b[A\n",
      " 30%|██▉       | 18015/61028 [04:06<07:42, 92.92it/s]\u001b[A\n",
      " 30%|██▉       | 18026/61028 [04:06<07:31, 95.27it/s]\u001b[A\n",
      " 30%|██▉       | 18036/61028 [04:07<08:12, 87.27it/s]\u001b[A\n",
      " 30%|██▉       | 18046/61028 [04:07<08:01, 89.28it/s]\u001b[A\n",
      " 30%|██▉       | 18056/61028 [04:07<08:01, 89.21it/s]\u001b[A\n",
      " 30%|██▉       | 18066/61028 [04:07<08:15, 86.73it/s]\u001b[A\n",
      " 30%|██▉       | 18076/61028 [04:07<07:57, 89.87it/s]\u001b[A\n",
      " 30%|██▉       | 18086/61028 [04:07<07:51, 91.02it/s]\u001b[A\n",
      " 30%|██▉       | 18097/61028 [04:07<07:39, 93.34it/s]\u001b[A\n",
      " 30%|██▉       | 18108/61028 [04:07<07:28, 95.60it/s]\u001b[A\n",
      " 30%|██▉       | 18118/61028 [04:07<07:34, 94.41it/s]\u001b[A\n",
      " 30%|██▉       | 18130/61028 [04:07<07:08, 100.05it/s]\u001b[A\n",
      " 30%|██▉       | 18141/61028 [04:08<07:22, 96.86it/s] \u001b[A\n",
      " 30%|██▉       | 18151/61028 [04:08<07:19, 97.52it/s]\u001b[A\n",
      " 30%|██▉       | 18161/61028 [04:08<07:48, 91.43it/s]\u001b[A\n",
      " 30%|██▉       | 18173/61028 [04:08<07:20, 97.30it/s]\u001b[A\n",
      " 30%|██▉       | 18183/61028 [04:08<07:22, 96.82it/s]\u001b[A\n",
      " 30%|██▉       | 18193/61028 [04:08<07:54, 90.36it/s]\u001b[A\n",
      " 30%|██▉       | 18203/61028 [04:08<07:53, 90.48it/s]\u001b[A\n",
      " 30%|██▉       | 18214/61028 [04:08<07:38, 93.37it/s]\u001b[A\n",
      " 30%|██▉       | 18224/61028 [04:09<14:11, 50.27it/s]\u001b[A\n",
      " 30%|██▉       | 18233/61028 [04:09<12:19, 57.86it/s]\u001b[A\n",
      " 30%|██▉       | 18244/61028 [04:09<10:41, 66.67it/s]\u001b[A\n",
      " 30%|██▉       | 18254/61028 [04:09<09:49, 72.58it/s]\u001b[A\n",
      " 30%|██▉       | 18264/61028 [04:09<09:04, 78.55it/s]\u001b[A\n",
      " 30%|██▉       | 18274/61028 [04:09<08:45, 81.40it/s]\u001b[A\n",
      " 30%|██▉       | 18285/61028 [04:09<08:19, 85.64it/s]\u001b[A\n",
      " 30%|██▉       | 18296/61028 [04:10<07:46, 91.69it/s]\u001b[A\n",
      " 30%|██▉       | 18306/61028 [04:10<07:37, 93.46it/s]\u001b[A\n",
      " 30%|███       | 18316/61028 [04:10<07:28, 95.25it/s]\u001b[A\n",
      " 30%|███       | 18326/61028 [04:10<07:27, 95.42it/s]\u001b[A\n",
      " 30%|███       | 18336/61028 [04:10<07:42, 92.28it/s]\u001b[A\n",
      " 30%|███       | 18346/61028 [04:10<08:01, 88.64it/s]\u001b[A\n",
      " 30%|███       | 18356/61028 [04:10<07:59, 89.01it/s]\u001b[A\n",
      " 30%|███       | 18370/61028 [04:10<07:10, 99.04it/s]\u001b[A\n",
      " 30%|███       | 18381/61028 [04:10<07:15, 97.85it/s]\u001b[A\n",
      " 30%|███       | 18392/61028 [04:11<07:32, 94.25it/s]\u001b[A\n",
      " 30%|███       | 18404/61028 [04:11<07:05, 100.18it/s]\u001b[A\n",
      " 30%|███       | 18415/61028 [04:11<07:12, 98.62it/s] \u001b[A\n",
      " 30%|███       | 18426/61028 [04:11<07:26, 95.50it/s]\u001b[A\n",
      " 30%|███       | 18436/61028 [04:11<08:08, 87.19it/s]\u001b[A\n",
      " 30%|███       | 18446/61028 [04:11<07:57, 89.25it/s]\u001b[A\n",
      " 30%|███       | 18456/61028 [04:11<08:21, 84.81it/s]\u001b[A\n",
      " 30%|███       | 18467/61028 [04:11<07:54, 89.75it/s]\u001b[A\n",
      " 30%|███       | 18477/61028 [04:12<08:01, 88.30it/s]\u001b[A\n",
      " 30%|███       | 18488/61028 [04:12<07:42, 91.99it/s]\u001b[A\n",
      " 30%|███       | 18498/61028 [04:12<07:41, 92.18it/s]\u001b[A\n",
      " 30%|███       | 18508/61028 [04:12<07:33, 93.75it/s]\u001b[A\n",
      " 30%|███       | 18518/61028 [04:12<07:39, 92.52it/s]\u001b[A\n",
      " 30%|███       | 18528/61028 [04:12<07:34, 93.56it/s]\u001b[A\n",
      " 30%|███       | 18538/61028 [04:12<08:02, 88.14it/s]\u001b[A\n",
      " 30%|███       | 18547/61028 [04:12<08:14, 85.83it/s]\u001b[A\n",
      " 30%|███       | 18556/61028 [04:12<08:22, 84.50it/s]\u001b[A\n",
      " 30%|███       | 18566/61028 [04:12<08:06, 87.33it/s]\u001b[A\n",
      " 30%|███       | 18575/61028 [04:13<08:21, 84.73it/s]\u001b[A\n",
      " 30%|███       | 18584/61028 [04:13<08:12, 86.21it/s]\u001b[A\n",
      " 30%|███       | 18593/61028 [04:13<08:21, 84.64it/s]\u001b[A\n",
      " 30%|███       | 18602/61028 [04:13<09:10, 77.04it/s]\u001b[A\n",
      " 30%|███       | 18611/61028 [04:13<09:00, 78.48it/s]\u001b[A\n",
      " 31%|███       | 18622/61028 [04:13<08:15, 85.62it/s]\u001b[A\n",
      " 31%|███       | 18631/61028 [04:13<08:23, 84.27it/s]\u001b[A\n",
      " 31%|███       | 18640/61028 [04:13<08:19, 84.84it/s]\u001b[A\n",
      " 31%|███       | 18651/61028 [04:13<08:01, 88.10it/s]\u001b[A\n",
      " 31%|███       | 18660/61028 [04:14<14:32, 48.54it/s]\u001b[A\n",
      " 31%|███       | 18671/61028 [04:14<12:11, 57.94it/s]\u001b[A\n",
      " 31%|███       | 18680/61028 [04:14<10:59, 64.23it/s]\u001b[A\n",
      " 31%|███       | 18690/61028 [04:14<09:53, 71.37it/s]\u001b[A\n",
      " 31%|███       | 18700/61028 [04:14<09:08, 77.12it/s]\u001b[A\n",
      " 31%|███       | 18709/61028 [04:14<08:49, 79.93it/s]\u001b[A\n",
      " 31%|███       | 18720/61028 [04:15<08:48, 80.03it/s]\u001b[A\n",
      " 31%|███       | 18729/61028 [04:15<09:14, 76.23it/s]\u001b[A\n",
      " 31%|███       | 18738/61028 [04:15<09:08, 77.15it/s]\u001b[A\n",
      " 31%|███       | 18747/61028 [04:15<08:48, 79.93it/s]\u001b[A\n",
      " 31%|███       | 18757/61028 [04:15<08:23, 83.96it/s]\u001b[A\n",
      " 31%|███       | 18767/61028 [04:15<07:59, 88.18it/s]\u001b[A\n",
      " 31%|███       | 18779/61028 [04:15<07:34, 92.86it/s]\u001b[A\n",
      " 31%|███       | 18791/61028 [04:15<07:10, 98.02it/s]\u001b[A\n",
      " 31%|███       | 18802/61028 [04:15<07:05, 99.19it/s]\u001b[A\n",
      " 31%|███       | 18813/61028 [04:16<07:02, 99.82it/s]\u001b[A\n",
      " 31%|███       | 18824/61028 [04:16<07:20, 95.82it/s]\u001b[A\n",
      " 31%|███       | 18835/61028 [04:16<07:16, 96.61it/s]\u001b[A\n",
      " 31%|███       | 18845/61028 [04:16<07:22, 95.38it/s]\u001b[A\n",
      " 31%|███       | 18856/61028 [04:16<07:08, 98.39it/s]\u001b[A\n",
      " 31%|███       | 18866/61028 [04:16<07:25, 94.63it/s]\u001b[A\n",
      " 31%|███       | 18877/61028 [04:16<07:11, 97.61it/s]\u001b[A\n",
      " 31%|███       | 18887/61028 [04:16<07:19, 95.91it/s]\u001b[A\n",
      " 31%|███       | 18897/61028 [04:16<07:18, 96.00it/s]\u001b[A\n",
      " 31%|███       | 18909/61028 [04:17<07:04, 99.13it/s]\u001b[A\n",
      " 31%|███       | 18921/61028 [04:17<06:45, 103.93it/s]\u001b[A\n",
      " 31%|███       | 18932/61028 [04:17<06:40, 105.15it/s]\u001b[A\n",
      " 31%|███       | 18943/61028 [04:17<06:48, 103.02it/s]\u001b[A\n",
      " 31%|███       | 18954/61028 [04:17<06:46, 103.54it/s]\u001b[A\n",
      " 31%|███       | 18965/61028 [04:17<06:48, 102.87it/s]\u001b[A\n",
      " 31%|███       | 18976/61028 [04:17<06:44, 103.92it/s]\u001b[A\n",
      " 31%|███       | 18987/61028 [04:17<06:43, 104.27it/s]\u001b[A\n",
      " 31%|███       | 18998/61028 [04:17<06:46, 103.28it/s]\u001b[A\n",
      " 31%|███       | 19009/61028 [04:17<07:02, 99.52it/s] \u001b[A\n",
      " 31%|███       | 19019/61028 [04:18<07:09, 97.75it/s]\u001b[A\n",
      " 31%|███       | 19030/61028 [04:18<07:08, 98.10it/s]\u001b[A\n",
      " 31%|███       | 19042/61028 [04:18<06:57, 100.58it/s]\u001b[A\n",
      " 31%|███       | 19055/61028 [04:18<06:33, 106.60it/s]\u001b[A\n",
      " 31%|███       | 19066/61028 [04:18<06:57, 100.55it/s]\u001b[A\n",
      " 31%|███▏      | 19077/61028 [04:18<06:57, 100.59it/s]\u001b[A\n",
      " 31%|███▏      | 19088/61028 [04:18<07:24, 94.33it/s] \u001b[A\n",
      " 31%|███▏      | 19101/61028 [04:18<06:55, 100.99it/s]\u001b[A\n",
      " 31%|███▏      | 19112/61028 [04:19<07:10, 97.47it/s] \u001b[A\n",
      " 31%|███▏      | 19123/61028 [04:19<06:59, 99.98it/s]\u001b[A\n",
      " 31%|███▏      | 19134/61028 [04:19<13:05, 53.36it/s]\u001b[A\n",
      " 31%|███▏      | 19145/61028 [04:19<11:08, 62.63it/s]\u001b[A\n",
      " 31%|███▏      | 19157/61028 [04:19<09:42, 71.89it/s]\u001b[A\n",
      " 31%|███▏      | 19167/61028 [04:19<09:33, 72.97it/s]\u001b[A\n",
      " 31%|███▏      | 19178/61028 [04:20<08:46, 79.48it/s]\u001b[A\n",
      " 31%|███▏      | 19188/61028 [04:20<09:06, 76.61it/s]\u001b[A\n",
      " 31%|███▏      | 19197/61028 [04:20<08:46, 79.50it/s]\u001b[A\n",
      " 31%|███▏      | 19206/61028 [04:20<08:35, 81.10it/s]\u001b[A\n",
      " 31%|███▏      | 19216/61028 [04:20<08:09, 85.43it/s]\u001b[A\n",
      " 32%|███▏      | 19228/61028 [04:20<07:32, 92.44it/s]\u001b[A\n",
      " 32%|███▏      | 19238/61028 [04:20<07:51, 88.54it/s]\u001b[A\n",
      " 32%|███▏      | 19250/61028 [04:20<07:26, 93.65it/s]\u001b[A\n",
      " 32%|███▏      | 19261/61028 [04:20<07:10, 96.99it/s]\u001b[A\n",
      " 32%|███▏      | 19274/61028 [04:21<06:46, 102.75it/s]\u001b[A\n",
      " 32%|███▏      | 19285/61028 [04:21<07:17, 95.38it/s] \u001b[A\n",
      " 32%|███▏      | 19295/61028 [04:21<07:17, 95.43it/s]\u001b[A\n",
      " 32%|███▏      | 19306/61028 [04:21<07:00, 99.33it/s]\u001b[A\n",
      " 32%|███▏      | 19317/61028 [04:21<07:22, 94.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 19329/61028 [04:21<06:58, 99.74it/s]\u001b[A\n",
      " 32%|███▏      | 19340/61028 [04:21<06:58, 99.53it/s]\u001b[A\n",
      " 32%|███▏      | 19351/61028 [04:21<07:04, 98.27it/s]\u001b[A\n",
      " 32%|███▏      | 19361/61028 [04:21<07:09, 97.04it/s]\u001b[A\n",
      " 32%|███▏      | 19372/61028 [04:22<06:59, 99.39it/s]\u001b[A\n",
      " 32%|███▏      | 19383/61028 [04:22<07:46, 89.32it/s]\u001b[A\n",
      " 32%|███▏      | 19393/61028 [04:22<07:31, 92.16it/s]\u001b[A\n",
      " 32%|███▏      | 19403/61028 [04:22<07:30, 92.30it/s]\u001b[A\n",
      " 32%|███▏      | 19413/61028 [04:22<07:38, 90.83it/s]\u001b[A\n",
      " 32%|███▏      | 19423/61028 [04:22<07:44, 89.60it/s]\u001b[A\n",
      " 32%|███▏      | 19433/61028 [04:22<07:50, 88.35it/s]\u001b[A\n",
      " 32%|███▏      | 19442/61028 [04:22<07:56, 87.33it/s]\u001b[A\n",
      " 32%|███▏      | 19452/61028 [04:22<07:41, 89.99it/s]\u001b[A\n",
      " 32%|███▏      | 19462/61028 [04:23<07:28, 92.77it/s]\u001b[A\n",
      " 32%|███▏      | 19472/61028 [04:23<07:59, 86.59it/s]\u001b[A\n",
      " 32%|███▏      | 19482/61028 [04:23<07:43, 89.67it/s]\u001b[A\n",
      " 32%|███▏      | 19492/61028 [04:23<07:46, 89.02it/s]\u001b[A\n",
      " 32%|███▏      | 19502/61028 [04:23<07:47, 88.78it/s]\u001b[A\n",
      " 32%|███▏      | 19514/61028 [04:23<07:17, 94.99it/s]\u001b[A\n",
      " 32%|███▏      | 19525/61028 [04:23<07:08, 96.78it/s]\u001b[A\n",
      " 32%|███▏      | 19537/61028 [04:23<06:50, 101.12it/s]\u001b[A\n",
      " 32%|███▏      | 19548/61028 [04:23<06:59, 98.91it/s] \u001b[A\n",
      " 32%|███▏      | 19559/61028 [04:24<06:53, 100.28it/s]\u001b[A\n",
      " 32%|███▏      | 19570/61028 [04:24<07:11, 95.97it/s] \u001b[A\n",
      " 32%|███▏      | 19580/61028 [04:24<07:58, 86.57it/s]\u001b[A\n",
      " 32%|███▏      | 19589/61028 [04:24<13:14, 52.14it/s]\u001b[A\n",
      " 32%|███▏      | 19601/61028 [04:24<11:09, 61.85it/s]\u001b[A\n",
      " 32%|███▏      | 19613/61028 [04:24<09:34, 72.09it/s]\u001b[A\n",
      " 32%|███▏      | 19623/61028 [04:24<08:59, 76.73it/s]\u001b[A\n",
      " 32%|███▏      | 19633/61028 [04:25<08:44, 78.87it/s]\u001b[A\n",
      " 32%|███▏      | 19642/61028 [04:25<08:34, 80.45it/s]\u001b[A\n",
      " 32%|███▏      | 19652/61028 [04:25<08:12, 84.07it/s]\u001b[A\n",
      " 32%|███▏      | 19662/61028 [04:25<07:49, 88.19it/s]\u001b[A\n",
      " 32%|███▏      | 19674/61028 [04:25<07:13, 95.45it/s]\u001b[A\n",
      " 32%|███▏      | 19686/61028 [04:25<06:56, 99.22it/s]\u001b[A\n",
      " 32%|███▏      | 19697/61028 [04:25<06:59, 98.61it/s]\u001b[A\n",
      " 32%|███▏      | 19708/61028 [04:25<06:48, 101.11it/s]\u001b[A\n",
      " 32%|███▏      | 19719/61028 [04:25<07:06, 96.90it/s] \u001b[A\n",
      " 32%|███▏      | 19729/61028 [04:26<07:20, 93.70it/s]\u001b[A\n",
      " 32%|███▏      | 19739/61028 [04:26<07:27, 92.36it/s]\u001b[A\n",
      " 32%|███▏      | 19749/61028 [04:26<07:24, 92.84it/s]\u001b[A\n",
      " 32%|███▏      | 19760/61028 [04:26<07:11, 95.62it/s]\u001b[A\n",
      " 32%|███▏      | 19771/61028 [04:26<06:58, 98.65it/s]\u001b[A\n",
      " 32%|███▏      | 19783/61028 [04:26<06:43, 102.26it/s]\u001b[A\n",
      " 32%|███▏      | 19794/61028 [04:26<06:58, 98.45it/s] \u001b[A\n",
      " 32%|███▏      | 19804/61028 [04:26<07:02, 97.52it/s]\u001b[A\n",
      " 32%|███▏      | 19814/61028 [04:26<07:26, 92.32it/s]\u001b[A\n",
      " 32%|███▏      | 19824/61028 [04:27<07:48, 87.95it/s]\u001b[A\n",
      " 32%|███▏      | 19833/61028 [04:27<08:31, 80.47it/s]\u001b[A\n",
      " 33%|███▎      | 19843/61028 [04:27<08:04, 84.94it/s]\u001b[A\n",
      " 33%|███▎      | 19853/61028 [04:27<07:50, 87.58it/s]\u001b[A\n",
      " 33%|███▎      | 19863/61028 [04:27<07:34, 90.57it/s]\u001b[A\n",
      " 33%|███▎      | 19874/61028 [04:27<07:11, 95.34it/s]\u001b[A\n",
      " 33%|███▎      | 19886/61028 [04:27<06:52, 99.74it/s]\u001b[A\n",
      " 33%|███▎      | 19897/61028 [04:27<06:50, 100.16it/s]\u001b[A\n",
      " 33%|███▎      | 19908/61028 [04:27<07:15, 94.44it/s] \u001b[A\n",
      " 33%|███▎      | 19918/61028 [04:28<07:18, 93.84it/s]\u001b[A\n",
      " 33%|███▎      | 19928/61028 [04:28<08:05, 84.65it/s]\u001b[A\n",
      " 33%|███▎      | 19938/61028 [04:28<07:52, 86.97it/s]\u001b[A\n",
      " 33%|███▎      | 19949/61028 [04:28<07:31, 90.98it/s]\u001b[A\n",
      " 33%|███▎      | 19961/61028 [04:28<07:14, 94.56it/s]\u001b[A\n",
      " 33%|███▎      | 19971/61028 [04:28<07:23, 92.51it/s]\u001b[A\n",
      " 33%|███▎      | 19981/61028 [04:28<07:39, 89.37it/s]\u001b[A\n",
      " 33%|███▎      | 19992/61028 [04:28<07:18, 93.60it/s]\u001b[A\n",
      " 33%|███▎      | 20002/61028 [04:29<07:20, 93.07it/s]\u001b[A\n",
      " 33%|███▎      | 20012/61028 [04:29<07:23, 92.38it/s]\u001b[A\n",
      " 33%|███▎      | 20022/61028 [04:29<07:18, 93.43it/s]\u001b[A\n",
      " 33%|███▎      | 20032/61028 [04:29<07:47, 87.75it/s]\u001b[A\n",
      " 33%|███▎      | 20041/61028 [04:29<14:02, 48.64it/s]\u001b[A\n",
      " 33%|███▎      | 20051/61028 [04:29<11:57, 57.13it/s]\u001b[A\n",
      " 33%|███▎      | 20060/61028 [04:29<10:41, 63.86it/s]\u001b[A\n",
      " 33%|███▎      | 20069/61028 [04:30<10:12, 66.86it/s]\u001b[A\n",
      " 33%|███▎      | 20079/61028 [04:30<09:12, 74.07it/s]\u001b[A\n",
      " 33%|███▎      | 20089/61028 [04:30<08:41, 78.52it/s]\u001b[A\n",
      " 33%|███▎      | 20099/61028 [04:30<08:18, 82.14it/s]\u001b[A\n",
      " 33%|███▎      | 20110/61028 [04:30<07:50, 86.91it/s]\u001b[A\n",
      " 33%|███▎      | 20120/61028 [04:30<07:47, 87.49it/s]\u001b[A\n",
      " 33%|███▎      | 20132/61028 [04:30<07:16, 93.63it/s]\u001b[A\n",
      " 33%|███▎      | 20142/61028 [04:30<07:09, 95.09it/s]\u001b[A\n",
      " 33%|███▎      | 20152/61028 [04:30<07:17, 93.52it/s]\u001b[A\n",
      " 33%|███▎      | 20162/61028 [04:31<07:11, 94.70it/s]\u001b[A\n",
      " 33%|███▎      | 20173/61028 [04:31<07:05, 95.95it/s]\u001b[A\n",
      " 33%|███▎      | 20183/61028 [04:31<07:29, 90.81it/s]\u001b[A\n",
      " 33%|███▎      | 20193/61028 [04:31<07:43, 88.09it/s]\u001b[A\n",
      " 33%|███▎      | 20203/61028 [04:31<07:40, 88.70it/s]\u001b[A\n",
      " 33%|███▎      | 20212/61028 [04:31<07:43, 88.13it/s]\u001b[A\n",
      " 33%|███▎      | 20223/61028 [04:31<07:26, 91.39it/s]\u001b[A\n",
      " 33%|███▎      | 20233/61028 [04:31<07:31, 90.28it/s]\u001b[A\n",
      " 33%|███▎      | 20243/61028 [04:31<07:28, 90.86it/s]\u001b[A\n",
      " 33%|███▎      | 20253/61028 [04:32<07:29, 90.74it/s]\u001b[A\n",
      " 33%|███▎      | 20265/61028 [04:32<07:07, 95.27it/s]\u001b[A\n",
      " 33%|███▎      | 20275/61028 [04:32<07:12, 94.27it/s]\u001b[A\n",
      " 33%|███▎      | 20286/61028 [04:32<07:06, 95.58it/s]\u001b[A\n",
      " 33%|███▎      | 20297/61028 [04:32<07:10, 94.64it/s]\u001b[A\n",
      " 33%|███▎      | 20307/61028 [04:32<07:09, 94.81it/s]\u001b[A\n",
      " 33%|███▎      | 20317/61028 [04:32<07:07, 95.21it/s]\u001b[A\n",
      " 33%|███▎      | 20328/61028 [04:32<07:00, 96.71it/s]\u001b[A\n",
      " 33%|███▎      | 20338/61028 [04:32<07:14, 93.66it/s]\u001b[A\n",
      " 33%|███▎      | 20348/61028 [04:33<07:27, 90.83it/s]\u001b[A\n",
      " 33%|███▎      | 20358/61028 [04:33<07:39, 88.60it/s]\u001b[A\n",
      " 33%|███▎      | 20368/61028 [04:33<07:37, 88.81it/s]\u001b[A\n",
      " 33%|███▎      | 20379/61028 [04:33<07:36, 89.14it/s]\u001b[A\n",
      " 33%|███▎      | 20390/61028 [04:33<07:18, 92.60it/s]\u001b[A\n",
      " 33%|███▎      | 20400/61028 [04:33<07:09, 94.54it/s]\u001b[A\n",
      " 33%|███▎      | 20410/61028 [04:33<07:03, 95.99it/s]\u001b[A\n",
      " 33%|███▎      | 20421/61028 [04:33<06:55, 97.64it/s]\u001b[A\n",
      " 33%|███▎      | 20431/61028 [04:33<06:58, 97.11it/s]\u001b[A\n",
      " 33%|███▎      | 20441/61028 [04:34<07:19, 92.32it/s]\u001b[A\n",
      " 34%|███▎      | 20451/61028 [04:34<07:39, 88.24it/s]\u001b[A\n",
      " 34%|███▎      | 20462/61028 [04:34<07:16, 92.99it/s]\u001b[A\n",
      " 34%|███▎      | 20472/61028 [04:34<07:32, 89.72it/s]\u001b[A\n",
      " 34%|███▎      | 20483/61028 [04:34<07:08, 94.53it/s]\u001b[A\n",
      " 34%|███▎      | 20493/61028 [04:34<12:14, 55.21it/s]\u001b[A\n",
      " 34%|███▎      | 20501/61028 [04:34<11:11, 60.31it/s]\u001b[A\n",
      " 34%|███▎      | 20513/61028 [04:35<09:42, 69.55it/s]\u001b[A\n",
      " 34%|███▎      | 20523/61028 [04:35<08:55, 75.67it/s]\u001b[A\n",
      " 34%|███▎      | 20533/61028 [04:35<08:26, 80.02it/s]\u001b[A\n",
      " 34%|███▎      | 20545/61028 [04:35<07:35, 88.89it/s]\u001b[A\n",
      " 34%|███▎      | 20555/61028 [04:35<07:23, 91.23it/s]\u001b[A\n",
      " 34%|███▎      | 20565/61028 [04:35<07:12, 93.65it/s]\u001b[A\n",
      " 34%|███▎      | 20576/61028 [04:35<07:07, 94.73it/s]\u001b[A\n",
      " 34%|███▎      | 20586/61028 [04:35<07:23, 91.19it/s]\u001b[A\n",
      " 34%|███▎      | 20596/61028 [04:35<07:28, 90.15it/s]\u001b[A\n",
      " 34%|███▍      | 20606/61028 [04:36<07:40, 87.70it/s]\u001b[A\n",
      " 34%|███▍      | 20618/61028 [04:36<07:05, 95.03it/s]\u001b[A\n",
      " 34%|███▍      | 20628/61028 [04:36<07:17, 92.38it/s]\u001b[A\n",
      " 34%|███▍      | 20638/61028 [04:36<07:20, 91.68it/s]\u001b[A\n",
      " 34%|███▍      | 20650/61028 [04:36<06:57, 96.71it/s]\u001b[A\n",
      " 34%|███▍      | 20660/61028 [04:36<06:54, 97.37it/s]\u001b[A\n",
      " 34%|███▍      | 20670/61028 [04:36<07:10, 93.65it/s]\u001b[A\n",
      " 34%|███▍      | 20680/61028 [04:36<07:12, 93.35it/s]\u001b[A\n",
      " 34%|███▍      | 20691/61028 [04:36<06:56, 96.87it/s]\u001b[A\n",
      " 34%|███▍      | 20701/61028 [04:37<06:58, 96.31it/s]\u001b[A\n",
      " 34%|███▍      | 20711/61028 [04:37<07:01, 95.69it/s]\u001b[A\n",
      " 34%|███▍      | 20721/61028 [04:37<07:27, 90.08it/s]\u001b[A\n",
      " 34%|███▍      | 20731/61028 [04:37<07:28, 89.93it/s]\u001b[A\n",
      " 34%|███▍      | 20741/61028 [04:37<07:21, 91.27it/s]\u001b[A\n",
      " 34%|███▍      | 20753/61028 [04:37<06:49, 98.31it/s]\u001b[A\n",
      " 34%|███▍      | 20764/61028 [04:37<06:38, 100.96it/s]\u001b[A\n",
      " 34%|███▍      | 20775/61028 [04:37<06:38, 101.07it/s]\u001b[A\n",
      " 34%|███▍      | 20786/61028 [04:37<06:38, 100.96it/s]\u001b[A\n",
      " 34%|███▍      | 20797/61028 [04:37<06:45, 99.18it/s] \u001b[A\n",
      " 34%|███▍      | 20807/61028 [04:38<07:01, 95.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 20818/61028 [04:38<06:55, 96.81it/s]\u001b[A\n",
      " 34%|███▍      | 20828/61028 [04:38<06:59, 95.94it/s]\u001b[A\n",
      " 34%|███▍      | 20838/61028 [04:38<06:58, 96.05it/s]\u001b[A\n",
      " 34%|███▍      | 20848/61028 [04:38<07:55, 84.58it/s]\u001b[A\n",
      " 34%|███▍      | 20860/61028 [04:38<07:13, 92.76it/s]\u001b[A\n",
      " 34%|███▍      | 20870/61028 [04:38<07:18, 91.66it/s]\u001b[A\n",
      " 34%|███▍      | 20880/61028 [04:38<07:20, 91.20it/s]\u001b[A\n",
      " 34%|███▍      | 20891/61028 [04:39<07:07, 93.80it/s]\u001b[A\n",
      " 34%|███▍      | 20901/61028 [04:39<07:37, 87.62it/s]\u001b[A\n",
      " 34%|███▍      | 20910/61028 [04:39<11:43, 57.06it/s]\u001b[A\n",
      " 34%|███▍      | 20920/61028 [04:39<10:17, 64.90it/s]\u001b[A\n",
      " 34%|███▍      | 20928/61028 [04:39<10:31, 63.48it/s]\u001b[A\n",
      " 34%|███▍      | 20936/61028 [04:40<16:06, 41.46it/s]\u001b[A\n",
      " 34%|███▍      | 20942/61028 [04:40<14:47, 45.15it/s]\u001b[A\n",
      " 34%|███▍      | 20951/61028 [04:40<12:44, 52.44it/s]\u001b[A\n",
      " 34%|███▍      | 20960/61028 [04:40<11:13, 59.50it/s]\u001b[A\n",
      " 34%|███▍      | 20970/61028 [04:40<09:59, 66.82it/s]\u001b[A\n",
      " 34%|███▍      | 20979/61028 [04:40<09:13, 72.30it/s]\u001b[A\n",
      " 34%|███▍      | 20990/61028 [04:40<08:16, 80.57it/s]\u001b[A\n",
      " 34%|███▍      | 21001/61028 [04:40<07:39, 87.09it/s]\u001b[A\n",
      " 34%|███▍      | 21011/61028 [04:40<07:38, 87.28it/s]\u001b[A\n",
      " 34%|███▍      | 21021/61028 [04:40<07:21, 90.59it/s]\u001b[A\n",
      " 34%|███▍      | 21031/61028 [04:41<07:38, 87.33it/s]\u001b[A\n",
      " 34%|███▍      | 21041/61028 [04:41<07:50, 84.93it/s]\u001b[A\n",
      " 34%|███▍      | 21051/61028 [04:41<07:35, 87.70it/s]\u001b[A\n",
      " 35%|███▍      | 21061/61028 [04:41<07:23, 90.04it/s]\u001b[A\n",
      " 35%|███▍      | 21072/61028 [04:41<07:09, 93.13it/s]\u001b[A\n",
      " 35%|███▍      | 21082/61028 [04:41<07:04, 94.18it/s]\u001b[A\n",
      " 35%|███▍      | 21092/61028 [04:41<07:30, 88.60it/s]\u001b[A\n",
      " 35%|███▍      | 21104/61028 [04:41<06:57, 95.74it/s]\u001b[A\n",
      " 35%|███▍      | 21114/61028 [04:41<07:05, 93.75it/s]\u001b[A\n",
      " 35%|███▍      | 21125/61028 [04:42<06:50, 97.09it/s]\u001b[A\n",
      " 35%|███▍      | 21137/61028 [04:42<07:21, 90.42it/s]\u001b[A\n",
      " 35%|███▍      | 21147/61028 [04:42<07:11, 92.43it/s]\u001b[A\n",
      " 35%|███▍      | 21158/61028 [04:42<06:57, 95.58it/s]\u001b[A\n",
      " 35%|███▍      | 21169/61028 [04:42<06:42, 99.00it/s]\u001b[A\n",
      " 35%|███▍      | 21180/61028 [04:42<06:53, 96.28it/s]\u001b[A\n",
      " 35%|███▍      | 21190/61028 [04:42<06:54, 96.22it/s]\u001b[A\n",
      " 35%|███▍      | 21200/61028 [04:42<06:55, 95.85it/s]\u001b[A\n",
      " 35%|███▍      | 21210/61028 [04:42<07:01, 94.43it/s]\u001b[A\n",
      " 35%|███▍      | 21220/61028 [04:43<07:06, 93.29it/s]\u001b[A\n",
      " 35%|███▍      | 21230/61028 [04:43<07:14, 91.56it/s]\u001b[A\n",
      " 35%|███▍      | 21241/61028 [04:43<06:53, 96.29it/s]\u001b[A\n",
      " 35%|███▍      | 21252/61028 [04:43<06:43, 98.55it/s]\u001b[A\n",
      " 35%|███▍      | 21263/61028 [04:43<06:39, 99.64it/s]\u001b[A\n",
      " 35%|███▍      | 21274/61028 [04:43<06:54, 95.99it/s]\u001b[A\n",
      " 35%|███▍      | 21284/61028 [04:43<06:53, 96.19it/s]\u001b[A\n",
      " 35%|███▍      | 21294/61028 [04:43<06:54, 95.78it/s]\u001b[A\n",
      " 35%|███▍      | 21306/61028 [04:43<06:41, 99.03it/s]\u001b[A\n",
      " 35%|███▍      | 21316/61028 [04:44<06:50, 96.71it/s]\u001b[A\n",
      " 35%|███▍      | 21327/61028 [04:44<06:48, 97.11it/s]\u001b[A\n",
      " 35%|███▍      | 21337/61028 [04:44<06:59, 94.71it/s]\u001b[A\n",
      " 35%|███▍      | 21348/61028 [04:44<06:48, 97.20it/s]\u001b[A\n",
      " 35%|███▍      | 21358/61028 [04:44<07:02, 93.81it/s]\u001b[A\n",
      " 35%|███▌      | 21369/61028 [04:44<06:48, 97.04it/s]\u001b[A\n",
      " 35%|███▌      | 21379/61028 [04:44<07:01, 94.02it/s]\u001b[A\n",
      " 35%|███▌      | 21389/61028 [04:45<13:11, 50.06it/s]\u001b[A\n",
      " 35%|███▌      | 21400/61028 [04:45<11:10, 59.11it/s]\u001b[A\n",
      " 35%|███▌      | 21412/61028 [04:45<09:30, 69.44it/s]\u001b[A\n",
      " 35%|███▌      | 21423/61028 [04:45<08:34, 77.03it/s]\u001b[A\n",
      " 35%|███▌      | 21435/61028 [04:45<07:41, 85.82it/s]\u001b[A\n",
      " 35%|███▌      | 21447/61028 [04:45<07:04, 93.14it/s]\u001b[A\n",
      " 35%|███▌      | 21458/61028 [04:45<07:16, 90.75it/s]\u001b[A\n",
      " 35%|███▌      | 21469/61028 [04:45<07:05, 93.00it/s]\u001b[A\n",
      " 35%|███▌      | 21480/61028 [04:46<06:52, 95.93it/s]\u001b[A\n",
      " 35%|███▌      | 21492/61028 [04:46<06:35, 99.91it/s]\u001b[A\n",
      " 35%|███▌      | 21504/61028 [04:46<06:17, 104.68it/s]\u001b[A\n",
      " 35%|███▌      | 21515/61028 [04:46<06:22, 103.17it/s]\u001b[A\n",
      " 35%|███▌      | 21526/61028 [04:46<06:41, 98.46it/s] \u001b[A\n",
      " 35%|███▌      | 21537/61028 [04:46<06:31, 100.87it/s]\u001b[A\n",
      " 35%|███▌      | 21548/61028 [04:46<06:35, 99.94it/s] \u001b[A\n",
      " 35%|███▌      | 21559/61028 [04:46<06:27, 101.81it/s]\u001b[A\n",
      " 35%|███▌      | 21570/61028 [04:46<06:28, 101.69it/s]\u001b[A\n",
      " 35%|███▌      | 21582/61028 [04:46<06:12, 105.79it/s]\u001b[A\n",
      " 35%|███▌      | 21593/61028 [04:47<06:30, 101.01it/s]\u001b[A\n",
      " 35%|███▌      | 21604/61028 [04:47<06:30, 100.92it/s]\u001b[A\n",
      " 35%|███▌      | 21615/61028 [04:47<06:25, 102.17it/s]\u001b[A\n",
      " 35%|███▌      | 21627/61028 [04:47<06:16, 104.66it/s]\u001b[A\n",
      " 35%|███▌      | 21639/61028 [04:47<06:02, 108.61it/s]\u001b[A\n",
      " 35%|███▌      | 21650/61028 [04:47<06:07, 107.05it/s]\u001b[A\n",
      " 35%|███▌      | 21661/61028 [04:47<06:32, 100.41it/s]\u001b[A\n",
      " 36%|███▌      | 21674/61028 [04:47<06:06, 107.41it/s]\u001b[A\n",
      " 36%|███▌      | 21685/61028 [04:47<06:32, 100.17it/s]\u001b[A\n",
      " 36%|███▌      | 21696/61028 [04:48<06:39, 98.50it/s] \u001b[A\n",
      " 36%|███▌      | 21707/61028 [04:48<06:42, 97.71it/s]\u001b[A\n",
      " 36%|███▌      | 21719/61028 [04:48<06:25, 101.93it/s]\u001b[A\n",
      " 36%|███▌      | 21730/61028 [04:48<06:31, 100.32it/s]\u001b[A\n",
      " 36%|███▌      | 21741/61028 [04:48<06:39, 98.24it/s] \u001b[A\n",
      " 36%|███▌      | 21751/61028 [04:48<06:48, 96.11it/s]\u001b[A\n",
      " 36%|███▌      | 21761/61028 [04:48<07:01, 93.16it/s]\u001b[A\n",
      " 36%|███▌      | 21772/61028 [04:48<06:43, 97.20it/s]\u001b[A\n",
      " 36%|███▌      | 21782/61028 [04:48<06:47, 96.39it/s]\u001b[A\n",
      " 36%|███▌      | 21792/61028 [04:49<07:11, 90.85it/s]\u001b[A\n",
      " 36%|███▌      | 21802/61028 [04:49<07:07, 91.65it/s]\u001b[A\n",
      " 36%|███▌      | 21812/61028 [04:49<07:11, 90.87it/s]\u001b[A\n",
      " 36%|███▌      | 21824/61028 [04:49<06:46, 96.35it/s]\u001b[A\n",
      " 36%|███▌      | 21836/61028 [04:49<06:29, 100.74it/s]\u001b[A\n",
      " 36%|███▌      | 21847/61028 [04:49<06:51, 95.11it/s] \u001b[A\n",
      " 36%|███▌      | 21857/61028 [04:49<06:55, 94.33it/s]\u001b[A\n",
      " 36%|███▌      | 21867/61028 [04:49<08:43, 74.84it/s]\u001b[A\n",
      " 36%|███▌      | 21876/61028 [04:50<13:20, 48.92it/s]\u001b[A\n",
      " 36%|███▌      | 21888/61028 [04:50<11:02, 59.08it/s]\u001b[A\n",
      " 36%|███▌      | 21897/61028 [04:50<10:30, 62.02it/s]\u001b[A\n",
      " 36%|███▌      | 21908/61028 [04:50<09:09, 71.15it/s]\u001b[A\n",
      " 36%|███▌      | 21918/61028 [04:50<08:25, 77.40it/s]\u001b[A\n",
      " 36%|███▌      | 21927/61028 [04:50<08:16, 78.73it/s]\u001b[A\n",
      " 36%|███▌      | 21938/61028 [04:50<07:45, 84.02it/s]\u001b[A\n",
      " 36%|███▌      | 21948/61028 [04:51<07:24, 87.85it/s]\u001b[A\n",
      " 36%|███▌      | 21958/61028 [04:51<07:31, 86.59it/s]\u001b[A\n",
      " 36%|███▌      | 21969/61028 [04:51<07:05, 91.90it/s]\u001b[A\n",
      " 36%|███▌      | 21980/61028 [04:51<06:49, 95.30it/s]\u001b[A\n",
      " 36%|███▌      | 21990/61028 [04:51<06:57, 93.53it/s]\u001b[A\n",
      " 36%|███▌      | 22002/61028 [04:51<06:39, 97.68it/s]\u001b[A\n",
      " 36%|███▌      | 22014/61028 [04:51<06:17, 103.36it/s]\u001b[A\n",
      " 36%|███▌      | 22026/61028 [04:51<06:02, 107.66it/s]\u001b[A\n",
      " 36%|███▌      | 22037/61028 [04:51<06:03, 107.19it/s]\u001b[A\n",
      " 36%|███▌      | 22048/61028 [04:52<06:13, 104.47it/s]\u001b[A\n",
      " 36%|███▌      | 22059/61028 [04:52<06:29, 100.07it/s]\u001b[A\n",
      " 36%|███▌      | 22073/61028 [04:52<06:05, 106.45it/s]\u001b[A\n",
      " 36%|███▌      | 22084/61028 [04:52<06:14, 103.94it/s]\u001b[A\n",
      " 36%|███▌      | 22095/61028 [04:52<06:40, 97.20it/s] \u001b[A\n",
      " 36%|███▌      | 22105/61028 [04:52<06:42, 96.62it/s]\u001b[A\n",
      " 36%|███▌      | 22118/61028 [04:52<06:24, 101.32it/s]\u001b[A\n",
      " 36%|███▋      | 22130/61028 [04:52<06:08, 105.69it/s]\u001b[A\n",
      " 36%|███▋      | 22141/61028 [04:52<06:29, 99.82it/s] \u001b[A\n",
      " 36%|███▋      | 22153/61028 [04:53<06:17, 102.87it/s]\u001b[A\n",
      " 36%|███▋      | 22164/61028 [04:53<06:12, 104.35it/s]\u001b[A\n",
      " 36%|███▋      | 22176/61028 [04:53<05:58, 108.29it/s]\u001b[A\n",
      " 36%|███▋      | 22187/61028 [04:53<06:11, 104.58it/s]\u001b[A\n",
      " 36%|███▋      | 22198/61028 [04:53<06:33, 98.80it/s] \u001b[A\n",
      " 36%|███▋      | 22209/61028 [04:53<06:34, 98.41it/s]\u001b[A\n",
      " 36%|███▋      | 22219/61028 [04:53<06:37, 97.55it/s]\u001b[A\n",
      " 36%|███▋      | 22230/61028 [04:53<06:27, 100.23it/s]\u001b[A\n",
      " 36%|███▋      | 22243/61028 [04:53<06:04, 106.38it/s]\u001b[A\n",
      " 36%|███▋      | 22254/61028 [04:54<06:01, 107.25it/s]\u001b[A\n",
      " 36%|███▋      | 22265/61028 [04:54<06:02, 106.79it/s]\u001b[A\n",
      " 37%|███▋      | 22276/61028 [04:54<06:11, 104.36it/s]\u001b[A\n",
      " 37%|███▋      | 22287/61028 [04:54<06:08, 105.13it/s]\u001b[A\n",
      " 37%|███▋      | 22298/61028 [04:54<06:24, 100.85it/s]\u001b[A\n",
      " 37%|███▋      | 22309/61028 [04:54<06:26, 100.09it/s]\u001b[A\n",
      " 37%|███▋      | 22320/61028 [04:54<06:28, 99.53it/s] \u001b[A\n",
      " 37%|███▋      | 22331/61028 [04:54<06:27, 99.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 22342/61028 [04:54<06:21, 101.42it/s]\u001b[A\n",
      " 37%|███▋      | 22353/61028 [04:55<11:17, 57.08it/s] \u001b[A\n",
      " 37%|███▋      | 22361/61028 [04:55<10:42, 60.15it/s]\u001b[A\n",
      " 37%|███▋      | 22370/61028 [04:55<09:46, 65.89it/s]\u001b[A\n",
      " 37%|███▋      | 22379/61028 [04:55<09:05, 70.81it/s]\u001b[A\n",
      " 37%|███▋      | 22390/61028 [04:55<08:21, 77.11it/s]\u001b[A\n",
      " 37%|███▋      | 22399/61028 [04:55<08:28, 75.97it/s]\u001b[A\n",
      " 37%|███▋      | 22412/61028 [04:55<07:27, 86.25it/s]\u001b[A\n",
      " 37%|███▋      | 22422/61028 [04:56<07:21, 87.53it/s]\u001b[A\n",
      " 37%|███▋      | 22432/61028 [04:56<07:23, 87.12it/s]\u001b[A\n",
      " 37%|███▋      | 22443/61028 [04:56<07:00, 91.74it/s]\u001b[A\n",
      " 37%|███▋      | 22453/61028 [04:56<06:59, 91.97it/s]\u001b[A\n",
      " 37%|███▋      | 22463/61028 [04:56<07:27, 86.13it/s]\u001b[A\n",
      " 37%|███▋      | 22474/61028 [04:56<07:01, 91.36it/s]\u001b[A\n",
      " 37%|███▋      | 22484/61028 [04:56<06:58, 92.02it/s]\u001b[A\n",
      " 37%|███▋      | 22496/61028 [04:56<06:33, 97.87it/s]\u001b[A\n",
      " 37%|███▋      | 22507/61028 [04:56<06:36, 97.23it/s]\u001b[A\n",
      " 37%|███▋      | 22517/61028 [04:57<06:36, 97.19it/s]\u001b[A\n",
      " 37%|███▋      | 22527/61028 [04:57<06:50, 93.73it/s]\u001b[A\n",
      " 37%|███▋      | 22540/61028 [04:57<06:25, 99.94it/s]\u001b[A\n",
      " 37%|███▋      | 22551/61028 [04:57<06:48, 94.12it/s]\u001b[A\n",
      " 37%|███▋      | 22561/61028 [04:57<07:06, 90.29it/s]\u001b[A\n",
      " 37%|███▋      | 22572/61028 [04:57<06:45, 94.72it/s]\u001b[A\n",
      " 37%|███▋      | 22582/61028 [04:57<06:48, 94.14it/s]\u001b[A\n",
      " 37%|███▋      | 22592/61028 [04:57<06:41, 95.73it/s]\u001b[A\n",
      " 37%|███▋      | 22602/61028 [04:57<06:52, 93.23it/s]\u001b[A\n",
      " 37%|███▋      | 22612/61028 [04:58<07:01, 91.22it/s]\u001b[A\n",
      " 37%|███▋      | 22623/61028 [04:58<06:49, 93.85it/s]\u001b[A\n",
      " 37%|███▋      | 22633/61028 [04:58<07:11, 89.06it/s]\u001b[A\n",
      " 37%|███▋      | 22643/61028 [04:58<07:02, 90.76it/s]\u001b[A\n",
      " 37%|███▋      | 22653/61028 [04:58<07:01, 91.08it/s]\u001b[A\n",
      " 37%|███▋      | 22663/61028 [04:58<07:05, 90.12it/s]\u001b[A\n",
      " 37%|███▋      | 22674/61028 [04:58<06:45, 94.48it/s]\u001b[A\n",
      " 37%|███▋      | 22684/61028 [04:58<06:40, 95.74it/s]\u001b[A\n",
      " 37%|███▋      | 22694/61028 [04:58<06:47, 94.01it/s]\u001b[A\n",
      " 37%|███▋      | 22706/61028 [04:59<06:29, 98.34it/s]\u001b[A\n",
      " 37%|███▋      | 22716/61028 [04:59<06:45, 94.46it/s]\u001b[A\n",
      " 37%|███▋      | 22728/61028 [04:59<06:25, 99.32it/s]\u001b[A\n",
      " 37%|███▋      | 22739/61028 [04:59<06:42, 95.04it/s]\u001b[A\n",
      " 37%|███▋      | 22750/61028 [04:59<06:30, 97.93it/s]\u001b[A\n",
      " 37%|███▋      | 22760/61028 [04:59<06:30, 97.98it/s]\u001b[A\n",
      " 37%|███▋      | 22770/61028 [04:59<06:42, 95.17it/s]\u001b[A\n",
      " 37%|███▋      | 22780/61028 [04:59<06:44, 94.52it/s]\u001b[A\n",
      " 37%|███▋      | 22790/61028 [04:59<07:10, 88.77it/s]\u001b[A\n",
      " 37%|███▋      | 22800/61028 [05:00<06:57, 91.54it/s]\u001b[A\n",
      " 37%|███▋      | 22810/61028 [05:00<12:08, 52.43it/s]\u001b[A\n",
      " 37%|███▋      | 22818/61028 [05:00<11:19, 56.23it/s]\u001b[A\n",
      " 37%|███▋      | 22829/61028 [05:00<09:41, 65.74it/s]\u001b[A\n",
      " 37%|███▋      | 22839/61028 [05:00<08:45, 72.64it/s]\u001b[A\n",
      " 37%|███▋      | 22848/61028 [05:00<08:16, 76.95it/s]\u001b[A\n",
      " 37%|███▋      | 22859/61028 [05:00<07:37, 83.34it/s]\u001b[A\n",
      " 37%|███▋      | 22870/61028 [05:01<07:04, 89.83it/s]\u001b[A\n",
      " 37%|███▋      | 22882/61028 [05:01<06:40, 95.23it/s]\u001b[A\n",
      " 38%|███▊      | 22893/61028 [05:01<06:47, 93.59it/s]\u001b[A\n",
      " 38%|███▊      | 22903/61028 [05:01<06:54, 91.91it/s]\u001b[A\n",
      " 38%|███▊      | 22915/61028 [05:01<06:32, 96.99it/s]\u001b[A\n",
      " 38%|███▊      | 22925/61028 [05:01<06:41, 94.79it/s]\u001b[A\n",
      " 38%|███▊      | 22935/61028 [05:01<06:42, 94.57it/s]\u001b[A\n",
      " 38%|███▊      | 22945/61028 [05:01<06:45, 93.89it/s]\u001b[A\n",
      " 38%|███▊      | 22955/61028 [05:01<06:40, 95.17it/s]\u001b[A\n",
      " 38%|███▊      | 22966/61028 [05:02<06:30, 97.40it/s]\u001b[A\n",
      " 38%|███▊      | 22976/61028 [05:02<06:37, 95.81it/s]\u001b[A\n",
      " 38%|███▊      | 22987/61028 [05:02<06:31, 97.19it/s]\u001b[A\n",
      " 38%|███▊      | 22997/61028 [05:02<06:35, 96.11it/s]\u001b[A\n",
      " 38%|███▊      | 23009/61028 [05:02<06:14, 101.57it/s]\u001b[A\n",
      " 38%|███▊      | 23020/61028 [05:02<06:06, 103.68it/s]\u001b[A\n",
      " 38%|███▊      | 23032/61028 [05:02<05:54, 107.23it/s]\u001b[A\n",
      " 38%|███▊      | 23044/61028 [05:02<05:44, 110.29it/s]\u001b[A\n",
      " 38%|███▊      | 23056/61028 [05:02<05:36, 112.72it/s]\u001b[A\n",
      " 38%|███▊      | 23068/61028 [05:03<05:48, 108.97it/s]\u001b[A\n",
      " 38%|███▊      | 23079/61028 [05:03<05:54, 107.03it/s]\u001b[A\n",
      " 38%|███▊      | 23090/61028 [05:03<05:57, 106.14it/s]\u001b[A\n",
      " 38%|███▊      | 23101/61028 [05:03<06:19, 100.06it/s]\u001b[A\n",
      " 38%|███▊      | 23112/61028 [05:03<06:10, 102.37it/s]\u001b[A\n",
      " 38%|███▊      | 23123/61028 [05:03<06:15, 100.96it/s]\u001b[A\n",
      " 38%|███▊      | 23134/61028 [05:03<06:42, 94.09it/s] \u001b[A\n",
      " 38%|███▊      | 23144/61028 [05:03<07:18, 86.38it/s]\u001b[A\n",
      " 38%|███▊      | 23155/61028 [05:03<06:51, 91.93it/s]\u001b[A\n",
      " 38%|███▊      | 23165/61028 [05:04<06:43, 93.79it/s]\u001b[A\n",
      " 38%|███▊      | 23176/61028 [05:04<06:26, 97.93it/s]\u001b[A\n",
      " 38%|███▊      | 23186/61028 [05:04<06:42, 94.02it/s]\u001b[A\n",
      " 38%|███▊      | 23196/61028 [05:04<07:00, 89.88it/s]\u001b[A\n",
      " 38%|███▊      | 23207/61028 [05:04<06:45, 93.36it/s]\u001b[A\n",
      " 38%|███▊      | 23218/61028 [05:04<06:28, 97.43it/s]\u001b[A\n",
      " 38%|███▊      | 23228/61028 [05:04<06:31, 96.65it/s]\u001b[A\n",
      " 38%|███▊      | 23239/61028 [05:04<06:20, 99.27it/s]\u001b[A\n",
      " 38%|███▊      | 23250/61028 [05:04<06:12, 101.54it/s]\u001b[A\n",
      " 38%|███▊      | 23261/61028 [05:05<06:31, 96.38it/s] \u001b[A\n",
      " 38%|███▊      | 23271/61028 [05:05<07:08, 88.20it/s]\u001b[A\n",
      " 38%|███▊      | 23281/61028 [05:05<11:54, 52.80it/s]\u001b[A\n",
      " 38%|███▊      | 23292/61028 [05:05<10:04, 62.38it/s]\u001b[A\n",
      " 38%|███▊      | 23302/61028 [05:05<09:07, 68.86it/s]\u001b[A\n",
      " 38%|███▊      | 23312/61028 [05:05<08:25, 74.65it/s]\u001b[A\n",
      " 38%|███▊      | 23323/61028 [05:05<07:46, 80.83it/s]\u001b[A\n",
      " 38%|███▊      | 23334/61028 [05:06<07:13, 86.99it/s]\u001b[A\n",
      " 38%|███▊      | 23345/61028 [05:06<06:53, 91.22it/s]\u001b[A\n",
      " 38%|███▊      | 23355/61028 [05:06<07:00, 89.62it/s]\u001b[A\n",
      " 38%|███▊      | 23365/61028 [05:06<06:48, 92.26it/s]\u001b[A\n",
      " 38%|███▊      | 23375/61028 [05:06<06:46, 92.60it/s]\u001b[A\n",
      " 38%|███▊      | 23385/61028 [05:06<06:44, 93.11it/s]\u001b[A\n",
      " 38%|███▊      | 23396/61028 [05:06<06:28, 96.97it/s]\u001b[A\n",
      " 38%|███▊      | 23406/61028 [05:06<07:00, 89.51it/s]\u001b[A\n",
      " 38%|███▊      | 23416/61028 [05:06<06:54, 90.78it/s]\u001b[A\n",
      " 38%|███▊      | 23427/61028 [05:07<06:32, 95.70it/s]\u001b[A\n",
      " 38%|███▊      | 23437/61028 [05:07<06:42, 93.50it/s]\u001b[A\n",
      " 38%|███▊      | 23449/61028 [05:07<06:19, 99.02it/s]\u001b[A\n",
      " 38%|███▊      | 23460/61028 [05:07<06:28, 96.67it/s]\u001b[A\n",
      " 38%|███▊      | 23471/61028 [05:07<06:18, 99.19it/s]\u001b[A\n",
      " 38%|███▊      | 23482/61028 [05:07<06:37, 94.47it/s]\u001b[A\n",
      " 38%|███▊      | 23492/61028 [05:07<06:38, 94.15it/s]\u001b[A\n",
      " 39%|███▊      | 23504/61028 [05:07<06:23, 97.85it/s]\u001b[A\n",
      " 39%|███▊      | 23515/61028 [05:07<06:13, 100.42it/s]\u001b[A\n",
      " 39%|███▊      | 23526/61028 [05:08<06:10, 101.10it/s]\u001b[A\n",
      " 39%|███▊      | 23537/61028 [05:08<06:29, 96.34it/s] \u001b[A\n",
      " 39%|███▊      | 23549/61028 [05:08<06:14, 100.02it/s]\u001b[A\n",
      " 39%|███▊      | 23561/61028 [05:08<05:58, 104.42it/s]\u001b[A\n",
      " 39%|███▊      | 23572/61028 [05:08<06:05, 102.50it/s]\u001b[A\n",
      " 39%|███▊      | 23583/61028 [05:08<06:16, 99.51it/s] \u001b[A\n",
      " 39%|███▊      | 23594/61028 [05:08<06:10, 101.17it/s]\u001b[A\n",
      " 39%|███▊      | 23605/61028 [05:08<06:12, 100.39it/s]\u001b[A\n",
      " 39%|███▊      | 23616/61028 [05:08<06:17, 99.08it/s] \u001b[A\n",
      " 39%|███▊      | 23626/61028 [05:09<06:41, 93.21it/s]\u001b[A\n",
      " 39%|███▊      | 23637/61028 [05:09<06:35, 94.50it/s]\u001b[A\n",
      " 39%|███▊      | 23648/61028 [05:09<06:25, 97.06it/s]\u001b[A\n",
      " 39%|███▉      | 23660/61028 [05:09<06:10, 100.75it/s]\u001b[A\n",
      " 39%|███▉      | 23671/61028 [05:09<06:07, 101.53it/s]\u001b[A\n",
      " 39%|███▉      | 23682/61028 [05:09<06:14, 99.75it/s] \u001b[A\n",
      " 39%|███▉      | 23694/61028 [05:09<06:03, 102.62it/s]\u001b[A\n",
      " 39%|███▉      | 23705/61028 [05:09<06:23, 97.41it/s] \u001b[A\n",
      " 39%|███▉      | 23716/61028 [05:09<06:11, 100.57it/s]\u001b[A\n",
      " 39%|███▉      | 23727/61028 [05:10<06:34, 94.59it/s] \u001b[A\n",
      " 39%|███▉      | 23737/61028 [05:10<07:22, 84.26it/s]\u001b[A\n",
      " 39%|███▉      | 23746/61028 [05:10<07:23, 83.98it/s]\u001b[A\n",
      " 39%|███▉      | 23755/61028 [05:10<12:34, 49.41it/s]\u001b[A\n",
      " 39%|███▉      | 23765/61028 [05:10<10:51, 57.19it/s]\u001b[A\n",
      " 39%|███▉      | 23775/61028 [05:10<09:29, 65.46it/s]\u001b[A\n",
      " 39%|███▉      | 23785/61028 [05:11<08:37, 72.01it/s]\u001b[A\n",
      " 39%|███▉      | 23794/61028 [05:11<08:22, 74.16it/s]\u001b[A\n",
      " 39%|███▉      | 23805/61028 [05:11<07:39, 80.94it/s]\u001b[A\n",
      " 39%|███▉      | 23815/61028 [05:11<07:24, 83.63it/s]\u001b[A\n",
      " 39%|███▉      | 23825/61028 [05:11<07:12, 86.03it/s]\u001b[A\n",
      " 39%|███▉      | 23835/61028 [05:11<07:13, 85.89it/s]\u001b[A\n",
      " 39%|███▉      | 23845/61028 [05:11<07:01, 88.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 23855/61028 [05:11<06:52, 90.07it/s]\u001b[A\n",
      " 39%|███▉      | 23867/61028 [05:11<06:30, 95.22it/s]\u001b[A\n",
      " 39%|███▉      | 23878/61028 [05:12<06:20, 97.52it/s]\u001b[A\n",
      " 39%|███▉      | 23888/61028 [05:12<07:11, 86.14it/s]\u001b[A\n",
      " 39%|███▉      | 23897/61028 [05:12<07:10, 86.19it/s]\u001b[A\n",
      " 39%|███▉      | 23909/61028 [05:12<06:36, 93.70it/s]\u001b[A\n",
      " 39%|███▉      | 23922/61028 [05:12<06:10, 100.24it/s]\u001b[A\n",
      " 39%|███▉      | 23933/61028 [05:12<06:07, 100.86it/s]\u001b[A\n",
      " 39%|███▉      | 23944/61028 [05:12<06:10, 100.10it/s]\u001b[A\n",
      " 39%|███▉      | 23955/61028 [05:12<06:17, 98.16it/s] \u001b[A\n",
      " 39%|███▉      | 23966/61028 [05:12<06:09, 100.26it/s]\u001b[A\n",
      " 39%|███▉      | 23977/61028 [05:13<06:32, 94.34it/s] \u001b[A\n",
      " 39%|███▉      | 23987/61028 [05:13<06:40, 92.57it/s]\u001b[A\n",
      " 39%|███▉      | 23998/61028 [05:13<06:32, 94.31it/s]\u001b[A\n",
      " 39%|███▉      | 24009/61028 [05:13<06:22, 96.83it/s]\u001b[A\n",
      " 39%|███▉      | 24019/61028 [05:13<06:19, 97.48it/s]\u001b[A\n",
      " 39%|███▉      | 24030/61028 [05:13<06:16, 98.29it/s]\u001b[A\n",
      " 39%|███▉      | 24042/61028 [05:13<06:01, 102.27it/s]\u001b[A\n",
      " 39%|███▉      | 24053/61028 [05:13<06:03, 101.65it/s]\u001b[A\n",
      " 39%|███▉      | 24064/61028 [05:13<06:16, 98.26it/s] \u001b[A\n",
      " 39%|███▉      | 24074/61028 [05:14<07:11, 85.65it/s]\u001b[A\n",
      " 39%|███▉      | 24085/61028 [05:14<06:55, 88.91it/s]\u001b[A\n",
      " 39%|███▉      | 24095/61028 [05:14<06:49, 90.20it/s]\u001b[A\n",
      " 39%|███▉      | 24106/61028 [05:14<06:29, 94.75it/s]\u001b[A\n",
      " 40%|███▉      | 24118/61028 [05:14<06:08, 100.23it/s]\u001b[A\n",
      " 40%|███▉      | 24129/61028 [05:14<06:26, 95.36it/s] \u001b[A\n",
      " 40%|███▉      | 24140/61028 [05:14<06:21, 96.76it/s]\u001b[A\n",
      " 40%|███▉      | 24151/61028 [05:14<06:15, 98.29it/s]\u001b[A\n",
      " 40%|███▉      | 24162/61028 [05:14<06:08, 100.11it/s]\u001b[A\n",
      " 40%|███▉      | 24173/61028 [05:15<06:14, 98.40it/s] \u001b[A\n",
      " 40%|███▉      | 24183/61028 [05:15<06:30, 94.45it/s]\u001b[A\n",
      " 40%|███▉      | 24195/61028 [05:15<06:14, 98.23it/s]\u001b[A\n",
      " 40%|███▉      | 24206/61028 [05:15<06:13, 98.54it/s]\u001b[A\n",
      " 40%|███▉      | 24216/61028 [05:15<10:24, 58.91it/s]\u001b[A\n",
      " 40%|███▉      | 24224/61028 [05:15<10:08, 60.50it/s]\u001b[A\n",
      " 40%|███▉      | 24236/61028 [05:15<08:38, 70.98it/s]\u001b[A\n",
      " 40%|███▉      | 24247/61028 [05:16<07:50, 78.14it/s]\u001b[A\n",
      " 40%|███▉      | 24257/61028 [05:16<07:47, 78.58it/s]\u001b[A\n",
      " 40%|███▉      | 24268/61028 [05:16<07:12, 85.02it/s]\u001b[A\n",
      " 40%|███▉      | 24280/61028 [05:16<06:35, 93.00it/s]\u001b[A\n",
      " 40%|███▉      | 24291/61028 [05:16<06:46, 90.36it/s]\u001b[A\n",
      " 40%|███▉      | 24303/61028 [05:16<06:20, 96.50it/s]\u001b[A\n",
      " 40%|███▉      | 24314/61028 [05:16<06:22, 95.90it/s]\u001b[A\n",
      " 40%|███▉      | 24325/61028 [05:16<06:18, 96.85it/s]\u001b[A\n",
      " 40%|███▉      | 24336/61028 [05:16<06:07, 99.75it/s]\u001b[A\n",
      " 40%|███▉      | 24347/61028 [05:17<06:23, 95.56it/s]\u001b[A\n",
      " 40%|███▉      | 24357/61028 [05:17<06:31, 93.74it/s]\u001b[A\n",
      " 40%|███▉      | 24368/61028 [05:17<06:18, 96.85it/s]\u001b[A\n",
      " 40%|███▉      | 24378/61028 [05:17<06:33, 93.13it/s]\u001b[A\n",
      " 40%|███▉      | 24388/61028 [05:17<06:27, 94.67it/s]\u001b[A\n",
      " 40%|███▉      | 24400/61028 [05:17<06:09, 99.15it/s]\u001b[A\n",
      " 40%|███▉      | 24411/61028 [05:17<06:19, 96.46it/s]\u001b[A\n",
      " 40%|████      | 24421/61028 [05:17<06:22, 95.77it/s]\u001b[A\n",
      " 40%|████      | 24431/61028 [05:17<06:23, 95.54it/s]\u001b[A\n",
      " 40%|████      | 24441/61028 [05:18<06:44, 90.52it/s]\u001b[A\n",
      " 40%|████      | 24452/61028 [05:18<06:28, 94.05it/s]\u001b[A\n",
      " 40%|████      | 24463/61028 [05:18<06:15, 97.33it/s]\u001b[A\n",
      " 40%|████      | 24473/61028 [05:18<06:38, 91.82it/s]\u001b[A\n",
      " 40%|████      | 24484/61028 [05:18<06:26, 94.62it/s]\u001b[A\n",
      " 40%|████      | 24495/61028 [05:18<06:17, 96.66it/s]\u001b[A\n",
      " 40%|████      | 24506/61028 [05:18<06:04, 100.30it/s]\u001b[A\n",
      " 40%|████      | 24519/61028 [05:18<05:39, 107.68it/s]\u001b[A\n",
      " 40%|████      | 24530/61028 [05:18<05:46, 105.44it/s]\u001b[A\n",
      " 40%|████      | 24541/61028 [05:19<06:05, 99.95it/s] \u001b[A\n",
      " 40%|████      | 24553/61028 [05:19<05:51, 103.87it/s]\u001b[A\n",
      " 40%|████      | 24564/61028 [05:19<06:13, 97.62it/s] \u001b[A\n",
      " 40%|████      | 24577/61028 [05:19<05:48, 104.52it/s]\u001b[A\n",
      " 40%|████      | 24588/61028 [05:19<05:51, 103.77it/s]\u001b[A\n",
      " 40%|████      | 24599/61028 [05:19<05:56, 102.30it/s]\u001b[A\n",
      " 40%|████      | 24610/61028 [05:19<06:06, 99.38it/s] \u001b[A\n",
      " 40%|████      | 24621/61028 [05:19<06:03, 100.22it/s]\u001b[A\n",
      " 40%|████      | 24633/61028 [05:19<05:45, 105.31it/s]\u001b[A\n",
      " 40%|████      | 24644/61028 [05:20<06:18, 96.18it/s] \u001b[A\n",
      " 40%|████      | 24654/61028 [05:20<06:32, 92.78it/s]\u001b[A\n",
      " 40%|████      | 24664/61028 [05:20<06:28, 93.57it/s]\u001b[A\n",
      " 40%|████      | 24674/61028 [05:20<06:36, 91.69it/s]\u001b[A\n",
      " 40%|████      | 24685/61028 [05:20<06:25, 94.37it/s]\u001b[A\n",
      " 40%|████      | 24695/61028 [05:20<10:34, 57.24it/s]\u001b[A\n",
      " 40%|████      | 24703/61028 [05:20<10:06, 59.93it/s]\u001b[A\n",
      " 40%|████      | 24712/61028 [05:21<09:07, 66.38it/s]\u001b[A\n",
      " 41%|████      | 24723/61028 [05:21<08:03, 75.14it/s]\u001b[A\n",
      " 41%|████      | 24733/61028 [05:21<07:55, 76.37it/s]\u001b[A\n",
      " 41%|████      | 24744/61028 [05:21<07:24, 81.55it/s]\u001b[A\n",
      " 41%|████      | 24756/61028 [05:21<07:05, 85.17it/s]\u001b[A\n",
      " 41%|████      | 24766/61028 [05:21<07:09, 84.46it/s]\u001b[A\n",
      " 41%|████      | 24778/61028 [05:21<06:31, 92.67it/s]\u001b[A\n",
      " 41%|████      | 24788/61028 [05:21<06:29, 93.13it/s]\u001b[A\n",
      " 41%|████      | 24798/61028 [05:21<06:26, 93.69it/s]\u001b[A\n",
      " 41%|████      | 24808/61028 [05:22<06:38, 90.92it/s]\u001b[A\n",
      " 41%|████      | 24818/61028 [05:22<06:32, 92.19it/s]\u001b[A\n",
      " 41%|████      | 24828/61028 [05:22<06:32, 92.23it/s]\u001b[A\n",
      " 41%|████      | 24839/61028 [05:22<06:20, 95.20it/s]\u001b[A\n",
      " 41%|████      | 24849/61028 [05:22<06:33, 92.05it/s]\u001b[A\n",
      " 41%|████      | 24859/61028 [05:22<06:36, 91.25it/s]\u001b[A\n",
      " 41%|████      | 24869/61028 [05:22<06:28, 93.16it/s]\u001b[A\n",
      " 41%|████      | 24879/61028 [05:22<06:22, 94.53it/s]\u001b[A\n",
      " 41%|████      | 24890/61028 [05:22<06:14, 96.38it/s]\u001b[A\n",
      " 41%|████      | 24901/61028 [05:23<06:12, 96.93it/s]\u001b[A\n",
      " 41%|████      | 24913/61028 [05:23<05:56, 101.33it/s]\u001b[A\n",
      " 41%|████      | 24926/61028 [05:23<05:34, 108.04it/s]\u001b[A\n",
      " 41%|████      | 24937/61028 [05:23<05:40, 105.91it/s]\u001b[A\n",
      " 41%|████      | 24948/61028 [05:23<05:52, 102.25it/s]\u001b[A\n",
      " 41%|████      | 24959/61028 [05:23<06:08, 97.81it/s] \u001b[A\n",
      " 41%|████      | 24970/61028 [05:23<05:59, 100.28it/s]\u001b[A\n",
      " 41%|████      | 24981/61028 [05:23<05:50, 102.98it/s]\u001b[A\n",
      " 41%|████      | 24992/61028 [05:23<06:02, 99.50it/s] \u001b[A\n",
      " 41%|████      | 25003/61028 [05:24<06:30, 92.30it/s]\u001b[A\n",
      " 41%|████      | 25013/61028 [05:24<06:26, 93.15it/s]\u001b[A\n",
      " 41%|████      | 25026/61028 [05:24<06:02, 99.18it/s]\u001b[A\n",
      " 41%|████      | 25037/61028 [05:24<06:07, 97.92it/s]\u001b[A\n",
      " 41%|████      | 25047/61028 [05:24<06:16, 95.66it/s]\u001b[A\n",
      " 41%|████      | 25059/61028 [05:24<06:01, 99.57it/s]\u001b[A\n",
      " 41%|████      | 25070/61028 [05:24<06:21, 94.23it/s]\u001b[A\n",
      " 41%|████      | 25080/61028 [05:24<06:25, 93.31it/s]\u001b[A\n",
      " 41%|████      | 25091/61028 [05:25<06:13, 96.31it/s]\u001b[A\n",
      " 41%|████      | 25102/61028 [05:25<06:06, 98.02it/s]\u001b[A\n",
      " 41%|████      | 25112/61028 [05:25<06:25, 93.06it/s]\u001b[A\n",
      " 41%|████      | 25122/61028 [05:25<06:49, 87.64it/s]\u001b[A\n",
      " 41%|████      | 25133/61028 [05:25<06:26, 92.98it/s]\u001b[A\n",
      " 41%|████      | 25143/61028 [05:25<06:28, 92.32it/s]\u001b[A\n",
      " 41%|████      | 25154/61028 [05:25<06:25, 93.08it/s]\u001b[A\n",
      " 41%|████      | 25164/61028 [05:26<11:29, 52.01it/s]\u001b[A\n",
      " 41%|████▏     | 25175/61028 [05:26<09:47, 60.99it/s]\u001b[A\n",
      " 41%|████▏     | 25188/61028 [05:26<08:18, 71.84it/s]\u001b[A\n",
      " 41%|████▏     | 25200/61028 [05:26<07:20, 81.37it/s]\u001b[A\n",
      " 41%|████▏     | 25212/61028 [05:26<06:44, 88.57it/s]\u001b[A\n",
      " 41%|████▏     | 25223/61028 [05:26<06:40, 89.45it/s]\u001b[A\n",
      " 41%|████▏     | 25235/61028 [05:26<06:11, 96.40it/s]\u001b[A\n",
      " 41%|████▏     | 25246/61028 [05:26<06:05, 97.83it/s]\u001b[A\n",
      " 41%|████▏     | 25257/61028 [05:26<06:18, 94.48it/s]\u001b[A\n",
      " 41%|████▏     | 25267/61028 [05:27<06:29, 91.78it/s]\u001b[A\n",
      " 41%|████▏     | 25277/61028 [05:27<06:35, 90.37it/s]\u001b[A\n",
      " 41%|████▏     | 25288/61028 [05:27<06:16, 94.88it/s]\u001b[A\n",
      " 41%|████▏     | 25300/61028 [05:27<06:00, 98.99it/s]\u001b[A\n",
      " 41%|████▏     | 25311/61028 [05:27<05:57, 99.97it/s]\u001b[A\n",
      " 41%|████▏     | 25322/61028 [05:27<06:03, 98.12it/s]\u001b[A\n",
      " 42%|████▏     | 25334/61028 [05:27<05:51, 101.49it/s]\u001b[A\n",
      " 42%|████▏     | 25345/61028 [05:27<06:06, 97.44it/s] \u001b[A\n",
      " 42%|████▏     | 25355/61028 [05:27<06:13, 95.41it/s]\u001b[A\n",
      " 42%|████▏     | 25366/61028 [05:28<06:05, 97.53it/s]\u001b[A\n",
      " 42%|████▏     | 25376/61028 [05:28<06:11, 96.00it/s]\u001b[A\n",
      " 42%|████▏     | 25388/61028 [05:28<05:53, 100.87it/s]\u001b[A\n",
      " 42%|████▏     | 25399/61028 [05:28<05:54, 100.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 25410/61028 [05:28<05:53, 100.62it/s]\u001b[A\n",
      " 42%|████▏     | 25423/61028 [05:28<05:31, 107.55it/s]\u001b[A\n",
      " 42%|████▏     | 25434/61028 [05:28<05:45, 103.05it/s]\u001b[A\n",
      " 42%|████▏     | 25445/61028 [05:28<05:43, 103.49it/s]\u001b[A\n",
      " 42%|████▏     | 25456/61028 [05:28<05:46, 102.76it/s]\u001b[A\n",
      " 42%|████▏     | 25467/61028 [05:29<05:58, 99.28it/s] \u001b[A\n",
      " 42%|████▏     | 25478/61028 [05:29<05:54, 100.41it/s]\u001b[A\n",
      " 42%|████▏     | 25489/61028 [05:29<06:00, 98.46it/s] \u001b[A\n",
      " 42%|████▏     | 25501/61028 [05:29<05:51, 100.98it/s]\u001b[A\n",
      " 42%|████▏     | 25512/61028 [05:29<05:51, 101.15it/s]\u001b[A\n",
      " 42%|████▏     | 25524/61028 [05:29<05:40, 104.30it/s]\u001b[A\n",
      " 42%|████▏     | 25535/61028 [05:29<05:37, 105.18it/s]\u001b[A\n",
      " 42%|████▏     | 25546/61028 [05:29<05:40, 104.23it/s]\u001b[A\n",
      " 42%|████▏     | 25557/61028 [05:29<05:46, 102.44it/s]\u001b[A\n",
      " 42%|████▏     | 25569/61028 [05:30<05:37, 105.10it/s]\u001b[A\n",
      " 42%|████▏     | 25580/61028 [05:30<05:46, 102.18it/s]\u001b[A\n",
      " 42%|████▏     | 25591/61028 [05:30<06:10, 95.71it/s] \u001b[A\n",
      " 42%|████▏     | 25601/61028 [05:30<06:23, 92.33it/s]\u001b[A\n",
      " 42%|████▏     | 25611/61028 [05:30<06:20, 93.12it/s]\u001b[A\n",
      " 42%|████▏     | 25623/61028 [05:30<06:05, 96.81it/s]\u001b[A\n",
      " 42%|████▏     | 25633/61028 [05:30<06:18, 93.64it/s]\u001b[A\n",
      " 42%|████▏     | 25643/61028 [05:30<06:43, 87.78it/s]\u001b[A\n",
      " 42%|████▏     | 25652/61028 [05:31<12:24, 47.54it/s]\u001b[A\n",
      " 42%|████▏     | 25665/61028 [05:31<10:10, 57.94it/s]\u001b[A\n",
      " 42%|████▏     | 25675/61028 [05:31<09:03, 64.99it/s]\u001b[A\n",
      " 42%|████▏     | 25687/61028 [05:31<07:56, 74.20it/s]\u001b[A\n",
      " 42%|████▏     | 25697/61028 [05:31<07:36, 77.38it/s]\u001b[A\n",
      " 42%|████▏     | 25709/61028 [05:31<06:52, 85.55it/s]\u001b[A\n",
      " 42%|████▏     | 25719/61028 [05:31<06:58, 84.38it/s]\u001b[A\n",
      " 42%|████▏     | 25730/61028 [05:32<06:33, 89.76it/s]\u001b[A\n",
      " 42%|████▏     | 25740/61028 [05:32<06:28, 90.94it/s]\u001b[A\n",
      " 42%|████▏     | 25751/61028 [05:32<06:14, 94.07it/s]\u001b[A\n",
      " 42%|████▏     | 25761/61028 [05:32<06:12, 94.61it/s]\u001b[A\n",
      " 42%|████▏     | 25771/61028 [05:32<06:13, 94.42it/s]\u001b[A\n",
      " 42%|████▏     | 25781/61028 [05:32<06:21, 92.44it/s]\u001b[A\n",
      " 42%|████▏     | 25792/61028 [05:32<06:05, 96.53it/s]\u001b[A\n",
      " 42%|████▏     | 25802/61028 [05:32<06:07, 95.89it/s]\u001b[A\n",
      " 42%|████▏     | 25812/61028 [05:32<06:03, 96.93it/s]\u001b[A\n",
      " 42%|████▏     | 25822/61028 [05:32<06:03, 96.90it/s]\u001b[A\n",
      " 42%|████▏     | 25833/61028 [05:33<05:55, 99.12it/s]\u001b[A\n",
      " 42%|████▏     | 25844/61028 [05:33<05:48, 101.00it/s]\u001b[A\n",
      " 42%|████▏     | 25855/61028 [05:33<05:59, 97.87it/s] \u001b[A\n",
      " 42%|████▏     | 25865/61028 [05:33<06:03, 96.63it/s]\u001b[A\n",
      " 42%|████▏     | 25876/61028 [05:33<05:56, 98.55it/s]\u001b[A\n",
      " 42%|████▏     | 25887/61028 [05:33<05:48, 100.93it/s]\u001b[A\n",
      " 42%|████▏     | 25900/61028 [05:33<05:31, 106.04it/s]\u001b[A\n",
      " 42%|████▏     | 25911/61028 [05:33<05:42, 102.61it/s]\u001b[A\n",
      " 42%|████▏     | 25922/61028 [05:33<05:43, 102.12it/s]\u001b[A\n",
      " 42%|████▏     | 25933/61028 [05:34<05:54, 98.88it/s] \u001b[A\n",
      " 43%|████▎     | 25944/61028 [05:34<06:08, 95.34it/s]\u001b[A\n",
      " 43%|████▎     | 25954/61028 [05:34<06:04, 96.28it/s]\u001b[A\n",
      " 43%|████▎     | 25964/61028 [05:34<06:15, 93.33it/s]\u001b[A\n",
      " 43%|████▎     | 25975/61028 [05:34<06:00, 97.33it/s]\u001b[A\n",
      " 43%|████▎     | 25987/61028 [05:34<05:47, 100.80it/s]\u001b[A\n",
      " 43%|████▎     | 25998/61028 [05:34<05:52, 99.49it/s] \u001b[A\n",
      " 43%|████▎     | 26009/61028 [05:34<05:57, 98.04it/s]\u001b[A\n",
      " 43%|████▎     | 26019/61028 [05:34<06:02, 96.54it/s]\u001b[A\n",
      " 43%|████▎     | 26029/61028 [05:35<06:06, 95.45it/s]\u001b[A\n",
      " 43%|████▎     | 26039/61028 [05:35<06:13, 93.78it/s]\u001b[A\n",
      " 43%|████▎     | 26050/61028 [05:35<06:03, 96.24it/s]\u001b[A\n",
      " 43%|████▎     | 26060/61028 [05:35<06:26, 90.43it/s]\u001b[A\n",
      " 43%|████▎     | 26070/61028 [05:35<06:16, 92.91it/s]\u001b[A\n",
      " 43%|████▎     | 26080/61028 [05:35<06:26, 90.49it/s]\u001b[A\n",
      " 43%|████▎     | 26090/61028 [05:35<06:21, 91.55it/s]\u001b[A\n",
      " 43%|████▎     | 26100/61028 [05:35<06:30, 89.37it/s]\u001b[A\n",
      " 43%|████▎     | 26109/61028 [05:35<06:54, 84.16it/s]\u001b[A\n",
      " 43%|████▎     | 26118/61028 [05:36<11:18, 51.43it/s]\u001b[A\n",
      " 43%|████▎     | 26129/61028 [05:36<09:36, 60.58it/s]\u001b[A\n",
      " 43%|████▎     | 26139/61028 [05:36<08:33, 67.92it/s]\u001b[A\n",
      " 43%|████▎     | 26149/61028 [05:36<07:44, 75.09it/s]\u001b[A\n",
      " 43%|████▎     | 26160/61028 [05:36<07:07, 81.51it/s]\u001b[A\n",
      " 43%|████▎     | 26171/61028 [05:36<06:40, 86.93it/s]\u001b[A\n",
      " 43%|████▎     | 26182/61028 [05:36<06:24, 90.65it/s]\u001b[A\n",
      " 43%|████▎     | 26192/61028 [05:37<06:15, 92.70it/s]\u001b[A\n",
      " 43%|████▎     | 26203/61028 [05:37<06:06, 95.13it/s]\u001b[A\n",
      " 43%|████▎     | 26213/61028 [05:37<06:14, 92.93it/s]\u001b[A\n",
      " 43%|████▎     | 26223/61028 [05:37<06:09, 94.28it/s]\u001b[A\n",
      " 43%|████▎     | 26233/61028 [05:37<06:10, 93.84it/s]\u001b[A\n",
      " 43%|████▎     | 26243/61028 [05:37<06:15, 92.68it/s]\u001b[A\n",
      " 43%|████▎     | 26253/61028 [05:37<06:14, 92.86it/s]\u001b[A\n",
      " 43%|████▎     | 26264/61028 [05:37<05:59, 96.70it/s]\u001b[A\n",
      " 43%|████▎     | 26274/61028 [05:37<06:06, 94.74it/s]\u001b[A\n",
      " 43%|████▎     | 26285/61028 [05:38<06:02, 95.90it/s]\u001b[A\n",
      " 43%|████▎     | 26296/61028 [05:38<05:54, 98.07it/s]\u001b[A\n",
      " 43%|████▎     | 26306/61028 [05:38<05:58, 96.98it/s]\u001b[A\n",
      " 43%|████▎     | 26318/61028 [05:38<05:47, 100.02it/s]\u001b[A\n",
      " 43%|████▎     | 26329/61028 [05:38<05:56, 97.35it/s] \u001b[A\n",
      " 43%|████▎     | 26339/61028 [05:38<05:58, 96.81it/s]\u001b[A\n",
      " 43%|████▎     | 26350/61028 [05:38<05:50, 98.87it/s]\u001b[A\n",
      " 43%|████▎     | 26361/61028 [05:38<05:47, 99.67it/s]\u001b[A\n",
      " 43%|████▎     | 26372/61028 [05:38<05:44, 100.46it/s]\u001b[A\n",
      " 43%|████▎     | 26383/61028 [05:39<05:48, 99.54it/s] \u001b[A\n",
      " 43%|████▎     | 26393/61028 [05:39<05:50, 98.74it/s]\u001b[A\n",
      " 43%|████▎     | 26403/61028 [05:39<06:04, 94.97it/s]\u001b[A\n",
      " 43%|████▎     | 26415/61028 [05:39<05:50, 98.76it/s]\u001b[A\n",
      " 43%|████▎     | 26427/61028 [05:39<05:40, 101.54it/s]\u001b[A\n",
      " 43%|████▎     | 26438/61028 [05:39<05:50, 98.60it/s] \u001b[A\n",
      " 43%|████▎     | 26448/61028 [05:39<05:56, 97.06it/s]\u001b[A\n",
      " 43%|████▎     | 26458/61028 [05:39<05:54, 97.65it/s]\u001b[A\n",
      " 43%|████▎     | 26469/61028 [05:39<05:47, 99.52it/s]\u001b[A\n",
      " 43%|████▎     | 26479/61028 [05:39<05:47, 99.42it/s]\u001b[A\n",
      " 43%|████▎     | 26489/61028 [05:40<05:51, 98.39it/s]\u001b[A\n",
      " 43%|████▎     | 26499/61028 [05:40<05:56, 96.96it/s]\u001b[A\n",
      " 43%|████▎     | 26509/61028 [05:40<06:39, 86.33it/s]\u001b[A\n",
      " 43%|████▎     | 26519/61028 [05:40<06:27, 89.00it/s]\u001b[A\n",
      " 43%|████▎     | 26530/61028 [05:40<06:13, 92.36it/s]\u001b[A\n",
      " 43%|████▎     | 26540/61028 [05:40<06:12, 92.59it/s]\u001b[A\n",
      " 44%|████▎     | 26551/61028 [05:40<05:55, 97.03it/s]\u001b[A\n",
      " 44%|████▎     | 26562/61028 [05:40<05:47, 99.20it/s]\u001b[A\n",
      " 44%|████▎     | 26573/61028 [05:40<05:55, 96.87it/s]\u001b[A\n",
      " 44%|████▎     | 26583/61028 [05:41<09:44, 58.92it/s]\u001b[A\n",
      " 44%|████▎     | 26591/61028 [05:41<09:30, 60.35it/s]\u001b[A\n",
      " 44%|████▎     | 26601/61028 [05:41<08:28, 67.68it/s]\u001b[A\n",
      " 44%|████▎     | 26613/61028 [05:41<07:28, 76.68it/s]\u001b[A\n",
      " 44%|████▎     | 26623/61028 [05:41<06:57, 82.37it/s]\u001b[A\n",
      " 44%|████▎     | 26633/61028 [05:41<06:39, 86.12it/s]\u001b[A\n",
      " 44%|████▎     | 26643/61028 [05:41<06:36, 86.74it/s]\u001b[A\n",
      " 44%|████▎     | 26653/61028 [05:42<06:23, 89.57it/s]\u001b[A\n",
      " 44%|████▎     | 26664/61028 [05:42<06:06, 93.64it/s]\u001b[A\n",
      " 44%|████▎     | 26674/61028 [05:42<06:02, 94.82it/s]\u001b[A\n",
      " 44%|████▎     | 26686/61028 [05:42<05:50, 98.04it/s]\u001b[A\n",
      " 44%|████▎     | 26698/61028 [05:42<05:35, 102.40it/s]\u001b[A\n",
      " 44%|████▍     | 26709/61028 [05:42<05:33, 103.00it/s]\u001b[A\n",
      " 44%|████▍     | 26720/61028 [05:42<05:38, 101.37it/s]\u001b[A\n",
      " 44%|████▍     | 26731/61028 [05:42<05:40, 100.59it/s]\u001b[A\n",
      " 44%|████▍     | 26742/61028 [05:42<05:34, 102.59it/s]\u001b[A\n",
      " 44%|████▍     | 26753/61028 [05:43<05:34, 102.54it/s]\u001b[A\n",
      " 44%|████▍     | 26765/61028 [05:43<05:24, 105.56it/s]\u001b[A\n",
      " 44%|████▍     | 26776/61028 [05:43<05:46, 98.80it/s] \u001b[A\n",
      " 44%|████▍     | 26787/61028 [05:43<05:40, 100.48it/s]\u001b[A\n",
      " 44%|████▍     | 26798/61028 [05:43<05:33, 102.55it/s]\u001b[A\n",
      " 44%|████▍     | 26809/61028 [05:43<05:32, 103.03it/s]\u001b[A\n",
      " 44%|████▍     | 26820/61028 [05:43<05:41, 100.05it/s]\u001b[A\n",
      " 44%|████▍     | 26831/61028 [05:43<05:45, 98.85it/s] \u001b[A\n",
      " 44%|████▍     | 26842/61028 [05:43<05:37, 101.14it/s]\u001b[A\n",
      " 44%|████▍     | 26853/61028 [05:44<06:02, 94.16it/s] \u001b[A\n",
      " 44%|████▍     | 26864/61028 [05:44<05:49, 97.82it/s]\u001b[A\n",
      " 44%|████▍     | 26874/61028 [05:44<06:00, 94.85it/s]\u001b[A\n",
      " 44%|████▍     | 26884/61028 [05:44<05:55, 96.04it/s]\u001b[A\n",
      " 44%|████▍     | 26894/61028 [05:44<05:56, 95.80it/s]\u001b[A\n",
      " 44%|████▍     | 26906/61028 [05:44<05:44, 99.05it/s]\u001b[A\n",
      " 44%|████▍     | 26916/61028 [05:44<05:52, 96.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 26926/61028 [05:44<05:53, 96.43it/s]\u001b[A\n",
      " 44%|████▍     | 26936/61028 [05:44<06:01, 94.37it/s]\u001b[A\n",
      " 44%|████▍     | 26946/61028 [05:45<06:01, 94.40it/s]\u001b[A\n",
      " 44%|████▍     | 26957/61028 [05:45<05:46, 98.36it/s]\u001b[A\n",
      " 44%|████▍     | 26967/61028 [05:45<06:06, 92.93it/s]\u001b[A\n",
      " 44%|████▍     | 26977/61028 [05:45<06:08, 92.30it/s]\u001b[A\n",
      " 44%|████▍     | 26987/61028 [05:45<06:26, 88.10it/s]\u001b[A\n",
      " 44%|████▍     | 26998/61028 [05:45<06:04, 93.42it/s]\u001b[A\n",
      " 44%|████▍     | 27009/61028 [05:45<05:56, 95.54it/s]\u001b[A\n",
      " 44%|████▍     | 27019/61028 [05:45<06:04, 93.21it/s]\u001b[A\n",
      " 44%|████▍     | 27029/61028 [05:45<06:06, 92.75it/s]\u001b[A\n",
      " 44%|████▍     | 27041/61028 [05:46<05:42, 99.37it/s]\u001b[A\n",
      " 44%|████▍     | 27052/61028 [05:46<05:53, 95.98it/s]\u001b[A\n",
      " 44%|████▍     | 27062/61028 [05:46<10:31, 53.78it/s]\u001b[A\n",
      " 44%|████▍     | 27072/61028 [05:46<09:12, 61.42it/s]\u001b[A\n",
      " 44%|████▍     | 27083/61028 [05:46<07:59, 70.73it/s]\u001b[A\n",
      " 44%|████▍     | 27094/61028 [05:46<07:23, 76.53it/s]\u001b[A\n",
      " 44%|████▍     | 27107/61028 [05:46<06:31, 86.59it/s]\u001b[A\n",
      " 44%|████▍     | 27118/61028 [05:47<06:15, 90.37it/s]\u001b[A\n",
      " 44%|████▍     | 27129/61028 [05:47<06:14, 90.56it/s]\u001b[A\n",
      " 44%|████▍     | 27139/61028 [05:47<06:14, 90.49it/s]\u001b[A\n",
      " 44%|████▍     | 27151/61028 [05:47<05:50, 96.55it/s]\u001b[A\n",
      " 45%|████▍     | 27162/61028 [05:47<05:50, 96.54it/s]\u001b[A\n",
      " 45%|████▍     | 27174/61028 [05:47<05:34, 101.32it/s]\u001b[A\n",
      " 45%|████▍     | 27185/61028 [05:47<06:04, 92.86it/s] \u001b[A\n",
      " 45%|████▍     | 27196/61028 [05:47<05:51, 96.24it/s]\u001b[A\n",
      " 45%|████▍     | 27206/61028 [05:47<06:03, 93.12it/s]\u001b[A\n",
      " 45%|████▍     | 27216/61028 [05:48<06:01, 93.46it/s]\u001b[A\n",
      " 45%|████▍     | 27226/61028 [05:48<05:56, 94.91it/s]\u001b[A\n",
      " 45%|████▍     | 27236/61028 [05:48<05:55, 95.14it/s]\u001b[A\n",
      " 45%|████▍     | 27248/61028 [05:48<05:33, 101.20it/s]\u001b[A\n",
      " 45%|████▍     | 27259/61028 [05:48<05:53, 95.42it/s] \u001b[A\n",
      " 45%|████▍     | 27269/61028 [05:48<06:06, 92.21it/s]\u001b[A\n",
      " 45%|████▍     | 27282/61028 [05:48<05:35, 100.58it/s]\u001b[A\n",
      " 45%|████▍     | 27293/61028 [05:48<05:45, 97.64it/s] \u001b[A\n",
      " 45%|████▍     | 27304/61028 [05:48<05:51, 96.00it/s]\u001b[A\n",
      " 45%|████▍     | 27316/61028 [05:49<05:34, 100.78it/s]\u001b[A\n",
      " 45%|████▍     | 27327/61028 [05:49<05:27, 102.80it/s]\u001b[A\n",
      " 45%|████▍     | 27338/61028 [05:49<05:41, 98.74it/s] \u001b[A\n",
      " 45%|████▍     | 27349/61028 [05:49<05:35, 100.25it/s]\u001b[A\n",
      " 45%|████▍     | 27360/61028 [05:49<05:45, 97.44it/s] \u001b[A\n",
      " 45%|████▍     | 27370/61028 [05:49<05:45, 97.48it/s]\u001b[A\n",
      " 45%|████▍     | 27380/61028 [05:49<05:42, 98.18it/s]\u001b[A\n",
      " 45%|████▍     | 27390/61028 [05:49<05:52, 95.46it/s]\u001b[A\n",
      " 45%|████▍     | 27400/61028 [05:49<05:48, 96.51it/s]\u001b[A\n",
      " 45%|████▍     | 27410/61028 [05:50<05:51, 95.58it/s]\u001b[A\n",
      " 45%|████▍     | 27420/61028 [05:50<05:53, 95.18it/s]\u001b[A\n",
      " 45%|████▍     | 27430/61028 [05:50<06:00, 93.12it/s]\u001b[A\n",
      " 45%|████▍     | 27440/61028 [05:50<06:25, 87.15it/s]\u001b[A\n",
      " 45%|████▍     | 27450/61028 [05:50<06:10, 90.59it/s]\u001b[A\n",
      " 45%|████▍     | 27461/61028 [05:50<05:52, 95.19it/s]\u001b[A\n",
      " 45%|████▌     | 27475/61028 [05:50<05:24, 103.31it/s]\u001b[A\n",
      " 45%|████▌     | 27486/61028 [05:50<05:49, 95.92it/s] \u001b[A\n",
      " 45%|████▌     | 27498/61028 [05:50<05:33, 100.47it/s]\u001b[A\n",
      " 45%|████▌     | 27509/61028 [05:51<05:43, 97.49it/s] \u001b[A\n",
      " 45%|████▌     | 27520/61028 [05:51<05:37, 99.28it/s]\u001b[A\n",
      " 45%|████▌     | 27531/61028 [05:51<05:52, 95.11it/s]\u001b[A\n",
      " 45%|████▌     | 27541/61028 [05:51<10:27, 53.38it/s]\u001b[A\n",
      " 45%|████▌     | 27550/61028 [05:51<09:12, 60.59it/s]\u001b[A\n",
      " 45%|████▌     | 27562/61028 [05:51<07:51, 71.00it/s]\u001b[A\n",
      " 45%|████▌     | 27572/61028 [05:51<07:20, 75.90it/s]\u001b[A\n",
      " 45%|████▌     | 27584/61028 [05:52<06:37, 84.05it/s]\u001b[A\n",
      " 45%|████▌     | 27594/61028 [05:52<06:28, 85.99it/s]\u001b[A\n",
      " 45%|████▌     | 27605/61028 [05:52<06:08, 90.68it/s]\u001b[A\n",
      " 45%|████▌     | 27616/61028 [05:52<05:50, 95.35it/s]\u001b[A\n",
      " 45%|████▌     | 27628/61028 [05:52<05:30, 100.97it/s]\u001b[A\n",
      " 45%|████▌     | 27639/61028 [05:52<05:32, 100.49it/s]\u001b[A\n",
      " 45%|████▌     | 27652/61028 [05:52<05:09, 107.75it/s]\u001b[A\n",
      " 45%|████▌     | 27664/61028 [05:52<05:18, 104.83it/s]\u001b[A\n",
      " 45%|████▌     | 27676/61028 [05:52<05:13, 106.22it/s]\u001b[A\n",
      " 45%|████▌     | 27687/61028 [05:53<05:15, 105.71it/s]\u001b[A\n",
      " 45%|████▌     | 27698/61028 [05:53<05:36, 99.04it/s] \u001b[A\n",
      " 45%|████▌     | 27709/61028 [05:53<06:09, 90.20it/s]\u001b[A\n",
      " 45%|████▌     | 27719/61028 [05:53<06:13, 89.21it/s]\u001b[A\n",
      " 45%|████▌     | 27730/61028 [05:53<05:57, 93.24it/s]\u001b[A\n",
      " 45%|████▌     | 27740/61028 [05:53<06:04, 91.34it/s]\u001b[A\n",
      " 45%|████▌     | 27751/61028 [05:53<05:52, 94.36it/s]\u001b[A\n",
      " 45%|████▌     | 27763/61028 [05:53<05:37, 98.61it/s]\u001b[A\n",
      " 46%|████▌     | 27775/61028 [05:53<05:24, 102.52it/s]\u001b[A\n",
      " 46%|████▌     | 27786/61028 [05:54<05:38, 98.18it/s] \u001b[A\n",
      " 46%|████▌     | 27797/61028 [05:54<05:33, 99.51it/s]\u001b[A\n",
      " 46%|████▌     | 27808/61028 [05:54<05:29, 100.96it/s]\u001b[A\n",
      " 46%|████▌     | 27819/61028 [05:54<05:57, 92.78it/s] \u001b[A\n",
      " 46%|████▌     | 27829/61028 [05:54<05:50, 94.73it/s]\u001b[A\n",
      " 46%|████▌     | 27840/61028 [05:54<05:37, 98.21it/s]\u001b[A\n",
      " 46%|████▌     | 27850/61028 [05:54<05:37, 98.36it/s]\u001b[A\n",
      " 46%|████▌     | 27861/61028 [05:54<05:29, 100.58it/s]\u001b[A\n",
      " 46%|████▌     | 27872/61028 [05:54<05:29, 100.67it/s]\u001b[A\n",
      " 46%|████▌     | 27883/61028 [05:55<05:28, 101.02it/s]\u001b[A\n",
      " 46%|████▌     | 27896/61028 [05:55<05:16, 104.71it/s]\u001b[A\n",
      " 46%|████▌     | 27907/61028 [05:55<05:35, 98.72it/s] \u001b[A\n",
      " 46%|████▌     | 27917/61028 [05:55<05:43, 96.34it/s]\u001b[A\n",
      " 46%|████▌     | 27927/61028 [05:55<05:43, 96.42it/s]\u001b[A\n",
      " 46%|████▌     | 27938/61028 [05:55<05:36, 98.36it/s]\u001b[A\n",
      " 46%|████▌     | 27948/61028 [05:55<05:37, 98.00it/s]\u001b[A\n",
      " 46%|████▌     | 27958/61028 [05:55<06:11, 89.13it/s]\u001b[A\n",
      " 46%|████▌     | 27971/61028 [05:56<05:44, 95.89it/s]\u001b[A\n",
      " 46%|████▌     | 27981/61028 [05:56<05:44, 95.83it/s]\u001b[A\n",
      " 46%|████▌     | 27991/61028 [05:56<05:52, 93.83it/s]\u001b[A\n",
      " 46%|████▌     | 28001/61028 [05:56<05:54, 93.23it/s]\u001b[A\n",
      " 46%|████▌     | 28011/61028 [05:56<05:54, 93.14it/s]\u001b[A\n",
      " 46%|████▌     | 28021/61028 [05:56<09:54, 55.50it/s]\u001b[A\n",
      " 46%|████▌     | 28031/61028 [05:56<08:36, 63.92it/s]\u001b[A\n",
      " 46%|████▌     | 28042/61028 [05:57<07:37, 72.06it/s]\u001b[A\n",
      " 46%|████▌     | 28053/61028 [05:57<06:56, 79.14it/s]\u001b[A\n",
      " 46%|████▌     | 28063/61028 [05:57<06:43, 81.68it/s]\u001b[A\n",
      " 46%|████▌     | 28073/61028 [05:57<06:29, 84.56it/s]\u001b[A\n",
      " 46%|████▌     | 28084/61028 [05:57<06:04, 90.27it/s]\u001b[A\n",
      " 46%|████▌     | 28094/61028 [05:57<06:46, 80.99it/s]\u001b[A\n",
      " 46%|████▌     | 28105/61028 [05:57<06:22, 86.11it/s]\u001b[A\n",
      " 46%|████▌     | 28115/61028 [05:57<06:40, 82.28it/s]\u001b[A\n",
      " 46%|████▌     | 28127/61028 [05:57<06:06, 89.69it/s]\u001b[A\n",
      " 46%|████▌     | 28137/61028 [05:58<06:12, 88.20it/s]\u001b[A\n",
      " 46%|████▌     | 28147/61028 [05:58<06:10, 88.65it/s]\u001b[A\n",
      " 46%|████▌     | 28157/61028 [05:58<06:04, 90.29it/s]\u001b[A\n",
      " 46%|████▌     | 28167/61028 [05:58<06:04, 90.05it/s]\u001b[A\n",
      " 46%|████▌     | 28177/61028 [05:58<06:01, 90.99it/s]\u001b[A\n",
      " 46%|████▌     | 28187/61028 [05:58<06:06, 89.64it/s]\u001b[A\n",
      " 46%|████▌     | 28199/61028 [05:58<05:47, 94.59it/s]\u001b[A\n",
      " 46%|████▌     | 28210/61028 [05:58<05:39, 96.74it/s]\u001b[A\n",
      " 46%|████▌     | 28222/61028 [05:58<05:26, 100.38it/s]\u001b[A\n",
      " 46%|████▋     | 28233/61028 [05:59<05:40, 96.20it/s] \u001b[A\n",
      " 46%|████▋     | 28244/61028 [05:59<05:33, 98.28it/s]\u001b[A\n",
      " 46%|████▋     | 28254/61028 [05:59<05:49, 93.84it/s]\u001b[A\n",
      " 46%|████▋     | 28267/61028 [05:59<05:26, 100.37it/s]\u001b[A\n",
      " 46%|████▋     | 28278/61028 [05:59<05:23, 101.09it/s]\u001b[A\n",
      " 46%|████▋     | 28289/61028 [05:59<05:36, 97.41it/s] \u001b[A\n",
      " 46%|████▋     | 28301/61028 [05:59<05:20, 102.00it/s]\u001b[A\n",
      " 46%|████▋     | 28312/61028 [05:59<05:30, 98.99it/s] \u001b[A\n",
      " 46%|████▋     | 28323/61028 [05:59<05:29, 99.37it/s]\u001b[A\n",
      " 46%|████▋     | 28334/61028 [06:00<05:34, 97.66it/s]\u001b[A\n",
      " 46%|████▋     | 28344/61028 [06:00<05:40, 96.03it/s]\u001b[A\n",
      " 46%|████▋     | 28354/61028 [06:00<05:39, 96.23it/s]\u001b[A\n",
      " 46%|████▋     | 28364/61028 [06:00<05:56, 91.72it/s]\u001b[A\n",
      " 46%|████▋     | 28376/61028 [06:00<05:31, 98.36it/s]\u001b[A\n",
      " 47%|████▋     | 28387/61028 [06:00<05:51, 92.89it/s]\u001b[A\n",
      " 47%|████▋     | 28397/61028 [06:00<05:54, 91.93it/s]\u001b[A\n",
      " 47%|████▋     | 28408/61028 [06:00<05:42, 95.22it/s]\u001b[A\n",
      " 47%|████▋     | 28420/61028 [06:00<05:30, 98.63it/s]\u001b[A\n",
      " 47%|████▋     | 28430/61028 [06:01<05:38, 96.37it/s]\u001b[A\n",
      " 47%|████▋     | 28441/61028 [06:01<05:36, 96.77it/s]\u001b[A\n",
      " 47%|████▋     | 28452/61028 [06:01<05:29, 98.93it/s]\u001b[A\n",
      " 47%|████▋     | 28462/61028 [06:01<05:37, 96.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 28473/61028 [06:01<05:28, 99.11it/s]\u001b[A\n",
      " 47%|████▋     | 28483/61028 [06:01<09:47, 55.36it/s]\u001b[A\n",
      " 47%|████▋     | 28494/61028 [06:01<08:25, 64.42it/s]\u001b[A\n",
      " 47%|████▋     | 28504/61028 [06:02<07:41, 70.52it/s]\u001b[A\n",
      " 47%|████▋     | 28513/61028 [06:02<07:16, 74.55it/s]\u001b[A\n",
      " 47%|████▋     | 28524/61028 [06:02<06:47, 79.68it/s]\u001b[A\n",
      " 47%|████▋     | 28534/61028 [06:02<06:27, 83.89it/s]\u001b[A\n",
      " 47%|████▋     | 28545/61028 [06:02<06:05, 88.90it/s]\u001b[A\n",
      " 47%|████▋     | 28557/61028 [06:02<05:40, 95.46it/s]\u001b[A\n",
      " 47%|████▋     | 28568/61028 [06:02<05:37, 96.30it/s]\u001b[A\n",
      " 47%|████▋     | 28579/61028 [06:02<05:41, 94.98it/s]\u001b[A\n",
      " 47%|████▋     | 28589/61028 [06:02<05:41, 95.06it/s]\u001b[A\n",
      " 47%|████▋     | 28600/61028 [06:03<05:32, 97.44it/s]\u001b[A\n",
      " 47%|████▋     | 28610/61028 [06:03<05:34, 96.78it/s]\u001b[A\n",
      " 47%|████▋     | 28621/61028 [06:03<05:27, 98.83it/s]\u001b[A\n",
      " 47%|████▋     | 28632/61028 [06:03<05:25, 99.45it/s]\u001b[A\n",
      " 47%|████▋     | 28643/61028 [06:03<05:39, 95.42it/s]\u001b[A\n",
      " 47%|████▋     | 28653/61028 [06:03<05:38, 95.78it/s]\u001b[A\n",
      " 47%|████▋     | 28663/61028 [06:03<05:39, 95.37it/s]\u001b[A\n",
      " 47%|████▋     | 28674/61028 [06:03<05:30, 97.77it/s]\u001b[A\n",
      " 47%|████▋     | 28684/61028 [06:03<05:28, 98.39it/s]\u001b[A\n",
      " 47%|████▋     | 28694/61028 [06:04<05:31, 97.43it/s]\u001b[A\n",
      " 47%|████▋     | 28705/61028 [06:04<05:22, 100.28it/s]\u001b[A\n",
      " 47%|████▋     | 28716/61028 [06:04<05:26, 98.85it/s] \u001b[A\n",
      " 47%|████▋     | 28726/61028 [06:04<05:29, 98.14it/s]\u001b[A\n",
      " 47%|████▋     | 28736/61028 [06:04<05:35, 96.36it/s]\u001b[A\n",
      " 47%|████▋     | 28746/61028 [06:04<05:59, 89.74it/s]\u001b[A\n",
      " 47%|████▋     | 28756/61028 [06:04<05:52, 91.49it/s]\u001b[A\n",
      " 47%|████▋     | 28766/61028 [06:04<05:43, 93.82it/s]\u001b[A\n",
      " 47%|████▋     | 28777/61028 [06:04<05:33, 96.73it/s]\u001b[A\n",
      " 47%|████▋     | 28787/61028 [06:05<05:45, 93.37it/s]\u001b[A\n",
      " 47%|████▋     | 28798/61028 [06:05<05:34, 96.32it/s]\u001b[A\n",
      " 47%|████▋     | 28809/61028 [06:05<05:22, 99.87it/s]\u001b[A\n",
      " 47%|████▋     | 28820/61028 [06:05<05:29, 97.75it/s]\u001b[A\n",
      " 47%|████▋     | 28830/61028 [06:05<05:43, 93.69it/s]\u001b[A\n",
      " 47%|████▋     | 28840/61028 [06:05<05:59, 89.54it/s]\u001b[A\n",
      " 47%|████▋     | 28850/61028 [06:05<05:51, 91.54it/s]\u001b[A\n",
      " 47%|████▋     | 28861/61028 [06:05<05:38, 94.96it/s]\u001b[A\n",
      " 47%|████▋     | 28872/61028 [06:05<05:31, 96.92it/s]\u001b[A\n",
      " 47%|████▋     | 28883/61028 [06:06<05:29, 97.51it/s]\u001b[A\n",
      " 47%|████▋     | 28893/61028 [06:06<05:31, 96.92it/s]\u001b[A\n",
      " 47%|████▋     | 28903/61028 [06:06<05:33, 96.46it/s]\u001b[A\n",
      " 47%|████▋     | 28913/61028 [06:06<05:33, 96.43it/s]\u001b[A\n",
      " 47%|████▋     | 28923/61028 [06:06<05:31, 96.81it/s]\u001b[A\n",
      " 47%|████▋     | 28933/61028 [06:06<05:28, 97.73it/s]\u001b[A\n",
      " 47%|████▋     | 28943/61028 [06:06<05:53, 90.71it/s]\u001b[A\n",
      " 47%|████▋     | 28953/61028 [06:07<10:27, 51.10it/s]\u001b[A\n",
      " 47%|████▋     | 28964/61028 [06:07<08:47, 60.80it/s]\u001b[A\n",
      " 47%|████▋     | 28975/61028 [06:07<07:41, 69.46it/s]\u001b[A\n",
      " 47%|████▋     | 28987/61028 [06:07<06:48, 78.50it/s]\u001b[A\n",
      " 48%|████▊     | 28997/61028 [06:07<06:24, 83.35it/s]\u001b[A\n",
      " 48%|████▊     | 29008/61028 [06:07<05:58, 89.26it/s]\u001b[A\n",
      " 48%|████▊     | 29019/61028 [06:07<05:41, 93.76it/s]\u001b[A\n",
      " 48%|████▊     | 29030/61028 [06:07<05:43, 93.17it/s]\u001b[A\n",
      " 48%|████▊     | 29040/61028 [06:07<05:47, 92.15it/s]\u001b[A\n",
      " 48%|████▊     | 29051/61028 [06:08<05:36, 95.14it/s]\u001b[A\n",
      " 48%|████▊     | 29062/61028 [06:08<05:31, 96.38it/s]\u001b[A\n",
      " 48%|████▊     | 29072/61028 [06:08<05:29, 96.87it/s]\u001b[A\n",
      " 48%|████▊     | 29083/61028 [06:08<05:23, 98.86it/s]\u001b[A\n",
      " 48%|████▊     | 29094/61028 [06:08<05:17, 100.42it/s]\u001b[A\n",
      " 48%|████▊     | 29105/61028 [06:08<05:19, 100.01it/s]\u001b[A\n",
      " 48%|████▊     | 29116/61028 [06:08<05:33, 95.80it/s] \u001b[A\n",
      " 48%|████▊     | 29127/61028 [06:08<05:21, 99.32it/s]\u001b[A\n",
      " 48%|████▊     | 29138/61028 [06:08<05:36, 94.73it/s]\u001b[A\n",
      " 48%|████▊     | 29148/61028 [06:09<05:40, 93.60it/s]\u001b[A\n",
      " 48%|████▊     | 29158/61028 [06:09<05:39, 93.96it/s]\u001b[A\n",
      " 48%|████▊     | 29170/61028 [06:09<05:22, 98.76it/s]\u001b[A\n",
      " 48%|████▊     | 29180/61028 [06:09<05:33, 95.39it/s]\u001b[A\n",
      " 48%|████▊     | 29190/61028 [06:09<05:31, 96.18it/s]\u001b[A\n",
      " 48%|████▊     | 29202/61028 [06:09<05:19, 99.64it/s]\u001b[A\n",
      " 48%|████▊     | 29213/61028 [06:09<05:24, 98.13it/s]\u001b[A\n",
      " 48%|████▊     | 29224/61028 [06:09<05:18, 99.83it/s]\u001b[A\n",
      " 48%|████▊     | 29235/61028 [06:09<05:21, 98.93it/s]\u001b[A\n",
      " 48%|████▊     | 29247/61028 [06:09<05:09, 102.71it/s]\u001b[A\n",
      " 48%|████▊     | 29258/61028 [06:10<05:27, 97.05it/s] \u001b[A\n",
      " 48%|████▊     | 29268/61028 [06:10<05:50, 90.60it/s]\u001b[A\n",
      " 48%|████▊     | 29278/61028 [06:10<06:01, 87.78it/s]\u001b[A\n",
      " 48%|████▊     | 29287/61028 [06:10<06:11, 85.40it/s]\u001b[A\n",
      " 48%|████▊     | 29297/61028 [06:10<06:01, 87.82it/s]\u001b[A\n",
      " 48%|████▊     | 29307/61028 [06:10<05:49, 90.70it/s]\u001b[A\n",
      " 48%|████▊     | 29317/61028 [06:10<05:43, 92.41it/s]\u001b[A\n",
      " 48%|████▊     | 29327/61028 [06:10<05:38, 93.69it/s]\u001b[A\n",
      " 48%|████▊     | 29339/61028 [06:11<05:23, 97.93it/s]\u001b[A\n",
      " 48%|████▊     | 29349/61028 [06:11<05:27, 96.86it/s]\u001b[A\n",
      " 48%|████▊     | 29359/61028 [06:11<05:31, 95.46it/s]\u001b[A\n",
      " 48%|████▊     | 29370/61028 [06:11<05:23, 97.77it/s]\u001b[A\n",
      " 48%|████▊     | 29380/61028 [06:11<05:38, 93.56it/s]\u001b[A\n",
      " 48%|████▊     | 29391/61028 [06:11<05:25, 97.30it/s]\u001b[A\n",
      " 48%|████▊     | 29401/61028 [06:11<05:28, 96.17it/s]\u001b[A\n",
      " 48%|████▊     | 29411/61028 [06:11<05:31, 95.35it/s]\u001b[A\n",
      " 48%|████▊     | 29421/61028 [06:12<10:08, 51.94it/s]\u001b[A\n",
      " 48%|████▊     | 29432/61028 [06:12<08:37, 61.04it/s]\u001b[A\n",
      " 48%|████▊     | 29441/61028 [06:12<07:55, 66.41it/s]\u001b[A\n",
      " 48%|████▊     | 29450/61028 [06:12<07:33, 69.69it/s]\u001b[A\n",
      " 48%|████▊     | 29459/61028 [06:12<07:12, 72.96it/s]\u001b[A\n",
      " 48%|████▊     | 29470/61028 [06:12<06:38, 79.19it/s]\u001b[A\n",
      " 48%|████▊     | 29481/61028 [06:12<06:07, 85.90it/s]\u001b[A\n",
      " 48%|████▊     | 29491/61028 [06:12<06:09, 85.25it/s]\u001b[A\n",
      " 48%|████▊     | 29505/61028 [06:13<05:31, 94.99it/s]\u001b[A\n",
      " 48%|████▊     | 29516/61028 [06:13<05:19, 98.55it/s]\u001b[A\n",
      " 48%|████▊     | 29527/61028 [06:13<05:26, 96.46it/s]\u001b[A\n",
      " 48%|████▊     | 29538/61028 [06:13<05:28, 95.92it/s]\u001b[A\n",
      " 48%|████▊     | 29549/61028 [06:13<05:22, 97.75it/s]\u001b[A\n",
      " 48%|████▊     | 29560/61028 [06:13<05:19, 98.63it/s]\u001b[A\n",
      " 48%|████▊     | 29572/61028 [06:13<05:04, 103.21it/s]\u001b[A\n",
      " 48%|████▊     | 29583/61028 [06:13<05:10, 101.40it/s]\u001b[A\n",
      " 48%|████▊     | 29594/61028 [06:13<05:11, 100.79it/s]\u001b[A\n",
      " 49%|████▊     | 29605/61028 [06:14<05:04, 103.28it/s]\u001b[A\n",
      " 49%|████▊     | 29616/61028 [06:14<05:13, 100.10it/s]\u001b[A\n",
      " 49%|████▊     | 29627/61028 [06:14<05:05, 102.82it/s]\u001b[A\n",
      " 49%|████▊     | 29639/61028 [06:14<04:56, 105.74it/s]\u001b[A\n",
      " 49%|████▊     | 29650/61028 [06:14<05:05, 102.84it/s]\u001b[A\n",
      " 49%|████▊     | 29661/61028 [06:14<05:31, 94.63it/s] \u001b[A\n",
      " 49%|████▊     | 29673/61028 [06:14<05:15, 99.45it/s]\u001b[A\n",
      " 49%|████▊     | 29684/61028 [06:14<05:27, 95.62it/s]\u001b[A\n",
      " 49%|████▊     | 29694/61028 [06:14<05:25, 96.13it/s]\u001b[A\n",
      " 49%|████▊     | 29704/61028 [06:15<05:23, 96.92it/s]\u001b[A\n",
      " 49%|████▊     | 29714/61028 [06:15<05:34, 93.51it/s]\u001b[A\n",
      " 49%|████▊     | 29724/61028 [06:15<05:40, 92.06it/s]\u001b[A\n",
      " 49%|████▊     | 29735/61028 [06:15<05:32, 94.19it/s]\u001b[A\n",
      " 49%|████▊     | 29745/61028 [06:15<05:39, 92.15it/s]\u001b[A\n",
      " 49%|████▉     | 29758/61028 [06:15<05:12, 99.92it/s]\u001b[A\n",
      " 49%|████▉     | 29769/61028 [06:15<05:18, 98.29it/s]\u001b[A\n",
      " 49%|████▉     | 29779/61028 [06:15<05:26, 95.61it/s]\u001b[A\n",
      " 49%|████▉     | 29789/61028 [06:15<05:32, 93.98it/s]\u001b[A\n",
      " 49%|████▉     | 29799/61028 [06:16<05:27, 95.29it/s]\u001b[A\n",
      " 49%|████▉     | 29811/61028 [06:16<05:14, 99.28it/s]\u001b[A\n",
      " 49%|████▉     | 29824/61028 [06:16<04:52, 106.57it/s]\u001b[A\n",
      " 49%|████▉     | 29835/61028 [06:16<05:14, 99.33it/s] \u001b[A\n",
      " 49%|████▉     | 29846/61028 [06:16<05:20, 97.22it/s]\u001b[A\n",
      " 49%|████▉     | 29857/61028 [06:16<05:12, 99.87it/s]\u001b[A\n",
      " 49%|████▉     | 29868/61028 [06:16<05:16, 98.54it/s]\u001b[A\n",
      " 49%|████▉     | 29878/61028 [06:16<05:21, 96.75it/s]\u001b[A\n",
      " 49%|████▉     | 29888/61028 [06:16<06:05, 85.17it/s]\u001b[A\n",
      " 49%|████▉     | 29897/61028 [06:17<11:20, 45.77it/s]\u001b[A\n",
      " 49%|████▉     | 29906/61028 [06:17<09:43, 53.31it/s]\u001b[A\n",
      " 49%|████▉     | 29917/61028 [06:17<08:19, 62.34it/s]\u001b[A\n",
      " 49%|████▉     | 29927/61028 [06:17<07:25, 69.79it/s]\u001b[A\n",
      " 49%|████▉     | 29938/61028 [06:17<06:46, 76.53it/s]\u001b[A\n",
      " 49%|████▉     | 29949/61028 [06:17<06:13, 83.18it/s]\u001b[A\n",
      " 49%|████▉     | 29960/61028 [06:18<05:51, 88.45it/s]\u001b[A\n",
      " 49%|████▉     | 29971/61028 [06:18<05:36, 92.42it/s]\u001b[A\n",
      " 49%|████▉     | 29982/61028 [06:18<05:26, 94.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 29993/61028 [06:18<05:16, 98.06it/s]\u001b[A\n",
      " 49%|████▉     | 30004/61028 [06:18<05:19, 97.13it/s]\u001b[A\n",
      " 49%|████▉     | 30016/61028 [06:18<05:02, 102.67it/s]\u001b[A\n",
      " 49%|████▉     | 30027/61028 [06:18<05:04, 101.90it/s]\u001b[A\n",
      " 49%|████▉     | 30039/61028 [06:18<04:56, 104.41it/s]\u001b[A\n",
      " 49%|████▉     | 30050/61028 [06:18<04:58, 103.67it/s]\u001b[A\n",
      " 49%|████▉     | 30061/61028 [06:18<05:09, 100.18it/s]\u001b[A\n",
      " 49%|████▉     | 30072/61028 [06:19<05:22, 96.03it/s] \u001b[A\n",
      " 49%|████▉     | 30082/61028 [06:19<05:22, 95.86it/s]\u001b[A\n",
      " 49%|████▉     | 30093/61028 [06:19<05:13, 98.82it/s]\u001b[A\n",
      " 49%|████▉     | 30104/61028 [06:19<05:08, 100.36it/s]\u001b[A\n",
      " 49%|████▉     | 30115/61028 [06:19<05:03, 101.98it/s]\u001b[A\n",
      " 49%|████▉     | 30126/61028 [06:19<05:40, 90.67it/s] \u001b[A\n",
      " 49%|████▉     | 30136/61028 [06:19<05:34, 92.31it/s]\u001b[A\n",
      " 49%|████▉     | 30146/61028 [06:19<05:48, 88.74it/s]\u001b[A\n",
      " 49%|████▉     | 30156/61028 [06:20<05:49, 88.30it/s]\u001b[A\n",
      " 49%|████▉     | 30168/61028 [06:20<05:26, 94.39it/s]\u001b[A\n",
      " 49%|████▉     | 30179/61028 [06:20<05:13, 98.34it/s]\u001b[A\n",
      " 49%|████▉     | 30191/61028 [06:20<04:59, 103.06it/s]\u001b[A\n",
      " 49%|████▉     | 30202/61028 [06:20<05:24, 95.02it/s] \u001b[A\n",
      " 50%|████▉     | 30212/61028 [06:20<05:28, 93.82it/s]\u001b[A\n",
      " 50%|████▉     | 30223/61028 [06:20<05:21, 95.72it/s]\u001b[A\n",
      " 50%|████▉     | 30234/61028 [06:20<05:19, 96.33it/s]\u001b[A\n",
      " 50%|████▉     | 30244/61028 [06:20<05:25, 94.70it/s]\u001b[A\n",
      " 50%|████▉     | 30254/61028 [06:21<05:28, 93.64it/s]\u001b[A\n",
      " 50%|████▉     | 30266/61028 [06:21<05:17, 96.81it/s]\u001b[A\n",
      " 50%|████▉     | 30280/61028 [06:21<04:56, 103.81it/s]\u001b[A\n",
      " 50%|████▉     | 30291/61028 [06:21<04:58, 103.08it/s]\u001b[A\n",
      " 50%|████▉     | 30302/61028 [06:21<05:00, 102.13it/s]\u001b[A\n",
      " 50%|████▉     | 30313/61028 [06:21<05:25, 94.26it/s] \u001b[A\n",
      " 50%|████▉     | 30323/61028 [06:21<05:36, 91.31it/s]\u001b[A\n",
      " 50%|████▉     | 30333/61028 [06:21<05:38, 90.58it/s]\u001b[A\n",
      " 50%|████▉     | 30343/61028 [06:21<05:30, 92.72it/s]\u001b[A\n",
      " 50%|████▉     | 30353/61028 [06:22<05:30, 92.88it/s]\u001b[A\n",
      " 50%|████▉     | 30363/61028 [06:22<09:14, 55.26it/s]\u001b[A\n",
      " 50%|████▉     | 30374/61028 [06:22<07:55, 64.53it/s]\u001b[A\n",
      " 50%|████▉     | 30386/61028 [06:22<06:57, 73.46it/s]\u001b[A\n",
      " 50%|████▉     | 30398/61028 [06:22<06:16, 81.27it/s]\u001b[A\n",
      " 50%|████▉     | 30408/61028 [06:22<06:05, 83.67it/s]\u001b[A\n",
      " 50%|████▉     | 30418/61028 [06:22<06:12, 82.10it/s]\u001b[A\n",
      " 50%|████▉     | 30428/61028 [06:23<06:01, 84.73it/s]\u001b[A\n",
      " 50%|████▉     | 30439/61028 [06:23<05:45, 88.54it/s]\u001b[A\n",
      " 50%|████▉     | 30450/61028 [06:23<05:28, 93.09it/s]\u001b[A\n",
      " 50%|████▉     | 30461/61028 [06:23<05:23, 94.61it/s]\u001b[A\n",
      " 50%|████▉     | 30471/61028 [06:23<05:41, 89.37it/s]\u001b[A\n",
      " 50%|████▉     | 30481/61028 [06:23<05:37, 90.59it/s]\u001b[A\n",
      " 50%|████▉     | 30493/61028 [06:23<05:15, 96.93it/s]\u001b[A\n",
      " 50%|████▉     | 30505/61028 [06:23<05:00, 101.58it/s]\u001b[A\n",
      " 50%|█████     | 30517/61028 [06:23<04:50, 105.15it/s]\u001b[A\n",
      " 50%|█████     | 30528/61028 [06:24<05:10, 98.21it/s] \u001b[A\n",
      " 50%|█████     | 30540/61028 [06:24<04:56, 102.83it/s]\u001b[A\n",
      " 50%|█████     | 30552/61028 [06:24<04:45, 106.88it/s]\u001b[A\n",
      " 50%|█████     | 30563/61028 [06:24<04:58, 101.96it/s]\u001b[A\n",
      " 50%|█████     | 30574/61028 [06:24<04:59, 101.55it/s]\u001b[A\n",
      " 50%|█████     | 30585/61028 [06:24<05:02, 100.74it/s]\u001b[A\n",
      " 50%|█████     | 30596/61028 [06:24<05:01, 100.90it/s]\u001b[A\n",
      " 50%|█████     | 30607/61028 [06:24<05:03, 100.33it/s]\u001b[A\n",
      " 50%|█████     | 30618/61028 [06:24<05:11, 97.49it/s] \u001b[A\n",
      " 50%|█████     | 30631/61028 [06:25<04:55, 102.71it/s]\u001b[A\n",
      " 50%|█████     | 30642/61028 [06:25<05:00, 101.28it/s]\u001b[A\n",
      " 50%|█████     | 30653/61028 [06:25<05:09, 98.25it/s] \u001b[A\n",
      " 50%|█████     | 30663/61028 [06:25<05:29, 92.11it/s]\u001b[A\n",
      " 50%|█████     | 30673/61028 [06:25<05:43, 88.36it/s]\u001b[A\n",
      " 50%|█████     | 30685/61028 [06:25<05:20, 94.73it/s]\u001b[A\n",
      " 50%|█████     | 30695/61028 [06:25<05:22, 94.15it/s]\u001b[A\n",
      " 50%|█████     | 30705/61028 [06:25<05:25, 93.18it/s]\u001b[A\n",
      " 50%|█████     | 30716/61028 [06:25<05:12, 96.87it/s]\u001b[A\n",
      " 50%|█████     | 30727/61028 [06:26<05:05, 99.34it/s]\u001b[A\n",
      " 50%|█████     | 30738/61028 [06:26<05:08, 98.28it/s]\u001b[A\n",
      " 50%|█████     | 30749/61028 [06:26<05:05, 99.18it/s]\u001b[A\n",
      " 50%|█████     | 30763/61028 [06:26<04:44, 106.54it/s]\u001b[A\n",
      " 50%|█████     | 30774/61028 [06:26<04:51, 103.96it/s]\u001b[A\n",
      " 50%|█████     | 30785/61028 [06:26<04:59, 101.02it/s]\u001b[A\n",
      " 50%|█████     | 30796/61028 [06:26<05:09, 97.74it/s] \u001b[A\n",
      " 50%|█████     | 30806/61028 [06:26<05:27, 92.36it/s]\u001b[A\n",
      " 50%|█████     | 30816/61028 [06:26<05:21, 94.07it/s]\u001b[A\n",
      " 51%|█████     | 30828/61028 [06:27<05:03, 99.64it/s]\u001b[A\n",
      " 51%|█████     | 30839/61028 [06:27<09:07, 55.18it/s]\u001b[A\n",
      " 51%|█████     | 30847/61028 [06:27<08:32, 58.88it/s]\u001b[A\n",
      " 51%|█████     | 30856/61028 [06:27<07:41, 65.32it/s]\u001b[A\n",
      " 51%|█████     | 30868/61028 [06:27<06:43, 74.72it/s]\u001b[A\n",
      " 51%|█████     | 30878/61028 [06:27<06:14, 80.46it/s]\u001b[A\n",
      " 51%|█████     | 30889/61028 [06:28<05:49, 86.29it/s]\u001b[A\n",
      " 51%|█████     | 30900/61028 [06:28<05:30, 91.15it/s]\u001b[A\n",
      " 51%|█████     | 30911/61028 [06:28<05:21, 93.78it/s]\u001b[A\n",
      " 51%|█████     | 30922/61028 [06:28<05:11, 96.59it/s]\u001b[A\n",
      " 51%|█████     | 30933/61028 [06:28<05:09, 97.20it/s]\u001b[A\n",
      " 51%|█████     | 30944/61028 [06:28<04:59, 100.34it/s]\u001b[A\n",
      " 51%|█████     | 30955/61028 [06:28<04:54, 102.06it/s]\u001b[A\n",
      " 51%|█████     | 30966/61028 [06:28<05:05, 98.44it/s] \u001b[A\n",
      " 51%|█████     | 30976/61028 [06:28<05:07, 97.87it/s]\u001b[A\n",
      " 51%|█████     | 30986/61028 [06:29<05:17, 94.52it/s]\u001b[A\n",
      " 51%|█████     | 30996/61028 [06:29<05:13, 95.93it/s]\u001b[A\n",
      " 51%|█████     | 31007/61028 [06:29<05:05, 98.37it/s]\u001b[A\n",
      " 51%|█████     | 31017/61028 [06:29<05:17, 94.41it/s]\u001b[A\n",
      " 51%|█████     | 31030/61028 [06:29<04:51, 102.78it/s]\u001b[A\n",
      " 51%|█████     | 31041/61028 [06:29<04:51, 102.90it/s]\u001b[A\n",
      " 51%|█████     | 31052/61028 [06:29<04:49, 103.38it/s]\u001b[A\n",
      " 51%|█████     | 31063/61028 [06:29<04:51, 102.83it/s]\u001b[A\n",
      " 51%|█████     | 31075/61028 [06:29<04:47, 104.28it/s]\u001b[A\n",
      " 51%|█████     | 31086/61028 [06:29<04:42, 105.81it/s]\u001b[A\n",
      " 51%|█████     | 31097/61028 [06:30<04:48, 103.68it/s]\u001b[A\n",
      " 51%|█████     | 31108/61028 [06:30<04:59, 99.99it/s] \u001b[A\n",
      " 51%|█████     | 31119/61028 [06:30<05:06, 97.53it/s]\u001b[A\n",
      " 51%|█████     | 31129/61028 [06:30<05:11, 96.14it/s]\u001b[A\n",
      " 51%|█████     | 31139/61028 [06:30<05:40, 87.82it/s]\u001b[A\n",
      " 51%|█████     | 31149/61028 [06:30<05:29, 90.78it/s]\u001b[A\n",
      " 51%|█████     | 31159/61028 [06:30<05:51, 85.08it/s]\u001b[A\n",
      " 51%|█████     | 31169/61028 [06:30<05:44, 86.78it/s]\u001b[A\n",
      " 51%|█████     | 31178/61028 [06:30<05:42, 87.28it/s]\u001b[A\n",
      " 51%|█████     | 31188/61028 [06:31<05:32, 89.82it/s]\u001b[A\n",
      " 51%|█████     | 31198/61028 [06:31<05:46, 86.11it/s]\u001b[A\n",
      " 51%|█████     | 31208/61028 [06:31<05:37, 88.31it/s]\u001b[A\n",
      " 51%|█████     | 31217/61028 [06:31<05:41, 87.17it/s]\u001b[A\n",
      " 51%|█████     | 31229/61028 [06:31<05:14, 94.63it/s]\u001b[A\n",
      " 51%|█████     | 31240/61028 [06:31<05:08, 96.45it/s]\u001b[A\n",
      " 51%|█████     | 31250/61028 [06:31<05:20, 92.80it/s]\u001b[A\n",
      " 51%|█████     | 31262/61028 [06:31<04:59, 99.50it/s]\u001b[A\n",
      " 51%|█████     | 31273/61028 [06:31<05:06, 97.08it/s]\u001b[A\n",
      " 51%|█████▏    | 31284/61028 [06:32<04:58, 99.55it/s]\u001b[A\n",
      " 51%|█████▏    | 31295/61028 [06:32<04:55, 100.70it/s]\u001b[A\n",
      " 51%|█████▏    | 31306/61028 [06:32<07:56, 62.35it/s] \u001b[A\n",
      " 51%|█████▏    | 31315/61028 [06:32<07:38, 64.83it/s]\u001b[A\n",
      " 51%|█████▏    | 31324/61028 [06:32<07:03, 70.18it/s]\u001b[A\n",
      " 51%|█████▏    | 31336/61028 [06:32<06:16, 78.83it/s]\u001b[A\n",
      " 51%|█████▏    | 31348/61028 [06:32<05:41, 86.95it/s]\u001b[A\n",
      " 51%|█████▏    | 31359/61028 [06:33<05:27, 90.63it/s]\u001b[A\n",
      " 51%|█████▏    | 31369/61028 [06:33<05:29, 89.92it/s]\u001b[A\n",
      " 51%|█████▏    | 31379/61028 [06:33<05:40, 87.09it/s]\u001b[A\n",
      " 51%|█████▏    | 31389/61028 [06:33<05:31, 89.30it/s]\u001b[A\n",
      " 51%|█████▏    | 31399/61028 [06:33<05:26, 90.82it/s]\u001b[A\n",
      " 51%|█████▏    | 31411/61028 [06:33<05:04, 97.28it/s]\u001b[A\n",
      " 51%|█████▏    | 31422/61028 [06:33<05:05, 96.89it/s]\u001b[A\n",
      " 52%|█████▏    | 31432/61028 [06:33<05:12, 94.61it/s]\u001b[A\n",
      " 52%|█████▏    | 31444/61028 [06:33<04:56, 99.81it/s]\u001b[A\n",
      " 52%|█████▏    | 31455/61028 [06:34<05:01, 98.06it/s]\u001b[A\n",
      " 52%|█████▏    | 31467/61028 [06:34<04:47, 102.96it/s]\u001b[A\n",
      " 52%|█████▏    | 31478/61028 [06:34<04:50, 101.75it/s]\u001b[A\n",
      " 52%|█████▏    | 31489/61028 [06:34<04:52, 101.08it/s]\u001b[A\n",
      " 52%|█████▏    | 31500/61028 [06:34<04:56, 99.69it/s] \u001b[A\n",
      " 52%|█████▏    | 31511/61028 [06:34<04:48, 102.29it/s]\u001b[A\n",
      " 52%|█████▏    | 31522/61028 [06:34<04:59, 98.38it/s] \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 31532/61028 [06:34<05:12, 94.43it/s]\u001b[A\n",
      " 52%|█████▏    | 31543/61028 [06:34<05:06, 96.18it/s]\u001b[A\n",
      " 52%|█████▏    | 31553/61028 [06:35<05:12, 94.22it/s]\u001b[A\n",
      " 52%|█████▏    | 31563/61028 [06:35<05:08, 95.38it/s]\u001b[A\n",
      " 52%|█████▏    | 31575/61028 [06:35<04:59, 98.34it/s]\u001b[A\n",
      " 52%|█████▏    | 31586/61028 [06:35<04:56, 99.34it/s]\u001b[A\n",
      " 52%|█████▏    | 31596/61028 [06:35<05:21, 91.50it/s]\u001b[A\n",
      " 52%|█████▏    | 31606/61028 [06:35<05:32, 88.41it/s]\u001b[A\n",
      " 52%|█████▏    | 31616/61028 [06:35<05:24, 90.55it/s]\u001b[A\n",
      " 52%|█████▏    | 31626/61028 [06:35<05:22, 91.04it/s]\u001b[A\n",
      " 52%|█████▏    | 31638/61028 [06:35<05:02, 97.17it/s]\u001b[A\n",
      " 52%|█████▏    | 31648/61028 [06:36<05:02, 96.97it/s]\u001b[A\n",
      " 52%|█████▏    | 31658/61028 [06:36<05:02, 97.24it/s]\u001b[A\n",
      " 52%|█████▏    | 31668/61028 [06:36<05:17, 92.51it/s]\u001b[A\n",
      " 52%|█████▏    | 31678/61028 [06:36<05:10, 94.57it/s]\u001b[A\n",
      " 52%|█████▏    | 31689/61028 [06:36<04:58, 98.17it/s]\u001b[A\n",
      " 52%|█████▏    | 31700/61028 [06:36<04:56, 98.97it/s]\u001b[A\n",
      " 52%|█████▏    | 31710/61028 [06:36<05:15, 93.00it/s]\u001b[A\n",
      " 52%|█████▏    | 31721/61028 [06:36<05:08, 94.97it/s]\u001b[A\n",
      " 52%|█████▏    | 31731/61028 [06:36<05:15, 92.82it/s]\u001b[A\n",
      " 52%|█████▏    | 31741/61028 [06:37<05:14, 93.27it/s]\u001b[A\n",
      " 52%|█████▏    | 31751/61028 [06:37<05:12, 93.82it/s]\u001b[A\n",
      " 52%|█████▏    | 31762/61028 [06:37<04:58, 97.95it/s]\u001b[A\n",
      " 52%|█████▏    | 31772/61028 [06:37<05:06, 95.33it/s]\u001b[A\n",
      " 52%|█████▏    | 31782/61028 [06:37<09:07, 53.39it/s]\u001b[A\n",
      " 52%|█████▏    | 31793/61028 [06:37<07:43, 63.03it/s]\u001b[A\n",
      " 52%|█████▏    | 31802/61028 [06:37<07:07, 68.31it/s]\u001b[A\n",
      " 52%|█████▏    | 31813/61028 [06:38<06:19, 77.03it/s]\u001b[A\n",
      " 52%|█████▏    | 31823/61028 [06:38<05:59, 81.34it/s]\u001b[A\n",
      " 52%|█████▏    | 31833/61028 [06:38<05:42, 85.33it/s]\u001b[A\n",
      " 52%|█████▏    | 31846/61028 [06:38<05:14, 92.89it/s]\u001b[A\n",
      " 52%|█████▏    | 31857/61028 [06:38<05:13, 93.08it/s]\u001b[A\n",
      " 52%|█████▏    | 31867/61028 [06:38<05:18, 91.43it/s]\u001b[A\n",
      " 52%|█████▏    | 31877/61028 [06:38<05:18, 91.57it/s]\u001b[A\n",
      " 52%|█████▏    | 31887/61028 [06:38<05:14, 92.69it/s]\u001b[A\n",
      " 52%|█████▏    | 31899/61028 [06:38<04:55, 98.73it/s]\u001b[A\n",
      " 52%|█████▏    | 31910/61028 [06:39<05:03, 96.04it/s]\u001b[A\n",
      " 52%|█████▏    | 31920/61028 [06:39<05:02, 96.21it/s]\u001b[A\n",
      " 52%|█████▏    | 31931/61028 [06:39<04:54, 98.80it/s]\u001b[A\n",
      " 52%|█████▏    | 31941/61028 [06:39<04:54, 98.66it/s]\u001b[A\n",
      " 52%|█████▏    | 31952/61028 [06:39<04:51, 99.72it/s]\u001b[A\n",
      " 52%|█████▏    | 31963/61028 [06:39<04:45, 101.80it/s]\u001b[A\n",
      " 52%|█████▏    | 31974/61028 [06:39<04:56, 97.97it/s] \u001b[A\n",
      " 52%|█████▏    | 31985/61028 [06:39<04:52, 99.31it/s]\u001b[A\n",
      " 52%|█████▏    | 31996/61028 [06:39<04:51, 99.50it/s]\u001b[A\n",
      " 52%|█████▏    | 32007/61028 [06:40<04:45, 101.64it/s]\u001b[A\n",
      " 52%|█████▏    | 32019/61028 [06:40<04:38, 104.16it/s]\u001b[A\n",
      " 52%|█████▏    | 32030/61028 [06:40<04:49, 100.08it/s]\u001b[A\n",
      " 53%|█████▎    | 32042/61028 [06:40<04:37, 104.31it/s]\u001b[A\n",
      " 53%|█████▎    | 32054/61028 [06:40<04:29, 107.57it/s]\u001b[A\n",
      " 53%|█████▎    | 32065/61028 [06:40<04:45, 101.37it/s]\u001b[A\n",
      " 53%|█████▎    | 32076/61028 [06:40<04:39, 103.72it/s]\u001b[A\n",
      " 53%|█████▎    | 32087/61028 [06:40<04:39, 103.69it/s]\u001b[A\n",
      " 53%|█████▎    | 32098/61028 [06:40<04:36, 104.56it/s]\u001b[A\n",
      " 53%|█████▎    | 32109/61028 [06:40<04:37, 104.15it/s]\u001b[A\n",
      " 53%|█████▎    | 32120/61028 [06:41<04:40, 102.94it/s]\u001b[A\n",
      " 53%|█████▎    | 32132/61028 [06:41<04:33, 105.56it/s]\u001b[A\n",
      " 53%|█████▎    | 32143/61028 [06:41<04:41, 102.77it/s]\u001b[A\n",
      " 53%|█████▎    | 32154/61028 [06:41<04:48, 100.17it/s]\u001b[A\n",
      " 53%|█████▎    | 32165/61028 [06:41<04:42, 102.05it/s]\u001b[A\n",
      " 53%|█████▎    | 32176/61028 [06:41<04:37, 104.11it/s]\u001b[A\n",
      " 53%|█████▎    | 32187/61028 [06:41<04:35, 104.67it/s]\u001b[A\n",
      " 53%|█████▎    | 32198/61028 [06:41<04:31, 106.13it/s]\u001b[A\n",
      " 53%|█████▎    | 32209/61028 [06:41<04:41, 102.22it/s]\u001b[A\n",
      " 53%|█████▎    | 32220/61028 [06:42<04:43, 101.63it/s]\u001b[A\n",
      " 53%|█████▎    | 32231/61028 [06:42<04:42, 102.07it/s]\u001b[A\n",
      " 53%|█████▎    | 32242/61028 [06:42<04:39, 102.92it/s]\u001b[A\n",
      " 53%|█████▎    | 32254/61028 [06:42<04:32, 105.45it/s]\u001b[A\n",
      " 53%|█████▎    | 32265/61028 [06:42<04:45, 100.89it/s]\u001b[A\n",
      " 53%|█████▎    | 32276/61028 [06:42<08:55, 53.65it/s] \u001b[A\n",
      " 53%|█████▎    | 32286/61028 [06:43<07:45, 61.79it/s]\u001b[A\n",
      " 53%|█████▎    | 32297/61028 [06:43<06:45, 70.81it/s]\u001b[A\n",
      " 53%|█████▎    | 32307/61028 [06:43<06:16, 76.38it/s]\u001b[A\n",
      " 53%|█████▎    | 32318/61028 [06:43<05:45, 83.09it/s]\u001b[A\n",
      " 53%|█████▎    | 32329/61028 [06:43<05:26, 87.97it/s]\u001b[A\n",
      " 53%|█████▎    | 32339/61028 [06:43<05:14, 91.10it/s]\u001b[A\n",
      " 53%|█████▎    | 32353/61028 [06:43<04:44, 100.76it/s]\u001b[A\n",
      " 53%|█████▎    | 32364/61028 [06:43<04:50, 98.76it/s] \u001b[A\n",
      " 53%|█████▎    | 32375/61028 [06:43<04:57, 96.31it/s]\u001b[A\n",
      " 53%|█████▎    | 32386/61028 [06:44<04:48, 99.17it/s]\u001b[A\n",
      " 53%|█████▎    | 32397/61028 [06:44<04:42, 101.19it/s]\u001b[A\n",
      " 53%|█████▎    | 32408/61028 [06:44<04:49, 99.02it/s] \u001b[A\n",
      " 53%|█████▎    | 32419/61028 [06:44<05:07, 93.18it/s]\u001b[A\n",
      " 53%|█████▎    | 32430/61028 [06:44<04:58, 95.84it/s]\u001b[A\n",
      " 53%|█████▎    | 32440/61028 [06:44<05:15, 90.59it/s]\u001b[A\n",
      " 53%|█████▎    | 32450/61028 [06:44<05:17, 90.11it/s]\u001b[A\n",
      " 53%|█████▎    | 32460/61028 [06:44<05:17, 89.94it/s]\u001b[A\n",
      " 53%|█████▎    | 32472/61028 [06:44<04:54, 97.03it/s]\u001b[A\n",
      " 53%|█████▎    | 32482/61028 [06:45<04:53, 97.24it/s]\u001b[A\n",
      " 53%|█████▎    | 32492/61028 [06:45<04:57, 96.01it/s]\u001b[A\n",
      " 53%|█████▎    | 32502/61028 [06:45<05:04, 93.61it/s]\u001b[A\n",
      " 53%|█████▎    | 32512/61028 [06:45<05:00, 94.81it/s]\u001b[A\n",
      " 53%|█████▎    | 32523/61028 [06:45<04:49, 98.40it/s]\u001b[A\n",
      " 53%|█████▎    | 32533/61028 [06:45<04:50, 98.25it/s]\u001b[A\n",
      " 53%|█████▎    | 32543/61028 [06:45<04:59, 95.09it/s]\u001b[A\n",
      " 53%|█████▎    | 32554/61028 [06:45<04:55, 96.36it/s]\u001b[A\n",
      " 53%|█████▎    | 32564/61028 [06:45<05:11, 91.44it/s]\u001b[A\n",
      " 53%|█████▎    | 32574/61028 [06:46<05:05, 93.23it/s]\u001b[A\n",
      " 53%|█████▎    | 32584/61028 [06:46<05:03, 93.86it/s]\u001b[A\n",
      " 53%|█████▎    | 32594/61028 [06:46<04:59, 94.98it/s]\u001b[A\n",
      " 53%|█████▎    | 32605/61028 [06:46<04:47, 98.96it/s]\u001b[A\n",
      " 53%|█████▎    | 32617/61028 [06:46<04:36, 102.62it/s]\u001b[A\n",
      " 53%|█████▎    | 32628/61028 [06:46<04:36, 102.57it/s]\u001b[A\n",
      " 53%|█████▎    | 32639/61028 [06:46<04:40, 101.18it/s]\u001b[A\n",
      " 54%|█████▎    | 32650/61028 [06:46<04:59, 94.78it/s] \u001b[A\n",
      " 54%|█████▎    | 32663/61028 [06:46<04:39, 101.44it/s]\u001b[A\n",
      " 54%|█████▎    | 32674/61028 [06:47<04:52, 96.90it/s] \u001b[A\n",
      " 54%|█████▎    | 32685/61028 [06:47<04:51, 97.33it/s]\u001b[A\n",
      " 54%|█████▎    | 32695/61028 [06:47<04:57, 95.13it/s]\u001b[A\n",
      " 54%|█████▎    | 32705/61028 [06:47<05:05, 92.61it/s]\u001b[A\n",
      " 54%|█████▎    | 32716/61028 [06:47<04:54, 96.03it/s]\u001b[A\n",
      " 54%|█████▎    | 32727/61028 [06:47<04:46, 98.89it/s]\u001b[A\n",
      " 54%|█████▎    | 32737/61028 [06:47<08:56, 52.72it/s]\u001b[A\n",
      " 54%|█████▎    | 32745/61028 [06:48<08:15, 57.09it/s]\u001b[A\n",
      " 54%|█████▎    | 32756/61028 [06:48<07:09, 65.86it/s]\u001b[A\n",
      " 54%|█████▎    | 32766/61028 [06:48<06:28, 72.72it/s]\u001b[A\n",
      " 54%|█████▎    | 32777/61028 [06:48<05:49, 80.73it/s]\u001b[A\n",
      " 54%|█████▎    | 32787/61028 [06:48<05:32, 84.81it/s]\u001b[A\n",
      " 54%|█████▎    | 32799/61028 [06:48<05:08, 91.43it/s]\u001b[A\n",
      " 54%|█████▍    | 32809/61028 [06:48<05:04, 92.64it/s]\u001b[A\n",
      " 54%|█████▍    | 32819/61028 [06:48<04:58, 94.44it/s]\u001b[A\n",
      " 54%|█████▍    | 32829/61028 [06:48<04:57, 94.84it/s]\u001b[A\n",
      " 54%|█████▍    | 32839/61028 [06:49<05:00, 93.71it/s]\u001b[A\n",
      " 54%|█████▍    | 32849/61028 [06:49<05:01, 93.55it/s]\u001b[A\n",
      " 54%|█████▍    | 32861/61028 [06:49<04:49, 97.29it/s]\u001b[A\n",
      " 54%|█████▍    | 32873/61028 [06:49<04:38, 101.05it/s]\u001b[A\n",
      " 54%|█████▍    | 32884/61028 [06:49<05:01, 93.28it/s] \u001b[A\n",
      " 54%|█████▍    | 32895/61028 [06:49<04:53, 95.97it/s]\u001b[A\n",
      " 54%|█████▍    | 32906/61028 [06:49<04:44, 98.68it/s]\u001b[A\n",
      " 54%|█████▍    | 32918/61028 [06:49<04:33, 102.67it/s]\u001b[A\n",
      " 54%|█████▍    | 32929/61028 [06:49<04:39, 100.58it/s]\u001b[A\n",
      " 54%|█████▍    | 32940/61028 [06:50<04:33, 102.61it/s]\u001b[A\n",
      " 54%|█████▍    | 32951/61028 [06:50<04:50, 96.50it/s] \u001b[A\n",
      " 54%|█████▍    | 32961/61028 [06:50<05:00, 93.47it/s]\u001b[A\n",
      " 54%|█████▍    | 32971/61028 [06:50<04:56, 94.57it/s]\u001b[A\n",
      " 54%|█████▍    | 32982/61028 [06:50<04:44, 98.68it/s]\u001b[A\n",
      " 54%|█████▍    | 32992/61028 [06:50<05:06, 91.57it/s]\u001b[A\n",
      " 54%|█████▍    | 33002/61028 [06:50<05:01, 92.96it/s]\u001b[A\n",
      " 54%|█████▍    | 33012/61028 [06:50<05:09, 90.49it/s]\u001b[A\n",
      " 54%|█████▍    | 33022/61028 [06:50<05:09, 90.54it/s]\u001b[A\n",
      " 54%|█████▍    | 33033/61028 [06:51<04:59, 93.37it/s]\u001b[A\n",
      " 54%|█████▍    | 33043/61028 [06:51<04:54, 95.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 33056/61028 [06:51<04:32, 102.59it/s]\u001b[A\n",
      " 54%|█████▍    | 33067/61028 [06:51<04:28, 104.06it/s]\u001b[A\n",
      " 54%|█████▍    | 33079/61028 [06:51<04:25, 105.40it/s]\u001b[A\n",
      " 54%|█████▍    | 33090/61028 [06:51<04:27, 104.32it/s]\u001b[A\n",
      " 54%|█████▍    | 33101/61028 [06:51<04:38, 100.33it/s]\u001b[A\n",
      " 54%|█████▍    | 33112/61028 [06:51<04:54, 94.91it/s] \u001b[A\n",
      " 54%|█████▍    | 33122/61028 [06:51<05:00, 92.72it/s]\u001b[A\n",
      " 54%|█████▍    | 33132/61028 [06:52<04:56, 94.00it/s]\u001b[A\n",
      " 54%|█████▍    | 33143/61028 [06:52<04:51, 95.50it/s]\u001b[A\n",
      " 54%|█████▍    | 33153/61028 [06:52<04:49, 96.24it/s]\u001b[A\n",
      " 54%|█████▍    | 33164/61028 [06:52<04:43, 98.15it/s]\u001b[A\n",
      " 54%|█████▍    | 33176/61028 [06:52<04:31, 102.76it/s]\u001b[A\n",
      " 54%|█████▍    | 33187/61028 [06:52<04:30, 102.78it/s]\u001b[A\n",
      " 54%|█████▍    | 33198/61028 [06:52<04:55, 94.31it/s] \u001b[A\n",
      " 54%|█████▍    | 33208/61028 [06:52<07:51, 59.04it/s]\u001b[A\n",
      " 54%|█████▍    | 33216/61028 [06:53<07:25, 62.45it/s]\u001b[A\n",
      " 54%|█████▍    | 33227/61028 [06:53<06:32, 70.86it/s]\u001b[A\n",
      " 54%|█████▍    | 33237/61028 [06:53<06:06, 75.89it/s]\u001b[A\n",
      " 54%|█████▍    | 33247/61028 [06:53<05:41, 81.25it/s]\u001b[A\n",
      " 54%|█████▍    | 33257/61028 [06:53<05:22, 86.02it/s]\u001b[A\n",
      " 55%|█████▍    | 33267/61028 [06:53<05:10, 89.51it/s]\u001b[A\n",
      " 55%|█████▍    | 33279/61028 [06:53<04:46, 96.75it/s]\u001b[A\n",
      " 55%|█████▍    | 33290/61028 [06:53<04:49, 95.85it/s]\u001b[A\n",
      " 55%|█████▍    | 33300/61028 [06:53<04:50, 95.48it/s]\u001b[A\n",
      " 55%|█████▍    | 33312/61028 [06:54<04:33, 101.18it/s]\u001b[A\n",
      " 55%|█████▍    | 33323/61028 [06:54<04:31, 102.11it/s]\u001b[A\n",
      " 55%|█████▍    | 33336/61028 [06:54<04:18, 107.08it/s]\u001b[A\n",
      " 55%|█████▍    | 33347/61028 [06:54<04:18, 107.27it/s]\u001b[A\n",
      " 55%|█████▍    | 33358/61028 [06:54<04:27, 103.61it/s]\u001b[A\n",
      " 55%|█████▍    | 33369/61028 [06:54<04:34, 100.66it/s]\u001b[A\n",
      " 55%|█████▍    | 33381/61028 [06:54<04:26, 103.66it/s]\u001b[A\n",
      " 55%|█████▍    | 33392/61028 [06:54<04:25, 103.98it/s]\u001b[A\n",
      " 55%|█████▍    | 33403/61028 [06:54<04:37, 99.61it/s] \u001b[A\n",
      " 55%|█████▍    | 33414/61028 [06:55<04:35, 100.11it/s]\u001b[A\n",
      " 55%|█████▍    | 33425/61028 [06:55<04:41, 97.90it/s] \u001b[A\n",
      " 55%|█████▍    | 33436/61028 [06:55<04:39, 98.88it/s]\u001b[A\n",
      " 55%|█████▍    | 33446/61028 [06:55<04:39, 98.54it/s]\u001b[A\n",
      " 55%|█████▍    | 33456/61028 [06:55<04:54, 93.78it/s]\u001b[A\n",
      " 55%|█████▍    | 33466/61028 [06:55<05:35, 82.27it/s]\u001b[A\n",
      " 55%|█████▍    | 33476/61028 [06:55<05:29, 83.63it/s]\u001b[A\n",
      " 55%|█████▍    | 33486/61028 [06:55<05:21, 85.75it/s]\u001b[A\n",
      " 55%|█████▍    | 33497/61028 [06:55<05:04, 90.49it/s]\u001b[A\n",
      " 55%|█████▍    | 33508/61028 [06:56<04:53, 93.61it/s]\u001b[A\n",
      " 55%|█████▍    | 33519/61028 [06:56<04:44, 96.58it/s]\u001b[A\n",
      " 55%|█████▍    | 33529/61028 [06:56<04:43, 97.09it/s]\u001b[A\n",
      " 55%|█████▍    | 33540/61028 [06:56<04:33, 100.38it/s]\u001b[A\n",
      " 55%|█████▍    | 33551/61028 [06:56<04:29, 102.08it/s]\u001b[A\n",
      " 55%|█████▍    | 33562/61028 [06:56<04:28, 102.42it/s]\u001b[A\n",
      " 55%|█████▌    | 33575/61028 [06:56<04:18, 106.21it/s]\u001b[A\n",
      " 55%|█████▌    | 33586/61028 [06:56<04:23, 104.25it/s]\u001b[A\n",
      " 55%|█████▌    | 33597/61028 [06:56<04:35, 99.44it/s] \u001b[A\n",
      " 55%|█████▌    | 33608/61028 [06:57<04:33, 100.26it/s]\u001b[A\n",
      " 55%|█████▌    | 33620/61028 [06:57<04:28, 102.23it/s]\u001b[A\n",
      " 55%|█████▌    | 33631/61028 [06:57<04:31, 101.02it/s]\u001b[A\n",
      " 55%|█████▌    | 33642/61028 [06:57<04:47, 95.31it/s] \u001b[A\n",
      " 55%|█████▌    | 33652/61028 [06:57<04:51, 94.07it/s]\u001b[A\n",
      " 55%|█████▌    | 33663/61028 [06:57<04:40, 97.71it/s]\u001b[A\n",
      " 55%|█████▌    | 33674/61028 [06:57<04:38, 98.29it/s]\u001b[A\n",
      " 55%|█████▌    | 33684/61028 [06:57<04:40, 97.31it/s]\u001b[A\n",
      " 55%|█████▌    | 33694/61028 [06:58<08:19, 54.69it/s]\u001b[A\n",
      " 55%|█████▌    | 33704/61028 [06:58<07:16, 62.60it/s]\u001b[A\n",
      " 55%|█████▌    | 33713/61028 [06:58<06:44, 67.50it/s]\u001b[A\n",
      " 55%|█████▌    | 33724/61028 [06:58<05:57, 76.27it/s]\u001b[A\n",
      " 55%|█████▌    | 33734/61028 [06:58<05:38, 80.68it/s]\u001b[A\n",
      " 55%|█████▌    | 33744/61028 [06:58<05:22, 84.62it/s]\u001b[A\n",
      " 55%|█████▌    | 33757/61028 [06:58<04:57, 91.71it/s]\u001b[A\n",
      " 55%|█████▌    | 33767/61028 [06:58<05:09, 88.05it/s]\u001b[A\n",
      " 55%|█████▌    | 33778/61028 [06:59<04:56, 91.88it/s]\u001b[A\n",
      " 55%|█████▌    | 33788/61028 [06:59<04:59, 90.84it/s]\u001b[A\n",
      " 55%|█████▌    | 33799/61028 [06:59<04:45, 95.40it/s]\u001b[A\n",
      " 55%|█████▌    | 33810/61028 [06:59<04:43, 95.96it/s]\u001b[A\n",
      " 55%|█████▌    | 33820/61028 [06:59<04:42, 96.46it/s]\u001b[A\n",
      " 55%|█████▌    | 33830/61028 [06:59<04:56, 91.85it/s]\u001b[A\n",
      " 55%|█████▌    | 33841/61028 [06:59<04:44, 95.50it/s]\u001b[A\n",
      " 55%|█████▌    | 33852/61028 [06:59<04:35, 98.80it/s]\u001b[A\n",
      " 55%|█████▌    | 33863/61028 [06:59<04:32, 99.51it/s]\u001b[A\n",
      " 56%|█████▌    | 33875/61028 [07:00<04:22, 103.30it/s]\u001b[A\n",
      " 56%|█████▌    | 33886/61028 [07:00<04:21, 103.73it/s]\u001b[A\n",
      " 56%|█████▌    | 33897/61028 [07:00<04:19, 104.51it/s]\u001b[A\n",
      " 56%|█████▌    | 33910/61028 [07:00<04:13, 106.89it/s]\u001b[A\n",
      " 56%|█████▌    | 33921/61028 [07:00<04:19, 104.54it/s]\u001b[A\n",
      " 56%|█████▌    | 33932/61028 [07:00<04:40, 96.74it/s] \u001b[A\n",
      " 56%|█████▌    | 33942/61028 [07:00<04:38, 97.35it/s]\u001b[A\n",
      " 56%|█████▌    | 33952/61028 [07:00<05:02, 89.45it/s]\u001b[A\n",
      " 56%|█████▌    | 33962/61028 [07:00<04:55, 91.51it/s]\u001b[A\n",
      " 56%|█████▌    | 33972/61028 [07:01<04:54, 91.88it/s]\u001b[A\n",
      " 56%|█████▌    | 33982/61028 [07:01<04:54, 91.86it/s]\u001b[A\n",
      " 56%|█████▌    | 33993/61028 [07:01<04:39, 96.57it/s]\u001b[A\n",
      " 56%|█████▌    | 34003/61028 [07:01<04:45, 94.75it/s]\u001b[A\n",
      " 56%|█████▌    | 34014/61028 [07:01<04:39, 96.54it/s]\u001b[A\n",
      " 56%|█████▌    | 34025/61028 [07:01<04:37, 97.29it/s]\u001b[A\n",
      " 56%|█████▌    | 34035/61028 [07:01<04:36, 97.45it/s]\u001b[A\n",
      " 56%|█████▌    | 34045/61028 [07:01<04:38, 96.87it/s]\u001b[A\n",
      " 56%|█████▌    | 34055/61028 [07:01<04:57, 90.57it/s]\u001b[A\n",
      " 56%|█████▌    | 34065/61028 [07:02<04:53, 91.96it/s]\u001b[A\n",
      " 56%|█████▌    | 34075/61028 [07:02<05:04, 88.55it/s]\u001b[A\n",
      " 56%|█████▌    | 34086/61028 [07:02<04:46, 94.03it/s]\u001b[A\n",
      " 56%|█████▌    | 34096/61028 [07:02<04:42, 95.37it/s]\u001b[A\n",
      " 56%|█████▌    | 34107/61028 [07:02<04:32, 98.76it/s]\u001b[A\n",
      " 56%|█████▌    | 34117/61028 [07:02<04:31, 99.04it/s]\u001b[A\n",
      " 56%|█████▌    | 34127/61028 [07:02<04:36, 97.34it/s]\u001b[A\n",
      " 56%|█████▌    | 34137/61028 [07:02<04:41, 95.37it/s]\u001b[A\n",
      " 56%|█████▌    | 34147/61028 [07:02<04:49, 92.95it/s]\u001b[A\n",
      " 56%|█████▌    | 34157/61028 [07:03<07:53, 56.76it/s]\u001b[A\n",
      " 56%|█████▌    | 34165/61028 [07:03<07:54, 56.60it/s]\u001b[A\n",
      " 56%|█████▌    | 34175/61028 [07:03<06:58, 64.10it/s]\u001b[A\n",
      " 56%|█████▌    | 34184/61028 [07:03<06:32, 68.44it/s]\u001b[A\n",
      " 56%|█████▌    | 34193/61028 [07:03<06:09, 72.55it/s]\u001b[A\n",
      " 56%|█████▌    | 34202/61028 [07:03<05:48, 76.90it/s]\u001b[A\n",
      " 56%|█████▌    | 34214/61028 [07:03<05:16, 84.60it/s]\u001b[A\n",
      " 56%|█████▌    | 34226/61028 [07:04<04:55, 90.77it/s]\u001b[A\n",
      " 56%|█████▌    | 34237/61028 [07:04<04:44, 94.17it/s]\u001b[A\n",
      " 56%|█████▌    | 34247/61028 [07:04<04:50, 92.19it/s]\u001b[A\n",
      " 56%|█████▌    | 34258/61028 [07:04<04:41, 94.93it/s]\u001b[A\n",
      " 56%|█████▌    | 34268/61028 [07:04<04:43, 94.41it/s]\u001b[A\n",
      " 56%|█████▌    | 34278/61028 [07:04<04:43, 94.40it/s]\u001b[A\n",
      " 56%|█████▌    | 34290/61028 [07:04<04:26, 100.51it/s]\u001b[A\n",
      " 56%|█████▌    | 34301/61028 [07:04<04:30, 98.81it/s] \u001b[A\n",
      " 56%|█████▌    | 34312/61028 [07:04<04:50, 91.83it/s]\u001b[A\n",
      " 56%|█████▌    | 34323/61028 [07:05<04:40, 95.13it/s]\u001b[A\n",
      " 56%|█████▋    | 34334/61028 [07:05<04:32, 97.81it/s]\u001b[A\n",
      " 56%|█████▋    | 34348/61028 [07:05<04:15, 104.58it/s]\u001b[A\n",
      " 56%|█████▋    | 34359/61028 [07:05<04:29, 98.94it/s] \u001b[A\n",
      " 56%|█████▋    | 34370/61028 [07:05<04:36, 96.54it/s]\u001b[A\n",
      " 56%|█████▋    | 34380/61028 [07:05<04:41, 94.51it/s]\u001b[A\n",
      " 56%|█████▋    | 34391/61028 [07:05<04:34, 96.92it/s]\u001b[A\n",
      " 56%|█████▋    | 34401/61028 [07:05<04:55, 90.09it/s]\u001b[A\n",
      " 56%|█████▋    | 34411/61028 [07:05<05:02, 88.08it/s]\u001b[A\n",
      " 56%|█████▋    | 34421/61028 [07:06<04:57, 89.53it/s]\u001b[A\n",
      " 56%|█████▋    | 34433/61028 [07:06<04:37, 95.75it/s]\u001b[A\n",
      " 56%|█████▋    | 34444/61028 [07:06<04:34, 96.73it/s]\u001b[A\n",
      " 56%|█████▋    | 34454/61028 [07:06<04:40, 94.58it/s]\u001b[A\n",
      " 56%|█████▋    | 34464/61028 [07:06<04:54, 90.12it/s]\u001b[A\n",
      " 56%|█████▋    | 34474/61028 [07:06<04:47, 92.23it/s]\u001b[A\n",
      " 57%|█████▋    | 34486/61028 [07:06<04:28, 98.68it/s]\u001b[A\n",
      " 57%|█████▋    | 34498/61028 [07:06<04:19, 102.08it/s]\u001b[A\n",
      " 57%|█████▋    | 34509/61028 [07:06<04:23, 100.53it/s]\u001b[A\n",
      " 57%|█████▋    | 34520/61028 [07:07<04:29, 98.31it/s] \u001b[A\n",
      " 57%|█████▋    | 34530/61028 [07:07<04:32, 97.38it/s]\u001b[A\n",
      " 57%|█████▋    | 34540/61028 [07:07<04:48, 91.93it/s]\u001b[A\n",
      " 57%|█████▋    | 34550/61028 [07:07<04:52, 90.64it/s]\u001b[A\n",
      " 57%|█████▋    | 34560/61028 [07:07<04:45, 92.82it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 34570/61028 [07:07<04:40, 94.48it/s]\u001b[A\n",
      " 57%|█████▋    | 34580/61028 [07:07<04:37, 95.26it/s]\u001b[A\n",
      " 57%|█████▋    | 34590/61028 [07:07<04:49, 91.38it/s]\u001b[A\n",
      " 57%|█████▋    | 34601/61028 [07:07<04:35, 95.80it/s]\u001b[A\n",
      " 57%|█████▋    | 34612/61028 [07:08<04:33, 96.47it/s]\u001b[A\n",
      " 57%|█████▋    | 34622/61028 [07:08<08:44, 50.33it/s]\u001b[A\n",
      " 57%|█████▋    | 34630/61028 [07:08<07:53, 55.74it/s]\u001b[A\n",
      " 57%|█████▋    | 34639/61028 [07:08<06:59, 62.87it/s]\u001b[A\n",
      " 57%|█████▋    | 34648/61028 [07:08<06:23, 68.70it/s]\u001b[A\n",
      " 57%|█████▋    | 34659/61028 [07:08<05:46, 76.10it/s]\u001b[A\n",
      " 57%|█████▋    | 34669/61028 [07:08<05:29, 80.09it/s]\u001b[A\n",
      " 57%|█████▋    | 34680/61028 [07:09<05:04, 86.55it/s]\u001b[A\n",
      " 57%|█████▋    | 34690/61028 [07:09<04:57, 88.65it/s]\u001b[A\n",
      " 57%|█████▋    | 34700/61028 [07:09<04:54, 89.52it/s]\u001b[A\n",
      " 57%|█████▋    | 34711/61028 [07:09<04:39, 94.20it/s]\u001b[A\n",
      " 57%|█████▋    | 34721/61028 [07:09<04:35, 95.63it/s]\u001b[A\n",
      " 57%|█████▋    | 34731/61028 [07:09<04:47, 91.40it/s]\u001b[A\n",
      " 57%|█████▋    | 34741/61028 [07:09<04:45, 92.00it/s]\u001b[A\n",
      " 57%|█████▋    | 34751/61028 [07:09<04:47, 91.47it/s]\u001b[A\n",
      " 57%|█████▋    | 34761/61028 [07:09<04:43, 92.57it/s]\u001b[A\n",
      " 57%|█████▋    | 34771/61028 [07:10<04:39, 93.97it/s]\u001b[A\n",
      " 57%|█████▋    | 34781/61028 [07:10<04:43, 92.61it/s]\u001b[A\n",
      " 57%|█████▋    | 34791/61028 [07:10<04:38, 94.08it/s]\u001b[A\n",
      " 57%|█████▋    | 34803/61028 [07:10<04:27, 98.00it/s]\u001b[A\n",
      " 57%|█████▋    | 34813/61028 [07:10<04:37, 94.45it/s]\u001b[A\n",
      " 57%|█████▋    | 34823/61028 [07:10<04:38, 94.00it/s]\u001b[A\n",
      " 57%|█████▋    | 34833/61028 [07:10<04:47, 91.21it/s]\u001b[A\n",
      " 57%|█████▋    | 34844/61028 [07:10<04:33, 95.56it/s]\u001b[A\n",
      " 57%|█████▋    | 34855/61028 [07:10<04:31, 96.52it/s]\u001b[A\n",
      " 57%|█████▋    | 34865/61028 [07:11<04:30, 96.66it/s]\u001b[A\n",
      " 57%|█████▋    | 34876/61028 [07:11<04:24, 98.82it/s]\u001b[A\n",
      " 57%|█████▋    | 34886/61028 [07:11<04:35, 94.98it/s]\u001b[A\n",
      " 57%|█████▋    | 34896/61028 [07:11<04:51, 89.73it/s]\u001b[A\n",
      " 57%|█████▋    | 34907/61028 [07:11<04:41, 92.84it/s]\u001b[A\n",
      " 57%|█████▋    | 34918/61028 [07:11<04:37, 94.21it/s]\u001b[A\n",
      " 57%|█████▋    | 34928/61028 [07:11<04:33, 95.29it/s]\u001b[A\n",
      " 57%|█████▋    | 34938/61028 [07:11<04:34, 95.16it/s]\u001b[A\n",
      " 57%|█████▋    | 34948/61028 [07:11<04:48, 90.36it/s]\u001b[A\n",
      " 57%|█████▋    | 34960/61028 [07:12<04:30, 96.53it/s]\u001b[A\n",
      " 57%|█████▋    | 34973/61028 [07:12<04:16, 101.57it/s]\u001b[A\n",
      " 57%|█████▋    | 34984/61028 [07:12<04:21, 99.61it/s] \u001b[A\n",
      " 57%|█████▋    | 34995/61028 [07:12<04:30, 96.30it/s]\u001b[A\n",
      " 57%|█████▋    | 35005/61028 [07:12<04:31, 95.81it/s]\u001b[A\n",
      " 57%|█████▋    | 35015/61028 [07:12<04:31, 95.75it/s]\u001b[A\n",
      " 57%|█████▋    | 35025/61028 [07:12<04:28, 96.99it/s]\u001b[A\n",
      " 57%|█████▋    | 35035/61028 [07:12<04:50, 89.43it/s]\u001b[A\n",
      " 57%|█████▋    | 35046/61028 [07:12<04:39, 93.10it/s]\u001b[A\n",
      " 57%|█████▋    | 35057/61028 [07:13<04:32, 95.29it/s]\u001b[A\n",
      " 57%|█████▋    | 35068/61028 [07:13<04:23, 98.68it/s]\u001b[A\n",
      " 57%|█████▋    | 35078/61028 [07:13<07:40, 56.30it/s]\u001b[A\n",
      " 57%|█████▋    | 35086/61028 [07:13<07:05, 60.94it/s]\u001b[A\n",
      " 58%|█████▊    | 35096/61028 [07:13<06:20, 68.07it/s]\u001b[A\n",
      " 58%|█████▊    | 35107/61028 [07:13<05:40, 76.06it/s]\u001b[A\n",
      " 58%|█████▊    | 35116/61028 [07:13<05:29, 78.56it/s]\u001b[A\n",
      " 58%|█████▊    | 35127/61028 [07:14<05:07, 84.33it/s]\u001b[A\n",
      " 58%|█████▊    | 35137/61028 [07:14<04:57, 87.14it/s]\u001b[A\n",
      " 58%|█████▊    | 35147/61028 [07:14<04:48, 89.79it/s]\u001b[A\n",
      " 58%|█████▊    | 35158/61028 [07:14<04:38, 92.75it/s]\u001b[A\n",
      " 58%|█████▊    | 35169/61028 [07:14<04:29, 96.05it/s]\u001b[A\n",
      " 58%|█████▊    | 35180/61028 [07:14<04:25, 97.45it/s]\u001b[A\n",
      " 58%|█████▊    | 35191/61028 [07:14<04:17, 100.43it/s]\u001b[A\n",
      " 58%|█████▊    | 35202/61028 [07:14<04:23, 97.87it/s] \u001b[A\n",
      " 58%|█████▊    | 35212/61028 [07:14<04:32, 94.70it/s]\u001b[A\n",
      " 58%|█████▊    | 35222/61028 [07:15<04:29, 95.69it/s]\u001b[A\n",
      " 58%|█████▊    | 35232/61028 [07:15<04:31, 95.17it/s]\u001b[A\n",
      " 58%|█████▊    | 35242/61028 [07:15<04:58, 86.50it/s]\u001b[A\n",
      " 58%|█████▊    | 35253/61028 [07:15<04:40, 91.75it/s]\u001b[A\n",
      " 58%|█████▊    | 35263/61028 [07:15<04:40, 91.88it/s]\u001b[A\n",
      " 58%|█████▊    | 35274/61028 [07:15<04:29, 95.44it/s]\u001b[A\n",
      " 58%|█████▊    | 35284/61028 [07:15<04:46, 89.78it/s]\u001b[A\n",
      " 58%|█████▊    | 35294/61028 [07:15<04:51, 88.30it/s]\u001b[A\n",
      " 58%|█████▊    | 35303/61028 [07:15<04:50, 88.47it/s]\u001b[A\n",
      " 58%|█████▊    | 35313/61028 [07:16<04:44, 90.38it/s]\u001b[A\n",
      " 58%|█████▊    | 35324/61028 [07:16<04:30, 94.93it/s]\u001b[A\n",
      " 58%|█████▊    | 35334/61028 [07:16<04:30, 95.05it/s]\u001b[A\n",
      " 58%|█████▊    | 35344/61028 [07:16<04:34, 93.72it/s]\u001b[A\n",
      " 58%|█████▊    | 35354/61028 [07:16<04:32, 94.11it/s]\u001b[A\n",
      " 58%|█████▊    | 35364/61028 [07:16<04:31, 94.58it/s]\u001b[A\n",
      " 58%|█████▊    | 35376/61028 [07:16<04:17, 99.53it/s]\u001b[A\n",
      " 58%|█████▊    | 35387/61028 [07:16<04:23, 97.23it/s]\u001b[A\n",
      " 58%|█████▊    | 35398/61028 [07:16<04:19, 98.83it/s]\u001b[A\n",
      " 58%|█████▊    | 35408/61028 [07:16<04:19, 98.81it/s]\u001b[A\n",
      " 58%|█████▊    | 35419/61028 [07:17<04:15, 100.09it/s]\u001b[A\n",
      " 58%|█████▊    | 35430/61028 [07:17<04:15, 100.08it/s]\u001b[A\n",
      " 58%|█████▊    | 35441/61028 [07:17<04:21, 97.70it/s] \u001b[A\n",
      " 58%|█████▊    | 35452/61028 [07:17<04:14, 100.57it/s]\u001b[A\n",
      " 58%|█████▊    | 35463/61028 [07:17<04:17, 99.22it/s] \u001b[A\n",
      " 58%|█████▊    | 35475/61028 [07:17<04:09, 102.34it/s]\u001b[A\n",
      " 58%|█████▊    | 35486/61028 [07:17<04:18, 98.80it/s] \u001b[A\n",
      " 58%|█████▊    | 35498/61028 [07:17<04:12, 101.10it/s]\u001b[A\n",
      " 58%|█████▊    | 35509/61028 [07:18<04:27, 95.49it/s] \u001b[A\n",
      " 58%|█████▊    | 35519/61028 [07:18<04:31, 93.82it/s]\u001b[A\n",
      " 58%|█████▊    | 35529/61028 [07:18<04:31, 94.05it/s]\u001b[A\n",
      " 58%|█████▊    | 35539/61028 [07:18<04:30, 94.29it/s]\u001b[A\n",
      " 58%|█████▊    | 35549/61028 [07:18<08:18, 51.09it/s]\u001b[A\n",
      " 58%|█████▊    | 35559/61028 [07:18<07:12, 58.90it/s]\u001b[A\n",
      " 58%|█████▊    | 35568/61028 [07:18<06:30, 65.17it/s]\u001b[A\n",
      " 58%|█████▊    | 35577/61028 [07:19<06:00, 70.62it/s]\u001b[A\n",
      " 58%|█████▊    | 35586/61028 [07:19<05:43, 74.11it/s]\u001b[A\n",
      " 58%|█████▊    | 35597/61028 [07:19<05:11, 81.57it/s]\u001b[A\n",
      " 58%|█████▊    | 35607/61028 [07:19<04:54, 86.30it/s]\u001b[A\n",
      " 58%|█████▊    | 35617/61028 [07:19<04:47, 88.50it/s]\u001b[A\n",
      " 58%|█████▊    | 35627/61028 [07:19<04:37, 91.44it/s]\u001b[A\n",
      " 58%|█████▊    | 35637/61028 [07:19<04:44, 89.19it/s]\u001b[A\n",
      " 58%|█████▊    | 35647/61028 [07:19<04:43, 89.62it/s]\u001b[A\n",
      " 58%|█████▊    | 35657/61028 [07:19<04:38, 91.26it/s]\u001b[A\n",
      " 58%|█████▊    | 35667/61028 [07:20<04:43, 89.33it/s]\u001b[A\n",
      " 58%|█████▊    | 35678/61028 [07:20<04:35, 92.10it/s]\u001b[A\n",
      " 58%|█████▊    | 35688/61028 [07:20<04:29, 93.98it/s]\u001b[A\n",
      " 58%|█████▊    | 35698/61028 [07:20<04:30, 93.56it/s]\u001b[A\n",
      " 59%|█████▊    | 35708/61028 [07:20<04:28, 94.28it/s]\u001b[A\n",
      " 59%|█████▊    | 35718/61028 [07:20<04:25, 95.19it/s]\u001b[A\n",
      " 59%|█████▊    | 35728/61028 [07:20<04:25, 95.26it/s]\u001b[A\n",
      " 59%|█████▊    | 35738/61028 [07:20<04:58, 84.75it/s]\u001b[A\n",
      " 59%|█████▊    | 35747/61028 [07:20<04:59, 84.36it/s]\u001b[A\n",
      " 59%|█████▊    | 35757/61028 [07:21<04:54, 85.78it/s]\u001b[A\n",
      " 59%|█████▊    | 35768/61028 [07:21<04:37, 91.18it/s]\u001b[A\n",
      " 59%|█████▊    | 35780/61028 [07:21<04:24, 95.45it/s]\u001b[A\n",
      " 59%|█████▊    | 35791/61028 [07:21<04:19, 97.32it/s]\u001b[A\n",
      " 59%|█████▊    | 35801/61028 [07:21<04:17, 98.10it/s]\u001b[A\n",
      " 59%|█████▊    | 35811/61028 [07:21<04:17, 97.88it/s]\u001b[A\n",
      " 59%|█████▊    | 35822/61028 [07:21<04:13, 99.32it/s]\u001b[A\n",
      " 59%|█████▊    | 35832/61028 [07:21<04:13, 99.47it/s]\u001b[A\n",
      " 59%|█████▊    | 35842/61028 [07:21<04:15, 98.43it/s]\u001b[A\n",
      " 59%|█████▊    | 35852/61028 [07:21<04:22, 95.95it/s]\u001b[A\n",
      " 59%|█████▉    | 35862/61028 [07:22<04:22, 95.94it/s]\u001b[A\n",
      " 59%|█████▉    | 35872/61028 [07:22<04:30, 93.13it/s]\u001b[A\n",
      " 59%|█████▉    | 35883/61028 [07:22<04:21, 96.20it/s]\u001b[A\n",
      " 59%|█████▉    | 35893/61028 [07:22<04:34, 91.61it/s]\u001b[A\n",
      " 59%|█████▉    | 35903/61028 [07:22<04:46, 87.73it/s]\u001b[A\n",
      " 59%|█████▉    | 35913/61028 [07:22<04:36, 90.70it/s]\u001b[A\n",
      " 59%|█████▉    | 35923/61028 [07:22<04:29, 93.06it/s]\u001b[A\n",
      " 59%|█████▉    | 35934/61028 [07:22<04:25, 94.62it/s]\u001b[A\n",
      " 59%|█████▉    | 35945/61028 [07:22<04:20, 96.15it/s]\u001b[A\n",
      " 59%|█████▉    | 35956/61028 [07:23<04:15, 97.97it/s]\u001b[A\n",
      " 59%|█████▉    | 35968/61028 [07:23<04:07, 101.18it/s]\u001b[A\n",
      " 59%|█████▉    | 35979/61028 [07:23<04:06, 101.74it/s]\u001b[A\n",
      " 59%|█████▉    | 35990/61028 [07:23<04:11, 99.70it/s] \u001b[A\n",
      " 59%|█████▉    | 36001/61028 [07:23<06:42, 62.25it/s]\u001b[A\n",
      " 59%|█████▉    | 36010/61028 [07:23<06:37, 62.95it/s]\u001b[A\n",
      " 59%|█████▉    | 36020/61028 [07:23<05:55, 70.44it/s]\u001b[A\n",
      " 59%|█████▉    | 36030/61028 [07:24<05:28, 76.08it/s]\u001b[A\n",
      " 59%|█████▉    | 36039/61028 [07:24<05:20, 77.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 36048/61028 [07:24<05:17, 78.63it/s]\u001b[A\n",
      " 59%|█████▉    | 36058/61028 [07:24<04:58, 83.67it/s]\u001b[A\n",
      " 59%|█████▉    | 36070/61028 [07:24<04:32, 91.71it/s]\u001b[A\n",
      " 59%|█████▉    | 36081/61028 [07:24<04:25, 94.05it/s]\u001b[A\n",
      " 59%|█████▉    | 36092/61028 [07:24<04:18, 96.31it/s]\u001b[A\n",
      " 59%|█████▉    | 36104/61028 [07:24<04:03, 102.26it/s]\u001b[A\n",
      " 59%|█████▉    | 36115/61028 [07:24<04:06, 100.89it/s]\u001b[A\n",
      " 59%|█████▉    | 36126/61028 [07:25<04:07, 100.42it/s]\u001b[A\n",
      " 59%|█████▉    | 36137/61028 [07:25<04:10, 99.38it/s] \u001b[A\n",
      " 59%|█████▉    | 36148/61028 [07:25<04:11, 98.90it/s]\u001b[A\n",
      " 59%|█████▉    | 36161/61028 [07:25<03:55, 105.58it/s]\u001b[A\n",
      " 59%|█████▉    | 36173/61028 [07:25<03:50, 107.72it/s]\u001b[A\n",
      " 59%|█████▉    | 36184/61028 [07:25<04:00, 103.30it/s]\u001b[A\n",
      " 59%|█████▉    | 36195/61028 [07:25<04:17, 96.47it/s] \u001b[A\n",
      " 59%|█████▉    | 36205/61028 [07:25<04:26, 92.97it/s]\u001b[A\n",
      " 59%|█████▉    | 36215/61028 [07:25<04:35, 90.02it/s]\u001b[A\n",
      " 59%|█████▉    | 36227/61028 [07:26<04:15, 96.98it/s]\u001b[A\n",
      " 59%|█████▉    | 36238/61028 [07:26<04:07, 100.04it/s]\u001b[A\n",
      " 59%|█████▉    | 36250/61028 [07:26<03:58, 104.00it/s]\u001b[A\n",
      " 59%|█████▉    | 36262/61028 [07:26<03:53, 105.93it/s]\u001b[A\n",
      " 59%|█████▉    | 36273/61028 [07:26<04:03, 101.77it/s]\u001b[A\n",
      " 59%|█████▉    | 36284/61028 [07:26<04:08, 99.59it/s] \u001b[A\n",
      " 59%|█████▉    | 36295/61028 [07:26<04:05, 100.56it/s]\u001b[A\n",
      " 59%|█████▉    | 36306/61028 [07:26<04:03, 101.34it/s]\u001b[A\n",
      " 60%|█████▉    | 36317/61028 [07:26<04:09, 98.96it/s] \u001b[A\n",
      " 60%|█████▉    | 36327/61028 [07:27<04:10, 98.56it/s]\u001b[A\n",
      " 60%|█████▉    | 36339/61028 [07:27<04:01, 102.12it/s]\u001b[A\n",
      " 60%|█████▉    | 36350/61028 [07:27<04:06, 99.98it/s] \u001b[A\n",
      " 60%|█████▉    | 36361/61028 [07:27<04:03, 101.28it/s]\u001b[A\n",
      " 60%|█████▉    | 36372/61028 [07:27<04:08, 99.30it/s] \u001b[A\n",
      " 60%|█████▉    | 36382/61028 [07:27<04:11, 98.16it/s]\u001b[A\n",
      " 60%|█████▉    | 36394/61028 [07:27<03:59, 102.85it/s]\u001b[A\n",
      " 60%|█████▉    | 36405/61028 [07:27<04:06, 99.96it/s] \u001b[A\n",
      " 60%|█████▉    | 36416/61028 [07:27<04:06, 99.81it/s]\u001b[A\n",
      " 60%|█████▉    | 36427/61028 [07:28<04:11, 97.78it/s]\u001b[A\n",
      " 60%|█████▉    | 36438/61028 [07:28<04:06, 99.95it/s]\u001b[A\n",
      " 60%|█████▉    | 36450/61028 [07:28<03:56, 103.87it/s]\u001b[A\n",
      " 60%|█████▉    | 36461/61028 [07:28<03:56, 103.96it/s]\u001b[A\n",
      " 60%|█████▉    | 36473/61028 [07:28<03:47, 107.76it/s]\u001b[A\n",
      " 60%|█████▉    | 36484/61028 [07:28<03:52, 105.45it/s]\u001b[A\n",
      " 60%|█████▉    | 36495/61028 [07:28<07:26, 54.94it/s] \u001b[A\n",
      " 60%|█████▉    | 36505/61028 [07:29<06:26, 63.38it/s]\u001b[A\n",
      " 60%|█████▉    | 36515/61028 [07:29<05:49, 70.20it/s]\u001b[A\n",
      " 60%|█████▉    | 36526/61028 [07:29<05:15, 77.72it/s]\u001b[A\n",
      " 60%|█████▉    | 36537/61028 [07:29<04:52, 83.67it/s]\u001b[A\n",
      " 60%|█████▉    | 36547/61028 [07:29<04:46, 85.50it/s]\u001b[A\n",
      " 60%|█████▉    | 36557/61028 [07:29<04:39, 87.58it/s]\u001b[A\n",
      " 60%|█████▉    | 36568/61028 [07:29<04:30, 90.35it/s]\u001b[A\n",
      " 60%|█████▉    | 36579/61028 [07:29<04:20, 93.82it/s]\u001b[A\n",
      " 60%|█████▉    | 36589/61028 [07:29<04:21, 93.61it/s]\u001b[A\n",
      " 60%|█████▉    | 36601/61028 [07:30<04:09, 98.04it/s]\u001b[A\n",
      " 60%|█████▉    | 36612/61028 [07:30<04:08, 98.29it/s]\u001b[A\n",
      " 60%|██████    | 36622/61028 [07:30<04:14, 96.06it/s]\u001b[A\n",
      " 60%|██████    | 36633/61028 [07:30<04:06, 99.05it/s]\u001b[A\n",
      " 60%|██████    | 36645/61028 [07:30<04:01, 101.10it/s]\u001b[A\n",
      " 60%|██████    | 36656/61028 [07:30<03:57, 102.52it/s]\u001b[A\n",
      " 60%|██████    | 36667/61028 [07:30<04:04, 99.58it/s] \u001b[A\n",
      " 60%|██████    | 36679/61028 [07:30<03:57, 102.49it/s]\u001b[A\n",
      " 60%|██████    | 36690/61028 [07:30<03:59, 101.58it/s]\u001b[A\n",
      " 60%|██████    | 36701/61028 [07:31<04:05, 99.12it/s] \u001b[A\n",
      " 60%|██████    | 36713/61028 [07:31<03:54, 103.75it/s]\u001b[A\n",
      " 60%|██████    | 36724/61028 [07:31<04:02, 100.25it/s]\u001b[A\n",
      " 60%|██████    | 36735/61028 [07:31<04:08, 97.77it/s] \u001b[A\n",
      " 60%|██████    | 36745/61028 [07:31<04:08, 97.74it/s]\u001b[A\n",
      " 60%|██████    | 36759/61028 [07:31<03:49, 105.80it/s]\u001b[A\n",
      " 60%|██████    | 36770/61028 [07:31<03:56, 102.38it/s]\u001b[A\n",
      " 60%|██████    | 36781/61028 [07:31<04:11, 96.33it/s] \u001b[A\n",
      " 60%|██████    | 36793/61028 [07:31<04:00, 100.96it/s]\u001b[A\n",
      " 60%|██████    | 36804/61028 [07:32<03:55, 103.00it/s]\u001b[A\n",
      " 60%|██████    | 36815/61028 [07:32<03:57, 102.11it/s]\u001b[A\n",
      " 60%|██████    | 36826/61028 [07:32<04:04, 98.89it/s] \u001b[A\n",
      " 60%|██████    | 36838/61028 [07:32<03:55, 102.71it/s]\u001b[A\n",
      " 60%|██████    | 36849/61028 [07:32<04:03, 99.47it/s] \u001b[A\n",
      " 60%|██████    | 36861/61028 [07:32<03:53, 103.57it/s]\u001b[A\n",
      " 60%|██████    | 36872/61028 [07:32<03:52, 103.72it/s]\u001b[A\n",
      " 60%|██████    | 36883/61028 [07:32<04:01, 100.16it/s]\u001b[A\n",
      " 60%|██████    | 36894/61028 [07:32<03:58, 101.37it/s]\u001b[A\n",
      " 60%|██████    | 36906/61028 [07:33<03:52, 103.78it/s]\u001b[A\n",
      " 60%|██████    | 36917/61028 [07:33<03:49, 104.98it/s]\u001b[A\n",
      " 61%|██████    | 36928/61028 [07:33<04:04, 98.51it/s] \u001b[A\n",
      " 61%|██████    | 36938/61028 [07:33<04:08, 96.82it/s]\u001b[A\n",
      " 61%|██████    | 36948/61028 [07:33<04:20, 92.36it/s]\u001b[A\n",
      " 61%|██████    | 36960/61028 [07:33<04:04, 98.38it/s]\u001b[A\n",
      " 61%|██████    | 36971/61028 [07:33<04:22, 91.56it/s]\u001b[A\n",
      " 61%|██████    | 36981/61028 [07:34<07:12, 55.57it/s]\u001b[A\n",
      " 61%|██████    | 36993/61028 [07:34<06:05, 65.78it/s]\u001b[A\n",
      " 61%|██████    | 37003/61028 [07:34<05:29, 72.82it/s]\u001b[A\n",
      " 61%|██████    | 37015/61028 [07:34<04:55, 81.36it/s]\u001b[A\n",
      " 61%|██████    | 37027/61028 [07:34<04:30, 88.66it/s]\u001b[A\n",
      " 61%|██████    | 37039/61028 [07:34<04:14, 94.08it/s]\u001b[A\n",
      " 61%|██████    | 37050/61028 [07:34<04:09, 96.13it/s]\u001b[A\n",
      " 61%|██████    | 37062/61028 [07:34<03:56, 101.33it/s]\u001b[A\n",
      " 61%|██████    | 37073/61028 [07:34<03:54, 102.24it/s]\u001b[A\n",
      " 61%|██████    | 37085/61028 [07:35<03:46, 105.67it/s]\u001b[A\n",
      " 61%|██████    | 37096/61028 [07:35<03:51, 103.57it/s]\u001b[A\n",
      " 61%|██████    | 37107/61028 [07:35<04:12, 94.56it/s] \u001b[A\n",
      " 61%|██████    | 37117/61028 [07:35<04:11, 94.90it/s]\u001b[A\n",
      " 61%|██████    | 37127/61028 [07:35<04:19, 91.98it/s]\u001b[A\n",
      " 61%|██████    | 37137/61028 [07:35<04:16, 93.32it/s]\u001b[A\n",
      " 61%|██████    | 37147/61028 [07:35<04:13, 94.36it/s]\u001b[A\n",
      " 61%|██████    | 37157/61028 [07:35<04:12, 94.47it/s]\u001b[A\n",
      " 61%|██████    | 37167/61028 [07:35<04:10, 95.24it/s]\u001b[A\n",
      " 61%|██████    | 37177/61028 [07:36<04:22, 90.76it/s]\u001b[A\n",
      " 61%|██████    | 37188/61028 [07:36<04:16, 92.87it/s]\u001b[A\n",
      " 61%|██████    | 37199/61028 [07:36<04:06, 96.73it/s]\u001b[A\n",
      " 61%|██████    | 37209/61028 [07:36<04:06, 96.69it/s]\u001b[A\n",
      " 61%|██████    | 37219/61028 [07:36<04:10, 94.97it/s]\u001b[A\n",
      " 61%|██████    | 37230/61028 [07:36<04:07, 95.98it/s]\u001b[A\n",
      " 61%|██████    | 37240/61028 [07:36<04:09, 95.33it/s]\u001b[A\n",
      " 61%|██████    | 37253/61028 [07:36<03:49, 103.57it/s]\u001b[A\n",
      " 61%|██████    | 37264/61028 [07:36<04:02, 97.86it/s] \u001b[A\n",
      " 61%|██████    | 37275/61028 [07:37<04:03, 97.64it/s]\u001b[A\n",
      " 61%|██████    | 37286/61028 [07:37<03:58, 99.42it/s]\u001b[A\n",
      " 61%|██████    | 37298/61028 [07:37<03:51, 102.38it/s]\u001b[A\n",
      " 61%|██████    | 37309/61028 [07:37<03:58, 99.28it/s] \u001b[A\n",
      " 61%|██████    | 37320/61028 [07:37<03:57, 99.84it/s]\u001b[A\n",
      " 61%|██████    | 37332/61028 [07:37<03:49, 103.41it/s]\u001b[A\n",
      " 61%|██████    | 37343/61028 [07:37<03:52, 101.84it/s]\u001b[A\n",
      " 61%|██████    | 37354/61028 [07:37<04:01, 98.05it/s] \u001b[A\n",
      " 61%|██████    | 37364/61028 [07:37<04:12, 93.79it/s]\u001b[A\n",
      " 61%|██████    | 37377/61028 [07:38<03:56, 100.08it/s]\u001b[A\n",
      " 61%|██████▏   | 37388/61028 [07:38<04:06, 96.06it/s] \u001b[A\n",
      " 61%|██████▏   | 37398/61028 [07:38<04:07, 95.44it/s]\u001b[A\n",
      " 61%|██████▏   | 37410/61028 [07:38<03:56, 99.70it/s]\u001b[A\n",
      " 61%|██████▏   | 37421/61028 [07:38<03:51, 101.91it/s]\u001b[A\n",
      " 61%|██████▏   | 37432/61028 [07:38<03:49, 102.71it/s]\u001b[A\n",
      " 61%|██████▏   | 37443/61028 [07:38<03:51, 102.09it/s]\u001b[A\n",
      " 61%|██████▏   | 37456/61028 [07:38<03:51, 101.86it/s]\u001b[A\n",
      " 61%|██████▏   | 37467/61028 [07:39<06:25, 61.04it/s] \u001b[A\n",
      " 61%|██████▏   | 37478/61028 [07:39<05:39, 69.32it/s]\u001b[A\n",
      " 61%|██████▏   | 37489/61028 [07:39<05:06, 76.83it/s]\u001b[A\n",
      " 61%|██████▏   | 37499/61028 [07:39<04:45, 82.53it/s]\u001b[A\n",
      " 61%|██████▏   | 37509/61028 [07:39<04:42, 83.40it/s]\u001b[A\n",
      " 61%|██████▏   | 37519/61028 [07:39<04:29, 87.24it/s]\u001b[A\n",
      " 61%|██████▏   | 37529/61028 [07:39<04:21, 89.80it/s]\u001b[A\n",
      " 62%|██████▏   | 37539/61028 [07:39<04:44, 82.43it/s]\u001b[A\n",
      " 62%|██████▏   | 37551/61028 [07:40<04:21, 89.80it/s]\u001b[A\n",
      " 62%|██████▏   | 37562/61028 [07:40<04:09, 94.02it/s]\u001b[A\n",
      " 62%|██████▏   | 37572/61028 [07:40<04:07, 94.69it/s]\u001b[A\n",
      " 62%|██████▏   | 37582/61028 [07:40<04:06, 95.00it/s]\u001b[A\n",
      " 62%|██████▏   | 37592/61028 [07:40<04:11, 93.10it/s]\u001b[A\n",
      " 62%|██████▏   | 37604/61028 [07:40<04:02, 96.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 37614/61028 [07:40<04:13, 92.30it/s]\u001b[A\n",
      " 62%|██████▏   | 37624/61028 [07:40<04:10, 93.27it/s]\u001b[A\n",
      " 62%|██████▏   | 37634/61028 [07:40<04:14, 91.99it/s]\u001b[A\n",
      " 62%|██████▏   | 37644/61028 [07:41<04:14, 91.94it/s]\u001b[A\n",
      " 62%|██████▏   | 37656/61028 [07:41<03:58, 97.96it/s]\u001b[A\n",
      " 62%|██████▏   | 37666/61028 [07:41<04:05, 95.30it/s]\u001b[A\n",
      " 62%|██████▏   | 37678/61028 [07:41<03:56, 98.67it/s]\u001b[A\n",
      " 62%|██████▏   | 37689/61028 [07:41<03:49, 101.64it/s]\u001b[A\n",
      " 62%|██████▏   | 37700/61028 [07:41<03:50, 101.24it/s]\u001b[A\n",
      " 62%|██████▏   | 37711/61028 [07:41<03:48, 102.26it/s]\u001b[A\n",
      " 62%|██████▏   | 37722/61028 [07:41<03:46, 102.81it/s]\u001b[A\n",
      " 62%|██████▏   | 37733/61028 [07:41<04:03, 95.83it/s] \u001b[A\n",
      " 62%|██████▏   | 37744/61028 [07:42<03:56, 98.55it/s]\u001b[A\n",
      " 62%|██████▏   | 37754/61028 [07:42<04:03, 95.56it/s]\u001b[A\n",
      " 62%|██████▏   | 37764/61028 [07:42<04:02, 96.11it/s]\u001b[A\n",
      " 62%|██████▏   | 37775/61028 [07:42<03:58, 97.38it/s]\u001b[A\n",
      " 62%|██████▏   | 37787/61028 [07:42<03:45, 103.14it/s]\u001b[A\n",
      " 62%|██████▏   | 37798/61028 [07:42<03:49, 101.14it/s]\u001b[A\n",
      " 62%|██████▏   | 37810/61028 [07:42<03:39, 105.86it/s]\u001b[A\n",
      " 62%|██████▏   | 37822/61028 [07:42<03:35, 107.60it/s]\u001b[A\n",
      " 62%|██████▏   | 37833/61028 [07:42<03:40, 105.23it/s]\u001b[A\n",
      " 62%|██████▏   | 37844/61028 [07:43<03:40, 105.01it/s]\u001b[A\n",
      " 62%|██████▏   | 37855/61028 [07:43<03:52, 99.70it/s] \u001b[A\n",
      " 62%|██████▏   | 37866/61028 [07:43<03:47, 101.76it/s]\u001b[A\n",
      " 62%|██████▏   | 37877/61028 [07:43<04:10, 92.27it/s] \u001b[A\n",
      " 62%|██████▏   | 37887/61028 [07:43<04:15, 90.60it/s]\u001b[A\n",
      " 62%|██████▏   | 37897/61028 [07:43<04:13, 91.22it/s]\u001b[A\n",
      " 62%|██████▏   | 37909/61028 [07:43<03:59, 96.62it/s]\u001b[A\n",
      " 62%|██████▏   | 37922/61028 [07:43<03:43, 103.17it/s]\u001b[A\n",
      " 62%|██████▏   | 37933/61028 [07:43<03:40, 104.94it/s]\u001b[A\n",
      " 62%|██████▏   | 37944/61028 [07:44<07:08, 53.89it/s] \u001b[A\n",
      " 62%|██████▏   | 37953/61028 [07:44<06:20, 60.64it/s]\u001b[A\n",
      " 62%|██████▏   | 37962/61028 [07:44<05:46, 66.52it/s]\u001b[A\n",
      " 62%|██████▏   | 37973/61028 [07:44<05:05, 75.41it/s]\u001b[A\n",
      " 62%|██████▏   | 37983/61028 [07:44<04:51, 78.93it/s]\u001b[A\n",
      " 62%|██████▏   | 37993/61028 [07:44<04:38, 82.78it/s]\u001b[A\n",
      " 62%|██████▏   | 38003/61028 [07:45<04:34, 83.91it/s]\u001b[A\n",
      " 62%|██████▏   | 38013/61028 [07:45<04:28, 85.59it/s]\u001b[A\n",
      " 62%|██████▏   | 38023/61028 [07:45<04:23, 87.25it/s]\u001b[A\n",
      " 62%|██████▏   | 38033/61028 [07:45<04:18, 88.97it/s]\u001b[A\n",
      " 62%|██████▏   | 38044/61028 [07:45<04:08, 92.66it/s]\u001b[A\n",
      " 62%|██████▏   | 38055/61028 [07:45<03:57, 96.70it/s]\u001b[A\n",
      " 62%|██████▏   | 38065/61028 [07:45<04:16, 89.56it/s]\u001b[A\n",
      " 62%|██████▏   | 38075/61028 [07:45<04:42, 81.12it/s]\u001b[A\n",
      " 62%|██████▏   | 38086/61028 [07:45<04:30, 84.71it/s]\u001b[A\n",
      " 62%|██████▏   | 38097/61028 [07:46<04:16, 89.43it/s]\u001b[A\n",
      " 62%|██████▏   | 38108/61028 [07:46<04:02, 94.58it/s]\u001b[A\n",
      " 62%|██████▏   | 38118/61028 [07:46<04:03, 94.22it/s]\u001b[A\n",
      " 62%|██████▏   | 38128/61028 [07:46<04:07, 92.53it/s]\u001b[A\n",
      " 62%|██████▏   | 38140/61028 [07:46<03:56, 96.61it/s]\u001b[A\n",
      " 63%|██████▎   | 38151/61028 [07:46<03:53, 97.95it/s]\u001b[A\n",
      " 63%|██████▎   | 38161/61028 [07:46<03:54, 97.50it/s]\u001b[A\n",
      " 63%|██████▎   | 38171/61028 [07:46<04:03, 94.06it/s]\u001b[A\n",
      " 63%|██████▎   | 38184/61028 [07:46<03:44, 101.54it/s]\u001b[A\n",
      " 63%|██████▎   | 38195/61028 [07:47<03:49, 99.46it/s] \u001b[A\n",
      " 63%|██████▎   | 38206/61028 [07:47<03:53, 97.67it/s]\u001b[A\n",
      " 63%|██████▎   | 38216/61028 [07:47<03:59, 95.24it/s]\u001b[A\n",
      " 63%|██████▎   | 38226/61028 [07:47<03:59, 95.04it/s]\u001b[A\n",
      " 63%|██████▎   | 38237/61028 [07:47<03:51, 98.54it/s]\u001b[A\n",
      " 63%|██████▎   | 38248/61028 [07:47<03:48, 99.58it/s]\u001b[A\n",
      " 63%|██████▎   | 38259/61028 [07:47<03:56, 96.15it/s]\u001b[A\n",
      " 63%|██████▎   | 38269/61028 [07:47<03:57, 96.02it/s]\u001b[A\n",
      " 63%|██████▎   | 38279/61028 [07:47<04:03, 93.59it/s]\u001b[A\n",
      " 63%|██████▎   | 38290/61028 [07:48<03:53, 97.51it/s]\u001b[A\n",
      " 63%|██████▎   | 38301/61028 [07:48<03:50, 98.67it/s]\u001b[A\n",
      " 63%|██████▎   | 38311/61028 [07:48<03:51, 98.14it/s]\u001b[A\n",
      " 63%|██████▎   | 38322/61028 [07:48<03:50, 98.57it/s]\u001b[A\n",
      " 63%|██████▎   | 38332/61028 [07:48<04:05, 92.30it/s]\u001b[A\n",
      " 63%|██████▎   | 38343/61028 [07:48<03:59, 94.89it/s]\u001b[A\n",
      " 63%|██████▎   | 38353/61028 [07:48<03:56, 95.95it/s]\u001b[A\n",
      " 63%|██████▎   | 38364/61028 [07:48<03:48, 99.22it/s]\u001b[A\n",
      " 63%|██████▎   | 38374/61028 [07:48<03:51, 97.97it/s]\u001b[A\n",
      " 63%|██████▎   | 38384/61028 [07:48<03:51, 97.79it/s]\u001b[A\n",
      " 63%|██████▎   | 38395/61028 [07:49<03:54, 96.50it/s]\u001b[A\n",
      " 63%|██████▎   | 38405/61028 [07:49<06:36, 57.04it/s]\u001b[A\n",
      " 63%|██████▎   | 38416/61028 [07:49<05:40, 66.48it/s]\u001b[A\n",
      " 63%|██████▎   | 38425/61028 [07:49<05:15, 71.70it/s]\u001b[A\n",
      " 63%|██████▎   | 38435/61028 [07:49<04:50, 77.64it/s]\u001b[A\n",
      " 63%|██████▎   | 38444/61028 [07:49<04:41, 80.35it/s]\u001b[A\n",
      " 63%|██████▎   | 38455/61028 [07:49<04:19, 86.94it/s]\u001b[A\n",
      " 63%|██████▎   | 38465/61028 [07:50<04:12, 89.51it/s]\u001b[A\n",
      " 63%|██████▎   | 38476/61028 [07:50<04:01, 93.41it/s]\u001b[A\n",
      " 63%|██████▎   | 38488/61028 [07:50<03:46, 99.31it/s]\u001b[A\n",
      " 63%|██████▎   | 38500/61028 [07:50<03:37, 103.58it/s]\u001b[A\n",
      " 63%|██████▎   | 38514/61028 [07:50<03:23, 110.69it/s]\u001b[A\n",
      " 63%|██████▎   | 38526/61028 [07:50<03:39, 102.29it/s]\u001b[A\n",
      " 63%|██████▎   | 38537/61028 [07:50<03:37, 103.58it/s]\u001b[A\n",
      " 63%|██████▎   | 38548/61028 [07:50<04:06, 91.29it/s] \u001b[A\n",
      " 63%|██████▎   | 38558/61028 [07:51<04:23, 85.34it/s]\u001b[A\n",
      " 63%|██████▎   | 38568/61028 [07:51<04:18, 86.93it/s]\u001b[A\n",
      " 63%|██████▎   | 38578/61028 [07:51<04:09, 90.08it/s]\u001b[A\n",
      " 63%|██████▎   | 38589/61028 [07:51<03:59, 93.54it/s]\u001b[A\n",
      " 63%|██████▎   | 38600/61028 [07:51<03:50, 97.30it/s]\u001b[A\n",
      " 63%|██████▎   | 38611/61028 [07:51<03:42, 100.62it/s]\u001b[A\n",
      " 63%|██████▎   | 38622/61028 [07:51<03:50, 97.24it/s] \u001b[A\n",
      " 63%|██████▎   | 38633/61028 [07:51<03:42, 100.44it/s]\u001b[A\n",
      " 63%|██████▎   | 38644/61028 [07:51<03:49, 97.33it/s] \u001b[A\n",
      " 63%|██████▎   | 38654/61028 [07:51<03:54, 95.37it/s]\u001b[A\n",
      " 63%|██████▎   | 38664/61028 [07:52<03:55, 95.08it/s]\u001b[A\n",
      " 63%|██████▎   | 38674/61028 [07:52<04:03, 91.82it/s]\u001b[A\n",
      " 63%|██████▎   | 38684/61028 [07:52<04:01, 92.59it/s]\u001b[A\n",
      " 63%|██████▎   | 38695/61028 [07:52<03:53, 95.52it/s]\u001b[A\n",
      " 63%|██████▎   | 38707/61028 [07:52<03:44, 99.47it/s]\u001b[A\n",
      " 63%|██████▎   | 38718/61028 [07:52<03:58, 93.64it/s]\u001b[A\n",
      " 63%|██████▎   | 38728/61028 [07:52<04:09, 89.25it/s]\u001b[A\n",
      " 63%|██████▎   | 38738/61028 [07:52<04:03, 91.71it/s]\u001b[A\n",
      " 63%|██████▎   | 38748/61028 [07:53<04:18, 86.05it/s]\u001b[A\n",
      " 64%|██████▎   | 38759/61028 [07:53<04:01, 92.03it/s]\u001b[A\n",
      " 64%|██████▎   | 38769/61028 [07:53<03:59, 93.03it/s]\u001b[A\n",
      " 64%|██████▎   | 38782/61028 [07:53<03:42, 99.88it/s]\u001b[A\n",
      " 64%|██████▎   | 38793/61028 [07:53<03:40, 100.89it/s]\u001b[A\n",
      " 64%|██████▎   | 38804/61028 [07:53<03:44, 99.09it/s] \u001b[A\n",
      " 64%|██████▎   | 38815/61028 [07:53<03:48, 97.37it/s]\u001b[A\n",
      " 64%|██████▎   | 38826/61028 [07:53<03:40, 100.64it/s]\u001b[A\n",
      " 64%|██████▎   | 38837/61028 [07:53<03:39, 100.96it/s]\u001b[A\n",
      " 64%|██████▎   | 38848/61028 [07:54<03:51, 96.01it/s] \u001b[A\n",
      " 64%|██████▎   | 38860/61028 [07:54<03:39, 100.99it/s]\u001b[A\n",
      " 64%|██████▎   | 38871/61028 [07:54<06:39, 55.50it/s] \u001b[A\n",
      " 64%|██████▎   | 38879/61028 [07:54<06:08, 60.12it/s]\u001b[A\n",
      " 64%|██████▎   | 38888/61028 [07:54<05:34, 66.14it/s]\u001b[A\n",
      " 64%|██████▎   | 38898/61028 [07:54<05:09, 71.47it/s]\u001b[A\n",
      " 64%|██████▍   | 38907/61028 [07:54<04:51, 75.86it/s]\u001b[A\n",
      " 64%|██████▍   | 38918/61028 [07:55<04:30, 81.82it/s]\u001b[A\n",
      " 64%|██████▍   | 38927/61028 [07:55<04:24, 83.63it/s]\u001b[A\n",
      " 64%|██████▍   | 38938/61028 [07:55<04:05, 89.87it/s]\u001b[A\n",
      " 64%|██████▍   | 38950/61028 [07:55<03:53, 94.40it/s]\u001b[A\n",
      " 64%|██████▍   | 38963/61028 [07:55<03:36, 102.01it/s]\u001b[A\n",
      " 64%|██████▍   | 38974/61028 [07:55<03:34, 102.98it/s]\u001b[A\n",
      " 64%|██████▍   | 38985/61028 [07:55<03:38, 100.75it/s]\u001b[A\n",
      " 64%|██████▍   | 38996/61028 [07:55<04:00, 91.65it/s] \u001b[A\n",
      " 64%|██████▍   | 39006/61028 [07:55<04:06, 89.29it/s]\u001b[A\n",
      " 64%|██████▍   | 39016/61028 [07:56<04:09, 88.11it/s]\u001b[A\n",
      " 64%|██████▍   | 39030/61028 [07:56<03:45, 97.44it/s]\u001b[A\n",
      " 64%|██████▍   | 39041/61028 [07:56<03:53, 94.19it/s]\u001b[A\n",
      " 64%|██████▍   | 39051/61028 [07:56<03:50, 95.15it/s]\u001b[A\n",
      " 64%|██████▍   | 39062/61028 [07:56<03:49, 95.86it/s]\u001b[A\n",
      " 64%|██████▍   | 39072/61028 [07:56<03:48, 95.94it/s]\u001b[A\n",
      " 64%|██████▍   | 39083/61028 [07:56<03:43, 98.35it/s]\u001b[A\n",
      " 64%|██████▍   | 39096/61028 [07:56<03:33, 102.88it/s]\u001b[A\n",
      " 64%|██████▍   | 39107/61028 [07:56<03:45, 97.08it/s] \u001b[A\n",
      " 64%|██████▍   | 39117/61028 [07:57<03:51, 94.70it/s]\u001b[A\n",
      " 64%|██████▍   | 39127/61028 [07:57<03:56, 92.59it/s]\u001b[A\n",
      " 64%|██████▍   | 39137/61028 [07:57<03:57, 92.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 39148/61028 [07:57<03:47, 96.22it/s]\u001b[A\n",
      " 64%|██████▍   | 39158/61028 [07:57<03:49, 95.39it/s]\u001b[A\n",
      " 64%|██████▍   | 39168/61028 [07:57<04:01, 90.63it/s]\u001b[A\n",
      " 64%|██████▍   | 39179/61028 [07:57<03:53, 93.73it/s]\u001b[A\n",
      " 64%|██████▍   | 39191/61028 [07:57<03:38, 100.07it/s]\u001b[A\n",
      " 64%|██████▍   | 39202/61028 [07:57<03:49, 95.00it/s] \u001b[A\n",
      " 64%|██████▍   | 39212/61028 [07:58<03:57, 91.70it/s]\u001b[A\n",
      " 64%|██████▍   | 39223/61028 [07:58<03:48, 95.29it/s]\u001b[A\n",
      " 64%|██████▍   | 39233/61028 [07:58<03:47, 95.81it/s]\u001b[A\n",
      " 64%|██████▍   | 39243/61028 [07:58<03:50, 94.41it/s]\u001b[A\n",
      " 64%|██████▍   | 39254/61028 [07:58<03:40, 98.57it/s]\u001b[A\n",
      " 64%|██████▍   | 39264/61028 [07:58<03:43, 97.18it/s]\u001b[A\n",
      " 64%|██████▍   | 39274/61028 [07:58<03:46, 96.14it/s]\u001b[A\n",
      " 64%|██████▍   | 39285/61028 [07:58<03:41, 98.07it/s]\u001b[A\n",
      " 64%|██████▍   | 39295/61028 [07:58<03:44, 96.97it/s]\u001b[A\n",
      " 64%|██████▍   | 39305/61028 [07:59<03:54, 92.55it/s]\u001b[A\n",
      " 64%|██████▍   | 39315/61028 [07:59<03:54, 92.49it/s]\u001b[A\n",
      " 64%|██████▍   | 39326/61028 [07:59<03:45, 96.41it/s]\u001b[A\n",
      " 64%|██████▍   | 39336/61028 [07:59<07:18, 49.51it/s]\u001b[A\n",
      " 64%|██████▍   | 39344/61028 [07:59<06:36, 54.74it/s]\u001b[A\n",
      " 64%|██████▍   | 39354/61028 [07:59<05:46, 62.55it/s]\u001b[A\n",
      " 64%|██████▍   | 39363/61028 [08:00<05:22, 67.14it/s]\u001b[A\n",
      " 65%|██████▍   | 39372/61028 [08:00<05:03, 71.27it/s]\u001b[A\n",
      " 65%|██████▍   | 39384/61028 [08:00<04:30, 80.14it/s]\u001b[A\n",
      " 65%|██████▍   | 39395/61028 [08:00<04:09, 86.61it/s]\u001b[A\n",
      " 65%|██████▍   | 39407/61028 [08:00<03:51, 93.22it/s]\u001b[A\n",
      " 65%|██████▍   | 39418/61028 [08:00<03:42, 97.14it/s]\u001b[A\n",
      " 65%|██████▍   | 39429/61028 [08:00<03:47, 95.12it/s]\u001b[A\n",
      " 65%|██████▍   | 39439/61028 [08:00<03:49, 94.11it/s]\u001b[A\n",
      " 65%|██████▍   | 39450/61028 [08:00<03:42, 97.11it/s]\u001b[A\n",
      " 65%|██████▍   | 39460/61028 [08:01<03:45, 95.50it/s]\u001b[A\n",
      " 65%|██████▍   | 39472/61028 [08:01<03:32, 101.66it/s]\u001b[A\n",
      " 65%|██████▍   | 39483/61028 [08:01<03:31, 101.69it/s]\u001b[A\n",
      " 65%|██████▍   | 39496/61028 [08:01<03:20, 107.20it/s]\u001b[A\n",
      " 65%|██████▍   | 39508/61028 [08:01<03:17, 108.96it/s]\u001b[A\n",
      " 65%|██████▍   | 39520/61028 [08:01<03:26, 103.98it/s]\u001b[A\n",
      " 65%|██████▍   | 39531/61028 [08:01<03:39, 97.98it/s] \u001b[A\n",
      " 65%|██████▍   | 39542/61028 [08:01<03:39, 97.98it/s]\u001b[A\n",
      " 65%|██████▍   | 39552/61028 [08:01<03:38, 98.38it/s]\u001b[A\n",
      " 65%|██████▍   | 39562/61028 [08:02<03:39, 97.70it/s]\u001b[A\n",
      " 65%|██████▍   | 39572/61028 [08:02<03:40, 97.18it/s]\u001b[A\n",
      " 65%|██████▍   | 39583/61028 [08:02<03:34, 100.14it/s]\u001b[A\n",
      " 65%|██████▍   | 39594/61028 [08:02<03:34, 99.72it/s] \u001b[A\n",
      " 65%|██████▍   | 39605/61028 [08:02<03:37, 98.42it/s]\u001b[A\n",
      " 65%|██████▍   | 39615/61028 [08:02<03:40, 97.00it/s]\u001b[A\n",
      " 65%|██████▍   | 39625/61028 [08:02<03:43, 95.66it/s]\u001b[A\n",
      " 65%|██████▍   | 39636/61028 [08:02<03:36, 98.95it/s]\u001b[A\n",
      " 65%|██████▍   | 39646/61028 [08:02<03:36, 98.92it/s]\u001b[A\n",
      " 65%|██████▍   | 39656/61028 [08:02<03:48, 93.34it/s]\u001b[A\n",
      " 65%|██████▍   | 39666/61028 [08:03<03:47, 93.99it/s]\u001b[A\n",
      " 65%|██████▌   | 39676/61028 [08:03<03:45, 94.52it/s]\u001b[A\n",
      " 65%|██████▌   | 39686/61028 [08:03<03:45, 94.56it/s]\u001b[A\n",
      " 65%|██████▌   | 39696/61028 [08:03<03:42, 95.79it/s]\u001b[A\n",
      " 65%|██████▌   | 39707/61028 [08:03<03:35, 99.01it/s]\u001b[A\n",
      " 65%|██████▌   | 39717/61028 [08:03<03:36, 98.51it/s]\u001b[A\n",
      " 65%|██████▌   | 39727/61028 [08:03<03:45, 94.28it/s]\u001b[A\n",
      " 65%|██████▌   | 39737/61028 [08:03<03:44, 94.95it/s]\u001b[A\n",
      " 65%|██████▌   | 39747/61028 [08:03<03:44, 94.86it/s]\u001b[A\n",
      " 65%|██████▌   | 39757/61028 [08:04<03:45, 94.44it/s]\u001b[A\n",
      " 65%|██████▌   | 39767/61028 [08:04<03:54, 90.69it/s]\u001b[A\n",
      " 65%|██████▌   | 39780/61028 [08:04<03:38, 97.19it/s]\u001b[A\n",
      " 65%|██████▌   | 39790/61028 [08:04<03:44, 94.62it/s]\u001b[A\n",
      " 65%|██████▌   | 39800/61028 [08:04<06:34, 53.80it/s]\u001b[A\n",
      " 65%|██████▌   | 39811/61028 [08:04<05:42, 61.99it/s]\u001b[A\n",
      " 65%|██████▌   | 39824/61028 [08:04<04:54, 71.98it/s]\u001b[A\n",
      " 65%|██████▌   | 39834/61028 [08:05<04:46, 74.04it/s]\u001b[A\n",
      " 65%|██████▌   | 39843/61028 [08:05<04:34, 77.26it/s]\u001b[A\n",
      " 65%|██████▌   | 39854/61028 [08:05<04:13, 83.68it/s]\u001b[A\n",
      " 65%|██████▌   | 39865/61028 [08:05<04:01, 87.47it/s]\u001b[A\n",
      " 65%|██████▌   | 39875/61028 [08:05<04:01, 87.50it/s]\u001b[A\n",
      " 65%|██████▌   | 39885/61028 [08:05<03:53, 90.36it/s]\u001b[A\n",
      " 65%|██████▌   | 39896/61028 [08:05<03:42, 95.08it/s]\u001b[A\n",
      " 65%|██████▌   | 39906/61028 [08:05<03:59, 88.26it/s]\u001b[A\n",
      " 65%|██████▌   | 39916/61028 [08:05<04:02, 87.18it/s]\u001b[A\n",
      " 65%|██████▌   | 39925/61028 [08:06<04:02, 86.85it/s]\u001b[A\n",
      " 65%|██████▌   | 39934/61028 [08:06<04:07, 85.37it/s]\u001b[A\n",
      " 65%|██████▌   | 39944/61028 [08:06<03:59, 87.98it/s]\u001b[A\n",
      " 65%|██████▌   | 39957/61028 [08:06<03:38, 96.40it/s]\u001b[A\n",
      " 65%|██████▌   | 39967/61028 [08:06<03:41, 95.11it/s]\u001b[A\n",
      " 66%|██████▌   | 39978/61028 [08:06<03:36, 97.04it/s]\u001b[A\n",
      " 66%|██████▌   | 39989/61028 [08:06<03:29, 100.23it/s]\u001b[A\n",
      " 66%|██████▌   | 40000/61028 [08:06<03:35, 97.80it/s] \u001b[A\n",
      " 66%|██████▌   | 40010/61028 [08:06<03:34, 98.11it/s]\u001b[A\n",
      " 66%|██████▌   | 40022/61028 [08:07<03:22, 103.62it/s]\u001b[A\n",
      " 66%|██████▌   | 40033/61028 [08:07<03:35, 97.27it/s] \u001b[A\n",
      " 66%|██████▌   | 40045/61028 [08:07<03:29, 100.30it/s]\u001b[A\n",
      " 66%|██████▌   | 40056/61028 [08:07<03:23, 102.91it/s]\u001b[A\n",
      " 66%|██████▌   | 40067/61028 [08:07<03:27, 100.95it/s]\u001b[A\n",
      " 66%|██████▌   | 40078/61028 [08:07<03:29, 99.76it/s] \u001b[A\n",
      " 66%|██████▌   | 40092/61028 [08:07<03:13, 108.33it/s]\u001b[A\n",
      " 66%|██████▌   | 40104/61028 [08:07<03:21, 104.01it/s]\u001b[A\n",
      " 66%|██████▌   | 40115/61028 [08:07<03:17, 105.68it/s]\u001b[A\n",
      " 66%|██████▌   | 40127/61028 [08:08<03:13, 108.08it/s]\u001b[A\n",
      " 66%|██████▌   | 40138/61028 [08:08<03:13, 108.19it/s]\u001b[A\n",
      " 66%|██████▌   | 40150/61028 [08:08<03:13, 108.15it/s]\u001b[A\n",
      " 66%|██████▌   | 40161/61028 [08:08<03:19, 104.42it/s]\u001b[A\n",
      " 66%|██████▌   | 40172/61028 [08:08<03:18, 105.21it/s]\u001b[A\n",
      " 66%|██████▌   | 40183/61028 [08:08<03:18, 105.01it/s]\u001b[A\n",
      " 66%|██████▌   | 40194/61028 [08:08<03:32, 98.13it/s] \u001b[A\n",
      " 66%|██████▌   | 40205/61028 [08:08<03:25, 101.24it/s]\u001b[A\n",
      " 66%|██████▌   | 40216/61028 [08:08<03:27, 100.42it/s]\u001b[A\n",
      " 66%|██████▌   | 40227/61028 [08:09<03:32, 97.89it/s] \u001b[A\n",
      " 66%|██████▌   | 40238/61028 [08:09<03:25, 101.00it/s]\u001b[A\n",
      " 66%|██████▌   | 40249/61028 [08:09<03:26, 100.82it/s]\u001b[A\n",
      " 66%|██████▌   | 40262/61028 [08:09<03:16, 105.88it/s]\u001b[A\n",
      " 66%|██████▌   | 40273/61028 [08:09<03:21, 103.09it/s]\u001b[A\n",
      " 66%|██████▌   | 40284/61028 [08:09<06:03, 57.10it/s] \u001b[A\n",
      " 66%|██████▌   | 40293/61028 [08:10<05:50, 59.12it/s]\u001b[A\n",
      " 66%|██████▌   | 40303/61028 [08:10<05:14, 65.92it/s]\u001b[A\n",
      " 66%|██████▌   | 40314/61028 [08:10<04:37, 74.61it/s]\u001b[A\n",
      " 66%|██████▌   | 40324/61028 [08:10<04:19, 79.80it/s]\u001b[A\n",
      " 66%|██████▌   | 40336/61028 [08:10<03:56, 87.61it/s]\u001b[A\n",
      " 66%|██████▌   | 40347/61028 [08:10<03:41, 93.19it/s]\u001b[A\n",
      " 66%|██████▌   | 40358/61028 [08:10<03:33, 96.84it/s]\u001b[A\n",
      " 66%|██████▌   | 40369/61028 [08:10<03:33, 96.74it/s]\u001b[A\n",
      " 66%|██████▌   | 40380/61028 [08:10<03:36, 95.54it/s]\u001b[A\n",
      " 66%|██████▌   | 40390/61028 [08:10<03:35, 95.60it/s]\u001b[A\n",
      " 66%|██████▌   | 40400/61028 [08:11<03:41, 93.02it/s]\u001b[A\n",
      " 66%|██████▌   | 40410/61028 [08:11<03:47, 90.53it/s]\u001b[A\n",
      " 66%|██████▌   | 40420/61028 [08:11<03:43, 92.02it/s]\u001b[A\n",
      " 66%|██████▌   | 40430/61028 [08:11<03:41, 93.13it/s]\u001b[A\n",
      " 66%|██████▋   | 40440/61028 [08:11<03:36, 95.07it/s]\u001b[A\n",
      " 66%|██████▋   | 40450/61028 [08:11<03:37, 94.44it/s]\u001b[A\n",
      " 66%|██████▋   | 40461/61028 [08:11<03:29, 98.22it/s]\u001b[A\n",
      " 66%|██████▋   | 40472/61028 [08:11<03:35, 95.59it/s]\u001b[A\n",
      " 66%|██████▋   | 40483/61028 [08:11<03:26, 99.50it/s]\u001b[A\n",
      " 66%|██████▋   | 40494/61028 [08:12<03:21, 101.68it/s]\u001b[A\n",
      " 66%|██████▋   | 40505/61028 [08:12<03:23, 100.69it/s]\u001b[A\n",
      " 66%|██████▋   | 40516/61028 [08:12<03:18, 103.10it/s]\u001b[A\n",
      " 66%|██████▋   | 40527/61028 [08:12<03:22, 101.24it/s]\u001b[A\n",
      " 66%|██████▋   | 40538/61028 [08:12<03:26, 99.03it/s] \u001b[A\n",
      " 66%|██████▋   | 40550/61028 [08:12<03:16, 104.30it/s]\u001b[A\n",
      " 66%|██████▋   | 40562/61028 [08:12<03:08, 108.35it/s]\u001b[A\n",
      " 66%|██████▋   | 40573/61028 [08:12<03:15, 104.80it/s]\u001b[A\n",
      " 67%|██████▋   | 40584/61028 [08:12<03:12, 105.96it/s]\u001b[A\n",
      " 67%|██████▋   | 40595/61028 [08:13<03:12, 106.18it/s]\u001b[A\n",
      " 67%|██████▋   | 40607/61028 [08:13<03:09, 107.87it/s]\u001b[A\n",
      " 67%|██████▋   | 40618/61028 [08:13<03:09, 107.79it/s]\u001b[A\n",
      " 67%|██████▋   | 40629/61028 [08:13<03:11, 106.37it/s]\u001b[A\n",
      " 67%|██████▋   | 40640/61028 [08:13<03:18, 102.60it/s]\u001b[A\n",
      " 67%|██████▋   | 40651/61028 [08:13<03:21, 101.09it/s]\u001b[A\n",
      " 67%|██████▋   | 40662/61028 [08:13<03:17, 103.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 40673/61028 [08:13<03:20, 101.75it/s]\u001b[A\n",
      " 67%|██████▋   | 40684/61028 [08:13<03:31, 96.34it/s] \u001b[A\n",
      " 67%|██████▋   | 40694/61028 [08:14<03:50, 88.28it/s]\u001b[A\n",
      " 67%|██████▋   | 40705/61028 [08:14<03:37, 93.51it/s]\u001b[A\n",
      " 67%|██████▋   | 40715/61028 [08:14<03:33, 95.01it/s]\u001b[A\n",
      " 67%|██████▋   | 40727/61028 [08:14<03:22, 100.02it/s]\u001b[A\n",
      " 67%|██████▋   | 40739/61028 [08:14<03:16, 103.09it/s]\u001b[A\n",
      " 67%|██████▋   | 40750/61028 [08:14<03:26, 98.08it/s] \u001b[A\n",
      " 67%|██████▋   | 40760/61028 [08:14<06:00, 56.19it/s]\u001b[A\n",
      " 67%|██████▋   | 40768/61028 [08:15<06:04, 55.57it/s]\u001b[A\n",
      " 67%|██████▋   | 40780/61028 [08:15<05:10, 65.13it/s]\u001b[A\n",
      " 67%|██████▋   | 40791/61028 [08:15<04:34, 73.64it/s]\u001b[A\n",
      " 67%|██████▋   | 40801/61028 [08:15<04:15, 79.10it/s]\u001b[A\n",
      " 67%|██████▋   | 40812/61028 [08:15<03:55, 85.77it/s]\u001b[A\n",
      " 67%|██████▋   | 40822/61028 [08:15<03:53, 86.69it/s]\u001b[A\n",
      " 67%|██████▋   | 40835/61028 [08:15<03:31, 95.58it/s]\u001b[A\n",
      " 67%|██████▋   | 40847/61028 [08:15<03:22, 99.62it/s]\u001b[A\n",
      " 67%|██████▋   | 40858/61028 [08:15<03:37, 92.76it/s]\u001b[A\n",
      " 67%|██████▋   | 40869/61028 [08:16<03:33, 94.39it/s]\u001b[A\n",
      " 67%|██████▋   | 40879/61028 [08:16<03:43, 90.02it/s]\u001b[A\n",
      " 67%|██████▋   | 40889/61028 [08:16<03:43, 90.10it/s]\u001b[A\n",
      " 67%|██████▋   | 40899/61028 [08:16<03:37, 92.46it/s]\u001b[A\n",
      " 67%|██████▋   | 40910/61028 [08:16<03:29, 96.14it/s]\u001b[A\n",
      " 67%|██████▋   | 40920/61028 [08:16<03:32, 94.58it/s]\u001b[A\n",
      " 67%|██████▋   | 40931/61028 [08:16<03:24, 98.21it/s]\u001b[A\n",
      " 67%|██████▋   | 40942/61028 [08:16<03:22, 99.26it/s]\u001b[A\n",
      " 67%|██████▋   | 40953/61028 [08:16<03:31, 94.82it/s]\u001b[A\n",
      " 67%|██████▋   | 40963/61028 [08:17<03:40, 90.96it/s]\u001b[A\n",
      " 67%|██████▋   | 40973/61028 [08:17<03:38, 91.58it/s]\u001b[A\n",
      " 67%|██████▋   | 40984/61028 [08:17<03:33, 93.71it/s]\u001b[A\n",
      " 67%|██████▋   | 40994/61028 [08:17<03:41, 90.45it/s]\u001b[A\n",
      " 67%|██████▋   | 41004/61028 [08:17<03:40, 91.00it/s]\u001b[A\n",
      " 67%|██████▋   | 41016/61028 [08:17<03:28, 95.86it/s]\u001b[A\n",
      " 67%|██████▋   | 41026/61028 [08:17<03:29, 95.55it/s]\u001b[A\n",
      " 67%|██████▋   | 41036/61028 [08:17<03:30, 95.00it/s]\u001b[A\n",
      " 67%|██████▋   | 41046/61028 [08:17<03:33, 93.66it/s]\u001b[A\n",
      " 67%|██████▋   | 41056/61028 [08:18<03:30, 94.71it/s]\u001b[A\n",
      " 67%|██████▋   | 41066/61028 [08:18<03:37, 91.72it/s]\u001b[A\n",
      " 67%|██████▋   | 41076/61028 [08:18<03:34, 92.94it/s]\u001b[A\n",
      " 67%|██████▋   | 41086/61028 [08:18<03:35, 92.64it/s]\u001b[A\n",
      " 67%|██████▋   | 41096/61028 [08:18<03:30, 94.56it/s]\u001b[A\n",
      " 67%|██████▋   | 41106/61028 [08:18<03:27, 96.02it/s]\u001b[A\n",
      " 67%|██████▋   | 41116/61028 [08:18<03:32, 93.58it/s]\u001b[A\n",
      " 67%|██████▋   | 41128/61028 [08:18<03:21, 98.92it/s]\u001b[A\n",
      " 67%|██████▋   | 41138/61028 [08:18<03:23, 97.63it/s]\u001b[A\n",
      " 67%|██████▋   | 41148/61028 [08:19<03:29, 94.86it/s]\u001b[A\n",
      " 67%|██████▋   | 41160/61028 [08:19<03:16, 101.16it/s]\u001b[A\n",
      " 67%|██████▋   | 41171/61028 [08:19<03:17, 100.54it/s]\u001b[A\n",
      " 67%|██████▋   | 41183/61028 [08:19<03:11, 103.83it/s]\u001b[A\n",
      " 68%|██████▊   | 41194/61028 [08:19<03:13, 102.41it/s]\u001b[A\n",
      " 68%|██████▊   | 41205/61028 [08:19<03:18, 99.73it/s] \u001b[A\n",
      " 68%|██████▊   | 41216/61028 [08:19<03:18, 99.63it/s]\u001b[A\n",
      " 68%|██████▊   | 41227/61028 [08:19<04:01, 82.07it/s]\u001b[A\n",
      " 68%|██████▊   | 41236/61028 [08:20<07:47, 42.30it/s]\u001b[A\n",
      " 68%|██████▊   | 41247/61028 [08:20<06:25, 51.37it/s]\u001b[A\n",
      " 68%|██████▊   | 41258/61028 [08:20<05:24, 60.89it/s]\u001b[A\n",
      " 68%|██████▊   | 41268/61028 [08:20<04:48, 68.59it/s]\u001b[A\n",
      " 68%|██████▊   | 41279/61028 [08:20<04:19, 76.12it/s]\u001b[A\n",
      " 68%|██████▊   | 41289/61028 [08:20<04:10, 78.93it/s]\u001b[A\n",
      " 68%|██████▊   | 41299/61028 [08:21<04:14, 77.55it/s]\u001b[A\n",
      " 68%|██████▊   | 41309/61028 [08:21<04:00, 82.05it/s]\u001b[A\n",
      " 68%|██████▊   | 41318/61028 [08:21<03:55, 83.66it/s]\u001b[A\n",
      " 68%|██████▊   | 41330/61028 [08:21<03:40, 89.24it/s]\u001b[A\n",
      " 68%|██████▊   | 41340/61028 [08:21<03:39, 89.60it/s]\u001b[A\n",
      " 68%|██████▊   | 41350/61028 [08:21<03:34, 91.69it/s]\u001b[A\n",
      " 68%|██████▊   | 41360/61028 [08:21<03:29, 93.78it/s]\u001b[A\n",
      " 68%|██████▊   | 41371/61028 [08:21<03:26, 95.31it/s]\u001b[A\n",
      " 68%|██████▊   | 41381/61028 [08:21<03:34, 91.66it/s]\u001b[A\n",
      " 68%|██████▊   | 41391/61028 [08:21<03:33, 92.14it/s]\u001b[A\n",
      " 68%|██████▊   | 41401/61028 [08:22<03:30, 93.35it/s]\u001b[A\n",
      " 68%|██████▊   | 41411/61028 [08:22<03:34, 91.51it/s]\u001b[A\n",
      " 68%|██████▊   | 41422/61028 [08:22<03:28, 94.02it/s]\u001b[A\n",
      " 68%|██████▊   | 41434/61028 [08:22<03:15, 100.01it/s]\u001b[A\n",
      " 68%|██████▊   | 41445/61028 [08:22<03:18, 98.82it/s] \u001b[A\n",
      " 68%|██████▊   | 41455/61028 [08:22<03:26, 94.93it/s]\u001b[A\n",
      " 68%|██████▊   | 41465/61028 [08:22<03:35, 90.94it/s]\u001b[A\n",
      " 68%|██████▊   | 41475/61028 [08:22<03:34, 91.27it/s]\u001b[A\n",
      " 68%|██████▊   | 41485/61028 [08:22<03:35, 90.48it/s]\u001b[A\n",
      " 68%|██████▊   | 41496/61028 [08:23<03:27, 94.27it/s]\u001b[A\n",
      " 68%|██████▊   | 41507/61028 [08:23<03:20, 97.56it/s]\u001b[A\n",
      " 68%|██████▊   | 41517/61028 [08:23<03:22, 96.19it/s]\u001b[A\n",
      " 68%|██████▊   | 41528/61028 [08:23<03:19, 97.94it/s]\u001b[A\n",
      " 68%|██████▊   | 41538/61028 [08:23<03:29, 92.96it/s]\u001b[A\n",
      " 68%|██████▊   | 41548/61028 [08:23<03:25, 94.85it/s]\u001b[A\n",
      " 68%|██████▊   | 41559/61028 [08:23<03:21, 96.54it/s]\u001b[A\n",
      " 68%|██████▊   | 41569/61028 [08:23<03:24, 95.11it/s]\u001b[A\n",
      " 68%|██████▊   | 41579/61028 [08:23<03:28, 93.49it/s]\u001b[A\n",
      " 68%|██████▊   | 41589/61028 [08:24<03:27, 93.64it/s]\u001b[A\n",
      " 68%|██████▊   | 41599/61028 [08:24<03:27, 93.43it/s]\u001b[A\n",
      " 68%|██████▊   | 41611/61028 [08:24<03:16, 98.75it/s]\u001b[A\n",
      " 68%|██████▊   | 41621/61028 [08:24<03:19, 97.41it/s]\u001b[A\n",
      " 68%|██████▊   | 41632/61028 [08:24<03:15, 99.07it/s]\u001b[A\n",
      " 68%|██████▊   | 41644/61028 [08:24<03:07, 103.20it/s]\u001b[A\n",
      " 68%|██████▊   | 41655/61028 [08:24<03:16, 98.71it/s] \u001b[A\n",
      " 68%|██████▊   | 41665/61028 [08:24<03:21, 96.07it/s]\u001b[A\n",
      " 68%|██████▊   | 41676/61028 [08:24<03:14, 99.54it/s]\u001b[A\n",
      " 68%|██████▊   | 41687/61028 [08:25<05:37, 57.31it/s]\u001b[A\n",
      " 68%|██████▊   | 41698/61028 [08:25<04:50, 66.52it/s]\u001b[A\n",
      " 68%|██████▊   | 41708/61028 [08:25<04:26, 72.55it/s]\u001b[A\n",
      " 68%|██████▊   | 41718/61028 [08:25<04:07, 78.05it/s]\u001b[A\n",
      " 68%|██████▊   | 41728/61028 [08:25<03:54, 82.16it/s]\u001b[A\n",
      " 68%|██████▊   | 41738/61028 [08:25<03:44, 85.88it/s]\u001b[A\n",
      " 68%|██████▊   | 41748/61028 [08:25<03:48, 84.30it/s]\u001b[A\n",
      " 68%|██████▊   | 41757/61028 [08:26<04:02, 79.40it/s]\u001b[A\n",
      " 68%|██████▊   | 41766/61028 [08:26<03:55, 81.90it/s]\u001b[A\n",
      " 68%|██████▊   | 41777/61028 [08:26<03:41, 86.91it/s]\u001b[A\n",
      " 68%|██████▊   | 41788/61028 [08:26<03:27, 92.71it/s]\u001b[A\n",
      " 68%|██████▊   | 41799/61028 [08:26<03:17, 97.26it/s]\u001b[A\n",
      " 69%|██████▊   | 41810/61028 [08:26<03:13, 99.29it/s]\u001b[A\n",
      " 69%|██████▊   | 41821/61028 [08:26<03:09, 101.15it/s]\u001b[A\n",
      " 69%|██████▊   | 41833/61028 [08:26<03:05, 103.49it/s]\u001b[A\n",
      " 69%|██████▊   | 41844/61028 [08:26<03:11, 100.34it/s]\u001b[A\n",
      " 69%|██████▊   | 41855/61028 [08:27<03:06, 103.02it/s]\u001b[A\n",
      " 69%|██████▊   | 41866/61028 [08:27<03:08, 101.56it/s]\u001b[A\n",
      " 69%|██████▊   | 41877/61028 [08:27<03:07, 101.95it/s]\u001b[A\n",
      " 69%|██████▊   | 41888/61028 [08:27<03:07, 101.91it/s]\u001b[A\n",
      " 69%|██████▊   | 41899/61028 [08:27<03:14, 98.18it/s] \u001b[A\n",
      " 69%|██████▊   | 41909/61028 [08:27<03:20, 95.42it/s]\u001b[A\n",
      " 69%|██████▊   | 41919/61028 [08:27<03:26, 92.39it/s]\u001b[A\n",
      " 69%|██████▊   | 41931/61028 [08:27<03:18, 96.24it/s]\u001b[A\n",
      " 69%|██████▊   | 41941/61028 [08:27<03:16, 97.00it/s]\u001b[A\n",
      " 69%|██████▊   | 41952/61028 [08:28<03:13, 98.74it/s]\u001b[A\n",
      " 69%|██████▉   | 41962/61028 [08:28<03:12, 99.02it/s]\u001b[A\n",
      " 69%|██████▉   | 41972/61028 [08:28<03:22, 94.25it/s]\u001b[A\n",
      " 69%|██████▉   | 41983/61028 [08:28<03:15, 97.67it/s]\u001b[A\n",
      " 69%|██████▉   | 41995/61028 [08:28<03:05, 102.67it/s]\u001b[A\n",
      " 69%|██████▉   | 42007/61028 [08:28<02:57, 107.17it/s]\u001b[A\n",
      " 69%|██████▉   | 42018/61028 [08:28<02:58, 106.65it/s]\u001b[A\n",
      " 69%|██████▉   | 42029/61028 [08:28<03:08, 100.77it/s]\u001b[A\n",
      " 69%|██████▉   | 42040/61028 [08:28<03:09, 99.99it/s] \u001b[A\n",
      " 69%|██████▉   | 42051/61028 [08:29<03:13, 97.86it/s]\u001b[A\n",
      " 69%|██████▉   | 42062/61028 [08:29<03:09, 100.18it/s]\u001b[A\n",
      " 69%|██████▉   | 42074/61028 [08:29<03:01, 104.52it/s]\u001b[A\n",
      " 69%|██████▉   | 42085/61028 [08:29<03:02, 104.07it/s]\u001b[A\n",
      " 69%|██████▉   | 42097/61028 [08:29<02:57, 106.67it/s]\u001b[A\n",
      " 69%|██████▉   | 42108/61028 [08:29<03:00, 104.55it/s]\u001b[A\n",
      " 69%|██████▉   | 42121/61028 [08:29<02:52, 109.87it/s]\u001b[A\n",
      " 69%|██████▉   | 42133/61028 [08:29<02:54, 108.44it/s]\u001b[A\n",
      " 69%|██████▉   | 42144/61028 [08:29<02:53, 108.63it/s]\u001b[A\n",
      " 69%|██████▉   | 42155/61028 [08:29<02:59, 105.07it/s]\u001b[A\n",
      " 69%|██████▉   | 42166/61028 [08:30<05:37, 55.82it/s] \u001b[A\n",
      " 69%|██████▉   | 42179/61028 [08:30<04:45, 65.98it/s]\u001b[A\n",
      " 69%|██████▉   | 42192/61028 [08:30<04:06, 76.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 42203/61028 [08:30<03:47, 82.75it/s]\u001b[A\n",
      " 69%|██████▉   | 42214/61028 [08:30<03:48, 82.29it/s]\u001b[A\n",
      " 69%|██████▉   | 42225/61028 [08:30<03:37, 86.34it/s]\u001b[A\n",
      " 69%|██████▉   | 42235/61028 [08:31<03:36, 86.82it/s]\u001b[A\n",
      " 69%|██████▉   | 42245/61028 [08:31<03:28, 90.26it/s]\u001b[A\n",
      " 69%|██████▉   | 42256/61028 [08:31<03:17, 94.94it/s]\u001b[A\n",
      " 69%|██████▉   | 42266/61028 [08:31<03:14, 96.30it/s]\u001b[A\n",
      " 69%|██████▉   | 42278/61028 [08:31<03:04, 101.61it/s]\u001b[A\n",
      " 69%|██████▉   | 42289/61028 [08:31<03:16, 95.61it/s] \u001b[A\n",
      " 69%|██████▉   | 42299/61028 [08:31<03:18, 94.15it/s]\u001b[A\n",
      " 69%|██████▉   | 42311/61028 [08:31<03:10, 98.06it/s]\u001b[A\n",
      " 69%|██████▉   | 42321/61028 [08:32<05:05, 61.33it/s]\u001b[A\n",
      " 69%|██████▉   | 42331/61028 [08:32<04:31, 68.82it/s]\u001b[A\n",
      " 69%|██████▉   | 42341/61028 [08:32<04:06, 75.67it/s]\u001b[A\n",
      " 69%|██████▉   | 42354/61028 [08:32<03:36, 86.44it/s]\u001b[A\n",
      " 69%|██████▉   | 42365/61028 [08:32<03:31, 88.15it/s]\u001b[A\n",
      " 69%|██████▉   | 42376/61028 [08:32<03:24, 91.10it/s]\u001b[A\n",
      " 69%|██████▉   | 42388/61028 [08:32<03:11, 97.29it/s]\u001b[A\n",
      " 69%|██████▉   | 42399/61028 [08:32<03:15, 95.25it/s]\u001b[A\n",
      " 69%|██████▉   | 42409/61028 [08:32<03:13, 96.12it/s]\u001b[A\n",
      " 70%|██████▉   | 42420/61028 [08:33<03:10, 97.92it/s]\u001b[A\n",
      " 70%|██████▉   | 42431/61028 [08:33<03:16, 94.83it/s]\u001b[A\n",
      " 70%|██████▉   | 42443/61028 [08:33<03:10, 97.73it/s]\u001b[A\n",
      " 70%|██████▉   | 42453/61028 [08:33<03:09, 98.01it/s]\u001b[A\n",
      " 70%|██████▉   | 42463/61028 [08:33<03:10, 97.34it/s]\u001b[A\n",
      " 70%|██████▉   | 42474/61028 [08:33<03:07, 99.18it/s]\u001b[A\n",
      " 70%|██████▉   | 42487/61028 [08:33<02:56, 105.05it/s]\u001b[A\n",
      " 70%|██████▉   | 42498/61028 [08:33<02:55, 105.55it/s]\u001b[A\n",
      " 70%|██████▉   | 42509/61028 [08:33<03:00, 102.49it/s]\u001b[A\n",
      " 70%|██████▉   | 42520/61028 [08:34<03:08, 98.21it/s] \u001b[A\n",
      " 70%|██████▉   | 42531/61028 [08:34<03:02, 101.24it/s]\u001b[A\n",
      " 70%|██████▉   | 42542/61028 [08:34<03:05, 99.60it/s] \u001b[A\n",
      " 70%|██████▉   | 42553/61028 [08:34<03:09, 97.43it/s]\u001b[A\n",
      " 70%|██████▉   | 42564/61028 [08:34<03:03, 100.66it/s]\u001b[A\n",
      " 70%|██████▉   | 42575/61028 [08:34<03:05, 99.51it/s] \u001b[A\n",
      " 70%|██████▉   | 42586/61028 [08:34<03:01, 101.46it/s]\u001b[A\n",
      " 70%|██████▉   | 42597/61028 [08:34<03:08, 97.87it/s] \u001b[A\n",
      " 70%|██████▉   | 42607/61028 [08:34<03:12, 95.57it/s]\u001b[A\n",
      " 70%|██████▉   | 42617/61028 [08:35<03:13, 95.27it/s]\u001b[A\n",
      " 70%|██████▉   | 42627/61028 [08:35<06:14, 49.18it/s]\u001b[A\n",
      " 70%|██████▉   | 42637/61028 [08:35<05:21, 57.13it/s]\u001b[A\n",
      " 70%|██████▉   | 42647/61028 [08:35<04:41, 65.36it/s]\u001b[A\n",
      " 70%|██████▉   | 42658/61028 [08:35<04:10, 73.35it/s]\u001b[A\n",
      " 70%|██████▉   | 42668/61028 [08:35<03:58, 76.88it/s]\u001b[A\n",
      " 70%|██████▉   | 42677/61028 [08:36<04:37, 66.18it/s]\u001b[A\n",
      " 70%|██████▉   | 42685/61028 [08:36<04:27, 68.60it/s]\u001b[A\n",
      " 70%|██████▉   | 42695/61028 [08:36<04:04, 74.97it/s]\u001b[A\n",
      " 70%|██████▉   | 42706/61028 [08:36<03:44, 81.49it/s]\u001b[A\n",
      " 70%|██████▉   | 42716/61028 [08:36<03:37, 84.11it/s]\u001b[A\n",
      " 70%|███████   | 42726/61028 [08:36<03:32, 86.03it/s]\u001b[A\n",
      " 70%|███████   | 42735/61028 [08:36<03:33, 85.85it/s]\u001b[A\n",
      " 70%|███████   | 42746/61028 [08:36<03:24, 89.40it/s]\u001b[A\n",
      " 70%|███████   | 42756/61028 [08:37<03:23, 89.58it/s]\u001b[A\n",
      " 70%|███████   | 42766/61028 [08:37<03:19, 91.34it/s]\u001b[A\n",
      " 70%|███████   | 42776/61028 [08:37<03:16, 92.83it/s]\u001b[A\n",
      " 70%|███████   | 42786/61028 [08:37<03:17, 92.56it/s]\u001b[A\n",
      " 70%|███████   | 42796/61028 [08:37<03:15, 93.17it/s]\u001b[A\n",
      " 70%|███████   | 42806/61028 [08:37<03:12, 94.72it/s]\u001b[A\n",
      " 70%|███████   | 42816/61028 [08:37<03:11, 94.88it/s]\u001b[A\n",
      " 70%|███████   | 42827/61028 [08:37<03:06, 97.47it/s]\u001b[A\n",
      " 70%|███████   | 42838/61028 [08:37<03:03, 99.23it/s]\u001b[A\n",
      " 70%|███████   | 42849/61028 [08:37<03:01, 100.04it/s]\u001b[A\n",
      " 70%|███████   | 42860/61028 [08:38<02:59, 100.98it/s]\u001b[A\n",
      " 70%|███████   | 42871/61028 [08:38<02:58, 101.69it/s]\u001b[A\n",
      " 70%|███████   | 42882/61028 [08:38<03:02, 99.23it/s] \u001b[A\n",
      " 70%|███████   | 42892/61028 [08:38<03:03, 98.70it/s]\u001b[A\n",
      " 70%|███████   | 42902/61028 [08:38<03:09, 95.53it/s]\u001b[A\n",
      " 70%|███████   | 42912/61028 [08:38<03:08, 96.10it/s]\u001b[A\n",
      " 70%|███████   | 42922/61028 [08:38<03:10, 95.12it/s]\u001b[A\n",
      " 70%|███████   | 42933/61028 [08:38<03:04, 97.91it/s]\u001b[A\n",
      " 70%|███████   | 42944/61028 [08:38<03:02, 98.92it/s]\u001b[A\n",
      " 70%|███████   | 42954/61028 [08:39<03:04, 98.21it/s]\u001b[A\n",
      " 70%|███████   | 42965/61028 [08:39<02:58, 101.06it/s]\u001b[A\n",
      " 70%|███████   | 42976/61028 [08:39<02:58, 101.06it/s]\u001b[A\n",
      " 70%|███████   | 42987/61028 [08:39<02:55, 102.53it/s]\u001b[A\n",
      " 70%|███████   | 42998/61028 [08:39<02:57, 101.51it/s]\u001b[A\n",
      " 70%|███████   | 43009/61028 [08:39<02:54, 102.98it/s]\u001b[A\n",
      " 70%|███████   | 43020/61028 [08:39<03:00, 99.86it/s] \u001b[A\n",
      " 71%|███████   | 43031/61028 [08:39<03:01, 99.31it/s]\u001b[A\n",
      " 71%|███████   | 43042/61028 [08:39<02:59, 100.12it/s]\u001b[A\n",
      " 71%|███████   | 43054/61028 [08:40<02:54, 102.94it/s]\u001b[A\n",
      " 71%|███████   | 43065/61028 [08:40<02:58, 100.46it/s]\u001b[A\n",
      " 71%|███████   | 43076/61028 [08:40<03:07, 95.68it/s] \u001b[A\n",
      " 71%|███████   | 43086/61028 [08:40<05:23, 55.47it/s]\u001b[A\n",
      " 71%|███████   | 43097/61028 [08:40<04:39, 64.24it/s]\u001b[A\n",
      " 71%|███████   | 43107/61028 [08:40<04:12, 70.98it/s]\u001b[A\n",
      " 71%|███████   | 43118/61028 [08:40<03:50, 77.54it/s]\u001b[A\n",
      " 71%|███████   | 43128/61028 [08:41<03:50, 77.64it/s]\u001b[A\n",
      " 71%|███████   | 43137/61028 [08:41<03:56, 75.59it/s]\u001b[A\n",
      " 71%|███████   | 43147/61028 [08:41<03:44, 79.62it/s]\u001b[A\n",
      " 71%|███████   | 43158/61028 [08:41<03:26, 86.35it/s]\u001b[A\n",
      " 71%|███████   | 43168/61028 [08:41<03:24, 87.43it/s]\u001b[A\n",
      " 71%|███████   | 43178/61028 [08:41<03:23, 87.69it/s]\u001b[A\n",
      " 71%|███████   | 43189/61028 [08:41<03:13, 91.99it/s]\u001b[A\n",
      " 71%|███████   | 43199/61028 [08:41<03:11, 92.87it/s]\u001b[A\n",
      " 71%|███████   | 43210/61028 [08:41<03:06, 95.79it/s]\u001b[A\n",
      " 71%|███████   | 43221/61028 [08:42<03:01, 98.25it/s]\u001b[A\n",
      " 71%|███████   | 43231/61028 [08:42<03:10, 93.58it/s]\u001b[A\n",
      " 71%|███████   | 43243/61028 [08:42<02:58, 99.55it/s]\u001b[A\n",
      " 71%|███████   | 43255/61028 [08:42<02:53, 102.26it/s]\u001b[A\n",
      " 71%|███████   | 43267/61028 [08:42<02:49, 104.93it/s]\u001b[A\n",
      " 71%|███████   | 43278/61028 [08:42<02:49, 104.72it/s]\u001b[A\n",
      " 71%|███████   | 43289/61028 [08:42<02:51, 103.60it/s]\u001b[A\n",
      " 71%|███████   | 43300/61028 [08:42<02:58, 99.51it/s] \u001b[A\n",
      " 71%|███████   | 43311/61028 [08:42<03:05, 95.27it/s]\u001b[A\n",
      " 71%|███████   | 43321/61028 [08:43<03:05, 95.54it/s]\u001b[A\n",
      " 71%|███████   | 43333/61028 [08:43<02:55, 101.03it/s]\u001b[A\n",
      " 71%|███████   | 43346/61028 [08:43<02:44, 107.41it/s]\u001b[A\n",
      " 71%|███████   | 43357/61028 [08:43<02:45, 107.02it/s]\u001b[A\n",
      " 71%|███████   | 43368/61028 [08:43<02:45, 106.91it/s]\u001b[A\n",
      " 71%|███████   | 43379/61028 [08:43<02:46, 106.15it/s]\u001b[A\n",
      " 71%|███████   | 43390/61028 [08:43<02:48, 104.49it/s]\u001b[A\n",
      " 71%|███████   | 43401/61028 [08:43<02:54, 101.20it/s]\u001b[A\n",
      " 71%|███████   | 43412/61028 [08:43<02:56, 99.59it/s] \u001b[A\n",
      " 71%|███████   | 43423/61028 [08:44<02:56, 99.70it/s]\u001b[A\n",
      " 71%|███████   | 43434/61028 [08:44<03:05, 95.05it/s]\u001b[A\n",
      " 71%|███████   | 43445/61028 [08:44<02:58, 98.32it/s]\u001b[A\n",
      " 71%|███████   | 43456/61028 [08:44<02:57, 99.24it/s]\u001b[A\n",
      " 71%|███████   | 43466/61028 [08:44<03:01, 97.02it/s]\u001b[A\n",
      " 71%|███████   | 43477/61028 [08:44<02:57, 98.66it/s]\u001b[A\n",
      " 71%|███████▏  | 43487/61028 [08:44<02:57, 98.69it/s]\u001b[A\n",
      " 71%|███████▏  | 43497/61028 [08:44<03:09, 92.50it/s]\u001b[A\n",
      " 71%|███████▏  | 43507/61028 [08:44<03:11, 91.33it/s]\u001b[A\n",
      " 71%|███████▏  | 43517/61028 [08:45<03:12, 91.05it/s]\u001b[A\n",
      " 71%|███████▏  | 43527/61028 [08:45<03:15, 89.47it/s]\u001b[A\n",
      " 71%|███████▏  | 43537/61028 [08:45<03:10, 91.86it/s]\u001b[A\n",
      " 71%|███████▏  | 43547/61028 [08:45<03:14, 89.72it/s]\u001b[A\n",
      " 71%|███████▏  | 43557/61028 [08:45<05:41, 51.18it/s]\u001b[A\n",
      " 71%|███████▏  | 43567/61028 [08:45<04:54, 59.35it/s]\u001b[A\n",
      " 71%|███████▏  | 43578/61028 [08:45<04:14, 68.54it/s]\u001b[A\n",
      " 71%|███████▏  | 43587/61028 [08:46<04:02, 71.82it/s]\u001b[A\n",
      " 71%|███████▏  | 43596/61028 [08:46<03:54, 74.24it/s]\u001b[A\n",
      " 71%|███████▏  | 43605/61028 [08:46<03:45, 77.40it/s]\u001b[A\n",
      " 71%|███████▏  | 43616/61028 [08:46<03:26, 84.13it/s]\u001b[A\n",
      " 71%|███████▏  | 43627/61028 [08:46<03:15, 89.04it/s]\u001b[A\n",
      " 72%|███████▏  | 43638/61028 [08:46<03:05, 93.78it/s]\u001b[A\n",
      " 72%|███████▏  | 43649/61028 [08:46<02:58, 97.28it/s]\u001b[A\n",
      " 72%|███████▏  | 43660/61028 [08:46<02:58, 97.25it/s]\u001b[A\n",
      " 72%|███████▏  | 43670/61028 [08:46<03:00, 96.03it/s]\u001b[A\n",
      " 72%|███████▏  | 43682/61028 [08:47<02:51, 101.25it/s]\u001b[A\n",
      " 72%|███████▏  | 43695/61028 [08:47<02:40, 108.31it/s]\u001b[A\n",
      " 72%|███████▏  | 43707/61028 [08:47<02:53, 99.71it/s] \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 43719/61028 [08:47<02:45, 104.54it/s]\u001b[A\n",
      " 72%|███████▏  | 43730/61028 [08:47<02:55, 98.57it/s] \u001b[A\n",
      " 72%|███████▏  | 43741/61028 [08:47<02:54, 99.24it/s]\u001b[A\n",
      " 72%|███████▏  | 43752/61028 [08:47<02:54, 99.03it/s]\u001b[A\n",
      " 72%|███████▏  | 43763/61028 [08:47<02:54, 99.05it/s]\u001b[A\n",
      " 72%|███████▏  | 43773/61028 [08:47<02:54, 98.60it/s]\u001b[A\n",
      " 72%|███████▏  | 43783/61028 [08:48<03:12, 89.63it/s]\u001b[A\n",
      " 72%|███████▏  | 43793/61028 [08:48<03:10, 90.24it/s]\u001b[A\n",
      " 72%|███████▏  | 43803/61028 [08:48<03:06, 92.52it/s]\u001b[A\n",
      " 72%|███████▏  | 43814/61028 [08:48<02:59, 95.95it/s]\u001b[A\n",
      " 72%|███████▏  | 43824/61028 [08:48<03:00, 95.36it/s]\u001b[A\n",
      " 72%|███████▏  | 43834/61028 [08:48<03:04, 92.95it/s]\u001b[A\n",
      " 72%|███████▏  | 43844/61028 [08:48<03:06, 92.34it/s]\u001b[A\n",
      " 72%|███████▏  | 43856/61028 [08:48<03:03, 93.74it/s]\u001b[A\n",
      " 72%|███████▏  | 43866/61028 [08:48<03:05, 92.57it/s]\u001b[A\n",
      " 72%|███████▏  | 43876/61028 [08:49<03:04, 92.91it/s]\u001b[A\n",
      " 72%|███████▏  | 43887/61028 [08:49<02:56, 97.09it/s]\u001b[A\n",
      " 72%|███████▏  | 43898/61028 [08:49<02:52, 99.43it/s]\u001b[A\n",
      " 72%|███████▏  | 43909/61028 [08:49<02:55, 97.68it/s]\u001b[A\n",
      " 72%|███████▏  | 43919/61028 [08:49<03:04, 92.97it/s]\u001b[A\n",
      " 72%|███████▏  | 43929/61028 [08:49<03:09, 90.18it/s]\u001b[A\n",
      " 72%|███████▏  | 43941/61028 [08:49<02:59, 95.45it/s]\u001b[A\n",
      " 72%|███████▏  | 43952/61028 [08:49<02:54, 97.64it/s]\u001b[A\n",
      " 72%|███████▏  | 43964/61028 [08:49<02:47, 102.16it/s]\u001b[A\n",
      " 72%|███████▏  | 43975/61028 [08:50<02:50, 100.17it/s]\u001b[A\n",
      " 72%|███████▏  | 43988/61028 [08:50<02:42, 105.13it/s]\u001b[A\n",
      " 72%|███████▏  | 43999/61028 [08:50<02:42, 104.65it/s]\u001b[A\n",
      " 72%|███████▏  | 44010/61028 [08:50<02:50, 99.94it/s] \u001b[A\n",
      " 72%|███████▏  | 44021/61028 [08:50<02:49, 100.34it/s]\u001b[A\n",
      " 72%|███████▏  | 44032/61028 [08:50<05:32, 51.10it/s] \u001b[A\n",
      " 72%|███████▏  | 44040/61028 [08:51<05:02, 56.15it/s]\u001b[A\n",
      " 72%|███████▏  | 44048/61028 [08:51<04:43, 59.83it/s]\u001b[A\n",
      " 72%|███████▏  | 44058/61028 [08:51<04:11, 67.53it/s]\u001b[A\n",
      " 72%|███████▏  | 44067/61028 [08:51<04:03, 69.74it/s]\u001b[A\n",
      " 72%|███████▏  | 44079/61028 [08:51<03:36, 78.17it/s]\u001b[A\n",
      " 72%|███████▏  | 44088/61028 [08:51<03:29, 80.88it/s]\u001b[A\n",
      " 72%|███████▏  | 44100/61028 [08:51<03:11, 88.60it/s]\u001b[A\n",
      " 72%|███████▏  | 44110/61028 [08:51<03:07, 90.17it/s]\u001b[A\n",
      " 72%|███████▏  | 44121/61028 [08:51<02:58, 94.53it/s]\u001b[A\n",
      " 72%|███████▏  | 44131/61028 [08:52<03:03, 92.12it/s]\u001b[A\n",
      " 72%|███████▏  | 44143/61028 [08:52<02:51, 98.57it/s]\u001b[A\n",
      " 72%|███████▏  | 44154/61028 [08:52<02:54, 96.97it/s]\u001b[A\n",
      " 72%|███████▏  | 44164/61028 [08:52<02:59, 94.02it/s]\u001b[A\n",
      " 72%|███████▏  | 44174/61028 [08:52<02:59, 93.96it/s]\u001b[A\n",
      " 72%|███████▏  | 44184/61028 [08:52<03:03, 91.63it/s]\u001b[A\n",
      " 72%|███████▏  | 44194/61028 [08:52<03:02, 92.31it/s]\u001b[A\n",
      " 72%|███████▏  | 44206/61028 [08:52<02:52, 97.31it/s]\u001b[A\n",
      " 72%|███████▏  | 44218/61028 [08:52<02:47, 100.50it/s]\u001b[A\n",
      " 72%|███████▏  | 44229/61028 [08:53<02:47, 100.01it/s]\u001b[A\n",
      " 72%|███████▏  | 44240/61028 [08:53<02:55, 95.48it/s] \u001b[A\n",
      " 73%|███████▎  | 44250/61028 [08:53<02:59, 93.60it/s]\u001b[A\n",
      " 73%|███████▎  | 44261/61028 [08:53<02:51, 97.78it/s]\u001b[A\n",
      " 73%|███████▎  | 44273/61028 [08:53<02:44, 101.73it/s]\u001b[A\n",
      " 73%|███████▎  | 44284/61028 [08:53<02:41, 103.90it/s]\u001b[A\n",
      " 73%|███████▎  | 44298/61028 [08:53<02:30, 111.34it/s]\u001b[A\n",
      " 73%|███████▎  | 44310/61028 [08:53<02:36, 107.09it/s]\u001b[A\n",
      " 73%|███████▎  | 44321/61028 [08:53<02:52, 97.08it/s] \u001b[A\n",
      " 73%|███████▎  | 44333/61028 [08:54<02:43, 102.41it/s]\u001b[A\n",
      " 73%|███████▎  | 44345/61028 [08:54<02:39, 104.58it/s]\u001b[A\n",
      " 73%|███████▎  | 44356/61028 [08:54<02:55, 95.14it/s] \u001b[A\n",
      " 73%|███████▎  | 44366/61028 [08:54<02:57, 93.65it/s]\u001b[A\n",
      " 73%|███████▎  | 44376/61028 [08:54<03:00, 92.40it/s]\u001b[A\n",
      " 73%|███████▎  | 44386/61028 [08:54<02:57, 93.53it/s]\u001b[A\n",
      " 73%|███████▎  | 44396/61028 [08:54<02:56, 94.41it/s]\u001b[A\n",
      " 73%|███████▎  | 44407/61028 [08:54<02:51, 96.92it/s]\u001b[A\n",
      " 73%|███████▎  | 44418/61028 [08:54<02:50, 97.65it/s]\u001b[A\n",
      " 73%|███████▎  | 44428/61028 [08:55<02:51, 96.77it/s]\u001b[A\n",
      " 73%|███████▎  | 44438/61028 [08:55<02:53, 95.54it/s]\u001b[A\n",
      " 73%|███████▎  | 44450/61028 [08:55<02:45, 100.36it/s]\u001b[A\n",
      " 73%|███████▎  | 44461/61028 [08:55<02:45, 100.08it/s]\u001b[A\n",
      " 73%|███████▎  | 44472/61028 [08:55<02:41, 102.21it/s]\u001b[A\n",
      " 73%|███████▎  | 44483/61028 [08:55<02:44, 100.71it/s]\u001b[A\n",
      " 73%|███████▎  | 44494/61028 [08:55<04:46, 57.63it/s] \u001b[A\n",
      " 73%|███████▎  | 44505/61028 [08:56<04:08, 66.49it/s]\u001b[A\n",
      " 73%|███████▎  | 44514/61028 [08:56<03:53, 70.74it/s]\u001b[A\n",
      " 73%|███████▎  | 44523/61028 [08:56<03:43, 73.71it/s]\u001b[A\n",
      " 73%|███████▎  | 44533/61028 [08:56<03:29, 78.90it/s]\u001b[A\n",
      " 73%|███████▎  | 44544/61028 [08:56<03:16, 84.08it/s]\u001b[A\n",
      " 73%|███████▎  | 44554/61028 [08:56<03:17, 83.56it/s]\u001b[A\n",
      " 73%|███████▎  | 44564/61028 [08:56<03:09, 86.89it/s]\u001b[A\n",
      " 73%|███████▎  | 44577/61028 [08:56<02:52, 95.63it/s]\u001b[A\n",
      " 73%|███████▎  | 44588/61028 [08:56<02:51, 96.10it/s]\u001b[A\n",
      " 73%|███████▎  | 44598/61028 [08:57<02:56, 92.83it/s]\u001b[A\n",
      " 73%|███████▎  | 44609/61028 [08:57<02:48, 97.21it/s]\u001b[A\n",
      " 73%|███████▎  | 44622/61028 [08:57<02:39, 102.93it/s]\u001b[A\n",
      " 73%|███████▎  | 44633/61028 [08:57<02:45, 99.15it/s] \u001b[A\n",
      " 73%|███████▎  | 44644/61028 [08:57<02:52, 95.22it/s]\u001b[A\n",
      " 73%|███████▎  | 44655/61028 [08:57<02:46, 98.58it/s]\u001b[A\n",
      " 73%|███████▎  | 44666/61028 [08:57<02:47, 97.40it/s]\u001b[A\n",
      " 73%|███████▎  | 44676/61028 [08:57<02:48, 97.26it/s]\u001b[A\n",
      " 73%|███████▎  | 44686/61028 [08:57<02:51, 95.30it/s]\u001b[A\n",
      " 73%|███████▎  | 44697/61028 [08:58<02:49, 96.62it/s]\u001b[A\n",
      " 73%|███████▎  | 44707/61028 [08:58<02:56, 92.67it/s]\u001b[A\n",
      " 73%|███████▎  | 44717/61028 [08:58<03:06, 87.46it/s]\u001b[A\n",
      " 73%|███████▎  | 44727/61028 [08:58<03:02, 89.24it/s]\u001b[A\n",
      " 73%|███████▎  | 44737/61028 [08:58<03:04, 88.28it/s]\u001b[A\n",
      " 73%|███████▎  | 44746/61028 [08:58<03:03, 88.60it/s]\u001b[A\n",
      " 73%|███████▎  | 44757/61028 [08:58<02:57, 91.53it/s]\u001b[A\n",
      " 73%|███████▎  | 44767/61028 [08:58<02:57, 91.56it/s]\u001b[A\n",
      " 73%|███████▎  | 44778/61028 [08:58<02:51, 94.71it/s]\u001b[A\n",
      " 73%|███████▎  | 44791/61028 [08:59<02:37, 102.90it/s]\u001b[A\n",
      " 73%|███████▎  | 44802/61028 [08:59<02:41, 100.61it/s]\u001b[A\n",
      " 73%|███████▎  | 44813/61028 [08:59<02:53, 93.57it/s] \u001b[A\n",
      " 73%|███████▎  | 44823/61028 [08:59<02:50, 95.17it/s]\u001b[A\n",
      " 73%|███████▎  | 44835/61028 [08:59<02:43, 98.93it/s]\u001b[A\n",
      " 73%|███████▎  | 44846/61028 [08:59<02:40, 100.79it/s]\u001b[A\n",
      " 74%|███████▎  | 44857/61028 [08:59<02:45, 97.70it/s] \u001b[A\n",
      " 74%|███████▎  | 44867/61028 [08:59<02:45, 97.42it/s]\u001b[A\n",
      " 74%|███████▎  | 44877/61028 [08:59<02:48, 95.88it/s]\u001b[A\n",
      " 74%|███████▎  | 44887/61028 [09:00<02:53, 93.28it/s]\u001b[A\n",
      " 74%|███████▎  | 44898/61028 [09:00<02:51, 94.21it/s]\u001b[A\n",
      " 74%|███████▎  | 44908/61028 [09:00<02:50, 94.42it/s]\u001b[A\n",
      " 74%|███████▎  | 44918/61028 [09:00<02:54, 92.07it/s]\u001b[A\n",
      " 74%|███████▎  | 44928/61028 [09:00<02:52, 93.34it/s]\u001b[A\n",
      " 74%|███████▎  | 44938/61028 [09:00<02:50, 94.57it/s]\u001b[A\n",
      " 74%|███████▎  | 44949/61028 [09:00<02:46, 96.64it/s]\u001b[A\n",
      " 74%|███████▎  | 44959/61028 [09:01<04:59, 53.68it/s]\u001b[A\n",
      " 74%|███████▎  | 44969/61028 [09:01<04:23, 61.02it/s]\u001b[A\n",
      " 74%|███████▎  | 44978/61028 [09:01<04:00, 66.68it/s]\u001b[A\n",
      " 74%|███████▎  | 44989/61028 [09:01<03:33, 75.14it/s]\u001b[A\n",
      " 74%|███████▎  | 44999/61028 [09:01<03:18, 80.74it/s]\u001b[A\n",
      " 74%|███████▍  | 45010/61028 [09:01<03:07, 85.59it/s]\u001b[A\n",
      " 74%|███████▍  | 45020/61028 [09:01<03:07, 85.37it/s]\u001b[A\n",
      " 74%|███████▍  | 45032/61028 [09:01<02:54, 91.50it/s]\u001b[A\n",
      " 74%|███████▍  | 45042/61028 [09:01<02:51, 93.05it/s]\u001b[A\n",
      " 74%|███████▍  | 45053/61028 [09:02<02:45, 96.38it/s]\u001b[A\n",
      " 74%|███████▍  | 45063/61028 [09:02<02:46, 95.88it/s]\u001b[A\n",
      " 74%|███████▍  | 45073/61028 [09:02<02:48, 94.86it/s]\u001b[A\n",
      " 74%|███████▍  | 45083/61028 [09:02<02:45, 96.29it/s]\u001b[A\n",
      " 74%|███████▍  | 45093/61028 [09:02<02:55, 90.85it/s]\u001b[A\n",
      " 74%|███████▍  | 45103/61028 [09:02<03:00, 88.11it/s]\u001b[A\n",
      " 74%|███████▍  | 45115/61028 [09:02<02:50, 93.54it/s]\u001b[A\n",
      " 74%|███████▍  | 45129/61028 [09:02<02:35, 102.20it/s]\u001b[A\n",
      " 74%|███████▍  | 45140/61028 [09:02<02:32, 103.94it/s]\u001b[A\n",
      " 74%|███████▍  | 45151/61028 [09:03<02:32, 104.05it/s]\u001b[A\n",
      " 74%|███████▍  | 45162/61028 [09:03<02:32, 103.86it/s]\u001b[A\n",
      " 74%|███████▍  | 45173/61028 [09:03<02:40, 98.70it/s] \u001b[A\n",
      " 74%|███████▍  | 45184/61028 [09:03<02:45, 95.81it/s]\u001b[A\n",
      " 74%|███████▍  | 45195/61028 [09:03<02:40, 98.58it/s]\u001b[A\n",
      " 74%|███████▍  | 45205/61028 [09:03<02:46, 94.89it/s]\u001b[A\n",
      " 74%|███████▍  | 45218/61028 [09:03<02:38, 99.96it/s]\u001b[A\n",
      " 74%|███████▍  | 45229/61028 [09:03<02:40, 98.15it/s]\u001b[A\n",
      " 74%|███████▍  | 45240/61028 [09:03<02:38, 99.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 45251/61028 [09:04<02:40, 98.60it/s]\u001b[A\n",
      " 74%|███████▍  | 45261/61028 [09:04<02:41, 97.62it/s]\u001b[A\n",
      " 74%|███████▍  | 45271/61028 [09:04<02:47, 94.21it/s]\u001b[A\n",
      " 74%|███████▍  | 45281/61028 [09:04<02:45, 95.02it/s]\u001b[A\n",
      " 74%|███████▍  | 45291/61028 [09:04<02:46, 94.35it/s]\u001b[A\n",
      " 74%|███████▍  | 45301/61028 [09:04<02:53, 90.80it/s]\u001b[A\n",
      " 74%|███████▍  | 45311/61028 [09:04<02:56, 88.82it/s]\u001b[A\n",
      " 74%|███████▍  | 45320/61028 [09:04<03:06, 84.31it/s]\u001b[A\n",
      " 74%|███████▍  | 45329/61028 [09:04<03:16, 79.92it/s]\u001b[A\n",
      " 74%|███████▍  | 45339/61028 [09:05<03:06, 83.91it/s]\u001b[A\n",
      " 74%|███████▍  | 45349/61028 [09:05<03:01, 86.51it/s]\u001b[A\n",
      " 74%|███████▍  | 45359/61028 [09:05<02:59, 87.39it/s]\u001b[A\n",
      " 74%|███████▍  | 45371/61028 [09:05<02:45, 94.51it/s]\u001b[A\n",
      " 74%|███████▍  | 45381/61028 [09:05<02:42, 96.06it/s]\u001b[A\n",
      " 74%|███████▍  | 45391/61028 [09:05<02:41, 96.97it/s]\u001b[A\n",
      " 74%|███████▍  | 45402/61028 [09:05<02:40, 97.47it/s]\u001b[A\n",
      " 74%|███████▍  | 45412/61028 [09:05<02:42, 96.01it/s]\u001b[A\n",
      " 74%|███████▍  | 45422/61028 [09:06<05:19, 48.85it/s]\u001b[A\n",
      " 74%|███████▍  | 45430/61028 [09:06<04:46, 54.39it/s]\u001b[A\n",
      " 74%|███████▍  | 45441/61028 [09:06<04:04, 63.79it/s]\u001b[A\n",
      " 74%|███████▍  | 45452/61028 [09:06<03:34, 72.56it/s]\u001b[A\n",
      " 74%|███████▍  | 45462/61028 [09:06<03:20, 77.51it/s]\u001b[A\n",
      " 75%|███████▍  | 45472/61028 [09:06<03:14, 79.85it/s]\u001b[A\n",
      " 75%|███████▍  | 45481/61028 [09:06<03:10, 81.71it/s]\u001b[A\n",
      " 75%|███████▍  | 45492/61028 [09:07<02:58, 86.93it/s]\u001b[A\n",
      " 75%|███████▍  | 45504/61028 [09:07<02:44, 94.44it/s]\u001b[A\n",
      " 75%|███████▍  | 45515/61028 [09:07<02:40, 96.83it/s]\u001b[A\n",
      " 75%|███████▍  | 45526/61028 [09:07<02:41, 95.77it/s]\u001b[A\n",
      " 75%|███████▍  | 45537/61028 [09:07<02:36, 99.01it/s]\u001b[A\n",
      " 75%|███████▍  | 45548/61028 [09:07<02:36, 98.61it/s]\u001b[A\n",
      " 75%|███████▍  | 45559/61028 [09:07<02:45, 93.23it/s]\u001b[A\n",
      " 75%|███████▍  | 45569/61028 [09:07<02:43, 94.64it/s]\u001b[A\n",
      " 75%|███████▍  | 45579/61028 [09:07<02:42, 95.06it/s]\u001b[A\n",
      " 75%|███████▍  | 45590/61028 [09:08<02:39, 96.57it/s]\u001b[A\n",
      " 75%|███████▍  | 45601/61028 [09:08<02:37, 98.14it/s]\u001b[A\n",
      " 75%|███████▍  | 45611/61028 [09:08<02:38, 97.17it/s]\u001b[A\n",
      " 75%|███████▍  | 45623/61028 [09:08<02:33, 100.68it/s]\u001b[A\n",
      " 75%|███████▍  | 45634/61028 [09:08<02:31, 101.89it/s]\u001b[A\n",
      " 75%|███████▍  | 45645/61028 [09:08<02:29, 102.81it/s]\u001b[A\n",
      " 75%|███████▍  | 45656/61028 [09:08<02:40, 95.57it/s] \u001b[A\n",
      " 75%|███████▍  | 45666/61028 [09:08<02:40, 95.62it/s]\u001b[A\n",
      " 75%|███████▍  | 45676/61028 [09:08<02:54, 88.05it/s]\u001b[A\n",
      " 75%|███████▍  | 45687/61028 [09:09<02:45, 92.76it/s]\u001b[A\n",
      " 75%|███████▍  | 45698/61028 [09:09<02:40, 95.65it/s]\u001b[A\n",
      " 75%|███████▍  | 45709/61028 [09:09<02:35, 98.40it/s]\u001b[A\n",
      " 75%|███████▍  | 45722/61028 [09:09<02:26, 104.60it/s]\u001b[A\n",
      " 75%|███████▍  | 45734/61028 [09:09<02:20, 108.56it/s]\u001b[A\n",
      " 75%|███████▍  | 45746/61028 [09:09<02:22, 107.36it/s]\u001b[A\n",
      " 75%|███████▍  | 45757/61028 [09:09<02:26, 104.05it/s]\u001b[A\n",
      " 75%|███████▍  | 45768/61028 [09:09<02:30, 101.46it/s]\u001b[A\n",
      " 75%|███████▌  | 45779/61028 [09:09<02:36, 97.27it/s] \u001b[A\n",
      " 75%|███████▌  | 45789/61028 [09:10<02:41, 94.52it/s]\u001b[A\n",
      " 75%|███████▌  | 45799/61028 [09:10<02:39, 95.37it/s]\u001b[A\n",
      " 75%|███████▌  | 45809/61028 [09:10<03:02, 83.30it/s]\u001b[A\n",
      " 75%|███████▌  | 45819/61028 [09:10<02:58, 85.44it/s]\u001b[A\n",
      " 75%|███████▌  | 45829/61028 [09:10<02:52, 87.88it/s]\u001b[A\n",
      " 75%|███████▌  | 45838/61028 [09:10<02:52, 87.98it/s]\u001b[A\n",
      " 75%|███████▌  | 45847/61028 [09:10<02:52, 88.26it/s]\u001b[A\n",
      " 75%|███████▌  | 45858/61028 [09:10<02:43, 92.87it/s]\u001b[A\n",
      " 75%|███████▌  | 45868/61028 [09:10<02:40, 94.43it/s]\u001b[A\n",
      " 75%|███████▌  | 45878/61028 [09:11<04:19, 58.34it/s]\u001b[A\n",
      " 75%|███████▌  | 45886/61028 [09:11<04:34, 55.15it/s]\u001b[A\n",
      " 75%|███████▌  | 45895/61028 [09:11<04:05, 61.64it/s]\u001b[A\n",
      " 75%|███████▌  | 45908/61028 [09:11<03:26, 73.05it/s]\u001b[A\n",
      " 75%|███████▌  | 45917/61028 [09:11<03:17, 76.54it/s]\u001b[A\n",
      " 75%|███████▌  | 45929/61028 [09:11<02:58, 84.53it/s]\u001b[A\n",
      " 75%|███████▌  | 45939/61028 [09:11<02:52, 87.59it/s]\u001b[A\n",
      " 75%|███████▌  | 45949/61028 [09:12<02:47, 90.25it/s]\u001b[A\n",
      " 75%|███████▌  | 45960/61028 [09:12<02:39, 94.69it/s]\u001b[A\n",
      " 75%|███████▌  | 45970/61028 [09:12<02:37, 95.40it/s]\u001b[A\n",
      " 75%|███████▌  | 45981/61028 [09:12<02:31, 99.16it/s]\u001b[A\n",
      " 75%|███████▌  | 45992/61028 [09:12<02:34, 97.22it/s]\u001b[A\n",
      " 75%|███████▌  | 46002/61028 [09:12<02:37, 95.41it/s]\u001b[A\n",
      " 75%|███████▌  | 46012/61028 [09:12<02:44, 91.02it/s]\u001b[A\n",
      " 75%|███████▌  | 46023/61028 [09:12<02:40, 93.28it/s]\u001b[A\n",
      " 75%|███████▌  | 46035/61028 [09:12<02:32, 98.39it/s]\u001b[A\n",
      " 75%|███████▌  | 46045/61028 [09:13<02:37, 94.89it/s]\u001b[A\n",
      " 75%|███████▌  | 46055/61028 [09:13<02:35, 96.16it/s]\u001b[A\n",
      " 75%|███████▌  | 46065/61028 [09:13<02:45, 90.29it/s]\u001b[A\n",
      " 75%|███████▌  | 46076/61028 [09:13<02:38, 94.17it/s]\u001b[A\n",
      " 76%|███████▌  | 46087/61028 [09:13<02:34, 96.79it/s]\u001b[A\n",
      " 76%|███████▌  | 46097/61028 [09:13<02:39, 93.72it/s]\u001b[A\n",
      " 76%|███████▌  | 46107/61028 [09:13<02:37, 94.81it/s]\u001b[A\n",
      " 76%|███████▌  | 46117/61028 [09:13<02:39, 93.35it/s]\u001b[A\n",
      " 76%|███████▌  | 46127/61028 [09:13<02:39, 93.15it/s]\u001b[A\n",
      " 76%|███████▌  | 46139/61028 [09:14<02:32, 97.51it/s]\u001b[A\n",
      " 76%|███████▌  | 46149/61028 [09:14<02:35, 95.55it/s]\u001b[A\n",
      " 76%|███████▌  | 46162/61028 [09:14<02:26, 101.78it/s]\u001b[A\n",
      " 76%|███████▌  | 46173/61028 [09:14<02:29, 99.28it/s] \u001b[A\n",
      " 76%|███████▌  | 46184/61028 [09:14<02:28, 100.20it/s]\u001b[A\n",
      " 76%|███████▌  | 46196/61028 [09:14<02:21, 104.92it/s]\u001b[A\n",
      " 76%|███████▌  | 46207/61028 [09:14<02:23, 103.44it/s]\u001b[A\n",
      " 76%|███████▌  | 46218/61028 [09:14<02:27, 100.69it/s]\u001b[A\n",
      " 76%|███████▌  | 46229/61028 [09:14<02:30, 98.01it/s] \u001b[A\n",
      " 76%|███████▌  | 46239/61028 [09:15<02:34, 95.48it/s]\u001b[A\n",
      " 76%|███████▌  | 46249/61028 [09:15<02:34, 95.83it/s]\u001b[A\n",
      " 76%|███████▌  | 46259/61028 [09:15<02:34, 95.30it/s]\u001b[A\n",
      " 76%|███████▌  | 46269/61028 [09:15<02:41, 91.34it/s]\u001b[A\n",
      " 76%|███████▌  | 46279/61028 [09:15<02:44, 89.80it/s]\u001b[A\n",
      " 76%|███████▌  | 46289/61028 [09:15<02:46, 88.56it/s]\u001b[A\n",
      " 76%|███████▌  | 46300/61028 [09:15<02:39, 92.44it/s]\u001b[A\n",
      " 76%|███████▌  | 46310/61028 [09:15<02:43, 89.77it/s]\u001b[A\n",
      " 76%|███████▌  | 46321/61028 [09:15<02:36, 93.99it/s]\u001b[A\n",
      " 76%|███████▌  | 46332/61028 [09:15<02:31, 97.27it/s]\u001b[A\n",
      " 76%|███████▌  | 46343/61028 [09:16<02:38, 92.76it/s]\u001b[A\n",
      " 76%|███████▌  | 46353/61028 [09:16<04:35, 53.26it/s]\u001b[A\n",
      " 76%|███████▌  | 46364/61028 [09:16<03:54, 62.52it/s]\u001b[A\n",
      " 76%|███████▌  | 46375/61028 [09:16<03:24, 71.70it/s]\u001b[A\n",
      " 76%|███████▌  | 46386/61028 [09:16<03:06, 78.48it/s]\u001b[A\n",
      " 76%|███████▌  | 46396/61028 [09:16<03:01, 80.59it/s]\u001b[A\n",
      " 76%|███████▌  | 46406/61028 [09:17<02:53, 84.23it/s]\u001b[A\n",
      " 76%|███████▌  | 46417/61028 [09:17<02:42, 90.17it/s]\u001b[A\n",
      " 76%|███████▌  | 46427/61028 [09:17<02:41, 90.23it/s]\u001b[A\n",
      " 76%|███████▌  | 46437/61028 [09:17<02:45, 88.15it/s]\u001b[A\n",
      " 76%|███████▌  | 46447/61028 [09:17<02:45, 88.23it/s]\u001b[A\n",
      " 76%|███████▌  | 46457/61028 [09:17<02:41, 90.11it/s]\u001b[A\n",
      " 76%|███████▌  | 46467/61028 [09:17<02:37, 92.74it/s]\u001b[A\n",
      " 76%|███████▌  | 46478/61028 [09:17<02:32, 95.48it/s]\u001b[A\n",
      " 76%|███████▌  | 46488/61028 [09:17<02:32, 95.63it/s]\u001b[A\n",
      " 76%|███████▌  | 46498/61028 [09:18<02:32, 95.47it/s]\u001b[A\n",
      " 76%|███████▌  | 46508/61028 [09:18<02:34, 94.08it/s]\u001b[A\n",
      " 76%|███████▌  | 46518/61028 [09:18<02:32, 95.43it/s]\u001b[A\n",
      " 76%|███████▌  | 46529/61028 [09:18<02:29, 96.66it/s]\u001b[A\n",
      " 76%|███████▋  | 46539/61028 [09:18<02:32, 94.81it/s]\u001b[A\n",
      " 76%|███████▋  | 46550/61028 [09:18<02:27, 98.18it/s]\u001b[A\n",
      " 76%|███████▋  | 46561/61028 [09:18<02:26, 98.94it/s]\u001b[A\n",
      " 76%|███████▋  | 46571/61028 [09:18<02:27, 97.81it/s]\u001b[A\n",
      " 76%|███████▋  | 46581/61028 [09:18<02:29, 96.84it/s]\u001b[A\n",
      " 76%|███████▋  | 46591/61028 [09:18<02:31, 95.42it/s]\u001b[A\n",
      " 76%|███████▋  | 46603/61028 [09:19<02:25, 99.22it/s]\u001b[A\n",
      " 76%|███████▋  | 46614/61028 [09:19<02:21, 101.91it/s]\u001b[A\n",
      " 76%|███████▋  | 46625/61028 [09:19<02:19, 103.37it/s]\u001b[A\n",
      " 76%|███████▋  | 46636/61028 [09:19<02:19, 102.96it/s]\u001b[A\n",
      " 76%|███████▋  | 46647/61028 [09:19<02:25, 98.65it/s] \u001b[A\n",
      " 76%|███████▋  | 46658/61028 [09:19<02:23, 100.03it/s]\u001b[A\n",
      " 76%|███████▋  | 46669/61028 [09:19<02:33, 93.47it/s] \u001b[A\n",
      " 76%|███████▋  | 46679/61028 [09:19<02:34, 92.76it/s]\u001b[A\n",
      " 77%|███████▋  | 46689/61028 [09:19<02:36, 91.79it/s]\u001b[A\n",
      " 77%|███████▋  | 46699/61028 [09:20<02:44, 86.96it/s]\u001b[A\n",
      " 77%|███████▋  | 46708/61028 [09:20<02:45, 86.37it/s]\u001b[A\n",
      " 77%|███████▋  | 46717/61028 [09:20<02:46, 86.01it/s]\u001b[A\n",
      " 77%|███████▋  | 46728/61028 [09:20<02:37, 90.84it/s]\u001b[A\n",
      " 77%|███████▋  | 46740/61028 [09:20<02:27, 96.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 46752/61028 [09:20<02:22, 100.50it/s]\u001b[A\n",
      " 77%|███████▋  | 46763/61028 [09:20<02:28, 96.01it/s] \u001b[A\n",
      " 77%|███████▋  | 46774/61028 [09:20<02:23, 99.17it/s]\u001b[A\n",
      " 77%|███████▋  | 46785/61028 [09:20<02:24, 98.54it/s]\u001b[A\n",
      " 77%|███████▋  | 46796/61028 [09:21<02:20, 101.04it/s]\u001b[A\n",
      " 77%|███████▋  | 46809/61028 [09:21<02:12, 107.04it/s]\u001b[A\n",
      " 77%|███████▋  | 46820/61028 [09:21<04:09, 56.96it/s] \u001b[A\n",
      " 77%|███████▋  | 46829/61028 [09:21<04:04, 58.08it/s]\u001b[A\n",
      " 77%|███████▋  | 46839/61028 [09:21<03:34, 66.24it/s]\u001b[A\n",
      " 77%|███████▋  | 46849/61028 [09:21<03:15, 72.42it/s]\u001b[A\n",
      " 77%|███████▋  | 46859/61028 [09:22<03:02, 77.69it/s]\u001b[A\n",
      " 77%|███████▋  | 46871/61028 [09:22<02:44, 85.90it/s]\u001b[A\n",
      " 77%|███████▋  | 46881/61028 [09:22<02:41, 87.35it/s]\u001b[A\n",
      " 77%|███████▋  | 46891/61028 [09:22<02:39, 88.87it/s]\u001b[A\n",
      " 77%|███████▋  | 46901/61028 [09:22<02:38, 89.27it/s]\u001b[A\n",
      " 77%|███████▋  | 46911/61028 [09:22<02:35, 90.89it/s]\u001b[A\n",
      " 77%|███████▋  | 46921/61028 [09:22<02:38, 89.14it/s]\u001b[A\n",
      " 77%|███████▋  | 46932/61028 [09:22<02:30, 93.66it/s]\u001b[A\n",
      " 77%|███████▋  | 46942/61028 [09:22<02:32, 92.16it/s]\u001b[A\n",
      " 77%|███████▋  | 46954/61028 [09:23<02:25, 96.73it/s]\u001b[A\n",
      " 77%|███████▋  | 46966/61028 [09:23<02:21, 99.36it/s]\u001b[A\n",
      " 77%|███████▋  | 46977/61028 [09:23<02:22, 98.71it/s]\u001b[A\n",
      " 77%|███████▋  | 46987/61028 [09:23<02:22, 98.47it/s]\u001b[A\n",
      " 77%|███████▋  | 46999/61028 [09:23<02:19, 100.38it/s]\u001b[A\n",
      " 77%|███████▋  | 47010/61028 [09:23<02:25, 96.13it/s] \u001b[A\n",
      " 77%|███████▋  | 47020/61028 [09:23<02:28, 94.20it/s]\u001b[A\n",
      " 77%|███████▋  | 47030/61028 [09:23<02:34, 90.65it/s]\u001b[A\n",
      " 77%|███████▋  | 47041/61028 [09:23<02:30, 92.91it/s]\u001b[A\n",
      " 77%|███████▋  | 47052/61028 [09:24<02:26, 95.45it/s]\u001b[A\n",
      " 77%|███████▋  | 47062/61028 [09:24<02:29, 93.12it/s]\u001b[A\n",
      " 77%|███████▋  | 47073/61028 [09:24<02:24, 96.53it/s]\u001b[A\n",
      " 77%|███████▋  | 47084/61028 [09:24<02:22, 98.00it/s]\u001b[A\n",
      " 77%|███████▋  | 47094/61028 [09:24<02:27, 94.15it/s]\u001b[A\n",
      " 77%|███████▋  | 47104/61028 [09:24<02:26, 95.16it/s]\u001b[A\n",
      " 77%|███████▋  | 47114/61028 [09:24<02:33, 90.66it/s]\u001b[A\n",
      " 77%|███████▋  | 47124/61028 [09:24<02:34, 89.99it/s]\u001b[A\n",
      " 77%|███████▋  | 47134/61028 [09:24<02:41, 86.12it/s]\u001b[A\n",
      " 77%|███████▋  | 47144/61028 [09:25<02:34, 89.64it/s]\u001b[A\n",
      " 77%|███████▋  | 47154/61028 [09:25<02:38, 87.47it/s]\u001b[A\n",
      " 77%|███████▋  | 47164/61028 [09:25<02:36, 88.62it/s]\u001b[A\n",
      " 77%|███████▋  | 47176/61028 [09:25<02:26, 94.26it/s]\u001b[A\n",
      " 77%|███████▋  | 47187/61028 [09:25<02:24, 96.00it/s]\u001b[A\n",
      " 77%|███████▋  | 47197/61028 [09:25<02:23, 96.66it/s]\u001b[A\n",
      " 77%|███████▋  | 47207/61028 [09:25<02:29, 92.52it/s]\u001b[A\n",
      " 77%|███████▋  | 47218/61028 [09:25<02:23, 96.17it/s]\u001b[A\n",
      " 77%|███████▋  | 47229/61028 [09:25<02:18, 99.77it/s]\u001b[A\n",
      " 77%|███████▋  | 47240/61028 [09:26<02:17, 100.15it/s]\u001b[A\n",
      " 77%|███████▋  | 47251/61028 [09:26<02:15, 101.33it/s]\u001b[A\n",
      " 77%|███████▋  | 47262/61028 [09:26<02:23, 95.93it/s] \u001b[A\n",
      " 77%|███████▋  | 47272/61028 [09:26<04:09, 55.24it/s]\u001b[A\n",
      " 77%|███████▋  | 47280/61028 [09:26<03:56, 58.14it/s]\u001b[A\n",
      " 77%|███████▋  | 47289/61028 [09:26<03:33, 64.44it/s]\u001b[A\n",
      " 78%|███████▊  | 47298/61028 [09:26<03:17, 69.39it/s]\u001b[A\n",
      " 78%|███████▊  | 47308/61028 [09:27<03:01, 75.69it/s]\u001b[A\n",
      " 78%|███████▊  | 47318/61028 [09:27<02:48, 81.24it/s]\u001b[A\n",
      " 78%|███████▊  | 47329/61028 [09:27<02:39, 85.63it/s]\u001b[A\n",
      " 78%|███████▊  | 47340/61028 [09:27<02:32, 89.81it/s]\u001b[A\n",
      " 78%|███████▊  | 47350/61028 [09:27<02:35, 88.10it/s]\u001b[A\n",
      " 78%|███████▊  | 47360/61028 [09:27<02:32, 89.69it/s]\u001b[A\n",
      " 78%|███████▊  | 47370/61028 [09:27<02:27, 92.35it/s]\u001b[A\n",
      " 78%|███████▊  | 47381/61028 [09:27<02:23, 95.40it/s]\u001b[A\n",
      " 78%|███████▊  | 47391/61028 [09:27<02:23, 94.96it/s]\u001b[A\n",
      " 78%|███████▊  | 47402/61028 [09:28<02:21, 96.51it/s]\u001b[A\n",
      " 78%|███████▊  | 47412/61028 [09:28<02:21, 96.04it/s]\u001b[A\n",
      " 78%|███████▊  | 47423/61028 [09:28<02:16, 99.32it/s]\u001b[A\n",
      " 78%|███████▊  | 47434/61028 [09:28<02:18, 98.00it/s]\u001b[A\n",
      " 78%|███████▊  | 47445/61028 [09:28<02:14, 100.89it/s]\u001b[A\n",
      " 78%|███████▊  | 47456/61028 [09:28<02:15, 100.52it/s]\u001b[A\n",
      " 78%|███████▊  | 47467/61028 [09:28<02:14, 100.68it/s]\u001b[A\n",
      " 78%|███████▊  | 47478/61028 [09:28<02:12, 102.40it/s]\u001b[A\n",
      " 78%|███████▊  | 47489/61028 [09:28<02:17, 98.47it/s] \u001b[A\n",
      " 78%|███████▊  | 47499/61028 [09:29<02:22, 95.08it/s]\u001b[A\n",
      " 78%|███████▊  | 47509/61028 [09:29<02:22, 94.60it/s]\u001b[A\n",
      " 78%|███████▊  | 47519/61028 [09:29<02:21, 95.36it/s]\u001b[A\n",
      " 78%|███████▊  | 47529/61028 [09:29<02:25, 92.77it/s]\u001b[A\n",
      " 78%|███████▊  | 47541/61028 [09:29<02:16, 98.66it/s]\u001b[A\n",
      " 78%|███████▊  | 47551/61028 [09:29<02:20, 96.24it/s]\u001b[A\n",
      " 78%|███████▊  | 47562/61028 [09:29<02:15, 99.44it/s]\u001b[A\n",
      " 78%|███████▊  | 47573/61028 [09:29<02:16, 98.42it/s]\u001b[A\n",
      " 78%|███████▊  | 47584/61028 [09:29<02:15, 99.24it/s]\u001b[A\n",
      " 78%|███████▊  | 47594/61028 [09:30<02:21, 94.87it/s]\u001b[A\n",
      " 78%|███████▊  | 47606/61028 [09:30<02:16, 98.51it/s]\u001b[A\n",
      " 78%|███████▊  | 47618/61028 [09:30<02:13, 100.58it/s]\u001b[A\n",
      " 78%|███████▊  | 47629/61028 [09:30<02:14, 99.98it/s] \u001b[A\n",
      " 78%|███████▊  | 47640/61028 [09:30<02:13, 100.54it/s]\u001b[A\n",
      " 78%|███████▊  | 47651/61028 [09:30<02:19, 96.20it/s] \u001b[A\n",
      " 78%|███████▊  | 47662/61028 [09:30<02:16, 98.27it/s]\u001b[A\n",
      " 78%|███████▊  | 47672/61028 [09:30<02:16, 97.63it/s]\u001b[A\n",
      " 78%|███████▊  | 47682/61028 [09:30<02:17, 97.29it/s]\u001b[A\n",
      " 78%|███████▊  | 47693/61028 [09:31<02:14, 99.17it/s]\u001b[A\n",
      " 78%|███████▊  | 47704/61028 [09:31<02:11, 100.98it/s]\u001b[A\n",
      " 78%|███████▊  | 47715/61028 [09:31<02:20, 94.89it/s] \u001b[A\n",
      " 78%|███████▊  | 47727/61028 [09:31<02:22, 93.49it/s]\u001b[A\n",
      " 78%|███████▊  | 47737/61028 [09:31<02:22, 93.36it/s]\u001b[A\n",
      " 78%|███████▊  | 47747/61028 [09:31<04:17, 51.64it/s]\u001b[A\n",
      " 78%|███████▊  | 47757/61028 [09:31<03:42, 59.52it/s]\u001b[A\n",
      " 78%|███████▊  | 47766/61028 [09:32<03:23, 65.22it/s]\u001b[A\n",
      " 78%|███████▊  | 47775/61028 [09:32<03:12, 68.97it/s]\u001b[A\n",
      " 78%|███████▊  | 47784/61028 [09:32<03:01, 73.14it/s]\u001b[A\n",
      " 78%|███████▊  | 47796/61028 [09:32<02:41, 81.87it/s]\u001b[A\n",
      " 78%|███████▊  | 47807/61028 [09:32<02:32, 86.64it/s]\u001b[A\n",
      " 78%|███████▊  | 47818/61028 [09:32<02:22, 92.44it/s]\u001b[A\n",
      " 78%|███████▊  | 47828/61028 [09:32<02:21, 93.44it/s]\u001b[A\n",
      " 78%|███████▊  | 47838/61028 [09:32<02:19, 94.62it/s]\u001b[A\n",
      " 78%|███████▊  | 47848/61028 [09:32<02:20, 93.96it/s]\u001b[A\n",
      " 78%|███████▊  | 47858/61028 [09:33<02:19, 94.53it/s]\u001b[A\n",
      " 78%|███████▊  | 47868/61028 [09:33<02:21, 92.92it/s]\u001b[A\n",
      " 78%|███████▊  | 47878/61028 [09:33<02:20, 93.54it/s]\u001b[A\n",
      " 78%|███████▊  | 47888/61028 [09:33<02:21, 92.96it/s]\u001b[A\n",
      " 78%|███████▊  | 47898/61028 [09:33<02:19, 94.10it/s]\u001b[A\n",
      " 79%|███████▊  | 47908/61028 [09:33<02:21, 92.80it/s]\u001b[A\n",
      " 79%|███████▊  | 47919/61028 [09:33<02:19, 94.19it/s]\u001b[A\n",
      " 79%|███████▊  | 47929/61028 [09:33<02:19, 93.66it/s]\u001b[A\n",
      " 79%|███████▊  | 47940/61028 [09:33<02:15, 96.70it/s]\u001b[A\n",
      " 79%|███████▊  | 47952/61028 [09:34<02:07, 102.24it/s]\u001b[A\n",
      " 79%|███████▊  | 47963/61028 [09:34<02:07, 102.39it/s]\u001b[A\n",
      " 79%|███████▊  | 47974/61028 [09:34<02:04, 104.53it/s]\u001b[A\n",
      " 79%|███████▊  | 47985/61028 [09:34<02:07, 102.25it/s]\u001b[A\n",
      " 79%|███████▊  | 47996/61028 [09:34<02:09, 100.93it/s]\u001b[A\n",
      " 79%|███████▊  | 48007/61028 [09:34<02:08, 101.14it/s]\u001b[A\n",
      " 79%|███████▊  | 48018/61028 [09:34<02:09, 100.14it/s]\u001b[A\n",
      " 79%|███████▊  | 48029/61028 [09:34<02:09, 100.16it/s]\u001b[A\n",
      " 79%|███████▊  | 48040/61028 [09:34<02:12, 97.92it/s] \u001b[A\n",
      " 79%|███████▊  | 48051/61028 [09:34<02:09, 100.59it/s]\u001b[A\n",
      " 79%|███████▉  | 48062/61028 [09:35<02:05, 103.21it/s]\u001b[A\n",
      " 79%|███████▉  | 48073/61028 [09:35<02:11, 98.49it/s] \u001b[A\n",
      " 79%|███████▉  | 48083/61028 [09:35<02:16, 94.95it/s]\u001b[A\n",
      " 79%|███████▉  | 48094/61028 [09:35<02:11, 98.65it/s]\u001b[A\n",
      " 79%|███████▉  | 48105/61028 [09:35<02:07, 101.12it/s]\u001b[A\n",
      " 79%|███████▉  | 48116/61028 [09:35<02:05, 102.76it/s]\u001b[A\n",
      " 79%|███████▉  | 48128/61028 [09:35<02:03, 104.84it/s]\u001b[A\n",
      " 79%|███████▉  | 48141/61028 [09:35<01:57, 110.09it/s]\u001b[A\n",
      " 79%|███████▉  | 48153/61028 [09:35<02:07, 101.01it/s]\u001b[A\n",
      " 79%|███████▉  | 48164/61028 [09:36<02:16, 94.13it/s] \u001b[A\n",
      " 79%|███████▉  | 48175/61028 [09:36<02:12, 97.24it/s]\u001b[A\n",
      " 79%|███████▉  | 48186/61028 [09:36<02:07, 100.49it/s]\u001b[A\n",
      " 79%|███████▉  | 48197/61028 [09:36<02:23, 89.64it/s] \u001b[A\n",
      " 79%|███████▉  | 48208/61028 [09:36<02:21, 90.50it/s]\u001b[A\n",
      " 79%|███████▉  | 48218/61028 [09:36<04:01, 52.97it/s]\u001b[A\n",
      " 79%|███████▉  | 48229/61028 [09:37<03:25, 62.19it/s]\u001b[A\n",
      " 79%|███████▉  | 48241/61028 [09:37<02:56, 72.45it/s]\u001b[A\n",
      " 79%|███████▉  | 48251/61028 [09:37<02:43, 78.29it/s]\u001b[A\n",
      " 79%|███████▉  | 48262/61028 [09:37<02:30, 84.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 48272/61028 [09:37<02:25, 87.51it/s]\u001b[A\n",
      " 79%|███████▉  | 48282/61028 [09:37<02:21, 90.33it/s]\u001b[A\n",
      " 79%|███████▉  | 48293/61028 [09:37<02:14, 94.74it/s]\u001b[A\n",
      " 79%|███████▉  | 48304/61028 [09:37<02:09, 98.57it/s]\u001b[A\n",
      " 79%|███████▉  | 48315/61028 [09:37<02:10, 97.46it/s]\u001b[A\n",
      " 79%|███████▉  | 48326/61028 [09:38<02:12, 95.64it/s]\u001b[A\n",
      " 79%|███████▉  | 48337/61028 [09:38<02:10, 97.23it/s]\u001b[A\n",
      " 79%|███████▉  | 48347/61028 [09:38<02:09, 97.76it/s]\u001b[A\n",
      " 79%|███████▉  | 48359/61028 [09:38<02:05, 101.33it/s]\u001b[A\n",
      " 79%|███████▉  | 48370/61028 [09:38<02:08, 98.54it/s] \u001b[A\n",
      " 79%|███████▉  | 48381/61028 [09:38<02:06, 100.23it/s]\u001b[A\n",
      " 79%|███████▉  | 48392/61028 [09:38<02:12, 95.17it/s] \u001b[A\n",
      " 79%|███████▉  | 48403/61028 [09:38<02:08, 98.19it/s]\u001b[A\n",
      " 79%|███████▉  | 48413/61028 [09:38<02:07, 98.71it/s]\u001b[A\n",
      " 79%|███████▉  | 48424/61028 [09:39<02:06, 99.99it/s]\u001b[A\n",
      " 79%|███████▉  | 48435/61028 [09:39<02:05, 100.22it/s]\u001b[A\n",
      " 79%|███████▉  | 48446/61028 [09:39<02:04, 100.74it/s]\u001b[A\n",
      " 79%|███████▉  | 48457/61028 [09:39<02:05, 99.87it/s] \u001b[A\n",
      " 79%|███████▉  | 48468/61028 [09:39<02:10, 96.53it/s]\u001b[A\n",
      " 79%|███████▉  | 48479/61028 [09:39<02:06, 98.96it/s]\u001b[A\n",
      " 79%|███████▉  | 48490/61028 [09:39<02:08, 97.62it/s]\u001b[A\n",
      " 79%|███████▉  | 48500/61028 [09:39<02:08, 97.21it/s]\u001b[A\n",
      " 79%|███████▉  | 48510/61028 [09:39<02:20, 89.28it/s]\u001b[A\n",
      " 80%|███████▉  | 48520/61028 [09:40<02:16, 91.89it/s]\u001b[A\n",
      " 80%|███████▉  | 48531/61028 [09:40<02:10, 96.04it/s]\u001b[A\n",
      " 80%|███████▉  | 48542/61028 [09:40<02:08, 97.48it/s]\u001b[A\n",
      " 80%|███████▉  | 48552/61028 [09:40<02:11, 94.94it/s]\u001b[A\n",
      " 80%|███████▉  | 48562/61028 [09:40<02:12, 94.04it/s]\u001b[A\n",
      " 80%|███████▉  | 48572/61028 [09:40<02:10, 95.60it/s]\u001b[A\n",
      " 80%|███████▉  | 48582/61028 [09:40<02:09, 96.42it/s]\u001b[A\n",
      " 80%|███████▉  | 48593/61028 [09:40<02:05, 99.33it/s]\u001b[A\n",
      " 80%|███████▉  | 48605/61028 [09:40<02:00, 102.85it/s]\u001b[A\n",
      " 80%|███████▉  | 48617/61028 [09:40<01:58, 105.04it/s]\u001b[A\n",
      " 80%|███████▉  | 48628/61028 [09:41<01:59, 103.42it/s]\u001b[A\n",
      " 80%|███████▉  | 48640/61028 [09:41<01:54, 107.76it/s]\u001b[A\n",
      " 80%|███████▉  | 48651/61028 [09:41<02:01, 101.82it/s]\u001b[A\n",
      " 80%|███████▉  | 48662/61028 [09:41<02:13, 92.35it/s] \u001b[A\n",
      " 80%|███████▉  | 48673/61028 [09:41<02:11, 94.22it/s]\u001b[A\n",
      " 80%|███████▉  | 48683/61028 [09:41<02:10, 94.60it/s]\u001b[A\n",
      " 80%|███████▉  | 48693/61028 [09:42<03:56, 52.17it/s]\u001b[A\n",
      " 80%|███████▉  | 48702/61028 [09:42<03:28, 59.03it/s]\u001b[A\n",
      " 80%|███████▉  | 48714/61028 [09:42<02:59, 68.66it/s]\u001b[A\n",
      " 80%|███████▉  | 48724/61028 [09:42<02:44, 74.63it/s]\u001b[A\n",
      " 80%|███████▉  | 48734/61028 [09:42<02:33, 80.34it/s]\u001b[A\n",
      " 80%|███████▉  | 48744/61028 [09:42<02:32, 80.77it/s]\u001b[A\n",
      " 80%|███████▉  | 48753/61028 [09:42<02:31, 81.19it/s]\u001b[A\n",
      " 80%|███████▉  | 48764/61028 [09:42<02:22, 85.78it/s]\u001b[A\n",
      " 80%|███████▉  | 48775/61028 [09:42<02:17, 89.31it/s]\u001b[A\n",
      " 80%|███████▉  | 48785/61028 [09:43<02:13, 91.74it/s]\u001b[A\n",
      " 80%|███████▉  | 48795/61028 [09:43<02:14, 91.28it/s]\u001b[A\n",
      " 80%|███████▉  | 48807/61028 [09:43<02:06, 96.67it/s]\u001b[A\n",
      " 80%|███████▉  | 48817/61028 [09:43<02:06, 96.38it/s]\u001b[A\n",
      " 80%|████████  | 48827/61028 [09:43<02:11, 92.45it/s]\u001b[A\n",
      " 80%|████████  | 48837/61028 [09:43<02:14, 90.85it/s]\u001b[A\n",
      " 80%|████████  | 48847/61028 [09:43<02:13, 91.17it/s]\u001b[A\n",
      " 80%|████████  | 48857/61028 [09:43<02:15, 89.82it/s]\u001b[A\n",
      " 80%|████████  | 48867/61028 [09:43<02:13, 91.13it/s]\u001b[A\n",
      " 80%|████████  | 48878/61028 [09:44<02:07, 95.57it/s]\u001b[A\n",
      " 80%|████████  | 48888/61028 [09:44<02:07, 95.44it/s]\u001b[A\n",
      " 80%|████████  | 48898/61028 [09:44<02:10, 93.11it/s]\u001b[A\n",
      " 80%|████████  | 48909/61028 [09:44<02:07, 95.35it/s]\u001b[A\n",
      " 80%|████████  | 48923/61028 [09:44<01:56, 103.94it/s]\u001b[A\n",
      " 80%|████████  | 48934/61028 [09:44<01:58, 102.05it/s]\u001b[A\n",
      " 80%|████████  | 48945/61028 [09:44<01:59, 101.23it/s]\u001b[A\n",
      " 80%|████████  | 48956/61028 [09:44<02:00, 100.24it/s]\u001b[A\n",
      " 80%|████████  | 48968/61028 [09:44<01:54, 105.21it/s]\u001b[A\n",
      " 80%|████████  | 48979/61028 [09:45<02:02, 98.00it/s] \u001b[A\n",
      " 80%|████████  | 48992/61028 [09:45<01:55, 104.61it/s]\u001b[A\n",
      " 80%|████████  | 49003/61028 [09:45<01:55, 104.21it/s]\u001b[A\n",
      " 80%|████████  | 49014/61028 [09:45<01:59, 100.62it/s]\u001b[A\n",
      " 80%|████████  | 49025/61028 [09:45<02:02, 97.98it/s] \u001b[A\n",
      " 80%|████████  | 49035/61028 [09:45<02:03, 97.06it/s]\u001b[A\n",
      " 80%|████████  | 49045/61028 [09:45<02:03, 97.09it/s]\u001b[A\n",
      " 80%|████████  | 49056/61028 [09:45<02:01, 98.66it/s]\u001b[A\n",
      " 80%|████████  | 49067/61028 [09:45<01:57, 101.73it/s]\u001b[A\n",
      " 80%|████████  | 49078/61028 [09:46<01:56, 102.83it/s]\u001b[A\n",
      " 80%|████████  | 49089/61028 [09:46<01:56, 102.56it/s]\u001b[A\n",
      " 80%|████████  | 49100/61028 [09:46<02:05, 95.32it/s] \u001b[A\n",
      " 80%|████████  | 49110/61028 [09:46<02:04, 95.88it/s]\u001b[A\n",
      " 80%|████████  | 49120/61028 [09:46<02:05, 95.03it/s]\u001b[A\n",
      " 81%|████████  | 49130/61028 [09:46<02:09, 92.21it/s]\u001b[A\n",
      " 81%|████████  | 49141/61028 [09:46<02:02, 96.76it/s]\u001b[A\n",
      " 81%|████████  | 49151/61028 [09:46<02:06, 94.10it/s]\u001b[A\n",
      " 81%|████████  | 49161/61028 [09:47<03:49, 51.60it/s]\u001b[A\n",
      " 81%|████████  | 49171/61028 [09:47<03:17, 60.10it/s]\u001b[A\n",
      " 81%|████████  | 49182/61028 [09:47<02:52, 68.61it/s]\u001b[A\n",
      " 81%|████████  | 49193/61028 [09:47<02:35, 75.89it/s]\u001b[A\n",
      " 81%|████████  | 49204/61028 [09:47<02:22, 82.70it/s]\u001b[A\n",
      " 81%|████████  | 49216/61028 [09:47<02:11, 89.92it/s]\u001b[A\n",
      " 81%|████████  | 49227/61028 [09:47<02:09, 91.48it/s]\u001b[A\n",
      " 81%|████████  | 49237/61028 [09:47<02:06, 92.87it/s]\u001b[A\n",
      " 81%|████████  | 49247/61028 [09:48<02:05, 94.04it/s]\u001b[A\n",
      " 81%|████████  | 49257/61028 [09:48<02:05, 93.64it/s]\u001b[A\n",
      " 81%|████████  | 49267/61028 [09:48<02:04, 94.15it/s]\u001b[A\n",
      " 81%|████████  | 49277/61028 [09:48<02:03, 95.39it/s]\u001b[A\n",
      " 81%|████████  | 49287/61028 [09:48<02:02, 95.89it/s]\u001b[A\n",
      " 81%|████████  | 49300/61028 [09:48<01:54, 102.19it/s]\u001b[A\n",
      " 81%|████████  | 49311/61028 [09:48<01:54, 102.51it/s]\u001b[A\n",
      " 81%|████████  | 49322/61028 [09:48<01:55, 101.33it/s]\u001b[A\n",
      " 81%|████████  | 49334/61028 [09:48<01:53, 102.99it/s]\u001b[A\n",
      " 81%|████████  | 49345/61028 [09:48<01:51, 104.39it/s]\u001b[A\n",
      " 81%|████████  | 49356/61028 [09:49<01:53, 102.71it/s]\u001b[A\n",
      " 81%|████████  | 49367/61028 [09:49<01:53, 102.59it/s]\u001b[A\n",
      " 81%|████████  | 49378/61028 [09:49<01:57, 98.83it/s] \u001b[A\n",
      " 81%|████████  | 49388/61028 [09:49<02:00, 96.78it/s]\u001b[A\n",
      " 81%|████████  | 49399/61028 [09:49<01:58, 97.96it/s]\u001b[A\n",
      " 81%|████████  | 49409/61028 [09:49<02:06, 92.14it/s]\u001b[A\n",
      " 81%|████████  | 49422/61028 [09:49<01:56, 99.70it/s]\u001b[A\n",
      " 81%|████████  | 49433/61028 [09:49<01:59, 97.28it/s]\u001b[A\n",
      " 81%|████████  | 49444/61028 [09:50<02:03, 93.63it/s]\u001b[A\n",
      " 81%|████████  | 49454/61028 [09:50<02:01, 95.40it/s]\u001b[A\n",
      " 81%|████████  | 49465/61028 [09:50<02:01, 95.52it/s]\u001b[A\n",
      " 81%|████████  | 49475/61028 [09:50<02:03, 93.46it/s]\u001b[A\n",
      " 81%|████████  | 49485/61028 [09:50<02:05, 92.08it/s]\u001b[A\n",
      " 81%|████████  | 49495/61028 [09:50<02:03, 93.61it/s]\u001b[A\n",
      " 81%|████████  | 49505/61028 [09:50<02:00, 95.41it/s]\u001b[A\n",
      " 81%|████████  | 49515/61028 [09:50<02:00, 95.54it/s]\u001b[A\n",
      " 81%|████████  | 49525/61028 [09:50<02:04, 92.14it/s]\u001b[A\n",
      " 81%|████████  | 49535/61028 [09:51<02:08, 89.57it/s]\u001b[A\n",
      " 81%|████████  | 49545/61028 [09:51<02:12, 86.79it/s]\u001b[A\n",
      " 81%|████████  | 49556/61028 [09:51<02:05, 91.26it/s]\u001b[A\n",
      " 81%|████████  | 49566/61028 [09:51<02:09, 88.19it/s]\u001b[A\n",
      " 81%|████████  | 49575/61028 [09:51<02:11, 87.13it/s]\u001b[A\n",
      " 81%|████████  | 49584/61028 [09:51<02:11, 87.31it/s]\u001b[A\n",
      " 81%|████████▏ | 49594/61028 [09:51<02:09, 88.63it/s]\u001b[A\n",
      " 81%|████████▏ | 49603/61028 [09:51<02:08, 88.90it/s]\u001b[A\n",
      " 81%|████████▏ | 49615/61028 [09:51<02:00, 94.41it/s]\u001b[A\n",
      " 81%|████████▏ | 49625/61028 [09:52<03:33, 53.40it/s]\u001b[A\n",
      " 81%|████████▏ | 49635/61028 [09:52<03:06, 61.21it/s]\u001b[A\n",
      " 81%|████████▏ | 49645/61028 [09:52<02:46, 68.28it/s]\u001b[A\n",
      " 81%|████████▏ | 49658/61028 [09:52<02:25, 78.12it/s]\u001b[A\n",
      " 81%|████████▏ | 49668/61028 [09:52<02:29, 76.16it/s]\u001b[A\n",
      " 81%|████████▏ | 49677/61028 [09:52<02:22, 79.53it/s]\u001b[A\n",
      " 81%|████████▏ | 49689/61028 [09:52<02:10, 86.95it/s]\u001b[A\n",
      " 81%|████████▏ | 49700/61028 [09:53<02:05, 90.46it/s]\u001b[A\n",
      " 81%|████████▏ | 49710/61028 [09:53<02:02, 92.05it/s]\u001b[A\n",
      " 81%|████████▏ | 49720/61028 [09:53<02:04, 91.05it/s]\u001b[A\n",
      " 81%|████████▏ | 49730/61028 [09:53<02:04, 90.99it/s]\u001b[A\n",
      " 82%|████████▏ | 49740/61028 [09:53<02:02, 91.85it/s]\u001b[A\n",
      " 82%|████████▏ | 49750/61028 [09:53<02:01, 93.12it/s]\u001b[A\n",
      " 82%|████████▏ | 49761/61028 [09:53<01:58, 95.41it/s]\u001b[A\n",
      " 82%|████████▏ | 49771/61028 [09:53<01:56, 96.57it/s]\u001b[A\n",
      " 82%|████████▏ | 49781/61028 [09:53<02:00, 93.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 49791/61028 [09:54<02:02, 91.93it/s]\u001b[A\n",
      " 82%|████████▏ | 49804/61028 [09:54<01:52, 99.67it/s]\u001b[A\n",
      " 82%|████████▏ | 49815/61028 [09:54<02:03, 91.10it/s]\u001b[A\n",
      " 82%|████████▏ | 49826/61028 [09:54<01:56, 95.97it/s]\u001b[A\n",
      " 82%|████████▏ | 49836/61028 [09:54<01:56, 96.48it/s]\u001b[A\n",
      " 82%|████████▏ | 49846/61028 [09:54<02:01, 91.71it/s]\u001b[A\n",
      " 82%|████████▏ | 49857/61028 [09:54<01:57, 95.34it/s]\u001b[A\n",
      " 82%|████████▏ | 49868/61028 [09:54<01:55, 96.43it/s]\u001b[A\n",
      " 82%|████████▏ | 49879/61028 [09:54<01:51, 99.79it/s]\u001b[A\n",
      " 82%|████████▏ | 49890/61028 [09:55<01:53, 98.20it/s]\u001b[A\n",
      " 82%|████████▏ | 49901/61028 [09:55<01:49, 101.23it/s]\u001b[A\n",
      " 82%|████████▏ | 49912/61028 [09:55<01:51, 99.66it/s] \u001b[A\n",
      " 82%|████████▏ | 49923/61028 [09:55<01:51, 99.92it/s]\u001b[A\n",
      " 82%|████████▏ | 49934/61028 [09:55<01:57, 94.80it/s]\u001b[A\n",
      " 82%|████████▏ | 49944/61028 [09:55<01:56, 94.80it/s]\u001b[A\n",
      " 82%|████████▏ | 49954/61028 [09:55<01:57, 94.18it/s]\u001b[A\n",
      " 82%|████████▏ | 49964/61028 [09:55<02:06, 87.79it/s]\u001b[A\n",
      " 82%|████████▏ | 49975/61028 [09:55<02:00, 91.40it/s]\u001b[A\n",
      " 82%|████████▏ | 49985/61028 [09:56<01:57, 93.66it/s]\u001b[A\n",
      " 82%|████████▏ | 49996/61028 [09:56<01:54, 96.09it/s]\u001b[A\n",
      " 82%|████████▏ | 50008/61028 [09:56<01:49, 100.72it/s]\u001b[A\n",
      " 82%|████████▏ | 50019/61028 [09:56<02:03, 89.47it/s] \u001b[A\n",
      " 82%|████████▏ | 50029/61028 [09:56<02:00, 91.24it/s]\u001b[A\n",
      " 82%|████████▏ | 50039/61028 [09:56<01:59, 91.78it/s]\u001b[A\n",
      " 82%|████████▏ | 50050/61028 [09:56<01:54, 95.76it/s]\u001b[A\n",
      " 82%|████████▏ | 50060/61028 [09:56<01:58, 92.46it/s]\u001b[A\n",
      " 82%|████████▏ | 50070/61028 [09:56<01:58, 92.82it/s]\u001b[A\n",
      " 82%|████████▏ | 50080/61028 [09:57<02:06, 86.30it/s]\u001b[A\n",
      " 82%|████████▏ | 50089/61028 [09:57<03:37, 50.24it/s]\u001b[A\n",
      " 82%|████████▏ | 50096/61028 [09:57<03:20, 54.63it/s]\u001b[A\n",
      " 82%|████████▏ | 50105/61028 [09:57<02:58, 61.07it/s]\u001b[A\n",
      " 82%|████████▏ | 50116/61028 [09:57<02:34, 70.41it/s]\u001b[A\n",
      " 82%|████████▏ | 50127/61028 [09:57<02:18, 78.64it/s]\u001b[A\n",
      " 82%|████████▏ | 50137/61028 [09:57<02:11, 82.82it/s]\u001b[A\n",
      " 82%|████████▏ | 50151/61028 [09:58<01:56, 93.32it/s]\u001b[A\n",
      " 82%|████████▏ | 50163/61028 [09:58<01:50, 98.46it/s]\u001b[A\n",
      " 82%|████████▏ | 50175/61028 [09:58<01:44, 104.00it/s]\u001b[A\n",
      " 82%|████████▏ | 50187/61028 [09:58<01:47, 101.05it/s]\u001b[A\n",
      " 82%|████████▏ | 50198/61028 [09:58<01:52, 96.45it/s] \u001b[A\n",
      " 82%|████████▏ | 50209/61028 [09:58<01:50, 98.31it/s]\u001b[A\n",
      " 82%|████████▏ | 50220/61028 [09:58<01:49, 98.36it/s]\u001b[A\n",
      " 82%|████████▏ | 50231/61028 [09:58<01:51, 96.99it/s]\u001b[A\n",
      " 82%|████████▏ | 50241/61028 [09:58<01:51, 96.71it/s]\u001b[A\n",
      " 82%|████████▏ | 50251/61028 [09:59<01:50, 97.33it/s]\u001b[A\n",
      " 82%|████████▏ | 50261/61028 [09:59<01:51, 96.29it/s]\u001b[A\n",
      " 82%|████████▏ | 50273/61028 [09:59<01:46, 101.05it/s]\u001b[A\n",
      " 82%|████████▏ | 50284/61028 [09:59<01:48, 99.46it/s] \u001b[A\n",
      " 82%|████████▏ | 50296/61028 [09:59<01:45, 101.76it/s]\u001b[A\n",
      " 82%|████████▏ | 50308/61028 [09:59<01:41, 106.07it/s]\u001b[A\n",
      " 82%|████████▏ | 50319/61028 [09:59<01:48, 98.41it/s] \u001b[A\n",
      " 82%|████████▏ | 50330/61028 [09:59<01:47, 99.62it/s]\u001b[A\n",
      " 82%|████████▏ | 50341/61028 [09:59<01:48, 98.30it/s]\u001b[A\n",
      " 83%|████████▎ | 50351/61028 [10:00<01:48, 97.98it/s]\u001b[A\n",
      " 83%|████████▎ | 50361/61028 [10:00<01:52, 95.06it/s]\u001b[A\n",
      " 83%|████████▎ | 50371/61028 [10:00<01:52, 94.92it/s]\u001b[A\n",
      " 83%|████████▎ | 50382/61028 [10:00<01:49, 97.04it/s]\u001b[A\n",
      " 83%|████████▎ | 50392/61028 [10:00<01:56, 90.93it/s]\u001b[A\n",
      " 83%|████████▎ | 50402/61028 [10:00<01:54, 92.69it/s]\u001b[A\n",
      " 83%|████████▎ | 50412/61028 [10:00<02:02, 86.84it/s]\u001b[A\n",
      " 83%|████████▎ | 50424/61028 [10:00<01:53, 93.75it/s]\u001b[A\n",
      " 83%|████████▎ | 50434/61028 [10:00<01:52, 94.33it/s]\u001b[A\n",
      " 83%|████████▎ | 50447/61028 [10:01<01:45, 100.25it/s]\u001b[A\n",
      " 83%|████████▎ | 50459/61028 [10:01<01:42, 102.79it/s]\u001b[A\n",
      " 83%|████████▎ | 50470/61028 [10:01<01:43, 102.01it/s]\u001b[A\n",
      " 83%|████████▎ | 50481/61028 [10:01<01:47, 97.94it/s] \u001b[A\n",
      " 83%|████████▎ | 50491/61028 [10:01<02:01, 87.03it/s]\u001b[A\n",
      " 83%|████████▎ | 50501/61028 [10:01<01:56, 90.13it/s]\u001b[A\n",
      " 83%|████████▎ | 50511/61028 [10:01<01:53, 92.32it/s]\u001b[A\n",
      " 83%|████████▎ | 50522/61028 [10:01<01:49, 96.20it/s]\u001b[A\n",
      " 83%|████████▎ | 50532/61028 [10:01<01:51, 94.54it/s]\u001b[A\n",
      " 83%|████████▎ | 50542/61028 [10:02<01:52, 93.11it/s]\u001b[A\n",
      " 83%|████████▎ | 50552/61028 [10:02<02:02, 85.46it/s]\u001b[A\n",
      " 83%|████████▎ | 50561/61028 [10:02<03:21, 52.04it/s]\u001b[A\n",
      " 83%|████████▎ | 50569/61028 [10:02<03:00, 57.89it/s]\u001b[A\n",
      " 83%|████████▎ | 50578/61028 [10:02<02:43, 63.92it/s]\u001b[A\n",
      " 83%|████████▎ | 50588/61028 [10:02<02:27, 70.54it/s]\u001b[A\n",
      " 83%|████████▎ | 50598/61028 [10:02<02:16, 76.52it/s]\u001b[A\n",
      " 83%|████████▎ | 50609/61028 [10:03<02:05, 83.05it/s]\u001b[A\n",
      " 83%|████████▎ | 50621/61028 [10:03<01:55, 89.73it/s]\u001b[A\n",
      " 83%|████████▎ | 50631/61028 [10:03<01:53, 91.56it/s]\u001b[A\n",
      " 83%|████████▎ | 50642/61028 [10:03<01:48, 95.46it/s]\u001b[A\n",
      " 83%|████████▎ | 50652/61028 [10:03<01:47, 96.27it/s]\u001b[A\n",
      " 83%|████████▎ | 50662/61028 [10:03<01:51, 92.71it/s]\u001b[A\n",
      " 83%|████████▎ | 50673/61028 [10:03<01:48, 95.22it/s]\u001b[A\n",
      " 83%|████████▎ | 50683/61028 [10:03<01:47, 96.44it/s]\u001b[A\n",
      " 83%|████████▎ | 50694/61028 [10:03<01:45, 98.36it/s]\u001b[A\n",
      " 83%|████████▎ | 50704/61028 [10:04<01:45, 97.97it/s]\u001b[A\n",
      " 83%|████████▎ | 50714/61028 [10:04<01:45, 98.01it/s]\u001b[A\n",
      " 83%|████████▎ | 50725/61028 [10:04<01:45, 97.92it/s]\u001b[A\n",
      " 83%|████████▎ | 50735/61028 [10:04<01:44, 98.05it/s]\u001b[A\n",
      " 83%|████████▎ | 50747/61028 [10:04<01:40, 102.77it/s]\u001b[A\n",
      " 83%|████████▎ | 50758/61028 [10:04<01:46, 96.46it/s] \u001b[A\n",
      " 83%|████████▎ | 50769/61028 [10:04<01:43, 99.42it/s]\u001b[A\n",
      " 83%|████████▎ | 50780/61028 [10:04<01:41, 101.23it/s]\u001b[A\n",
      " 83%|████████▎ | 50791/61028 [10:04<01:43, 98.69it/s] \u001b[A\n",
      " 83%|████████▎ | 50801/61028 [10:05<01:46, 96.24it/s]\u001b[A\n",
      " 83%|████████▎ | 50813/61028 [10:05<01:41, 100.90it/s]\u001b[A\n",
      " 83%|████████▎ | 50824/61028 [10:05<01:42, 99.46it/s] \u001b[A\n",
      " 83%|████████▎ | 50835/61028 [10:05<01:41, 100.61it/s]\u001b[A\n",
      " 83%|████████▎ | 50846/61028 [10:05<01:45, 96.95it/s] \u001b[A\n",
      " 83%|████████▎ | 50856/61028 [10:05<01:48, 94.02it/s]\u001b[A\n",
      " 83%|████████▎ | 50866/61028 [10:05<01:53, 89.90it/s]\u001b[A\n",
      " 83%|████████▎ | 50876/61028 [10:05<01:52, 90.03it/s]\u001b[A\n",
      " 83%|████████▎ | 50887/61028 [10:05<01:47, 94.50it/s]\u001b[A\n",
      " 83%|████████▎ | 50897/61028 [10:06<01:49, 92.12it/s]\u001b[A\n",
      " 83%|████████▎ | 50907/61028 [10:06<01:53, 89.25it/s]\u001b[A\n",
      " 83%|████████▎ | 50917/61028 [10:06<01:55, 87.23it/s]\u001b[A\n",
      " 83%|████████▎ | 50926/61028 [10:06<02:00, 83.64it/s]\u001b[A\n",
      " 83%|████████▎ | 50935/61028 [10:06<02:02, 82.73it/s]\u001b[A\n",
      " 83%|████████▎ | 50944/61028 [10:06<02:04, 80.74it/s]\u001b[A\n",
      " 83%|████████▎ | 50954/61028 [10:06<01:58, 85.02it/s]\u001b[A\n",
      " 84%|████████▎ | 50964/61028 [10:06<01:54, 88.10it/s]\u001b[A\n",
      " 84%|████████▎ | 50973/61028 [10:06<01:53, 88.30it/s]\u001b[A\n",
      " 84%|████████▎ | 50985/61028 [10:07<01:45, 94.89it/s]\u001b[A\n",
      " 84%|████████▎ | 50995/61028 [10:07<01:47, 93.40it/s]\u001b[A\n",
      " 84%|████████▎ | 51005/61028 [10:07<01:52, 89.42it/s]\u001b[A\n",
      " 84%|████████▎ | 51015/61028 [10:07<03:07, 53.39it/s]\u001b[A\n",
      " 84%|████████▎ | 51026/61028 [10:07<02:40, 62.40it/s]\u001b[A\n",
      " 84%|████████▎ | 51036/61028 [10:07<02:23, 69.81it/s]\u001b[A\n",
      " 84%|████████▎ | 51047/61028 [10:07<02:09, 77.09it/s]\u001b[A\n",
      " 84%|████████▎ | 51058/61028 [10:08<01:58, 84.21it/s]\u001b[A\n",
      " 84%|████████▎ | 51068/61028 [10:08<01:57, 84.75it/s]\u001b[A\n",
      " 84%|████████▎ | 51078/61028 [10:08<01:55, 85.80it/s]\u001b[A\n",
      " 84%|████████▎ | 51089/61028 [10:08<01:51, 89.46it/s]\u001b[A\n",
      " 84%|████████▎ | 51100/61028 [10:08<01:45, 94.29it/s]\u001b[A\n",
      " 84%|████████▍ | 51111/61028 [10:08<01:40, 98.32it/s]\u001b[A\n",
      " 84%|████████▍ | 51122/61028 [10:08<01:39, 99.88it/s]\u001b[A\n",
      " 84%|████████▍ | 51133/61028 [10:08<01:43, 95.95it/s]\u001b[A\n",
      " 84%|████████▍ | 51143/61028 [10:08<01:44, 94.83it/s]\u001b[A\n",
      " 84%|████████▍ | 51155/61028 [10:09<01:40, 98.60it/s]\u001b[A\n",
      " 84%|████████▍ | 51165/61028 [10:09<01:44, 94.07it/s]\u001b[A\n",
      " 84%|████████▍ | 51175/61028 [10:09<01:42, 95.66it/s]\u001b[A\n",
      " 84%|████████▍ | 51187/61028 [10:09<01:38, 99.90it/s]\u001b[A\n",
      " 84%|████████▍ | 51198/61028 [10:09<01:39, 99.10it/s]\u001b[A\n",
      " 84%|████████▍ | 51208/61028 [10:09<01:48, 90.52it/s]\u001b[A\n",
      " 84%|████████▍ | 51218/61028 [10:09<01:49, 89.74it/s]\u001b[A\n",
      " 84%|████████▍ | 51229/61028 [10:09<01:44, 93.59it/s]\u001b[A\n",
      " 84%|████████▍ | 51241/61028 [10:09<01:38, 99.15it/s]\u001b[A\n",
      " 84%|████████▍ | 51252/61028 [10:10<01:48, 90.27it/s]\u001b[A\n",
      " 84%|████████▍ | 51262/61028 [10:10<01:48, 89.73it/s]\u001b[A\n",
      " 84%|████████▍ | 51272/61028 [10:10<01:47, 90.52it/s]\u001b[A\n",
      " 84%|████████▍ | 51282/61028 [10:10<01:48, 90.12it/s]\u001b[A\n",
      " 84%|████████▍ | 51292/61028 [10:10<01:50, 87.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 51302/61028 [10:10<01:50, 88.28it/s]\u001b[A\n",
      " 84%|████████▍ | 51312/61028 [10:10<01:47, 90.66it/s]\u001b[A\n",
      " 84%|████████▍ | 51323/61028 [10:10<01:42, 95.10it/s]\u001b[A\n",
      " 84%|████████▍ | 51334/61028 [10:10<01:37, 98.93it/s]\u001b[A\n",
      " 84%|████████▍ | 51345/61028 [10:11<01:38, 97.83it/s]\u001b[A\n",
      " 84%|████████▍ | 51355/61028 [10:11<01:39, 96.95it/s]\u001b[A\n",
      " 84%|████████▍ | 51365/61028 [10:11<01:38, 97.82it/s]\u001b[A\n",
      " 84%|████████▍ | 51376/61028 [10:11<01:36, 100.36it/s]\u001b[A\n",
      " 84%|████████▍ | 51387/61028 [10:11<01:47, 89.94it/s] \u001b[A\n",
      " 84%|████████▍ | 51397/61028 [10:11<01:46, 90.33it/s]\u001b[A\n",
      " 84%|████████▍ | 51409/61028 [10:11<01:41, 95.00it/s]\u001b[A\n",
      " 84%|████████▍ | 51419/61028 [10:11<01:42, 93.60it/s]\u001b[A\n",
      " 84%|████████▍ | 51429/61028 [10:11<01:44, 91.76it/s]\u001b[A\n",
      " 84%|████████▍ | 51439/61028 [10:12<01:42, 93.69it/s]\u001b[A\n",
      " 84%|████████▍ | 51450/61028 [10:12<01:39, 96.61it/s]\u001b[A\n",
      " 84%|████████▍ | 51461/61028 [10:12<01:36, 99.07it/s]\u001b[A\n",
      " 84%|████████▍ | 51471/61028 [10:12<01:37, 97.61it/s]\u001b[A\n",
      " 84%|████████▍ | 51481/61028 [10:12<02:49, 56.21it/s]\u001b[A\n",
      " 84%|████████▍ | 51490/61028 [10:12<02:32, 62.72it/s]\u001b[A\n",
      " 84%|████████▍ | 51500/61028 [10:12<02:16, 69.62it/s]\u001b[A\n",
      " 84%|████████▍ | 51509/61028 [10:13<02:08, 74.37it/s]\u001b[A\n",
      " 84%|████████▍ | 51519/61028 [10:13<01:59, 79.49it/s]\u001b[A\n",
      " 84%|████████▍ | 51530/61028 [10:13<01:50, 85.65it/s]\u001b[A\n",
      " 84%|████████▍ | 51541/61028 [10:13<01:46, 88.99it/s]\u001b[A\n",
      " 84%|████████▍ | 51551/61028 [10:13<01:44, 90.30it/s]\u001b[A\n",
      " 84%|████████▍ | 51562/61028 [10:13<01:39, 94.74it/s]\u001b[A\n",
      " 85%|████████▍ | 51574/61028 [10:13<01:35, 98.81it/s]\u001b[A\n",
      " 85%|████████▍ | 51585/61028 [10:13<01:37, 97.02it/s]\u001b[A\n",
      " 85%|████████▍ | 51596/61028 [10:13<01:36, 97.32it/s]\u001b[A\n",
      " 85%|████████▍ | 51606/61028 [10:14<01:37, 96.68it/s]\u001b[A\n",
      " 85%|████████▍ | 51618/61028 [10:14<01:33, 100.96it/s]\u001b[A\n",
      " 85%|████████▍ | 51629/61028 [10:14<01:35, 98.73it/s] \u001b[A\n",
      " 85%|████████▍ | 51639/61028 [10:14<01:36, 97.52it/s]\u001b[A\n",
      " 85%|████████▍ | 51650/61028 [10:14<01:34, 99.49it/s]\u001b[A\n",
      " 85%|████████▍ | 51661/61028 [10:14<01:35, 98.42it/s]\u001b[A\n",
      " 85%|████████▍ | 51671/61028 [10:14<01:37, 95.81it/s]\u001b[A\n",
      " 85%|████████▍ | 51681/61028 [10:14<01:38, 94.93it/s]\u001b[A\n",
      " 85%|████████▍ | 51692/61028 [10:14<01:34, 98.52it/s]\u001b[A\n",
      " 85%|████████▍ | 51702/61028 [10:15<01:35, 97.66it/s]\u001b[A\n",
      " 85%|████████▍ | 51712/61028 [10:15<01:36, 96.93it/s]\u001b[A\n",
      " 85%|████████▍ | 51725/61028 [10:15<01:29, 103.64it/s]\u001b[A\n",
      " 85%|████████▍ | 51736/61028 [10:15<01:29, 103.94it/s]\u001b[A\n",
      " 85%|████████▍ | 51747/61028 [10:15<01:35, 96.83it/s] \u001b[A\n",
      " 85%|████████▍ | 51758/61028 [10:15<01:34, 98.50it/s]\u001b[A\n",
      " 85%|████████▍ | 51768/61028 [10:15<01:34, 97.56it/s]\u001b[A\n",
      " 85%|████████▍ | 51778/61028 [10:15<01:35, 97.33it/s]\u001b[A\n",
      " 85%|████████▍ | 51788/61028 [10:15<01:36, 95.76it/s]\u001b[A\n",
      " 85%|████████▍ | 51800/61028 [10:15<01:32, 100.05it/s]\u001b[A\n",
      " 85%|████████▍ | 51811/61028 [10:16<01:34, 97.90it/s] \u001b[A\n",
      " 85%|████████▍ | 51821/61028 [10:16<01:38, 93.27it/s]\u001b[A\n",
      " 85%|████████▍ | 51831/61028 [10:16<01:39, 92.12it/s]\u001b[A\n",
      " 85%|████████▍ | 51841/61028 [10:16<01:43, 88.99it/s]\u001b[A\n",
      " 85%|████████▍ | 51852/61028 [10:16<01:37, 93.75it/s]\u001b[A\n",
      " 85%|████████▍ | 51862/61028 [10:16<01:37, 93.70it/s]\u001b[A\n",
      " 85%|████████▍ | 51872/61028 [10:16<01:39, 91.56it/s]\u001b[A\n",
      " 85%|████████▌ | 51884/61028 [10:16<01:32, 98.33it/s]\u001b[A\n",
      " 85%|████████▌ | 51895/61028 [10:16<01:32, 98.73it/s]\u001b[A\n",
      " 85%|████████▌ | 51906/61028 [10:17<01:33, 97.69it/s]\u001b[A\n",
      " 85%|████████▌ | 51918/61028 [10:17<01:29, 102.13it/s]\u001b[A\n",
      " 85%|████████▌ | 51929/61028 [10:17<01:34, 96.25it/s] \u001b[A\n",
      " 85%|████████▌ | 51939/61028 [10:17<01:35, 95.50it/s]\u001b[A\n",
      " 85%|████████▌ | 51949/61028 [10:17<01:43, 87.43it/s]\u001b[A\n",
      " 85%|████████▌ | 51958/61028 [10:17<02:49, 53.43it/s]\u001b[A\n",
      " 85%|████████▌ | 51968/61028 [10:18<02:28, 60.96it/s]\u001b[A\n",
      " 85%|████████▌ | 51979/61028 [10:18<02:09, 69.76it/s]\u001b[A\n",
      " 85%|████████▌ | 51990/61028 [10:18<01:56, 77.80it/s]\u001b[A\n",
      " 85%|████████▌ | 52000/61028 [10:18<01:48, 83.14it/s]\u001b[A\n",
      " 85%|████████▌ | 52011/61028 [10:18<01:42, 88.19it/s]\u001b[A\n",
      " 85%|████████▌ | 52021/61028 [10:18<01:39, 90.54it/s]\u001b[A\n",
      " 85%|████████▌ | 52034/61028 [10:18<01:31, 97.80it/s]\u001b[A\n",
      " 85%|████████▌ | 52045/61028 [10:18<01:33, 96.42it/s]\u001b[A\n",
      " 85%|████████▌ | 52056/61028 [10:18<01:34, 95.33it/s]\u001b[A\n",
      " 85%|████████▌ | 52067/61028 [10:18<01:30, 98.84it/s]\u001b[A\n",
      " 85%|████████▌ | 52078/61028 [10:19<01:37, 91.84it/s]\u001b[A\n",
      " 85%|████████▌ | 52088/61028 [10:19<01:37, 91.95it/s]\u001b[A\n",
      " 85%|████████▌ | 52098/61028 [10:19<01:35, 93.20it/s]\u001b[A\n",
      " 85%|████████▌ | 52108/61028 [10:19<01:37, 91.86it/s]\u001b[A\n",
      " 85%|████████▌ | 52118/61028 [10:19<01:36, 91.99it/s]\u001b[A\n",
      " 85%|████████▌ | 52128/61028 [10:19<01:35, 93.32it/s]\u001b[A\n",
      " 85%|████████▌ | 52138/61028 [10:19<01:34, 94.40it/s]\u001b[A\n",
      " 85%|████████▌ | 52148/61028 [10:19<01:38, 90.06it/s]\u001b[A\n",
      " 85%|████████▌ | 52158/61028 [10:20<01:38, 89.78it/s]\u001b[A\n",
      " 85%|████████▌ | 52168/61028 [10:20<01:38, 89.82it/s]\u001b[A\n",
      " 85%|████████▌ | 52178/61028 [10:20<01:36, 92.15it/s]\u001b[A\n",
      " 86%|████████▌ | 52190/61028 [10:20<01:31, 96.99it/s]\u001b[A\n",
      " 86%|████████▌ | 52200/61028 [10:20<01:31, 96.67it/s]\u001b[A\n",
      " 86%|████████▌ | 52210/61028 [10:20<01:30, 97.30it/s]\u001b[A\n",
      " 86%|████████▌ | 52220/61028 [10:20<01:31, 95.79it/s]\u001b[A\n",
      " 86%|████████▌ | 52230/61028 [10:20<01:31, 96.22it/s]\u001b[A\n",
      " 86%|████████▌ | 52240/61028 [10:20<01:31, 95.77it/s]\u001b[A\n",
      " 86%|████████▌ | 52250/61028 [10:20<01:33, 94.23it/s]\u001b[A\n",
      " 86%|████████▌ | 52260/61028 [10:21<01:33, 93.94it/s]\u001b[A\n",
      " 86%|████████▌ | 52270/61028 [10:21<01:35, 91.66it/s]\u001b[A\n",
      " 86%|████████▌ | 52280/61028 [10:21<01:33, 93.72it/s]\u001b[A\n",
      " 86%|████████▌ | 52291/61028 [10:21<01:32, 94.96it/s]\u001b[A\n",
      " 86%|████████▌ | 52301/61028 [10:21<01:38, 88.16it/s]\u001b[A\n",
      " 86%|████████▌ | 52311/61028 [10:21<01:39, 87.20it/s]\u001b[A\n",
      " 86%|████████▌ | 52320/61028 [10:21<01:44, 82.98it/s]\u001b[A\n",
      " 86%|████████▌ | 52329/61028 [10:21<01:51, 77.75it/s]\u001b[A\n",
      " 86%|████████▌ | 52339/61028 [10:22<01:47, 81.17it/s]\u001b[A\n",
      " 86%|████████▌ | 52349/61028 [10:22<01:41, 85.60it/s]\u001b[A\n",
      " 86%|████████▌ | 52359/61028 [10:22<01:40, 86.33it/s]\u001b[A\n",
      " 86%|████████▌ | 52368/61028 [10:22<01:39, 87.30it/s]\u001b[A\n",
      " 86%|████████▌ | 52377/61028 [10:22<01:39, 87.15it/s]\u001b[A\n",
      " 86%|████████▌ | 52388/61028 [10:22<01:34, 91.85it/s]\u001b[A\n",
      " 86%|████████▌ | 52398/61028 [10:22<01:34, 91.45it/s]\u001b[A\n",
      " 86%|████████▌ | 52408/61028 [10:23<02:47, 51.51it/s]\u001b[A\n",
      " 86%|████████▌ | 52419/61028 [10:23<02:20, 61.18it/s]\u001b[A\n",
      " 86%|████████▌ | 52431/61028 [10:23<02:00, 71.17it/s]\u001b[A\n",
      " 86%|████████▌ | 52441/61028 [10:23<01:53, 75.42it/s]\u001b[A\n",
      " 86%|████████▌ | 52451/61028 [10:23<01:49, 78.17it/s]\u001b[A\n",
      " 86%|████████▌ | 52464/61028 [10:23<01:37, 87.46it/s]\u001b[A\n",
      " 86%|████████▌ | 52474/61028 [10:23<01:36, 88.94it/s]\u001b[A\n",
      " 86%|████████▌ | 52485/61028 [10:23<01:32, 92.66it/s]\u001b[A\n",
      " 86%|████████▌ | 52495/61028 [10:23<01:37, 87.21it/s]\u001b[A\n",
      " 86%|████████▌ | 52505/61028 [10:24<01:36, 88.76it/s]\u001b[A\n",
      " 86%|████████▌ | 52515/61028 [10:24<01:33, 91.42it/s]\u001b[A\n",
      " 86%|████████▌ | 52525/61028 [10:24<01:33, 91.36it/s]\u001b[A\n",
      " 86%|████████▌ | 52536/61028 [10:24<01:29, 95.02it/s]\u001b[A\n",
      " 86%|████████▌ | 52546/61028 [10:24<01:30, 93.89it/s]\u001b[A\n",
      " 86%|████████▌ | 52558/61028 [10:24<01:25, 99.11it/s]\u001b[A\n",
      " 86%|████████▌ | 52569/61028 [10:24<01:23, 101.16it/s]\u001b[A\n",
      " 86%|████████▌ | 52581/61028 [10:24<01:20, 104.57it/s]\u001b[A\n",
      " 86%|████████▌ | 52592/61028 [10:24<01:26, 98.05it/s] \u001b[A\n",
      " 86%|████████▌ | 52605/61028 [10:25<01:20, 104.72it/s]\u001b[A\n",
      " 86%|████████▌ | 52617/61028 [10:25<01:17, 108.17it/s]\u001b[A\n",
      " 86%|████████▌ | 52629/61028 [10:25<01:19, 106.20it/s]\u001b[A\n",
      " 86%|████████▋ | 52640/61028 [10:25<01:20, 104.18it/s]\u001b[A\n",
      " 86%|████████▋ | 52651/61028 [10:25<01:23, 99.89it/s] \u001b[A\n",
      " 86%|████████▋ | 52662/61028 [10:25<01:26, 97.18it/s]\u001b[A\n",
      " 86%|████████▋ | 52672/61028 [10:25<01:26, 96.55it/s]\u001b[A\n",
      " 86%|████████▋ | 52683/61028 [10:25<01:23, 99.75it/s]\u001b[A\n",
      " 86%|████████▋ | 52694/61028 [10:25<01:21, 102.56it/s]\u001b[A\n",
      " 86%|████████▋ | 52705/61028 [10:26<01:27, 94.77it/s] \u001b[A\n",
      " 86%|████████▋ | 52717/61028 [10:26<01:24, 98.93it/s]\u001b[A\n",
      " 86%|████████▋ | 52730/61028 [10:26<01:18, 105.28it/s]\u001b[A\n",
      " 86%|████████▋ | 52741/61028 [10:26<01:19, 104.54it/s]\u001b[A\n",
      " 86%|████████▋ | 52752/61028 [10:26<01:20, 102.88it/s]\u001b[A\n",
      " 86%|████████▋ | 52763/61028 [10:26<01:23, 99.38it/s] \u001b[A\n",
      " 86%|████████▋ | 52774/61028 [10:26<01:33, 88.35it/s]\u001b[A\n",
      " 86%|████████▋ | 52786/61028 [10:26<01:28, 93.61it/s]\u001b[A\n",
      " 87%|████████▋ | 52796/61028 [10:26<01:26, 95.18it/s]\u001b[A\n",
      " 87%|████████▋ | 52806/61028 [10:27<01:26, 94.89it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 52818/61028 [10:27<01:21, 100.43it/s]\u001b[A\n",
      " 87%|████████▋ | 52829/61028 [10:27<01:22, 99.84it/s] \u001b[A\n",
      " 87%|████████▋ | 52841/61028 [10:27<01:20, 101.68it/s]\u001b[A\n",
      " 87%|████████▋ | 52852/61028 [10:27<01:19, 103.11it/s]\u001b[A\n",
      " 87%|████████▋ | 52863/61028 [10:27<01:17, 104.70it/s]\u001b[A\n",
      " 87%|████████▋ | 52874/61028 [10:27<01:17, 105.71it/s]\u001b[A\n",
      " 87%|████████▋ | 52886/61028 [10:27<01:19, 102.30it/s]\u001b[A\n",
      " 87%|████████▋ | 52897/61028 [10:28<02:17, 59.14it/s] \u001b[A\n",
      " 87%|████████▋ | 52907/61028 [10:28<02:02, 66.26it/s]\u001b[A\n",
      " 87%|████████▋ | 52917/61028 [10:28<01:50, 73.41it/s]\u001b[A\n",
      " 87%|████████▋ | 52926/61028 [10:28<01:47, 75.09it/s]\u001b[A\n",
      " 87%|████████▋ | 52935/61028 [10:28<01:43, 78.00it/s]\u001b[A\n",
      " 87%|████████▋ | 52944/61028 [10:28<01:39, 81.24it/s]\u001b[A\n",
      " 87%|████████▋ | 52956/61028 [10:28<01:31, 87.86it/s]\u001b[A\n",
      " 87%|████████▋ | 52966/61028 [10:28<01:34, 85.30it/s]\u001b[A\n",
      " 87%|████████▋ | 52975/61028 [10:29<01:33, 86.24it/s]\u001b[A\n",
      " 87%|████████▋ | 52984/61028 [10:29<01:33, 86.23it/s]\u001b[A\n",
      " 87%|████████▋ | 52994/61028 [10:29<01:30, 88.34it/s]\u001b[A\n",
      " 87%|████████▋ | 53004/61028 [10:29<01:27, 91.52it/s]\u001b[A\n",
      " 87%|████████▋ | 53014/61028 [10:29<01:26, 93.00it/s]\u001b[A\n",
      " 87%|████████▋ | 53024/61028 [10:29<01:27, 91.95it/s]\u001b[A\n",
      " 87%|████████▋ | 53034/61028 [10:29<01:31, 87.68it/s]\u001b[A\n",
      " 87%|████████▋ | 53043/61028 [10:29<01:34, 84.74it/s]\u001b[A\n",
      " 87%|████████▋ | 53054/61028 [10:29<01:29, 88.68it/s]\u001b[A\n",
      " 87%|████████▋ | 53064/61028 [10:30<01:27, 91.44it/s]\u001b[A\n",
      " 87%|████████▋ | 53074/61028 [10:30<01:27, 90.98it/s]\u001b[A\n",
      " 87%|████████▋ | 53084/61028 [10:30<01:26, 92.34it/s]\u001b[A\n",
      " 87%|████████▋ | 53094/61028 [10:30<01:25, 92.79it/s]\u001b[A\n",
      " 87%|████████▋ | 53105/61028 [10:30<01:22, 96.00it/s]\u001b[A\n",
      " 87%|████████▋ | 53115/61028 [10:30<01:21, 97.03it/s]\u001b[A\n",
      " 87%|████████▋ | 53125/61028 [10:30<01:28, 89.65it/s]\u001b[A\n",
      " 87%|████████▋ | 53136/61028 [10:30<01:24, 93.87it/s]\u001b[A\n",
      " 87%|████████▋ | 53147/61028 [10:30<01:21, 96.33it/s]\u001b[A\n",
      " 87%|████████▋ | 53157/61028 [10:31<01:25, 91.63it/s]\u001b[A\n",
      " 87%|████████▋ | 53167/61028 [10:31<01:26, 91.23it/s]\u001b[A\n",
      " 87%|████████▋ | 53177/61028 [10:31<01:28, 89.00it/s]\u001b[A\n",
      " 87%|████████▋ | 53187/61028 [10:31<01:26, 90.61it/s]\u001b[A\n",
      " 87%|████████▋ | 53198/61028 [10:31<01:22, 94.43it/s]\u001b[A\n",
      " 87%|████████▋ | 53208/61028 [10:31<01:23, 93.51it/s]\u001b[A\n",
      " 87%|████████▋ | 53218/61028 [10:31<01:26, 90.05it/s]\u001b[A\n",
      " 87%|████████▋ | 53228/61028 [10:31<01:30, 85.73it/s]\u001b[A\n",
      " 87%|████████▋ | 53238/61028 [10:31<01:27, 88.88it/s]\u001b[A\n",
      " 87%|████████▋ | 53249/61028 [10:32<01:23, 93.22it/s]\u001b[A\n",
      " 87%|████████▋ | 53259/61028 [10:32<01:23, 93.55it/s]\u001b[A\n",
      " 87%|████████▋ | 53269/61028 [10:32<01:23, 92.86it/s]\u001b[A\n",
      " 87%|████████▋ | 53281/61028 [10:32<01:18, 98.13it/s]\u001b[A\n",
      " 87%|████████▋ | 53293/61028 [10:32<01:16, 101.63it/s]\u001b[A\n",
      " 87%|████████▋ | 53304/61028 [10:32<01:16, 100.40it/s]\u001b[A\n",
      " 87%|████████▋ | 53316/61028 [10:32<01:14, 104.20it/s]\u001b[A\n",
      " 87%|████████▋ | 53327/61028 [10:32<01:15, 102.23it/s]\u001b[A\n",
      " 87%|████████▋ | 53338/61028 [10:32<01:15, 101.68it/s]\u001b[A\n",
      " 87%|████████▋ | 53349/61028 [10:33<02:12, 57.85it/s] \u001b[A\n",
      " 87%|████████▋ | 53361/61028 [10:33<01:53, 67.67it/s]\u001b[A\n",
      " 87%|████████▋ | 53372/61028 [10:33<01:41, 75.47it/s]\u001b[A\n",
      " 87%|████████▋ | 53383/61028 [10:33<01:33, 81.52it/s]\u001b[A\n",
      " 87%|████████▋ | 53394/61028 [10:33<01:27, 86.90it/s]\u001b[A\n",
      " 88%|████████▊ | 53404/61028 [10:33<01:24, 90.05it/s]\u001b[A\n",
      " 88%|████████▊ | 53414/61028 [10:33<01:23, 90.72it/s]\u001b[A\n",
      " 88%|████████▊ | 53424/61028 [10:34<01:22, 92.28it/s]\u001b[A\n",
      " 88%|████████▊ | 53434/61028 [10:34<01:20, 94.18it/s]\u001b[A\n",
      " 88%|████████▊ | 53445/61028 [10:34<01:17, 97.74it/s]\u001b[A\n",
      " 88%|████████▊ | 53456/61028 [10:34<01:21, 93.33it/s]\u001b[A\n",
      " 88%|████████▊ | 53466/61028 [10:34<01:20, 94.18it/s]\u001b[A\n",
      " 88%|████████▊ | 53478/61028 [10:34<01:16, 98.38it/s]\u001b[A\n",
      " 88%|████████▊ | 53488/61028 [10:34<01:17, 97.50it/s]\u001b[A\n",
      " 88%|████████▊ | 53499/61028 [10:34<01:15, 99.63it/s]\u001b[A\n",
      " 88%|████████▊ | 53511/61028 [10:34<01:12, 104.25it/s]\u001b[A\n",
      " 88%|████████▊ | 53522/61028 [10:34<01:10, 105.76it/s]\u001b[A\n",
      " 88%|████████▊ | 53533/61028 [10:35<01:11, 105.11it/s]\u001b[A\n",
      " 88%|████████▊ | 53544/61028 [10:35<01:14, 100.21it/s]\u001b[A\n",
      " 88%|████████▊ | 53555/61028 [10:35<01:16, 98.15it/s] \u001b[A\n",
      " 88%|████████▊ | 53565/61028 [10:35<01:19, 94.35it/s]\u001b[A\n",
      " 88%|████████▊ | 53575/61028 [10:35<01:18, 94.76it/s]\u001b[A\n",
      " 88%|████████▊ | 53585/61028 [10:35<01:20, 92.60it/s]\u001b[A\n",
      " 88%|████████▊ | 53595/61028 [10:35<01:20, 92.09it/s]\u001b[A\n",
      " 88%|████████▊ | 53606/61028 [10:35<01:18, 94.60it/s]\u001b[A\n",
      " 88%|████████▊ | 53616/61028 [10:35<01:17, 95.28it/s]\u001b[A\n",
      " 88%|████████▊ | 53626/61028 [10:36<01:18, 94.28it/s]\u001b[A\n",
      " 88%|████████▊ | 53638/61028 [10:36<01:14, 98.65it/s]\u001b[A\n",
      " 88%|████████▊ | 53648/61028 [10:36<01:17, 95.18it/s]\u001b[A\n",
      " 88%|████████▊ | 53659/61028 [10:36<01:15, 96.98it/s]\u001b[A\n",
      " 88%|████████▊ | 53670/61028 [10:36<01:14, 98.62it/s]\u001b[A\n",
      " 88%|████████▊ | 53680/61028 [10:36<01:20, 91.78it/s]\u001b[A\n",
      " 88%|████████▊ | 53690/61028 [10:36<01:28, 83.06it/s]\u001b[A\n",
      " 88%|████████▊ | 53699/61028 [10:36<01:28, 82.99it/s]\u001b[A\n",
      " 88%|████████▊ | 53710/61028 [10:37<01:22, 88.18it/s]\u001b[A\n",
      " 88%|████████▊ | 53720/61028 [10:37<01:29, 81.61it/s]\u001b[A\n",
      " 88%|████████▊ | 53730/61028 [10:37<01:25, 85.50it/s]\u001b[A\n",
      " 88%|████████▊ | 53741/61028 [10:37<01:20, 90.70it/s]\u001b[A\n",
      " 88%|████████▊ | 53751/61028 [10:37<01:20, 90.02it/s]\u001b[A\n",
      " 88%|████████▊ | 53763/61028 [10:37<01:15, 96.80it/s]\u001b[A\n",
      " 88%|████████▊ | 53774/61028 [10:37<01:14, 97.42it/s]\u001b[A\n",
      " 88%|████████▊ | 53784/61028 [10:37<01:13, 97.99it/s]\u001b[A\n",
      " 88%|████████▊ | 53794/61028 [10:37<01:17, 93.52it/s]\u001b[A\n",
      " 88%|████████▊ | 53804/61028 [10:38<01:22, 87.04it/s]\u001b[A\n",
      " 88%|████████▊ | 53813/61028 [10:38<02:22, 50.64it/s]\u001b[A\n",
      " 88%|████████▊ | 53823/61028 [10:38<02:03, 58.57it/s]\u001b[A\n",
      " 88%|████████▊ | 53832/61028 [10:38<01:52, 63.92it/s]\u001b[A\n",
      " 88%|████████▊ | 53840/61028 [10:38<01:45, 67.96it/s]\u001b[A\n",
      " 88%|████████▊ | 53849/61028 [10:38<01:37, 73.33it/s]\u001b[A\n",
      " 88%|████████▊ | 53860/61028 [10:38<01:28, 80.54it/s]\u001b[A\n",
      " 88%|████████▊ | 53872/61028 [10:39<01:20, 89.24it/s]\u001b[A\n",
      " 88%|████████▊ | 53882/61028 [10:39<01:19, 90.40it/s]\u001b[A\n",
      " 88%|████████▊ | 53892/61028 [10:39<01:20, 88.88it/s]\u001b[A\n",
      " 88%|████████▊ | 53903/61028 [10:39<01:18, 91.12it/s]\u001b[A\n",
      " 88%|████████▊ | 53914/61028 [10:39<01:14, 95.83it/s]\u001b[A\n",
      " 88%|████████▊ | 53924/61028 [10:39<01:17, 91.93it/s]\u001b[A\n",
      " 88%|████████▊ | 53935/61028 [10:39<01:13, 96.16it/s]\u001b[A\n",
      " 88%|████████▊ | 53946/61028 [10:39<01:12, 97.68it/s]\u001b[A\n",
      " 88%|████████▊ | 53956/61028 [10:39<01:12, 97.80it/s]\u001b[A\n",
      " 88%|████████▊ | 53966/61028 [10:39<01:12, 97.55it/s]\u001b[A\n",
      " 88%|████████▊ | 53976/61028 [10:40<01:14, 95.11it/s]\u001b[A\n",
      " 88%|████████▊ | 53988/61028 [10:40<01:10, 99.52it/s]\u001b[A\n",
      " 88%|████████▊ | 53999/61028 [10:40<01:10, 99.83it/s]\u001b[A\n",
      " 89%|████████▊ | 54010/61028 [10:40<01:08, 102.55it/s]\u001b[A\n",
      " 89%|████████▊ | 54022/61028 [10:40<01:06, 105.65it/s]\u001b[A\n",
      " 89%|████████▊ | 54033/61028 [10:40<01:12, 95.88it/s] \u001b[A\n",
      " 89%|████████▊ | 54043/61028 [10:40<01:14, 93.97it/s]\u001b[A\n",
      " 89%|████████▊ | 54053/61028 [10:40<01:14, 93.22it/s]\u001b[A\n",
      " 89%|████████▊ | 54064/61028 [10:40<01:12, 96.52it/s]\u001b[A\n",
      " 89%|████████▊ | 54075/61028 [10:41<01:10, 98.23it/s]\u001b[A\n",
      " 89%|████████▊ | 54086/61028 [10:41<01:10, 98.72it/s]\u001b[A\n",
      " 89%|████████▊ | 54098/61028 [10:41<01:07, 102.45it/s]\u001b[A\n",
      " 89%|████████▊ | 54109/61028 [10:41<01:16, 90.54it/s] \u001b[A\n",
      " 89%|████████▊ | 54120/61028 [10:41<01:14, 92.60it/s]\u001b[A\n",
      " 89%|████████▊ | 54130/61028 [10:41<01:23, 82.19it/s]\u001b[A\n",
      " 89%|████████▊ | 54139/61028 [10:41<01:24, 81.80it/s]\u001b[A\n",
      " 89%|████████▊ | 54150/61028 [10:41<01:19, 86.72it/s]\u001b[A\n",
      " 89%|████████▊ | 54160/61028 [10:42<01:16, 89.28it/s]\u001b[A\n",
      " 89%|████████▉ | 54170/61028 [10:42<01:14, 92.11it/s]\u001b[A\n",
      " 89%|████████▉ | 54181/61028 [10:42<01:12, 94.23it/s]\u001b[A\n",
      " 89%|████████▉ | 54191/61028 [10:42<01:11, 95.84it/s]\u001b[A\n",
      " 89%|████████▉ | 54202/61028 [10:42<01:08, 98.97it/s]\u001b[A\n",
      " 89%|████████▉ | 54212/61028 [10:42<01:09, 98.63it/s]\u001b[A\n",
      " 89%|████████▉ | 54225/61028 [10:42<01:04, 105.09it/s]\u001b[A\n",
      " 89%|████████▉ | 54236/61028 [10:42<01:04, 104.98it/s]\u001b[A\n",
      " 89%|████████▉ | 54247/61028 [10:42<01:09, 97.41it/s] \u001b[A\n",
      " 89%|████████▉ | 54258/61028 [10:43<01:07, 100.64it/s]\u001b[A\n",
      " 89%|████████▉ | 54269/61028 [10:43<01:08, 99.32it/s] \u001b[A\n",
      " 89%|████████▉ | 54280/61028 [10:43<01:54, 58.98it/s]\u001b[A\n",
      " 89%|████████▉ | 54291/61028 [10:43<01:38, 68.44it/s]\u001b[A\n",
      " 89%|████████▉ | 54301/61028 [10:43<01:30, 74.16it/s]\u001b[A\n",
      " 89%|████████▉ | 54312/61028 [10:43<01:22, 81.58it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 54322/61028 [10:43<01:17, 86.28it/s]\u001b[A\n",
      " 89%|████████▉ | 54334/61028 [10:44<01:12, 91.89it/s]\u001b[A\n",
      " 89%|████████▉ | 54344/61028 [10:44<01:13, 90.77it/s]\u001b[A\n",
      " 89%|████████▉ | 54355/61028 [10:44<01:10, 94.61it/s]\u001b[A\n",
      " 89%|████████▉ | 54366/61028 [10:44<01:08, 97.44it/s]\u001b[A\n",
      " 89%|████████▉ | 54377/61028 [10:44<01:07, 98.12it/s]\u001b[A\n",
      " 89%|████████▉ | 54389/61028 [10:44<01:04, 102.50it/s]\u001b[A\n",
      " 89%|████████▉ | 54400/61028 [10:44<01:03, 103.71it/s]\u001b[A\n",
      " 89%|████████▉ | 54411/61028 [10:44<01:05, 100.72it/s]\u001b[A\n",
      " 89%|████████▉ | 54422/61028 [10:44<01:05, 101.19it/s]\u001b[A\n",
      " 89%|████████▉ | 54433/61028 [10:45<01:08, 96.73it/s] \u001b[A\n",
      " 89%|████████▉ | 54443/61028 [10:45<01:07, 97.30it/s]\u001b[A\n",
      " 89%|████████▉ | 54454/61028 [10:45<01:07, 97.92it/s]\u001b[A\n",
      " 89%|████████▉ | 54467/61028 [10:45<01:02, 104.51it/s]\u001b[A\n",
      " 89%|████████▉ | 54478/61028 [10:45<01:05, 99.74it/s] \u001b[A\n",
      " 89%|████████▉ | 54490/61028 [10:45<01:03, 103.64it/s]\u001b[A\n",
      " 89%|████████▉ | 54501/61028 [10:45<01:03, 102.28it/s]\u001b[A\n",
      " 89%|████████▉ | 54512/61028 [10:45<01:03, 102.03it/s]\u001b[A\n",
      " 89%|████████▉ | 54523/61028 [10:45<01:05, 100.05it/s]\u001b[A\n",
      " 89%|████████▉ | 54534/61028 [10:46<01:07, 95.65it/s] \u001b[A\n",
      " 89%|████████▉ | 54544/61028 [10:46<01:11, 90.68it/s]\u001b[A\n",
      " 89%|████████▉ | 54555/61028 [10:46<01:09, 93.03it/s]\u001b[A\n",
      " 89%|████████▉ | 54565/61028 [10:46<01:08, 94.70it/s]\u001b[A\n",
      " 89%|████████▉ | 54576/61028 [10:46<01:07, 95.87it/s]\u001b[A\n",
      " 89%|████████▉ | 54586/61028 [10:46<01:13, 88.08it/s]\u001b[A\n",
      " 89%|████████▉ | 54595/61028 [10:46<01:14, 86.72it/s]\u001b[A\n",
      " 89%|████████▉ | 54606/61028 [10:46<01:10, 91.64it/s]\u001b[A\n",
      " 89%|████████▉ | 54616/61028 [10:46<01:09, 92.11it/s]\u001b[A\n",
      " 90%|████████▉ | 54626/61028 [10:47<01:07, 94.22it/s]\u001b[A\n",
      " 90%|████████▉ | 54636/61028 [10:47<01:07, 94.81it/s]\u001b[A\n",
      " 90%|████████▉ | 54647/61028 [10:47<01:05, 96.93it/s]\u001b[A\n",
      " 90%|████████▉ | 54657/61028 [10:47<01:09, 92.23it/s]\u001b[A\n",
      " 90%|████████▉ | 54668/61028 [10:47<01:05, 96.44it/s]\u001b[A\n",
      " 90%|████████▉ | 54679/61028 [10:47<01:03, 99.48it/s]\u001b[A\n",
      " 90%|████████▉ | 54690/61028 [10:47<01:03, 99.22it/s]\u001b[A\n",
      " 90%|████████▉ | 54700/61028 [10:47<01:04, 98.67it/s]\u001b[A\n",
      " 90%|████████▉ | 54710/61028 [10:47<01:05, 96.12it/s]\u001b[A\n",
      " 90%|████████▉ | 54720/61028 [10:47<01:05, 96.78it/s]\u001b[A\n",
      " 90%|████████▉ | 54731/61028 [10:48<01:04, 97.94it/s]\u001b[A\n",
      " 90%|████████▉ | 54742/61028 [10:48<01:02, 99.84it/s]\u001b[A\n",
      " 90%|████████▉ | 54753/61028 [10:48<01:48, 58.10it/s]\u001b[A\n",
      " 90%|████████▉ | 54763/61028 [10:48<01:34, 66.31it/s]\u001b[A\n",
      " 90%|████████▉ | 54772/61028 [10:48<01:28, 70.65it/s]\u001b[A\n",
      " 90%|████████▉ | 54783/61028 [10:48<01:19, 78.51it/s]\u001b[A\n",
      " 90%|████████▉ | 54794/61028 [10:48<01:12, 85.67it/s]\u001b[A\n",
      " 90%|████████▉ | 54804/61028 [10:49<01:10, 88.16it/s]\u001b[A\n",
      " 90%|████████▉ | 54815/61028 [10:49<01:08, 90.78it/s]\u001b[A\n",
      " 90%|████████▉ | 54826/61028 [10:49<01:05, 94.74it/s]\u001b[A\n",
      " 90%|████████▉ | 54836/61028 [10:49<01:04, 96.21it/s]\u001b[A\n",
      " 90%|████████▉ | 54847/61028 [10:49<01:01, 99.91it/s]\u001b[A\n",
      " 90%|████████▉ | 54858/61028 [10:49<01:02, 98.24it/s]\u001b[A\n",
      " 90%|████████▉ | 54869/61028 [10:49<01:05, 94.50it/s]\u001b[A\n",
      " 90%|████████▉ | 54879/61028 [10:49<01:06, 93.16it/s]\u001b[A\n",
      " 90%|████████▉ | 54889/61028 [10:49<01:05, 93.07it/s]\u001b[A\n",
      " 90%|████████▉ | 54900/61028 [10:50<01:04, 95.57it/s]\u001b[A\n",
      " 90%|████████▉ | 54910/61028 [10:50<01:03, 96.42it/s]\u001b[A\n",
      " 90%|████████▉ | 54920/61028 [10:50<01:05, 92.71it/s]\u001b[A\n",
      " 90%|█████████ | 54930/61028 [10:50<01:06, 92.30it/s]\u001b[A\n",
      " 90%|█████████ | 54940/61028 [10:50<01:06, 92.18it/s]\u001b[A\n",
      " 90%|█████████ | 54951/61028 [10:50<01:03, 95.97it/s]\u001b[A\n",
      " 90%|█████████ | 54961/61028 [10:50<01:04, 94.09it/s]\u001b[A\n",
      " 90%|█████████ | 54971/61028 [10:50<01:04, 94.29it/s]\u001b[A\n",
      " 90%|█████████ | 54982/61028 [10:50<01:03, 95.05it/s]\u001b[A\n",
      " 90%|█████████ | 54992/61028 [10:51<01:03, 95.33it/s]\u001b[A\n",
      " 90%|█████████ | 55002/61028 [10:51<01:04, 93.93it/s]\u001b[A\n",
      " 90%|█████████ | 55013/61028 [10:51<01:03, 95.38it/s]\u001b[A\n",
      " 90%|█████████ | 55023/61028 [10:51<01:03, 94.45it/s]\u001b[A\n",
      " 90%|█████████ | 55033/61028 [10:51<01:04, 92.48it/s]\u001b[A\n",
      " 90%|█████████ | 55044/61028 [10:51<01:02, 95.94it/s]\u001b[A\n",
      " 90%|█████████ | 55054/61028 [10:51<01:03, 94.66it/s]\u001b[A\n",
      " 90%|█████████ | 55064/61028 [10:51<01:08, 86.66it/s]\u001b[A\n",
      " 90%|█████████ | 55073/61028 [10:51<01:09, 86.08it/s]\u001b[A\n",
      " 90%|█████████ | 55082/61028 [10:52<01:08, 86.52it/s]\u001b[A\n",
      " 90%|█████████ | 55091/61028 [10:52<01:07, 87.44it/s]\u001b[A\n",
      " 90%|█████████ | 55102/61028 [10:52<01:03, 92.85it/s]\u001b[A\n",
      " 90%|█████████ | 55113/61028 [10:52<01:01, 96.07it/s]\u001b[A\n",
      " 90%|█████████ | 55124/61028 [10:52<01:00, 97.81it/s]\u001b[A\n",
      " 90%|█████████ | 55134/61028 [10:52<01:03, 93.23it/s]\u001b[A\n",
      " 90%|█████████ | 55144/61028 [10:52<01:07, 87.28it/s]\u001b[A\n",
      " 90%|█████████ | 55155/61028 [10:52<01:04, 90.90it/s]\u001b[A\n",
      " 90%|█████████ | 55166/61028 [10:52<01:02, 94.04it/s]\u001b[A\n",
      " 90%|█████████ | 55176/61028 [10:53<01:02, 93.02it/s]\u001b[A\n",
      " 90%|█████████ | 55187/61028 [10:53<01:00, 96.97it/s]\u001b[A\n",
      " 90%|█████████ | 55198/61028 [10:53<00:59, 98.41it/s]\u001b[A\n",
      " 90%|█████████ | 55210/61028 [10:53<00:56, 103.69it/s]\u001b[A\n",
      " 90%|█████████ | 55221/61028 [10:53<01:36, 60.38it/s] \u001b[A\n",
      " 91%|█████████ | 55232/61028 [10:53<01:24, 68.49it/s]\u001b[A\n",
      " 91%|█████████ | 55241/61028 [10:53<01:18, 73.51it/s]\u001b[A\n",
      " 91%|█████████ | 55250/61028 [10:54<01:14, 77.55it/s]\u001b[A\n",
      " 91%|█████████ | 55261/61028 [10:54<01:09, 83.45it/s]\u001b[A\n",
      " 91%|█████████ | 55271/61028 [10:54<01:07, 85.82it/s]\u001b[A\n",
      " 91%|█████████ | 55281/61028 [10:54<01:08, 84.10it/s]\u001b[A\n",
      " 91%|█████████ | 55291/61028 [10:54<01:08, 83.76it/s]\u001b[A\n",
      " 91%|█████████ | 55300/61028 [10:54<01:07, 85.46it/s]\u001b[A\n",
      " 91%|█████████ | 55309/61028 [10:54<01:07, 85.33it/s]\u001b[A\n",
      " 91%|█████████ | 55320/61028 [10:54<01:02, 91.26it/s]\u001b[A\n",
      " 91%|█████████ | 55330/61028 [10:54<01:04, 88.41it/s]\u001b[A\n",
      " 91%|█████████ | 55340/61028 [10:55<01:02, 91.01it/s]\u001b[A\n",
      " 91%|█████████ | 55351/61028 [10:55<01:00, 93.92it/s]\u001b[A\n",
      " 91%|█████████ | 55363/61028 [10:55<00:56, 99.46it/s]\u001b[A\n",
      " 91%|█████████ | 55374/61028 [10:55<01:00, 93.60it/s]\u001b[A\n",
      " 91%|█████████ | 55385/61028 [10:55<00:58, 97.29it/s]\u001b[A\n",
      " 91%|█████████ | 55395/61028 [10:55<00:57, 97.86it/s]\u001b[A\n",
      " 91%|█████████ | 55405/61028 [10:55<00:58, 96.73it/s]\u001b[A\n",
      " 91%|█████████ | 55415/61028 [10:55<00:59, 95.12it/s]\u001b[A\n",
      " 91%|█████████ | 55425/61028 [10:55<01:02, 90.20it/s]\u001b[A\n",
      " 91%|█████████ | 55435/61028 [10:56<01:00, 92.40it/s]\u001b[A\n",
      " 91%|█████████ | 55446/61028 [10:56<00:58, 95.61it/s]\u001b[A\n",
      " 91%|█████████ | 55456/61028 [10:56<00:59, 93.25it/s]\u001b[A\n",
      " 91%|█████████ | 55467/61028 [10:56<00:57, 96.19it/s]\u001b[A\n",
      " 91%|█████████ | 55477/61028 [10:56<00:58, 95.67it/s]\u001b[A\n",
      " 91%|█████████ | 55488/61028 [10:56<00:56, 97.21it/s]\u001b[A\n",
      " 91%|█████████ | 55501/61028 [10:56<00:53, 103.36it/s]\u001b[A\n",
      " 91%|█████████ | 55512/61028 [10:56<00:56, 97.65it/s] \u001b[A\n",
      " 91%|█████████ | 55522/61028 [10:56<01:00, 91.68it/s]\u001b[A\n",
      " 91%|█████████ | 55533/61028 [10:57<00:57, 96.21it/s]\u001b[A\n",
      " 91%|█████████ | 55543/61028 [10:57<00:58, 94.34it/s]\u001b[A\n",
      " 91%|█████████ | 55553/61028 [10:57<00:58, 93.39it/s]\u001b[A\n",
      " 91%|█████████ | 55563/61028 [10:57<00:58, 93.93it/s]\u001b[A\n",
      " 91%|█████████ | 55573/61028 [10:57<00:58, 93.58it/s]\u001b[A\n",
      " 91%|█████████ | 55585/61028 [10:57<00:54, 99.02it/s]\u001b[A\n",
      " 91%|█████████ | 55596/61028 [10:57<00:53, 101.24it/s]\u001b[A\n",
      " 91%|█████████ | 55607/61028 [10:57<00:54, 99.73it/s] \u001b[A\n",
      " 91%|█████████ | 55619/61028 [10:57<00:52, 102.71it/s]\u001b[A\n",
      " 91%|█████████ | 55630/61028 [10:57<00:53, 101.37it/s]\u001b[A\n",
      " 91%|█████████ | 55641/61028 [10:58<00:52, 103.56it/s]\u001b[A\n",
      " 91%|█████████ | 55652/61028 [10:58<00:52, 101.57it/s]\u001b[A\n",
      " 91%|█████████ | 55663/61028 [10:58<00:54, 98.66it/s] \u001b[A\n",
      " 91%|█████████ | 55675/61028 [10:58<00:52, 102.79it/s]\u001b[A\n",
      " 91%|█████████ | 55686/61028 [10:58<01:30, 59.07it/s] \u001b[A\n",
      " 91%|█████████▏| 55697/61028 [10:58<01:19, 67.05it/s]\u001b[A\n",
      " 91%|█████████▏| 55708/61028 [10:59<01:10, 75.66it/s]\u001b[A\n",
      " 91%|█████████▏| 55718/61028 [10:59<01:07, 78.35it/s]\u001b[A\n",
      " 91%|█████████▏| 55730/61028 [10:59<01:01, 85.79it/s]\u001b[A\n",
      " 91%|█████████▏| 55740/61028 [10:59<01:01, 86.59it/s]\u001b[A\n",
      " 91%|█████████▏| 55751/61028 [10:59<00:57, 91.25it/s]\u001b[A\n",
      " 91%|█████████▏| 55761/61028 [10:59<00:57, 91.43it/s]\u001b[A\n",
      " 91%|█████████▏| 55773/61028 [10:59<00:53, 97.43it/s]\u001b[A\n",
      " 91%|█████████▏| 55784/61028 [10:59<00:55, 94.84it/s]\u001b[A\n",
      " 91%|█████████▏| 55794/61028 [10:59<00:55, 94.96it/s]\u001b[A\n",
      " 91%|█████████▏| 55804/61028 [11:00<00:55, 93.87it/s]\u001b[A\n",
      " 91%|█████████▏| 55815/61028 [11:00<00:53, 97.87it/s]\u001b[A\n",
      " 91%|█████████▏| 55825/61028 [11:00<00:54, 95.98it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 55836/61028 [11:00<00:52, 98.02it/s]\u001b[A\n",
      " 92%|█████████▏| 55847/61028 [11:00<00:51, 100.51it/s]\u001b[A\n",
      " 92%|█████████▏| 55858/61028 [11:00<00:52, 99.14it/s] \u001b[A\n",
      " 92%|█████████▏| 55871/61028 [11:00<00:48, 106.05it/s]\u001b[A\n",
      " 92%|█████████▏| 55882/61028 [11:00<00:50, 102.08it/s]\u001b[A\n",
      " 92%|█████████▏| 55893/61028 [11:00<00:50, 101.86it/s]\u001b[A\n",
      " 92%|█████████▏| 55904/61028 [11:00<00:51, 99.53it/s] \u001b[A\n",
      " 92%|█████████▏| 55915/61028 [11:01<00:52, 98.28it/s]\u001b[A\n",
      " 92%|█████████▏| 55927/61028 [11:01<00:51, 99.71it/s]\u001b[A\n",
      " 92%|█████████▏| 55938/61028 [11:01<00:51, 98.21it/s]\u001b[A\n",
      " 92%|█████████▏| 55948/61028 [11:01<00:54, 93.57it/s]\u001b[A\n",
      " 92%|█████████▏| 55958/61028 [11:01<00:53, 94.80it/s]\u001b[A\n",
      " 92%|█████████▏| 55968/61028 [11:01<00:53, 93.99it/s]\u001b[A\n",
      " 92%|█████████▏| 55978/61028 [11:01<00:56, 89.29it/s]\u001b[A\n",
      " 92%|█████████▏| 55988/61028 [11:01<00:57, 87.41it/s]\u001b[A\n",
      " 92%|█████████▏| 56001/61028 [11:02<00:52, 95.44it/s]\u001b[A\n",
      " 92%|█████████▏| 56011/61028 [11:02<00:54, 92.90it/s]\u001b[A\n",
      " 92%|█████████▏| 56022/61028 [11:02<00:51, 96.62it/s]\u001b[A\n",
      " 92%|█████████▏| 56032/61028 [11:02<00:53, 94.16it/s]\u001b[A\n",
      " 92%|█████████▏| 56042/61028 [11:02<00:53, 93.83it/s]\u001b[A\n",
      " 92%|█████████▏| 56055/61028 [11:02<00:49, 101.08it/s]\u001b[A\n",
      " 92%|█████████▏| 56066/61028 [11:02<00:51, 96.66it/s] \u001b[A\n",
      " 92%|█████████▏| 56076/61028 [11:02<00:51, 96.95it/s]\u001b[A\n",
      " 92%|█████████▏| 56086/61028 [11:02<00:53, 92.27it/s]\u001b[A\n",
      " 92%|█████████▏| 56099/61028 [11:03<00:49, 100.45it/s]\u001b[A\n",
      " 92%|█████████▏| 56111/61028 [11:03<00:47, 104.47it/s]\u001b[A\n",
      " 92%|█████████▏| 56122/61028 [11:03<00:49, 98.61it/s] \u001b[A\n",
      " 92%|█████████▏| 56133/61028 [11:03<00:49, 98.06it/s]\u001b[A\n",
      " 92%|█████████▏| 56143/61028 [11:03<00:49, 98.50it/s]\u001b[A\n",
      " 92%|█████████▏| 56153/61028 [11:03<00:51, 94.40it/s]\u001b[A\n",
      " 92%|█████████▏| 56163/61028 [11:03<01:20, 60.62it/s]\u001b[A\n",
      " 92%|█████████▏| 56171/61028 [11:04<01:25, 56.84it/s]\u001b[A\n",
      " 92%|█████████▏| 56182/61028 [11:04<01:13, 65.61it/s]\u001b[A\n",
      " 92%|█████████▏| 56191/61028 [11:04<01:09, 69.62it/s]\u001b[A\n",
      " 92%|█████████▏| 56201/61028 [11:04<01:03, 76.52it/s]\u001b[A\n",
      " 92%|█████████▏| 56211/61028 [11:04<00:58, 81.68it/s]\u001b[A\n",
      " 92%|█████████▏| 56220/61028 [11:04<00:58, 82.86it/s]\u001b[A\n",
      " 92%|█████████▏| 56230/61028 [11:04<00:56, 85.50it/s]\u001b[A\n",
      " 92%|█████████▏| 56239/61028 [11:04<00:58, 82.26it/s]\u001b[A\n",
      " 92%|█████████▏| 56249/61028 [11:04<00:55, 86.30it/s]\u001b[A\n",
      " 92%|█████████▏| 56261/61028 [11:05<00:51, 93.00it/s]\u001b[A\n",
      " 92%|█████████▏| 56273/61028 [11:05<00:48, 98.71it/s]\u001b[A\n",
      " 92%|█████████▏| 56284/61028 [11:05<00:50, 94.07it/s]\u001b[A\n",
      " 92%|█████████▏| 56295/61028 [11:05<00:49, 96.19it/s]\u001b[A\n",
      " 92%|█████████▏| 56305/61028 [11:05<00:50, 94.37it/s]\u001b[A\n",
      " 92%|█████████▏| 56315/61028 [11:05<00:51, 90.80it/s]\u001b[A\n",
      " 92%|█████████▏| 56325/61028 [11:05<00:54, 86.58it/s]\u001b[A\n",
      " 92%|█████████▏| 56334/61028 [11:05<00:55, 84.63it/s]\u001b[A\n",
      " 92%|█████████▏| 56344/61028 [11:05<00:53, 87.76it/s]\u001b[A\n",
      " 92%|█████████▏| 56353/61028 [11:06<00:53, 87.36it/s]\u001b[A\n",
      " 92%|█████████▏| 56362/61028 [11:06<00:54, 85.83it/s]\u001b[A\n",
      " 92%|█████████▏| 56372/61028 [11:06<00:52, 89.36it/s]\u001b[A\n",
      " 92%|█████████▏| 56382/61028 [11:06<00:50, 91.14it/s]\u001b[A\n",
      " 92%|█████████▏| 56392/61028 [11:06<00:49, 93.16it/s]\u001b[A\n",
      " 92%|█████████▏| 56403/61028 [11:06<00:47, 97.26it/s]\u001b[A\n",
      " 92%|█████████▏| 56414/61028 [11:06<00:46, 99.32it/s]\u001b[A\n",
      " 92%|█████████▏| 56425/61028 [11:06<00:49, 92.47it/s]\u001b[A\n",
      " 92%|█████████▏| 56435/61028 [11:06<00:51, 89.07it/s]\u001b[A\n",
      " 92%|█████████▏| 56445/61028 [11:07<00:50, 91.00it/s]\u001b[A\n",
      " 93%|█████████▎| 56456/61028 [11:07<00:48, 94.99it/s]\u001b[A\n",
      " 93%|█████████▎| 56466/61028 [11:07<00:48, 93.88it/s]\u001b[A\n",
      " 93%|█████████▎| 56477/61028 [11:07<00:47, 96.37it/s]\u001b[A\n",
      " 93%|█████████▎| 56488/61028 [11:07<00:45, 99.70it/s]\u001b[A\n",
      " 93%|█████████▎| 56499/61028 [11:07<00:46, 96.75it/s]\u001b[A\n",
      " 93%|█████████▎| 56509/61028 [11:07<00:47, 94.76it/s]\u001b[A\n",
      " 93%|█████████▎| 56519/61028 [11:07<00:47, 94.81it/s]\u001b[A\n",
      " 93%|█████████▎| 56530/61028 [11:07<00:46, 96.71it/s]\u001b[A\n",
      " 93%|█████████▎| 56541/61028 [11:07<00:46, 97.50it/s]\u001b[A\n",
      " 93%|█████████▎| 56551/61028 [11:08<00:46, 97.03it/s]\u001b[A\n",
      " 93%|█████████▎| 56561/61028 [11:08<00:47, 94.47it/s]\u001b[A\n",
      " 93%|█████████▎| 56571/61028 [11:08<00:47, 93.71it/s]\u001b[A\n",
      " 93%|█████████▎| 56583/61028 [11:08<00:44, 100.01it/s]\u001b[A\n",
      " 93%|█████████▎| 56594/61028 [11:08<00:45, 97.70it/s] \u001b[A\n",
      " 93%|█████████▎| 56604/61028 [11:08<00:45, 98.12it/s]\u001b[A\n",
      " 93%|█████████▎| 56615/61028 [11:08<00:43, 101.18it/s]\u001b[A\n",
      " 93%|█████████▎| 56626/61028 [11:09<01:11, 61.15it/s] \u001b[A\n",
      " 93%|█████████▎| 56635/61028 [11:09<01:11, 61.64it/s]\u001b[A\n",
      " 93%|█████████▎| 56646/61028 [11:09<01:02, 70.68it/s]\u001b[A\n",
      " 93%|█████████▎| 56655/61028 [11:09<00:59, 73.61it/s]\u001b[A\n",
      " 93%|█████████▎| 56667/61028 [11:09<00:52, 82.34it/s]\u001b[A\n",
      " 93%|█████████▎| 56677/61028 [11:09<00:52, 83.13it/s]\u001b[A\n",
      " 93%|█████████▎| 56687/61028 [11:09<00:50, 86.39it/s]\u001b[A\n",
      " 93%|█████████▎| 56699/61028 [11:09<00:45, 94.23it/s]\u001b[A\n",
      " 93%|█████████▎| 56712/61028 [11:09<00:42, 102.47it/s]\u001b[A\n",
      " 93%|█████████▎| 56723/61028 [11:10<00:41, 104.26it/s]\u001b[A\n",
      " 93%|█████████▎| 56734/61028 [11:10<00:42, 102.19it/s]\u001b[A\n",
      " 93%|█████████▎| 56745/61028 [11:10<00:42, 101.31it/s]\u001b[A\n",
      " 93%|█████████▎| 56757/61028 [11:10<00:41, 103.70it/s]\u001b[A\n",
      " 93%|█████████▎| 56768/61028 [11:10<00:41, 103.23it/s]\u001b[A\n",
      " 93%|█████████▎| 56779/61028 [11:10<00:43, 96.84it/s] \u001b[A\n",
      " 93%|█████████▎| 56789/61028 [11:10<00:45, 94.16it/s]\u001b[A\n",
      " 93%|█████████▎| 56800/61028 [11:10<00:43, 97.24it/s]\u001b[A\n",
      " 93%|█████████▎| 56810/61028 [11:10<00:45, 92.06it/s]\u001b[A\n",
      " 93%|█████████▎| 56820/61028 [11:11<00:45, 92.27it/s]\u001b[A\n",
      " 93%|█████████▎| 56830/61028 [11:11<00:46, 90.44it/s]\u001b[A\n",
      " 93%|█████████▎| 56841/61028 [11:11<00:44, 93.50it/s]\u001b[A\n",
      " 93%|█████████▎| 56853/61028 [11:11<00:41, 100.02it/s]\u001b[A\n",
      " 93%|█████████▎| 56864/61028 [11:11<00:42, 97.25it/s] \u001b[A\n",
      " 93%|█████████▎| 56874/61028 [11:11<00:43, 94.80it/s]\u001b[A\n",
      " 93%|█████████▎| 56884/61028 [11:11<00:43, 94.77it/s]\u001b[A\n",
      " 93%|█████████▎| 56894/61028 [11:11<00:45, 90.60it/s]\u001b[A\n",
      " 93%|█████████▎| 56904/61028 [11:11<00:47, 87.55it/s]\u001b[A\n",
      " 93%|█████████▎| 56915/61028 [11:12<00:45, 91.09it/s]\u001b[A\n",
      " 93%|█████████▎| 56925/61028 [11:12<00:45, 89.82it/s]\u001b[A\n",
      " 93%|█████████▎| 56937/61028 [11:12<00:42, 95.77it/s]\u001b[A\n",
      " 93%|█████████▎| 56948/61028 [11:12<00:41, 98.31it/s]\u001b[A\n",
      " 93%|█████████▎| 56958/61028 [11:12<00:44, 92.02it/s]\u001b[A\n",
      " 93%|█████████▎| 56968/61028 [11:12<00:45, 89.52it/s]\u001b[A\n",
      " 93%|█████████▎| 56979/61028 [11:12<00:43, 92.98it/s]\u001b[A\n",
      " 93%|█████████▎| 56989/61028 [11:12<00:44, 91.59it/s]\u001b[A\n",
      " 93%|█████████▎| 56999/61028 [11:12<00:43, 92.63it/s]\u001b[A\n",
      " 93%|█████████▎| 57009/61028 [11:13<00:44, 90.78it/s]\u001b[A\n",
      " 93%|█████████▎| 57019/61028 [11:13<00:43, 92.16it/s]\u001b[A\n",
      " 93%|█████████▎| 57030/61028 [11:13<00:41, 95.69it/s]\u001b[A\n",
      " 93%|█████████▎| 57041/61028 [11:13<00:40, 97.48it/s]\u001b[A\n",
      " 93%|█████████▎| 57052/61028 [11:13<00:40, 99.14it/s]\u001b[A\n",
      " 94%|█████████▎| 57064/61028 [11:13<00:37, 104.32it/s]\u001b[A\n",
      " 94%|█████████▎| 57075/61028 [11:13<00:38, 102.23it/s]\u001b[A\n",
      " 94%|█████████▎| 57086/61028 [11:13<00:38, 101.94it/s]\u001b[A\n",
      " 94%|█████████▎| 57097/61028 [11:14<01:07, 58.25it/s] \u001b[A\n",
      " 94%|█████████▎| 57108/61028 [11:14<00:58, 67.54it/s]\u001b[A\n",
      " 94%|█████████▎| 57117/61028 [11:14<00:54, 72.42it/s]\u001b[A\n",
      " 94%|█████████▎| 57128/61028 [11:14<00:49, 78.90it/s]\u001b[A\n",
      " 94%|█████████▎| 57138/61028 [11:14<00:46, 82.90it/s]\u001b[A\n",
      " 94%|█████████▎| 57148/61028 [11:14<00:44, 86.56it/s]\u001b[A\n",
      " 94%|█████████▎| 57160/61028 [11:14<00:41, 94.02it/s]\u001b[A\n",
      " 94%|█████████▎| 57171/61028 [11:14<00:40, 96.07it/s]\u001b[A\n",
      " 94%|█████████▎| 57182/61028 [11:15<00:40, 94.71it/s]\u001b[A\n",
      " 94%|█████████▎| 57193/61028 [11:15<00:39, 96.21it/s]\u001b[A\n",
      " 94%|█████████▎| 57204/61028 [11:15<00:38, 99.49it/s]\u001b[A\n",
      " 94%|█████████▍| 57219/61028 [11:15<00:35, 107.44it/s]\u001b[A\n",
      " 94%|█████████▍| 57231/61028 [11:15<00:35, 106.10it/s]\u001b[A\n",
      " 94%|█████████▍| 57242/61028 [11:15<00:35, 105.92it/s]\u001b[A\n",
      " 94%|█████████▍| 57253/61028 [11:15<00:40, 93.57it/s] \u001b[A\n",
      " 94%|█████████▍| 57265/61028 [11:15<00:37, 99.24it/s]\u001b[A\n",
      " 94%|█████████▍| 57276/61028 [11:15<00:37, 100.45it/s]\u001b[A\n",
      " 94%|█████████▍| 57288/61028 [11:16<00:35, 105.26it/s]\u001b[A\n",
      " 94%|█████████▍| 57300/61028 [11:16<00:34, 107.48it/s]\u001b[A\n",
      " 94%|█████████▍| 57311/61028 [11:16<00:36, 100.68it/s]\u001b[A\n",
      " 94%|█████████▍| 57322/61028 [11:16<00:37, 99.06it/s] \u001b[A\n",
      " 94%|█████████▍| 57334/61028 [11:16<00:36, 102.13it/s]\u001b[A\n",
      " 94%|█████████▍| 57346/61028 [11:16<00:35, 104.77it/s]\u001b[A\n",
      " 94%|█████████▍| 57357/61028 [11:16<00:35, 104.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 57368/61028 [11:16<00:39, 93.82it/s] \u001b[A\n",
      " 94%|█████████▍| 57380/61028 [11:17<00:37, 97.30it/s]\u001b[A\n",
      " 94%|█████████▍| 57390/61028 [11:17<00:38, 95.10it/s]\u001b[A\n",
      " 94%|█████████▍| 57401/61028 [11:17<00:37, 96.49it/s]\u001b[A\n",
      " 94%|█████████▍| 57411/61028 [11:17<00:38, 94.72it/s]\u001b[A\n",
      " 94%|█████████▍| 57423/61028 [11:17<00:36, 99.30it/s]\u001b[A\n",
      " 94%|█████████▍| 57434/61028 [11:17<00:36, 97.34it/s]\u001b[A\n",
      " 94%|█████████▍| 57444/61028 [11:17<00:39, 91.02it/s]\u001b[A\n",
      " 94%|█████████▍| 57455/61028 [11:17<00:37, 94.26it/s]\u001b[A\n",
      " 94%|█████████▍| 57466/61028 [11:17<00:36, 96.85it/s]\u001b[A\n",
      " 94%|█████████▍| 57478/61028 [11:18<00:34, 102.09it/s]\u001b[A\n",
      " 94%|█████████▍| 57491/61028 [11:18<00:32, 107.39it/s]\u001b[A\n",
      " 94%|█████████▍| 57502/61028 [11:18<00:33, 105.81it/s]\u001b[A\n",
      " 94%|█████████▍| 57513/61028 [11:18<00:33, 103.90it/s]\u001b[A\n",
      " 94%|█████████▍| 57524/61028 [11:18<00:34, 100.19it/s]\u001b[A\n",
      " 94%|█████████▍| 57535/61028 [11:18<00:35, 98.17it/s] \u001b[A\n",
      " 94%|█████████▍| 57545/61028 [11:18<00:35, 98.52it/s]\u001b[A\n",
      " 94%|█████████▍| 57555/61028 [11:18<00:35, 98.70it/s]\u001b[A\n",
      " 94%|█████████▍| 57567/61028 [11:18<00:34, 101.40it/s]\u001b[A\n",
      " 94%|█████████▍| 57578/61028 [11:19<00:35, 95.96it/s] \u001b[A\n",
      " 94%|█████████▍| 57588/61028 [11:19<00:57, 59.73it/s]\u001b[A\n",
      " 94%|█████████▍| 57597/61028 [11:19<00:52, 65.59it/s]\u001b[A\n",
      " 94%|█████████▍| 57608/61028 [11:19<00:46, 73.25it/s]\u001b[A\n",
      " 94%|█████████▍| 57619/61028 [11:19<00:41, 81.24it/s]\u001b[A\n",
      " 94%|█████████▍| 57630/61028 [11:19<00:39, 86.55it/s]\u001b[A\n",
      " 94%|█████████▍| 57640/61028 [11:19<00:38, 88.71it/s]\u001b[A\n",
      " 94%|█████████▍| 57651/61028 [11:19<00:36, 93.12it/s]\u001b[A\n",
      " 94%|█████████▍| 57661/61028 [11:20<00:35, 94.18it/s]\u001b[A\n",
      " 95%|█████████▍| 57673/61028 [11:20<00:33, 99.59it/s]\u001b[A\n",
      " 95%|█████████▍| 57684/61028 [11:20<00:34, 98.10it/s]\u001b[A\n",
      " 95%|█████████▍| 57695/61028 [11:20<00:33, 98.68it/s]\u001b[A\n",
      " 95%|█████████▍| 57706/61028 [11:20<00:34, 97.11it/s]\u001b[A\n",
      " 95%|█████████▍| 57717/61028 [11:20<00:33, 97.67it/s]\u001b[A\n",
      " 95%|█████████▍| 57727/61028 [11:20<00:34, 95.45it/s]\u001b[A\n",
      " 95%|█████████▍| 57738/61028 [11:20<00:34, 94.91it/s]\u001b[A\n",
      " 95%|█████████▍| 57749/61028 [11:20<00:34, 95.47it/s]\u001b[A\n",
      " 95%|█████████▍| 57760/61028 [11:21<00:33, 98.59it/s]\u001b[A\n",
      " 95%|█████████▍| 57770/61028 [11:21<00:33, 97.00it/s]\u001b[A\n",
      " 95%|█████████▍| 57780/61028 [11:21<00:33, 97.33it/s]\u001b[A\n",
      " 95%|█████████▍| 57790/61028 [11:21<00:33, 96.80it/s]\u001b[A\n",
      " 95%|█████████▍| 57801/61028 [11:21<00:35, 90.94it/s]\u001b[A\n",
      " 95%|█████████▍| 57812/61028 [11:21<00:34, 93.95it/s]\u001b[A\n",
      " 95%|█████████▍| 57823/61028 [11:21<00:32, 97.98it/s]\u001b[A\n",
      " 95%|█████████▍| 57833/61028 [11:21<00:34, 92.43it/s]\u001b[A\n",
      " 95%|█████████▍| 57843/61028 [11:21<00:36, 87.06it/s]\u001b[A\n",
      " 95%|█████████▍| 57853/61028 [11:22<00:36, 87.53it/s]\u001b[A\n",
      " 95%|█████████▍| 57863/61028 [11:22<00:35, 90.07it/s]\u001b[A\n",
      " 95%|█████████▍| 57873/61028 [11:22<00:35, 89.67it/s]\u001b[A\n",
      " 95%|█████████▍| 57884/61028 [11:22<00:34, 92.28it/s]\u001b[A\n",
      " 95%|█████████▍| 57897/61028 [11:22<00:31, 99.34it/s]\u001b[A\n",
      " 95%|█████████▍| 57908/61028 [11:22<00:31, 99.57it/s]\u001b[A\n",
      " 95%|█████████▍| 57919/61028 [11:22<00:31, 97.21it/s]\u001b[A\n",
      " 95%|█████████▍| 57930/61028 [11:22<00:31, 99.18it/s]\u001b[A\n",
      " 95%|█████████▍| 57941/61028 [11:22<00:30, 101.16it/s]\u001b[A\n",
      " 95%|█████████▍| 57952/61028 [11:23<00:31, 98.99it/s] \u001b[A\n",
      " 95%|█████████▍| 57964/61028 [11:23<00:30, 102.07it/s]\u001b[A\n",
      " 95%|█████████▍| 57975/61028 [11:23<00:30, 98.73it/s] \u001b[A\n",
      " 95%|█████████▌| 57985/61028 [11:23<00:32, 95.03it/s]\u001b[A\n",
      " 95%|█████████▌| 57995/61028 [11:23<00:31, 96.28it/s]\u001b[A\n",
      " 95%|█████████▌| 58005/61028 [11:23<00:31, 96.22it/s]\u001b[A\n",
      " 95%|█████████▌| 58015/61028 [11:23<00:31, 95.03it/s]\u001b[A\n",
      " 95%|█████████▌| 58025/61028 [11:23<00:31, 95.37it/s]\u001b[A\n",
      " 95%|█████████▌| 58036/61028 [11:23<00:31, 95.87it/s]\u001b[A\n",
      " 95%|█████████▌| 58048/61028 [11:24<00:29, 100.20it/s]\u001b[A\n",
      " 95%|█████████▌| 58059/61028 [11:24<00:51, 58.21it/s] \u001b[A\n",
      " 95%|█████████▌| 58070/61028 [11:24<00:43, 67.65it/s]\u001b[A\n",
      " 95%|█████████▌| 58082/61028 [11:24<00:38, 77.21it/s]\u001b[A\n",
      " 95%|█████████▌| 58092/61028 [11:24<00:35, 82.84it/s]\u001b[A\n",
      " 95%|█████████▌| 58104/61028 [11:24<00:32, 91.26it/s]\u001b[A\n",
      " 95%|█████████▌| 58115/61028 [11:24<00:31, 93.68it/s]\u001b[A\n",
      " 95%|█████████▌| 58127/61028 [11:25<00:29, 98.15it/s]\u001b[A\n",
      " 95%|█████████▌| 58138/61028 [11:25<00:29, 99.14it/s]\u001b[A\n",
      " 95%|█████████▌| 58149/61028 [11:25<00:31, 92.64it/s]\u001b[A\n",
      " 95%|█████████▌| 58159/61028 [11:25<00:30, 94.72it/s]\u001b[A\n",
      " 95%|█████████▌| 58172/61028 [11:25<00:28, 101.94it/s]\u001b[A\n",
      " 95%|█████████▌| 58184/61028 [11:25<00:27, 103.76it/s]\u001b[A\n",
      " 95%|█████████▌| 58195/61028 [11:25<00:28, 100.12it/s]\u001b[A\n",
      " 95%|█████████▌| 58206/61028 [11:25<00:28, 99.11it/s] \u001b[A\n",
      " 95%|█████████▌| 58217/61028 [11:25<00:29, 95.58it/s]\u001b[A\n",
      " 95%|█████████▌| 58227/61028 [11:26<00:30, 92.67it/s]\u001b[A\n",
      " 95%|█████████▌| 58237/61028 [11:26<00:30, 91.39it/s]\u001b[A\n",
      " 95%|█████████▌| 58247/61028 [11:26<00:29, 93.10it/s]\u001b[A\n",
      " 95%|█████████▌| 58260/61028 [11:26<00:27, 100.20it/s]\u001b[A\n",
      " 95%|█████████▌| 58271/61028 [11:26<00:27, 100.80it/s]\u001b[A\n",
      " 96%|█████████▌| 58282/61028 [11:26<00:27, 99.24it/s] \u001b[A\n",
      " 96%|█████████▌| 58293/61028 [11:26<00:28, 96.72it/s]\u001b[A\n",
      " 96%|█████████▌| 58304/61028 [11:26<00:27, 98.13it/s]\u001b[A\n",
      " 96%|█████████▌| 58314/61028 [11:27<00:32, 84.70it/s]\u001b[A\n",
      " 96%|█████████▌| 58326/61028 [11:27<00:29, 91.87it/s]\u001b[A\n",
      " 96%|█████████▌| 58337/61028 [11:27<00:27, 96.24it/s]\u001b[A\n",
      " 96%|█████████▌| 58347/61028 [11:27<00:28, 93.82it/s]\u001b[A\n",
      " 96%|█████████▌| 58357/61028 [11:27<00:30, 87.80it/s]\u001b[A\n",
      " 96%|█████████▌| 58367/61028 [11:27<00:29, 89.79it/s]\u001b[A\n",
      " 96%|█████████▌| 58379/61028 [11:27<00:27, 94.74it/s]\u001b[A\n",
      " 96%|█████████▌| 58389/61028 [11:27<00:27, 96.18it/s]\u001b[A\n",
      " 96%|█████████▌| 58399/61028 [11:27<00:27, 94.29it/s]\u001b[A\n",
      " 96%|█████████▌| 58409/61028 [11:28<00:28, 93.23it/s]\u001b[A\n",
      " 96%|█████████▌| 58419/61028 [11:28<00:28, 91.68it/s]\u001b[A\n",
      " 96%|█████████▌| 58430/61028 [11:28<00:27, 94.01it/s]\u001b[A\n",
      " 96%|█████████▌| 58442/61028 [11:28<00:26, 98.39it/s]\u001b[A\n",
      " 96%|█████████▌| 58452/61028 [11:28<00:26, 98.24it/s]\u001b[A\n",
      " 96%|█████████▌| 58463/61028 [11:28<00:25, 100.38it/s]\u001b[A\n",
      " 96%|█████████▌| 58474/61028 [11:28<00:25, 101.86it/s]\u001b[A\n",
      " 96%|█████████▌| 58485/61028 [11:28<00:24, 102.82it/s]\u001b[A\n",
      " 96%|█████████▌| 58496/61028 [11:28<00:24, 102.17it/s]\u001b[A\n",
      " 96%|█████████▌| 58507/61028 [11:28<00:24, 102.07it/s]\u001b[A\n",
      " 96%|█████████▌| 58518/61028 [11:29<00:24, 103.67it/s]\u001b[A\n",
      " 96%|█████████▌| 58529/61028 [11:29<00:26, 93.85it/s] \u001b[A\n",
      " 96%|█████████▌| 58539/61028 [11:29<00:44, 56.47it/s]\u001b[A\n",
      " 96%|█████████▌| 58549/61028 [11:29<00:38, 64.78it/s]\u001b[A\n",
      " 96%|█████████▌| 58560/61028 [11:29<00:34, 72.29it/s]\u001b[A\n",
      " 96%|█████████▌| 58570/61028 [11:29<00:31, 78.31it/s]\u001b[A\n",
      " 96%|█████████▌| 58582/61028 [11:29<00:28, 87.15it/s]\u001b[A\n",
      " 96%|█████████▌| 58592/61028 [11:30<00:27, 89.45it/s]\u001b[A\n",
      " 96%|█████████▌| 58602/61028 [11:30<00:26, 91.15it/s]\u001b[A\n",
      " 96%|█████████▌| 58612/61028 [11:30<00:26, 91.00it/s]\u001b[A\n",
      " 96%|█████████▌| 58623/61028 [11:30<00:25, 94.19it/s]\u001b[A\n",
      " 96%|█████████▌| 58633/61028 [11:30<00:25, 95.02it/s]\u001b[A\n",
      " 96%|█████████▌| 58643/61028 [11:30<00:24, 95.82it/s]\u001b[A\n",
      " 96%|█████████▌| 58653/61028 [11:30<00:25, 92.71it/s]\u001b[A\n",
      " 96%|█████████▌| 58663/61028 [11:30<00:25, 91.76it/s]\u001b[A\n",
      " 96%|█████████▌| 58674/61028 [11:30<00:24, 95.20it/s]\u001b[A\n",
      " 96%|█████████▌| 58684/61028 [11:31<00:26, 88.70it/s]\u001b[A\n",
      " 96%|█████████▌| 58694/61028 [11:31<00:26, 88.11it/s]\u001b[A\n",
      " 96%|█████████▌| 58704/61028 [11:31<00:25, 91.33it/s]\u001b[A\n",
      " 96%|█████████▌| 58715/61028 [11:31<00:24, 94.98it/s]\u001b[A\n",
      " 96%|█████████▌| 58725/61028 [11:31<00:24, 94.38it/s]\u001b[A\n",
      " 96%|█████████▌| 58735/61028 [11:31<00:24, 93.76it/s]\u001b[A\n",
      " 96%|█████████▋| 58746/61028 [11:31<00:23, 97.40it/s]\u001b[A\n",
      " 96%|█████████▋| 58756/61028 [11:31<00:23, 97.49it/s]\u001b[A\n",
      " 96%|█████████▋| 58766/61028 [11:31<00:25, 88.41it/s]\u001b[A\n",
      " 96%|█████████▋| 58776/61028 [11:32<00:25, 86.67it/s]\u001b[A\n",
      " 96%|█████████▋| 58787/61028 [11:32<00:24, 91.32it/s]\u001b[A\n",
      " 96%|█████████▋| 58799/61028 [11:32<00:23, 95.89it/s]\u001b[A\n",
      " 96%|█████████▋| 58809/61028 [11:32<00:23, 96.23it/s]\u001b[A\n",
      " 96%|█████████▋| 58820/61028 [11:32<00:22, 98.65it/s]\u001b[A\n",
      " 96%|█████████▋| 58831/61028 [11:32<00:21, 99.99it/s]\u001b[A\n",
      " 96%|█████████▋| 58842/61028 [11:32<00:22, 96.55it/s]\u001b[A\n",
      " 96%|█████████▋| 58852/61028 [11:32<00:22, 96.07it/s]\u001b[A\n",
      " 96%|█████████▋| 58862/61028 [11:32<00:23, 93.45it/s]\u001b[A\n",
      " 96%|█████████▋| 58872/61028 [11:33<00:23, 93.12it/s]\u001b[A\n",
      " 96%|█████████▋| 58882/61028 [11:33<00:23, 93.24it/s]\u001b[A\n",
      " 96%|█████████▋| 58892/61028 [11:33<00:22, 93.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 58902/61028 [11:33<00:23, 91.74it/s]\u001b[A\n",
      " 97%|█████████▋| 58916/61028 [11:33<00:20, 101.93it/s]\u001b[A\n",
      " 97%|█████████▋| 58927/61028 [11:33<00:20, 100.36it/s]\u001b[A\n",
      " 97%|█████████▋| 58938/61028 [11:33<00:20, 102.90it/s]\u001b[A\n",
      " 97%|█████████▋| 58949/61028 [11:33<00:20, 100.57it/s]\u001b[A\n",
      " 97%|█████████▋| 58960/61028 [11:33<00:21, 97.27it/s] \u001b[A\n",
      " 97%|█████████▋| 58970/61028 [11:34<00:21, 95.79it/s]\u001b[A\n",
      " 97%|█████████▋| 58981/61028 [11:34<00:20, 97.83it/s]\u001b[A\n",
      " 97%|█████████▋| 58992/61028 [11:34<00:20, 98.79it/s]\u001b[A\n",
      " 97%|█████████▋| 59002/61028 [11:34<00:33, 60.73it/s]\u001b[A\n",
      " 97%|█████████▋| 59010/61028 [11:34<00:34, 58.82it/s]\u001b[A\n",
      " 97%|█████████▋| 59019/61028 [11:34<00:31, 64.46it/s]\u001b[A\n",
      " 97%|█████████▋| 59030/61028 [11:34<00:27, 72.73it/s]\u001b[A\n",
      " 97%|█████████▋| 59042/61028 [11:35<00:24, 81.40it/s]\u001b[A\n",
      " 97%|█████████▋| 59053/61028 [11:35<00:22, 87.39it/s]\u001b[A\n",
      " 97%|█████████▋| 59064/61028 [11:35<00:21, 92.58it/s]\u001b[A\n",
      " 97%|█████████▋| 59075/61028 [11:35<00:20, 96.35it/s]\u001b[A\n",
      " 97%|█████████▋| 59086/61028 [11:35<00:19, 98.38it/s]\u001b[A\n",
      " 97%|█████████▋| 59097/61028 [11:35<00:19, 97.08it/s]\u001b[A\n",
      " 97%|█████████▋| 59108/61028 [11:35<00:19, 99.47it/s]\u001b[A\n",
      " 97%|█████████▋| 59119/61028 [11:35<00:19, 98.69it/s]\u001b[A\n",
      " 97%|█████████▋| 59130/61028 [11:35<00:19, 99.43it/s]\u001b[A\n",
      " 97%|█████████▋| 59142/61028 [11:36<00:18, 104.25it/s]\u001b[A\n",
      " 97%|█████████▋| 59153/61028 [11:36<00:17, 105.84it/s]\u001b[A\n",
      " 97%|█████████▋| 59164/61028 [11:36<00:17, 105.49it/s]\u001b[A\n",
      " 97%|█████████▋| 59175/61028 [11:36<00:17, 105.10it/s]\u001b[A\n",
      " 97%|█████████▋| 59187/61028 [11:36<00:17, 106.98it/s]\u001b[A\n",
      " 97%|█████████▋| 59198/61028 [11:36<00:17, 105.68it/s]\u001b[A\n",
      " 97%|█████████▋| 59209/61028 [11:36<00:17, 104.31it/s]\u001b[A\n",
      " 97%|█████████▋| 59220/61028 [11:36<00:17, 101.66it/s]\u001b[A\n",
      " 97%|█████████▋| 59231/61028 [11:36<00:17, 99.95it/s] \u001b[A\n",
      " 97%|█████████▋| 59242/61028 [11:37<00:18, 94.22it/s]\u001b[A\n",
      " 97%|█████████▋| 59252/61028 [11:37<00:19, 92.23it/s]\u001b[A\n",
      " 97%|█████████▋| 59262/61028 [11:37<00:19, 90.60it/s]\u001b[A\n",
      " 97%|█████████▋| 59273/61028 [11:37<00:18, 93.91it/s]\u001b[A\n",
      " 97%|█████████▋| 59285/61028 [11:37<00:17, 99.76it/s]\u001b[A\n",
      " 97%|█████████▋| 59296/61028 [11:37<00:17, 101.39it/s]\u001b[A\n",
      " 97%|█████████▋| 59308/61028 [11:37<00:16, 104.85it/s]\u001b[A\n",
      " 97%|█████████▋| 59319/61028 [11:37<00:18, 90.87it/s] \u001b[A\n",
      " 97%|█████████▋| 59329/61028 [11:38<00:24, 68.63it/s]\u001b[A\n",
      " 97%|█████████▋| 59338/61028 [11:38<00:22, 73.72it/s]\u001b[A\n",
      " 97%|█████████▋| 59349/61028 [11:38<00:20, 80.04it/s]\u001b[A\n",
      " 97%|█████████▋| 59360/61028 [11:38<00:19, 86.14it/s]\u001b[A\n",
      " 97%|█████████▋| 59370/61028 [11:38<00:18, 88.52it/s]\u001b[A\n",
      " 97%|█████████▋| 59382/61028 [11:38<00:17, 93.33it/s]\u001b[A\n",
      " 97%|█████████▋| 59392/61028 [11:38<00:17, 94.36it/s]\u001b[A\n",
      " 97%|█████████▋| 59403/61028 [11:38<00:16, 97.86it/s]\u001b[A\n",
      " 97%|█████████▋| 59414/61028 [11:38<00:16, 100.30it/s]\u001b[A\n",
      " 97%|█████████▋| 59425/61028 [11:38<00:15, 101.86it/s]\u001b[A\n",
      " 97%|█████████▋| 59436/61028 [11:39<00:15, 100.57it/s]\u001b[A\n",
      " 97%|█████████▋| 59447/61028 [11:39<00:15, 102.77it/s]\u001b[A\n",
      " 97%|█████████▋| 59458/61028 [11:39<00:15, 104.29it/s]\u001b[A\n",
      " 97%|█████████▋| 59469/61028 [11:39<00:14, 104.06it/s]\u001b[A\n",
      " 97%|█████████▋| 59480/61028 [11:39<00:25, 61.00it/s] \u001b[A\n",
      " 97%|█████████▋| 59491/61028 [11:39<00:21, 69.93it/s]\u001b[A\n",
      " 97%|█████████▋| 59502/61028 [11:39<00:20, 76.07it/s]\u001b[A\n",
      " 98%|█████████▊| 59513/61028 [11:40<00:18, 82.29it/s]\u001b[A\n",
      " 98%|█████████▊| 59523/61028 [11:40<00:17, 84.20it/s]\u001b[A\n",
      " 98%|█████████▊| 59533/61028 [11:40<00:16, 88.28it/s]\u001b[A\n",
      " 98%|█████████▊| 59544/61028 [11:40<00:15, 93.66it/s]\u001b[A\n",
      " 98%|█████████▊| 59556/61028 [11:40<00:14, 99.13it/s]\u001b[A\n",
      " 98%|█████████▊| 59567/61028 [11:40<00:14, 99.89it/s]\u001b[A\n",
      " 98%|█████████▊| 59578/61028 [11:40<00:14, 101.92it/s]\u001b[A\n",
      " 98%|█████████▊| 59589/61028 [11:40<00:13, 104.04it/s]\u001b[A\n",
      " 98%|█████████▊| 59600/61028 [11:40<00:13, 103.38it/s]\u001b[A\n",
      " 98%|█████████▊| 59611/61028 [11:41<00:13, 104.17it/s]\u001b[A\n",
      " 98%|█████████▊| 59622/61028 [11:41<00:13, 104.37it/s]\u001b[A\n",
      " 98%|█████████▊| 59633/61028 [11:41<00:13, 99.98it/s] \u001b[A\n",
      " 98%|█████████▊| 59644/61028 [11:41<00:13, 99.06it/s]\u001b[A\n",
      " 98%|█████████▊| 59654/61028 [11:41<00:14, 97.77it/s]\u001b[A\n",
      " 98%|█████████▊| 59665/61028 [11:41<00:13, 97.75it/s]\u001b[A\n",
      " 98%|█████████▊| 59675/61028 [11:41<00:14, 96.28it/s]\u001b[A\n",
      " 98%|█████████▊| 59687/61028 [11:41<00:13, 101.71it/s]\u001b[A\n",
      " 98%|█████████▊| 59699/61028 [11:41<00:12, 105.35it/s]\u001b[A\n",
      " 98%|█████████▊| 59710/61028 [11:42<00:13, 95.90it/s] \u001b[A\n",
      " 98%|█████████▊| 59720/61028 [11:42<00:13, 95.20it/s]\u001b[A\n",
      " 98%|█████████▊| 59731/61028 [11:42<00:13, 96.99it/s]\u001b[A\n",
      " 98%|█████████▊| 59741/61028 [11:42<00:13, 97.79it/s]\u001b[A\n",
      " 98%|█████████▊| 59752/61028 [11:42<00:12, 98.73it/s]\u001b[A\n",
      " 98%|█████████▊| 59764/61028 [11:42<00:12, 102.65it/s]\u001b[A\n",
      " 98%|█████████▊| 59777/61028 [11:42<00:11, 105.61it/s]\u001b[A\n",
      " 98%|█████████▊| 59788/61028 [11:42<00:12, 102.85it/s]\u001b[A\n",
      " 98%|█████████▊| 59799/61028 [11:42<00:12, 100.20it/s]\u001b[A\n",
      " 98%|█████████▊| 59810/61028 [11:43<00:12, 98.10it/s] \u001b[A\n",
      " 98%|█████████▊| 59820/61028 [11:43<00:12, 95.26it/s]\u001b[A\n",
      " 98%|█████████▊| 59831/61028 [11:43<00:12, 97.36it/s]\u001b[A\n",
      " 98%|█████████▊| 59841/61028 [11:43<00:12, 91.43it/s]\u001b[A\n",
      " 98%|█████████▊| 59851/61028 [11:43<00:12, 92.10it/s]\u001b[A\n",
      " 98%|█████████▊| 59861/61028 [11:43<00:12, 93.05it/s]\u001b[A\n",
      " 98%|█████████▊| 59872/61028 [11:43<00:12, 94.78it/s]\u001b[A\n",
      " 98%|█████████▊| 59882/61028 [11:43<00:12, 94.87it/s]\u001b[A\n",
      " 98%|█████████▊| 59894/61028 [11:43<00:11, 100.22it/s]\u001b[A\n",
      " 98%|█████████▊| 59905/61028 [11:44<00:11, 97.93it/s] \u001b[A\n",
      " 98%|█████████▊| 59915/61028 [11:44<00:11, 98.20it/s]\u001b[A\n",
      " 98%|█████████▊| 59927/61028 [11:44<00:10, 101.94it/s]\u001b[A\n",
      " 98%|█████████▊| 59938/61028 [11:44<00:10, 104.04it/s]\u001b[A\n",
      " 98%|█████████▊| 59949/61028 [11:44<00:10, 100.12it/s]\u001b[A\n",
      " 98%|█████████▊| 59960/61028 [11:44<00:10, 100.19it/s]\u001b[A\n",
      " 98%|█████████▊| 59971/61028 [11:44<00:18, 56.65it/s] \u001b[A\n",
      " 98%|█████████▊| 59980/61028 [11:45<00:16, 63.36it/s]\u001b[A\n",
      " 98%|█████████▊| 59991/61028 [11:45<00:14, 71.06it/s]\u001b[A\n",
      " 98%|█████████▊| 60002/61028 [11:45<00:12, 79.39it/s]\u001b[A\n",
      " 98%|█████████▊| 60013/61028 [11:45<00:12, 84.58it/s]\u001b[A\n",
      " 98%|█████████▊| 60023/61028 [11:45<00:11, 87.59it/s]\u001b[A\n",
      " 98%|█████████▊| 60034/61028 [11:45<00:10, 92.09it/s]\u001b[A\n",
      " 98%|█████████▊| 60044/61028 [11:45<00:11, 89.41it/s]\u001b[A\n",
      " 98%|█████████▊| 60055/61028 [11:45<00:10, 94.24it/s]\u001b[A\n",
      " 98%|█████████▊| 60066/61028 [11:45<00:09, 96.30it/s]\u001b[A\n",
      " 98%|█████████▊| 60076/61028 [11:46<00:09, 96.92it/s]\u001b[A\n",
      " 98%|█████████▊| 60086/61028 [11:46<00:09, 96.91it/s]\u001b[A\n",
      " 98%|█████████▊| 60096/61028 [11:46<00:09, 97.44it/s]\u001b[A\n",
      " 98%|█████████▊| 60106/61028 [11:46<00:09, 94.87it/s]\u001b[A\n",
      " 99%|█████████▊| 60116/61028 [11:46<00:09, 92.32it/s]\u001b[A\n",
      " 99%|█████████▊| 60126/61028 [11:46<00:09, 94.08it/s]\u001b[A\n",
      " 99%|█████████▊| 60136/61028 [11:46<00:09, 94.77it/s]\u001b[A\n",
      " 99%|█████████▊| 60147/61028 [11:46<00:09, 95.82it/s]\u001b[A\n",
      " 99%|█████████▊| 60158/61028 [11:46<00:08, 99.25it/s]\u001b[A\n",
      " 99%|█████████▊| 60169/61028 [11:46<00:08, 101.39it/s]\u001b[A\n",
      " 99%|█████████▊| 60180/61028 [11:47<00:09, 91.62it/s] \u001b[A\n",
      " 99%|█████████▊| 60191/61028 [11:47<00:08, 94.72it/s]\u001b[A\n",
      " 99%|█████████▊| 60202/61028 [11:47<00:08, 98.49it/s]\u001b[A\n",
      " 99%|█████████▊| 60213/61028 [11:47<00:08, 93.63it/s]\u001b[A\n",
      " 99%|█████████▊| 60224/61028 [11:47<00:08, 97.05it/s]\u001b[A\n",
      " 99%|█████████▊| 60234/61028 [11:47<00:08, 90.86it/s]\u001b[A\n",
      " 99%|█████████▊| 60245/61028 [11:47<00:08, 93.92it/s]\u001b[A\n",
      " 99%|█████████▊| 60256/61028 [11:47<00:07, 96.57it/s]\u001b[A\n",
      " 99%|█████████▉| 60266/61028 [11:48<00:08, 94.95it/s]\u001b[A\n",
      " 99%|█████████▉| 60276/61028 [11:48<00:08, 92.80it/s]\u001b[A\n",
      " 99%|█████████▉| 60287/61028 [11:48<00:07, 96.59it/s]\u001b[A\n",
      " 99%|█████████▉| 60298/61028 [11:48<00:07, 99.18it/s]\u001b[A\n",
      " 99%|█████████▉| 60309/61028 [11:48<00:07, 101.54it/s]\u001b[A\n",
      " 99%|█████████▉| 60320/61028 [11:48<00:07, 96.86it/s] \u001b[A\n",
      " 99%|█████████▉| 60331/61028 [11:48<00:07, 98.03it/s]\u001b[A\n",
      " 99%|█████████▉| 60343/61028 [11:48<00:06, 103.50it/s]\u001b[A\n",
      " 99%|█████████▉| 60354/61028 [11:48<00:06, 105.25it/s]\u001b[A\n",
      " 99%|█████████▉| 60365/61028 [11:48<00:06, 106.59it/s]\u001b[A\n",
      " 99%|█████████▉| 60377/61028 [11:49<00:05, 108.74it/s]\u001b[A\n",
      " 99%|█████████▉| 60388/61028 [11:49<00:05, 106.88it/s]\u001b[A\n",
      " 99%|█████████▉| 60399/61028 [11:49<00:06, 101.72it/s]\u001b[A\n",
      " 99%|█████████▉| 60411/61028 [11:49<00:05, 106.44it/s]\u001b[A\n",
      " 99%|█████████▉| 60422/61028 [11:49<00:06, 100.93it/s]\u001b[A\n",
      " 99%|█████████▉| 60434/61028 [11:49<00:05, 105.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 60445/61028 [11:50<00:09, 59.11it/s] \u001b[A\n",
      " 99%|█████████▉| 60456/61028 [11:50<00:08, 67.82it/s]\u001b[A\n",
      " 99%|█████████▉| 60466/61028 [11:50<00:07, 74.36it/s]\u001b[A\n",
      " 99%|█████████▉| 60477/61028 [11:50<00:06, 82.20it/s]\u001b[A\n",
      " 99%|█████████▉| 60490/61028 [11:50<00:05, 90.75it/s]\u001b[A\n",
      " 99%|█████████▉| 60503/61028 [11:50<00:05, 98.24it/s]\u001b[A\n",
      " 99%|█████████▉| 60514/61028 [11:50<00:05, 96.63it/s]\u001b[A\n",
      " 99%|█████████▉| 60525/61028 [11:50<00:05, 100.09it/s]\u001b[A\n",
      " 99%|█████████▉| 60536/61028 [11:50<00:04, 100.06it/s]\u001b[A\n",
      " 99%|█████████▉| 60547/61028 [11:50<00:04, 100.56it/s]\u001b[A\n",
      " 99%|█████████▉| 60558/61028 [11:51<00:04, 97.44it/s] \u001b[A\n",
      " 99%|█████████▉| 60568/61028 [11:51<00:04, 95.52it/s]\u001b[A\n",
      " 99%|█████████▉| 60578/61028 [11:51<00:04, 93.05it/s]\u001b[A\n",
      " 99%|█████████▉| 60589/61028 [11:51<00:04, 96.59it/s]\u001b[A\n",
      " 99%|█████████▉| 60599/61028 [11:51<00:04, 94.47it/s]\u001b[A\n",
      " 99%|█████████▉| 60609/61028 [11:51<00:04, 95.21it/s]\u001b[A\n",
      " 99%|█████████▉| 60620/61028 [11:51<00:04, 97.05it/s]\u001b[A\n",
      " 99%|█████████▉| 60631/61028 [11:51<00:04, 98.97it/s]\u001b[A\n",
      " 99%|█████████▉| 60642/61028 [11:51<00:03, 100.24it/s]\u001b[A\n",
      " 99%|█████████▉| 60653/61028 [11:52<00:04, 90.95it/s] \u001b[A\n",
      " 99%|█████████▉| 60663/61028 [11:52<00:04, 86.44it/s]\u001b[A\n",
      " 99%|█████████▉| 60675/61028 [11:52<00:03, 93.19it/s]\u001b[A\n",
      " 99%|█████████▉| 60688/61028 [11:52<00:03, 100.46it/s]\u001b[A\n",
      " 99%|█████████▉| 60699/61028 [11:52<00:03, 99.05it/s] \u001b[A\n",
      " 99%|█████████▉| 60710/61028 [11:52<00:03, 99.65it/s]\u001b[A\n",
      " 99%|█████████▉| 60721/61028 [11:52<00:03, 98.42it/s]\u001b[A\n",
      "100%|█████████▉| 60732/61028 [11:52<00:02, 99.74it/s]\u001b[A\n",
      "100%|█████████▉| 60744/61028 [11:53<00:02, 102.41it/s]\u001b[A\n",
      "100%|█████████▉| 60755/61028 [11:53<00:02, 99.43it/s] \u001b[A\n",
      "100%|█████████▉| 60767/61028 [11:53<00:02, 101.86it/s]\u001b[A\n",
      "100%|█████████▉| 60778/61028 [11:53<00:02, 98.92it/s] \u001b[A\n",
      "100%|█████████▉| 60788/61028 [11:53<00:02, 98.96it/s]\u001b[A\n",
      "100%|█████████▉| 60798/61028 [11:53<00:02, 96.93it/s]\u001b[A\n",
      "100%|█████████▉| 60809/61028 [11:53<00:02, 99.16it/s]\u001b[A\n",
      "100%|█████████▉| 60820/61028 [11:53<00:02, 99.57it/s]\u001b[A\n",
      "100%|█████████▉| 60830/61028 [11:53<00:02, 98.32it/s]\u001b[A\n",
      "100%|█████████▉| 60841/61028 [11:53<00:01, 99.22it/s]\u001b[A\n",
      "100%|█████████▉| 60851/61028 [11:54<00:01, 99.24it/s]\u001b[A\n",
      "100%|█████████▉| 60862/61028 [11:54<00:01, 100.98it/s]\u001b[A\n",
      "100%|█████████▉| 60873/61028 [11:54<00:01, 98.95it/s] \u001b[A\n",
      "100%|█████████▉| 60884/61028 [11:54<00:01, 101.33it/s]\u001b[A\n",
      "100%|█████████▉| 60895/61028 [11:54<00:01, 95.90it/s] \u001b[A\n",
      "100%|█████████▉| 60905/61028 [11:54<00:01, 94.73it/s]\u001b[A\n",
      "100%|█████████▉| 60916/61028 [11:54<00:01, 97.83it/s]\u001b[A\n",
      "100%|█████████▉| 60926/61028 [11:55<00:01, 56.15it/s]\u001b[A\n",
      "100%|█████████▉| 60935/61028 [11:55<00:01, 61.76it/s]\u001b[A\n",
      "100%|█████████▉| 60944/61028 [11:55<00:01, 67.21it/s]\u001b[A\n",
      "100%|█████████▉| 60956/61028 [11:55<00:00, 76.52it/s]\u001b[A\n",
      "100%|█████████▉| 60967/61028 [11:55<00:00, 83.46it/s]\u001b[A\n",
      "100%|█████████▉| 60978/61028 [11:55<00:00, 88.76it/s]\u001b[A\n",
      "100%|█████████▉| 60988/61028 [11:55<00:00, 88.50it/s]\u001b[A\n",
      "100%|█████████▉| 60999/61028 [11:55<00:00, 92.53it/s]\u001b[A\n",
      "100%|█████████▉| 61010/61028 [11:55<00:00, 95.74it/s]\u001b[A\n",
      "100%|██████████| 61028/61028 [11:56<00:00, 85.22it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "file2annotation = {}\n",
    "# file2header = {}\n",
    "for file in tqdm(files):\n",
    "    with open(file,'r') as f:\n",
    "        content = f.read()\n",
    "    annotation_info=get_annotation_header(content)\n",
    "    file2annotation[file]=annotation_info\n",
    "#     file2header[file]=header_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61028"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file2annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results_1_26.txt','w') as fout:\n",
    "    json.dump(file2annotation, fout, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1171184 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 7107/1171184 [00:00<00:16, 71065.15it/s]\u001b[A\n",
      "  1%|          | 14308/1171184 [00:00<00:16, 71345.91it/s]\u001b[A\n",
      "  2%|▏         | 22216/1171184 [00:00<00:15, 73500.66it/s]\u001b[A\n",
      "  3%|▎         | 30215/1171184 [00:00<00:15, 75300.74it/s]\u001b[A\n",
      "  3%|▎         | 37681/1171184 [00:00<00:15, 75106.36it/s]\u001b[A\n",
      "  4%|▍         | 45029/1171184 [00:00<00:15, 74606.74it/s]\u001b[A\n",
      "  5%|▍         | 53103/1171184 [00:00<00:14, 76344.14it/s]\u001b[A\n",
      "  5%|▌         | 60171/1171184 [00:00<00:15, 73713.21it/s]\u001b[A\n",
      "  6%|▌         | 67655/1171184 [00:00<00:14, 74047.01it/s]\u001b[A\n",
      "  6%|▋         | 75133/1171184 [00:01<00:14, 74259.61it/s]\u001b[A\n",
      "  7%|▋         | 82490/1171184 [00:01<00:14, 74046.97it/s]\u001b[A\n",
      "  8%|▊         | 90088/1171184 [00:01<00:14, 74615.65it/s]\u001b[A\n",
      "  8%|▊         | 97461/1171184 [00:01<00:14, 72765.27it/s]\u001b[A\n",
      "  9%|▉         | 105103/1171184 [00:01<00:14, 73821.92it/s]\u001b[A\n",
      " 10%|▉         | 112453/1171184 [00:01<00:14, 71601.08it/s]\u001b[A\n",
      " 10%|█         | 119605/1171184 [00:01<00:14, 70632.64it/s]\u001b[A\n",
      " 11%|█         | 126761/1171184 [00:01<00:14, 70907.53it/s]\u001b[A\n",
      " 11%|█▏        | 133850/1171184 [00:01<00:14, 70448.96it/s]\u001b[A\n",
      " 12%|█▏        | 140895/1171184 [00:01<00:14, 69797.41it/s]\u001b[A\n",
      " 13%|█▎        | 147876/1171184 [00:02<00:14, 69539.07it/s]\u001b[A\n",
      " 13%|█▎        | 155024/1171184 [00:02<00:14, 70108.73it/s]\u001b[A\n",
      " 14%|█▍        | 162762/1171184 [00:02<00:13, 72141.57it/s]\u001b[A\n",
      " 15%|█▍        | 170530/1171184 [00:02<00:13, 73717.93it/s]\u001b[A\n",
      " 15%|█▌        | 178300/1171184 [00:02<00:13, 74868.94it/s]\u001b[A\n",
      " 16%|█▌        | 185832/1171184 [00:02<00:13, 75003.61it/s]\u001b[A\n",
      " 17%|█▋        | 193346/1171184 [00:02<00:13, 75017.38it/s]\u001b[A\n",
      " 17%|█▋        | 200946/1171184 [00:02<00:12, 75214.14it/s]\u001b[A\n",
      " 18%|█▊        | 208474/1171184 [00:02<00:12, 75087.43it/s]\u001b[A\n",
      " 18%|█▊        | 215988/1171184 [00:02<00:13, 72196.24it/s]\u001b[A\n",
      " 19%|█▉        | 223489/1171184 [00:03<00:12, 73016.85it/s]\u001b[A\n",
      " 20%|█▉        | 231645/1171184 [00:03<00:12, 75385.25it/s]\u001b[A\n",
      " 20%|██        | 239218/1171184 [00:03<00:12, 74387.23it/s]\u001b[A\n",
      " 21%|██        | 246684/1171184 [00:03<00:13, 70481.32it/s]\u001b[A\n",
      " 22%|██▏       | 254162/1171184 [00:03<00:12, 71716.86it/s]\u001b[A\n",
      " 22%|██▏       | 261704/1171184 [00:03<00:12, 72786.86it/s]\u001b[A\n",
      " 23%|██▎       | 269703/1171184 [00:03<00:12, 74807.67it/s]\u001b[A\n",
      " 24%|██▎       | 277240/1171184 [00:03<00:11, 74974.87it/s]\u001b[A\n",
      " 24%|██▍       | 284766/1171184 [00:03<00:11, 73872.46it/s]\u001b[A\n",
      " 25%|██▍       | 292177/1171184 [00:03<00:12, 72909.04it/s]\u001b[A\n",
      " 26%|██▌       | 299488/1171184 [00:04<00:12, 72369.17it/s]\u001b[A\n",
      " 26%|██▌       | 306740/1171184 [00:04<00:11, 72264.44it/s]\u001b[A\n",
      " 27%|██▋       | 313977/1171184 [00:04<00:11, 72049.55it/s]\u001b[A\n",
      " 27%|██▋       | 321773/1171184 [00:04<00:11, 73725.62it/s]\u001b[A\n",
      " 28%|██▊       | 329161/1171184 [00:04<00:11, 72379.20it/s]\u001b[A\n",
      " 29%|██▉       | 336824/1171184 [00:04<00:11, 73599.35it/s]\u001b[A\n",
      " 29%|██▉       | 344200/1171184 [00:04<00:11, 73206.81it/s]\u001b[A\n",
      " 30%|███       | 351533/1171184 [00:04<00:11, 71732.98it/s]\u001b[A\n",
      " 31%|███       | 358722/1171184 [00:04<00:11, 71523.77it/s]\u001b[A\n",
      " 31%|███▏      | 366526/1171184 [00:05<00:10, 73360.03it/s]\u001b[A\n",
      " 32%|███▏      | 373882/1171184 [00:05<00:11, 71600.69it/s]\u001b[A\n",
      " 33%|███▎      | 381065/1171184 [00:05<00:11, 71283.94it/s]\u001b[A\n",
      " 33%|███▎      | 388210/1171184 [00:05<00:11, 69093.55it/s]\u001b[A\n",
      " 34%|███▍      | 395401/1171184 [00:05<00:11, 69913.32it/s]\u001b[A\n",
      " 34%|███▍      | 402413/1171184 [00:05<00:11, 68869.46it/s]\u001b[A\n",
      " 35%|███▍      | 409318/1171184 [00:05<00:11, 68820.22it/s]\u001b[A\n",
      " 36%|███▌      | 416910/1171184 [00:05<00:10, 70804.64it/s]\u001b[A\n",
      " 36%|███▌      | 424336/1171184 [00:05<00:10, 71804.99it/s]\u001b[A\n",
      " 37%|███▋      | 431537/1171184 [00:05<00:10, 71171.14it/s]\u001b[A\n",
      " 37%|███▋      | 438670/1171184 [00:06<00:10, 71128.12it/s]\u001b[A\n",
      " 38%|███▊      | 446164/1171184 [00:06<00:10, 72228.27it/s]\u001b[A\n",
      " 39%|███▊      | 453399/1171184 [00:06<00:09, 71779.96it/s]\u001b[A\n",
      " 39%|███▉      | 460586/1171184 [00:06<00:10, 69049.67it/s]\u001b[A\n",
      " 40%|███▉      | 467520/1171184 [00:06<00:10, 66823.80it/s]\u001b[A\n",
      " 41%|████      | 475082/1171184 [00:06<00:10, 69238.13it/s]\u001b[A\n",
      " 41%|████      | 482461/1171184 [00:06<00:09, 70537.75it/s]\u001b[A\n",
      " 42%|████▏     | 489650/1171184 [00:06<00:09, 70936.92it/s]\u001b[A\n",
      " 42%|████▏     | 496909/1171184 [00:06<00:09, 71423.70it/s]\u001b[A\n",
      " 43%|████▎     | 504072/1171184 [00:06<00:09, 71441.58it/s]\u001b[A\n",
      " 44%|████▎     | 511375/1171184 [00:07<00:09, 71909.35it/s]\u001b[A\n",
      " 44%|████▍     | 518577/1171184 [00:07<00:09, 71800.38it/s]\u001b[A\n",
      " 45%|████▍     | 525765/1171184 [00:07<00:09, 69815.12it/s]\u001b[A\n",
      " 45%|████▌     | 532840/1171184 [00:07<00:09, 70090.96it/s]\u001b[A\n",
      " 46%|████▌     | 539862/1171184 [00:07<00:09, 69196.37it/s]\u001b[A\n",
      " 47%|████▋     | 546793/1171184 [00:07<00:09, 68079.32it/s]\u001b[A\n",
      " 47%|████▋     | 553780/1171184 [00:07<00:08, 68605.14it/s]\u001b[A\n",
      " 48%|████▊     | 560650/1171184 [00:07<00:08, 68598.79it/s]\u001b[A\n",
      " 48%|████▊     | 567517/1171184 [00:07<00:09, 66083.27it/s]\u001b[A\n",
      " 49%|████▉     | 574405/1171184 [00:07<00:08, 66898.12it/s]\u001b[A\n",
      " 50%|████▉     | 581115/1171184 [00:08<00:08, 66344.69it/s]\u001b[A\n",
      " 50%|█████     | 588015/1171184 [00:08<00:08, 67117.07it/s]\u001b[A\n",
      " 51%|█████     | 595174/1171184 [00:08<00:08, 68396.82it/s]\u001b[A\n",
      " 51%|█████▏    | 602668/1171184 [00:08<00:08, 70236.31it/s]\u001b[A\n",
      " 52%|█████▏    | 609715/1171184 [00:08<00:08, 70050.14it/s]\u001b[A\n",
      " 53%|█████▎    | 616736/1171184 [00:08<00:08, 67997.70it/s]\u001b[A\n",
      " 53%|█████▎    | 623913/1171184 [00:08<00:07, 69085.97it/s]\u001b[A\n",
      " 54%|█████▍    | 630843/1171184 [00:08<00:08, 66110.99it/s]\u001b[A\n",
      " 54%|█████▍    | 637497/1171184 [00:08<00:08, 65674.43it/s]\u001b[A\n",
      " 55%|█████▌    | 644833/1171184 [00:09<00:07, 67804.92it/s]\u001b[A\n",
      " 56%|█████▌    | 651652/1171184 [00:09<00:07, 67176.62it/s]\u001b[A\n",
      " 56%|█████▌    | 658398/1171184 [00:09<00:07, 67196.14it/s]\u001b[A\n",
      " 57%|█████▋    | 665325/1171184 [00:09<00:07, 67804.45it/s]\u001b[A\n",
      " 57%|█████▋    | 672146/1171184 [00:09<00:07, 67925.04it/s]\u001b[A\n",
      " 58%|█████▊    | 678950/1171184 [00:09<00:07, 66542.62it/s]\u001b[A\n",
      " 59%|█████▊    | 685998/1171184 [00:09<00:07, 67674.92it/s]\u001b[A\n",
      " 59%|█████▉    | 692780/1171184 [00:09<00:07, 67181.88it/s]\u001b[A\n",
      " 60%|█████▉    | 699676/1171184 [00:09<00:06, 67702.69it/s]\u001b[A\n",
      " 60%|██████    | 706455/1171184 [00:09<00:06, 66948.24it/s]\u001b[A\n",
      " 61%|██████    | 713158/1171184 [00:10<00:06, 65783.55it/s]\u001b[A\n",
      " 61%|██████▏   | 719747/1171184 [00:10<00:06, 65559.92it/s]\u001b[A\n",
      " 62%|██████▏   | 726634/1171184 [00:10<00:06, 66512.95it/s]\u001b[A\n",
      " 63%|██████▎   | 733392/1171184 [00:10<00:06, 66824.00it/s]\u001b[A\n",
      " 63%|██████▎   | 740081/1171184 [00:10<00:06, 65077.04it/s]\u001b[A\n",
      " 64%|██████▍   | 747243/1171184 [00:10<00:06, 66908.02it/s]\u001b[A\n",
      " 64%|██████▍   | 753957/1171184 [00:10<00:06, 65914.92it/s]\u001b[A\n",
      " 65%|██████▍   | 761081/1171184 [00:10<00:06, 67424.40it/s]\u001b[A\n",
      " 66%|██████▌   | 767846/1171184 [00:10<00:06, 64054.19it/s]\u001b[A\n",
      " 66%|██████▌   | 774526/1171184 [00:10<00:06, 64853.32it/s]\u001b[A\n",
      " 67%|██████▋   | 781050/1171184 [00:11<00:06, 64880.50it/s]\u001b[A\n",
      " 67%|██████▋   | 787570/1171184 [00:11<00:05, 64972.66it/s]\u001b[A\n",
      " 68%|██████▊   | 794086/1171184 [00:11<00:05, 64210.80it/s]\u001b[A\n",
      " 68%|██████▊   | 800523/1171184 [00:11<00:05, 62500.92it/s]\u001b[A\n",
      " 69%|██████▉   | 806794/1171184 [00:11<00:05, 62158.59it/s]\u001b[A\n",
      " 69%|██████▉   | 813616/1171184 [00:11<00:05, 63859.08it/s]\u001b[A\n",
      " 70%|███████   | 820962/1171184 [00:11<00:05, 66464.34it/s]\u001b[A\n",
      " 71%|███████   | 827652/1171184 [00:11<00:05, 63804.41it/s]\u001b[A\n",
      " 71%|███████   | 834162/1171184 [00:11<00:05, 64186.93it/s]\u001b[A\n",
      " 72%|███████▏  | 841139/1171184 [00:12<00:05, 65762.86it/s]\u001b[A\n",
      " 72%|███████▏  | 847752/1171184 [00:12<00:04, 65436.17it/s]\u001b[A\n",
      " 73%|███████▎  | 854508/1171184 [00:12<00:04, 66059.04it/s]\u001b[A\n",
      " 74%|███████▎  | 861134/1171184 [00:12<00:04, 64189.39it/s]\u001b[A\n",
      " 74%|███████▍  | 867578/1171184 [00:12<00:04, 63993.15it/s]\u001b[A\n",
      " 75%|███████▍  | 874221/1171184 [00:12<00:04, 64704.88it/s]\u001b[A\n",
      " 75%|███████▌  | 880706/1171184 [00:12<00:04, 60895.25it/s]\u001b[A\n",
      " 76%|███████▌  | 887901/1171184 [00:12<00:04, 63837.24it/s]\u001b[A\n",
      " 76%|███████▋  | 894362/1171184 [00:12<00:04, 63332.68it/s]\u001b[A\n",
      " 77%|███████▋  | 901024/1171184 [00:12<00:04, 64283.70it/s]\u001b[A\n",
      " 78%|███████▊  | 907866/1171184 [00:13<00:04, 65467.58it/s]\u001b[A\n",
      " 78%|███████▊  | 914448/1171184 [00:13<00:03, 64833.43it/s]\u001b[A\n",
      " 79%|███████▊  | 921379/1171184 [00:13<00:03, 66111.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 928016/1171184 [00:13<00:03, 66187.32it/s]\u001b[A\n",
      " 80%|███████▉  | 934715/1171184 [00:13<00:03, 66424.61it/s]\u001b[A\n",
      " 80%|████████  | 941370/1171184 [00:13<00:03, 65815.81it/s]\u001b[A\n",
      " 81%|████████  | 947962/1171184 [00:13<00:03, 63961.19it/s]\u001b[A\n",
      " 81%|████████▏ | 954377/1171184 [00:13<00:03, 63986.49it/s]\u001b[A\n",
      " 82%|████████▏ | 961167/1171184 [00:13<00:03, 65107.36it/s]\u001b[A\n",
      " 83%|████████▎ | 967729/1171184 [00:13<00:03, 65260.05it/s]\u001b[A\n",
      " 83%|████████▎ | 974265/1171184 [00:14<00:03, 64641.25it/s]\u001b[A\n",
      " 84%|████████▎ | 980738/1171184 [00:14<00:03, 62974.80it/s]\u001b[A\n",
      " 84%|████████▍ | 987105/1171184 [00:14<00:02, 63179.71it/s]\u001b[A\n",
      " 85%|████████▍ | 993629/1171184 [00:14<00:02, 63783.31it/s]\u001b[A\n",
      " 85%|████████▌ | 1000167/1171184 [00:14<00:02, 64252.41it/s]\u001b[A\n",
      " 86%|████████▌ | 1006805/1171184 [00:14<00:02, 64875.16it/s]\u001b[A\n",
      " 87%|████████▋ | 1013464/1171184 [00:14<00:02, 65379.09it/s]\u001b[A\n",
      " 87%|████████▋ | 1020008/1171184 [00:14<00:02, 61679.57it/s]\u001b[A\n",
      " 88%|████████▊ | 1026240/1171184 [00:14<00:02, 61869.71it/s]\u001b[A\n",
      " 88%|████████▊ | 1032460/1171184 [00:15<00:02, 59492.80it/s]\u001b[A\n",
      " 89%|████████▊ | 1038980/1171184 [00:15<00:02, 61094.98it/s]\u001b[A\n",
      " 89%|████████▉ | 1045596/1171184 [00:15<00:02, 62530.10it/s]\u001b[A\n",
      " 90%|████████▉ | 1051886/1171184 [00:15<00:01, 60813.53it/s]\u001b[A\n",
      " 90%|█████████ | 1058560/1171184 [00:15<00:01, 62477.53it/s]\u001b[A\n",
      " 91%|█████████ | 1064845/1171184 [00:15<00:01, 61994.20it/s]\u001b[A\n",
      " 91%|█████████▏| 1071269/1171184 [00:15<00:01, 62643.47it/s]\u001b[A\n",
      " 92%|█████████▏| 1077554/1171184 [00:15<00:01, 62606.48it/s]\u001b[A\n",
      " 93%|█████████▎| 1083829/1171184 [00:15<00:01, 62063.31it/s]\u001b[A\n",
      " 93%|█████████▎| 1090047/1171184 [00:15<00:01, 61985.78it/s]\u001b[A\n",
      " 94%|█████████▎| 1096314/1171184 [00:16<00:01, 62188.92it/s]\u001b[A\n",
      " 94%|█████████▍| 1102985/1171184 [00:16<00:01, 63479.23it/s]\u001b[A\n",
      " 95%|█████████▍| 1109344/1171184 [00:16<00:00, 63428.93it/s]\u001b[A\n",
      " 95%|█████████▌| 1115695/1171184 [00:16<00:00, 62445.18it/s]\u001b[A\n",
      " 96%|█████████▌| 1122168/1171184 [00:16<00:00, 63112.74it/s]\u001b[A\n",
      " 96%|█████████▋| 1128487/1171184 [00:16<00:00, 60507.20it/s]\u001b[A\n",
      " 97%|█████████▋| 1134914/1171184 [00:16<00:00, 61588.71it/s]\u001b[A\n",
      " 97%|█████████▋| 1141098/1171184 [00:16<00:00, 61231.56it/s]\u001b[A\n",
      " 98%|█████████▊| 1147239/1171184 [00:16<00:00, 59090.84it/s]\u001b[A\n",
      " 98%|█████████▊| 1153314/1171184 [00:16<00:00, 59577.97it/s]\u001b[A\n",
      " 99%|█████████▉| 1159293/1171184 [00:17<00:00, 58504.64it/s]\u001b[A\n",
      "100%|██████████| 1171184/1171184 [00:17<00:00, 67810.72it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "for g in tqdm(graphs):\n",
    "    file = g[\"file\"]\n",
    "    annotations = find_annotation_before_index(file2annotation[file], g[\"target_lineno\"])\n",
    "    g[\"annotation\"] = annotations\n",
    "#     print('='*20)\n",
    "#     print(file)\n",
    "#     print(g[\"target_lineno\"])\n",
    "#     print(g[\"context\"])\n",
    "#     print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377068\n",
      "0.32195453489801773\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for g in graphs:\n",
    "    if g[\"annotation\"]!=[]:\n",
    "        counter+=1\n",
    "print(counter)\n",
    "print(counter/len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'funcs': ['sklearn.decomposition.PCA',\n",
       "  'sklearn.decomposition.PCA.fit_transform',\n",
       "  'analyzeVectorizer.toarray',\n",
       "  'analyzeVectorizer',\n",
       "  'pullTerm'],\n",
       " 'file': '/projects/bdata/jupyter/target/nb_772610.py',\n",
       " 'target_func': 'none_func',\n",
       " 'context': \"\\npca = PCA(n_components=2)\\n\\npca_fiction_all = pca.fit_transform(analyzeVectorizer(pullTerm(datum, 'words'), 0.7, 0.05).toarray())\\n\",\n",
       " 'target_lineno': 500,\n",
       " 'nodes': [{'type': 'Module', 'children': [1, 7]},\n",
       "  {'type': 'Assign', 'children': [2, 3]},\n",
       "  {'type': 'NameStore', 'value': 'pca'},\n",
       "  {'type': 'Call', 'children': [4, 5]},\n",
       "  {'type': 'NameLoad', 'value': 'PCA'},\n",
       "  {'type': 'keyword', 'children': [6], 'value': 'n_components'},\n",
       "  {'type': 'Num', 'value': '2'},\n",
       "  {'type': 'Assign', 'children': [8, 9]},\n",
       "  {'type': 'NameStore', 'value': 'pca_fiction_all'},\n",
       "  {'type': 'Call', 'children': [10, 13]},\n",
       "  {'type': 'AttributeLoad', 'children': [11, 12]},\n",
       "  {'type': 'NameLoad', 'value': 'pca'},\n",
       "  {'type': 'attr', 'value': 'fit_transform'},\n",
       "  {'type': 'Call', 'children': [14]},\n",
       "  {'type': 'AttributeLoad', 'children': [15, 23]},\n",
       "  {'type': 'Call', 'children': [16, 17, 21, 22]},\n",
       "  {'type': 'NameLoad', 'value': 'analyzeVectorizer'},\n",
       "  {'type': 'Call', 'children': [18, 19, 20]},\n",
       "  {'type': 'NameLoad', 'value': 'pullTerm'},\n",
       "  {'type': 'NameLoad', 'value': 'datum'},\n",
       "  {'type': 'Str', 'value': 'words'},\n",
       "  {'type': 'Num', 'value': '0.7'},\n",
       "  {'type': 'Num', 'value': '0.05'},\n",
       "  {'type': 'attr', 'value': 'toarray'}],\n",
       " 'stage': None,\n",
       " 'id': 10,\n",
       " 'neighbor_cells': [9],\n",
       " 'header': ' This is the evaluation for all the books',\n",
       " 'annotation': [' This is the evaluation for all the books']}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1171184 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 2241/1171184 [00:00<00:52, 22405.53it/s]\u001b[A\n",
      "  0%|          | 4438/1171184 [00:00<00:52, 22272.93it/s]\u001b[A\n",
      "  1%|          | 6872/1171184 [00:00<00:50, 22853.47it/s]\u001b[A\n",
      "  1%|          | 9306/1171184 [00:00<00:49, 23277.80it/s]\u001b[A\n",
      "  1%|          | 11943/1171184 [00:00<00:48, 24125.56it/s]\u001b[A\n",
      "  1%|          | 14189/1171184 [00:00<00:49, 23599.23it/s]\u001b[A\n",
      "  1%|▏         | 16590/1171184 [00:00<00:48, 23720.17it/s]\u001b[A\n",
      "  2%|▏         | 18961/1171184 [00:00<00:48, 23717.00it/s]\u001b[A\n",
      "  2%|▏         | 21385/1171184 [00:00<00:48, 23866.92it/s]\u001b[A\n",
      "  2%|▏         | 23785/1171184 [00:01<00:47, 23905.16it/s]\u001b[A\n",
      "  2%|▏         | 26115/1171184 [00:01<00:48, 23539.10it/s]\u001b[A\n",
      "  2%|▏         | 28480/1171184 [00:01<00:48, 23568.76it/s]\u001b[A\n",
      "  3%|▎         | 30809/1171184 [00:01<00:48, 23473.44it/s]\u001b[A\n",
      "  3%|▎         | 33277/1171184 [00:01<00:47, 23819.99it/s]\u001b[A\n",
      "  3%|▎         | 35647/1171184 [00:01<00:47, 23727.57it/s]\u001b[A\n",
      "  3%|▎         | 38063/1171184 [00:01<00:47, 23851.92it/s]\u001b[A\n",
      "  3%|▎         | 40443/1171184 [00:01<00:47, 23627.11it/s]\u001b[A\n",
      "  4%|▎         | 42871/1171184 [00:01<00:47, 23818.30it/s]\u001b[A\n",
      "  4%|▍         | 45253/1171184 [00:01<00:47, 23816.74it/s]\u001b[A\n",
      "  4%|▍         | 47634/1171184 [00:02<00:47, 23771.95it/s]\u001b[A\n",
      "  4%|▍         | 50040/1171184 [00:02<00:46, 23857.10it/s]\u001b[A\n",
      "  4%|▍         | 52488/1171184 [00:02<00:46, 24038.41it/s]\u001b[A\n",
      "  5%|▍         | 54892/1171184 [00:02<00:46, 23931.22it/s]\u001b[A\n",
      "  5%|▍         | 57286/1171184 [00:02<00:47, 23545.02it/s]\u001b[A\n",
      "  5%|▌         | 59642/1171184 [00:02<00:47, 23322.39it/s]\u001b[A\n",
      "  5%|▌         | 62004/1171184 [00:02<00:47, 23410.27it/s]\u001b[A\n",
      "  6%|▌         | 64478/1171184 [00:02<00:46, 23793.48it/s]\u001b[A\n",
      "  6%|▌         | 66860/1171184 [00:02<00:47, 23445.14it/s]\u001b[A\n",
      "  6%|▌         | 69208/1171184 [00:02<00:47, 23444.62it/s]\u001b[A\n",
      "  6%|▌         | 71555/1171184 [00:03<00:47, 23298.85it/s]\u001b[A\n",
      "  6%|▋         | 73998/1171184 [00:03<00:46, 23624.27it/s]\u001b[A\n",
      "  7%|▋         | 76363/1171184 [00:03<00:46, 23497.10it/s]\u001b[A\n",
      "  7%|▋         | 78784/1171184 [00:03<00:46, 23704.64it/s]\u001b[A\n",
      "  7%|▋         | 81157/1171184 [00:03<00:46, 23637.04it/s]\u001b[A\n",
      "  7%|▋         | 83522/1171184 [00:03<00:46, 23240.36it/s]\u001b[A\n",
      "  7%|▋         | 86022/1171184 [00:03<00:45, 23740.67it/s]\u001b[A\n",
      "  8%|▊         | 88410/1171184 [00:03<00:45, 23781.10it/s]\u001b[A\n",
      "  8%|▊         | 90863/1171184 [00:03<00:45, 23997.81it/s]\u001b[A\n",
      "  8%|▊         | 93266/1171184 [00:03<00:45, 23728.86it/s]\u001b[A\n",
      "  8%|▊         | 95689/1171184 [00:04<00:45, 23871.41it/s]\u001b[A\n",
      "  8%|▊         | 98158/1171184 [00:04<00:44, 24110.14it/s]\u001b[A\n",
      "  9%|▊         | 100579/1171184 [00:04<00:44, 24138.56it/s]\u001b[A\n",
      "  9%|▉         | 102995/1171184 [00:04<00:44, 23938.07it/s]\u001b[A\n",
      "  9%|▉         | 105489/1171184 [00:04<00:43, 24227.02it/s]\u001b[A\n",
      "  9%|▉         | 107914/1171184 [00:04<00:44, 24051.36it/s]\u001b[A\n",
      "  9%|▉         | 110321/1171184 [00:04<00:44, 23992.38it/s]\u001b[A\n",
      " 10%|▉         | 112789/1171184 [00:04<00:43, 24193.50it/s]\u001b[A\n",
      " 10%|▉         | 115210/1171184 [00:04<00:44, 23967.83it/s]\u001b[A\n",
      " 10%|█         | 117644/1171184 [00:04<00:43, 24075.26it/s]\u001b[A\n",
      " 10%|█         | 120113/1171184 [00:05<00:43, 24253.94it/s]\u001b[A\n",
      " 10%|█         | 122590/1171184 [00:05<00:42, 24403.43it/s]\u001b[A\n",
      " 11%|█         | 125032/1171184 [00:05<00:43, 24040.61it/s]\u001b[A\n",
      " 11%|█         | 127438/1171184 [00:05<00:44, 23518.23it/s]\u001b[A\n",
      " 11%|█         | 129794/1171184 [00:05<00:44, 23155.28it/s]\u001b[A\n",
      " 11%|█▏        | 132114/1171184 [00:05<00:44, 23166.45it/s]\u001b[A\n",
      " 11%|█▏        | 134434/1171184 [00:05<00:44, 23144.59it/s]\u001b[A\n",
      " 12%|█▏        | 136751/1171184 [00:05<00:44, 23090.12it/s]\u001b[A\n",
      " 12%|█▏        | 139117/1171184 [00:05<00:44, 23257.06it/s]\u001b[A\n",
      " 12%|█▏        | 141444/1171184 [00:05<00:44, 23054.39it/s]\u001b[A\n",
      " 12%|█▏        | 143837/1171184 [00:06<00:44, 23308.60it/s]\u001b[A\n",
      " 12%|█▏        | 146170/1171184 [00:06<00:44, 23068.46it/s]\u001b[A\n",
      " 13%|█▎        | 148504/1171184 [00:06<00:44, 23145.54it/s]\u001b[A\n",
      " 13%|█▎        | 150820/1171184 [00:06<00:44, 22959.57it/s]\u001b[A\n",
      " 13%|█▎        | 153118/1171184 [00:06<00:44, 22825.21it/s]\u001b[A\n",
      " 13%|█▎        | 155402/1171184 [00:06<00:44, 22618.40it/s]\u001b[A\n",
      " 13%|█▎        | 157665/1171184 [00:06<00:44, 22599.70it/s]\u001b[A\n",
      " 14%|█▎        | 160097/1171184 [00:06<00:43, 23087.16it/s]\u001b[A\n",
      " 14%|█▍        | 162438/1171184 [00:06<00:43, 23178.37it/s]\u001b[A\n",
      " 14%|█▍        | 164866/1171184 [00:06<00:42, 23496.55it/s]\u001b[A\n",
      " 14%|█▍        | 167219/1171184 [00:07<00:42, 23488.54it/s]\u001b[A\n",
      " 14%|█▍        | 169570/1171184 [00:07<00:42, 23477.61it/s]\u001b[A\n",
      " 15%|█▍        | 171920/1171184 [00:07<00:42, 23386.84it/s]\u001b[A\n",
      " 15%|█▍        | 174261/1171184 [00:07<00:42, 23391.36it/s]\u001b[A\n",
      " 15%|█▌        | 176601/1171184 [00:07<00:42, 23350.27it/s]\u001b[A\n",
      " 15%|█▌        | 178938/1171184 [00:07<00:42, 23351.70it/s]\u001b[A\n",
      " 15%|█▌        | 181274/1171184 [00:07<00:42, 23184.96it/s]\u001b[A\n",
      " 16%|█▌        | 183594/1171184 [00:07<00:42, 23168.65it/s]\u001b[A\n",
      " 16%|█▌        | 185912/1171184 [00:07<00:43, 22870.34it/s]\u001b[A\n",
      " 16%|█▌        | 188201/1171184 [00:07<00:43, 22716.51it/s]\u001b[A\n",
      " 16%|█▋        | 190573/1171184 [00:08<00:42, 23007.25it/s]\u001b[A\n",
      " 16%|█▋        | 192876/1171184 [00:08<00:42, 23013.98it/s]\u001b[A\n",
      " 17%|█▋        | 195297/1171184 [00:08<00:41, 23359.63it/s]\u001b[A\n",
      " 17%|█▋        | 197636/1171184 [00:08<00:41, 23221.98it/s]\u001b[A\n",
      " 17%|█▋        | 199967/1171184 [00:08<00:41, 23247.96it/s]\u001b[A\n",
      " 17%|█▋        | 202293/1171184 [00:08<00:41, 23190.54it/s]\u001b[A\n",
      " 17%|█▋        | 204729/1171184 [00:08<00:41, 23526.79it/s]\u001b[A\n",
      " 18%|█▊        | 207084/1171184 [00:08<00:41, 23487.99it/s]\u001b[A\n",
      " 18%|█▊        | 209457/1171184 [00:08<00:40, 23557.34it/s]\u001b[A\n",
      " 18%|█▊        | 211814/1171184 [00:08<00:40, 23518.45it/s]\u001b[A\n",
      " 18%|█▊        | 214187/1171184 [00:09<00:40, 23579.95it/s]\u001b[A\n",
      " 18%|█▊        | 216546/1171184 [00:09<00:40, 23571.15it/s]\u001b[A\n",
      " 19%|█▊        | 218904/1171184 [00:09<00:41, 23045.62it/s]\u001b[A\n",
      " 19%|█▉        | 221276/1171184 [00:09<00:40, 23241.80it/s]\u001b[A\n",
      " 19%|█▉        | 223695/1171184 [00:09<00:40, 23517.12it/s]\u001b[A\n",
      " 19%|█▉        | 226050/1171184 [00:09<00:40, 23258.28it/s]\u001b[A\n",
      " 20%|█▉        | 228383/1171184 [00:09<00:40, 23277.46it/s]\u001b[A\n",
      " 20%|█▉        | 230824/1171184 [00:09<00:39, 23605.70it/s]\u001b[A\n",
      " 20%|█▉        | 233218/1171184 [00:09<00:39, 23704.93it/s]\u001b[A\n",
      " 20%|██        | 235598/1171184 [00:10<00:39, 23732.22it/s]\u001b[A\n",
      " 20%|██        | 237974/1171184 [00:10<00:39, 23737.64it/s]\u001b[A\n",
      " 21%|██        | 240349/1171184 [00:11<03:42, 4177.30it/s] \u001b[A\n",
      " 21%|██        | 243236/1171184 [00:11<02:45, 5619.10it/s]\u001b[A\n",
      " 21%|██        | 246228/1171184 [00:11<02:04, 7429.14it/s]\u001b[A\n",
      " 21%|██▏       | 249149/1171184 [00:12<01:36, 9569.92it/s]\u001b[A\n",
      " 22%|██▏       | 252174/1171184 [00:12<01:16, 12038.24it/s]\u001b[A\n",
      " 22%|██▏       | 255440/1171184 [00:12<01:01, 14851.28it/s]\u001b[A\n",
      " 22%|██▏       | 258525/1171184 [00:12<00:51, 17586.90it/s]\u001b[A\n",
      " 22%|██▏       | 261663/1171184 [00:12<00:44, 20257.03it/s]\u001b[A\n",
      " 23%|██▎       | 264782/1171184 [00:12<00:40, 22637.51it/s]\u001b[A\n",
      " 23%|██▎       | 268020/1171184 [00:12<00:36, 24881.80it/s]\u001b[A\n",
      " 23%|██▎       | 271108/1171184 [00:12<00:34, 26210.36it/s]\u001b[A\n",
      " 23%|██▎       | 274282/1171184 [00:12<00:32, 27655.46it/s]\u001b[A\n",
      " 24%|██▎       | 277479/1171184 [00:12<00:31, 28822.02it/s]\u001b[A\n",
      " 24%|██▍       | 280706/1171184 [00:13<00:29, 29776.33it/s]\u001b[A\n",
      " 24%|██▍       | 283863/1171184 [00:13<00:29, 30288.80it/s]\u001b[A\n",
      " 25%|██▍       | 287019/1171184 [00:13<00:29, 30330.91it/s]\u001b[A\n",
      " 25%|██▍       | 290141/1171184 [00:13<00:29, 29936.67it/s]\u001b[A\n",
      " 25%|██▌       | 293198/1171184 [00:13<00:29, 29858.69it/s]\u001b[A\n",
      " 25%|██▌       | 296290/1171184 [00:13<00:29, 30168.25it/s]\u001b[A\n",
      " 26%|██▌       | 299339/1171184 [00:13<00:28, 30089.24it/s]\u001b[A\n",
      " 26%|██▌       | 302428/1171184 [00:13<00:28, 30323.98it/s]\u001b[A\n",
      " 26%|██▌       | 305477/1171184 [00:13<00:28, 30317.54it/s]\u001b[A\n",
      " 26%|██▋       | 308520/1171184 [00:13<00:28, 30166.10it/s]\u001b[A\n",
      " 27%|██▋       | 311673/1171184 [00:14<00:28, 30561.08it/s]\u001b[A\n",
      " 27%|██▋       | 314762/1171184 [00:14<00:27, 30658.50it/s]\u001b[A\n",
      " 27%|██▋       | 317971/1171184 [00:14<00:27, 31073.08it/s]\u001b[A\n",
      " 27%|██▋       | 321102/1171184 [00:14<00:27, 31140.64it/s]\u001b[A\n",
      " 28%|██▊       | 324220/1171184 [00:14<00:27, 31026.33it/s]\u001b[A\n",
      " 28%|██▊       | 327326/1171184 [00:14<00:27, 30964.64it/s]\u001b[A\n",
      " 28%|██▊       | 330425/1171184 [00:14<00:27, 30531.17it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 333481/1171184 [00:14<00:27, 30358.58it/s]\u001b[A\n",
      " 29%|██▊       | 336551/1171184 [00:14<00:27, 30458.38it/s]\u001b[A\n",
      " 29%|██▉       | 339599/1171184 [00:15<00:27, 30232.27it/s]\u001b[A\n",
      " 29%|██▉       | 342653/1171184 [00:15<00:27, 30323.17it/s]\u001b[A\n",
      " 30%|██▉       | 345778/1171184 [00:15<00:26, 30594.29it/s]\u001b[A\n",
      " 30%|██▉       | 348889/1171184 [00:15<00:26, 30746.14it/s]\u001b[A\n",
      " 30%|███       | 352057/1171184 [00:15<00:26, 31016.70it/s]\u001b[A\n",
      " 30%|███       | 355212/1171184 [00:15<00:26, 31172.52it/s]\u001b[A\n",
      " 31%|███       | 358331/1171184 [00:15<00:26, 30684.94it/s]\u001b[A\n",
      " 31%|███       | 361611/1171184 [00:15<00:25, 31286.37it/s]\u001b[A\n",
      " 31%|███       | 364802/1171184 [00:15<00:25, 31469.76it/s]\u001b[A\n",
      " 31%|███▏      | 368088/1171184 [00:15<00:25, 31871.77it/s]\u001b[A\n",
      " 32%|███▏      | 371354/1171184 [00:16<00:24, 32103.48it/s]\u001b[A\n",
      " 32%|███▏      | 374568/1171184 [00:16<00:25, 30866.38it/s]\u001b[A\n",
      " 32%|███▏      | 377720/1171184 [00:16<00:25, 31056.63it/s]\u001b[A\n",
      " 33%|███▎      | 380835/1171184 [00:16<00:25, 30449.65it/s]\u001b[A\n",
      " 33%|███▎      | 383889/1171184 [00:16<00:26, 29876.47it/s]\u001b[A\n",
      " 33%|███▎      | 387038/1171184 [00:16<00:25, 30341.23it/s]\u001b[A\n",
      " 33%|███▎      | 390080/1171184 [00:16<00:25, 30351.09it/s]\u001b[A\n",
      " 34%|███▎      | 393137/1171184 [00:16<00:25, 30414.99it/s]\u001b[A\n",
      " 34%|███▍      | 396374/1171184 [00:16<00:25, 30975.76it/s]\u001b[A\n",
      " 34%|███▍      | 399578/1171184 [00:16<00:24, 31287.39it/s]\u001b[A\n",
      " 34%|███▍      | 402712/1171184 [00:17<00:24, 31297.02it/s]\u001b[A\n",
      " 35%|███▍      | 405904/1171184 [00:17<00:24, 31481.20it/s]\u001b[A\n",
      " 35%|███▍      | 409055/1171184 [00:17<00:24, 31099.77it/s]\u001b[A\n",
      " 35%|███▌      | 412180/1171184 [00:17<00:24, 31144.38it/s]\u001b[A\n",
      " 35%|███▌      | 415368/1171184 [00:17<00:24, 31360.25it/s]\u001b[A\n",
      " 36%|███▌      | 418506/1171184 [00:17<00:24, 30986.98it/s]\u001b[A\n",
      " 36%|███▌      | 421647/1171184 [00:17<00:24, 31111.81it/s]\u001b[A\n",
      " 36%|███▋      | 424760/1171184 [00:17<00:24, 31045.53it/s]\u001b[A\n",
      " 37%|███▋      | 427866/1171184 [00:17<00:24, 30955.41it/s]\u001b[A\n",
      " 37%|███▋      | 430979/1171184 [00:17<00:23, 31005.07it/s]\u001b[A\n",
      " 37%|███▋      | 434081/1171184 [00:18<00:24, 30314.79it/s]\u001b[A\n",
      " 37%|███▋      | 437117/1171184 [00:18<00:25, 28376.85it/s]\u001b[A\n",
      " 38%|███▊      | 439983/1171184 [00:18<00:27, 26771.86it/s]\u001b[A\n",
      " 38%|███▊      | 442699/1171184 [00:18<00:28, 25696.47it/s]\u001b[A\n",
      " 38%|███▊      | 445305/1171184 [00:18<00:28, 25043.62it/s]\u001b[A\n",
      " 38%|███▊      | 447839/1171184 [00:18<00:29, 24788.35it/s]\u001b[A\n",
      " 38%|███▊      | 450339/1171184 [00:18<00:29, 24658.76it/s]\u001b[A\n",
      " 39%|███▊      | 452820/1171184 [00:18<00:29, 24361.61it/s]\u001b[A\n",
      " 39%|███▉      | 455268/1171184 [00:18<00:29, 23935.84it/s]\u001b[A\n",
      " 39%|███▉      | 457672/1171184 [00:19<00:30, 23614.77it/s]\u001b[A\n",
      " 39%|███▉      | 460042/1171184 [00:19<00:30, 23258.88it/s]\u001b[A\n",
      " 39%|███▉      | 462375/1171184 [00:19<00:31, 22549.41it/s]\u001b[A\n",
      " 40%|███▉      | 464752/1171184 [00:19<00:30, 22900.87it/s]\u001b[A\n",
      " 40%|███▉      | 467141/1171184 [00:19<00:30, 23187.91it/s]\u001b[A\n",
      " 40%|████      | 469467/1171184 [00:19<00:30, 23207.01it/s]\u001b[A\n",
      " 40%|████      | 471872/1171184 [00:19<00:29, 23452.84it/s]\u001b[A\n",
      " 40%|████      | 474325/1171184 [00:19<00:29, 23763.85it/s]\u001b[A\n",
      " 41%|████      | 476705/1171184 [00:19<00:29, 23530.11it/s]\u001b[A\n",
      " 41%|████      | 479115/1171184 [00:19<00:29, 23695.68it/s]\u001b[A\n",
      " 41%|████      | 481487/1171184 [00:20<00:29, 23237.14it/s]\u001b[A\n",
      " 41%|████▏     | 483894/1171184 [00:20<00:29, 23479.14it/s]\u001b[A\n",
      " 42%|████▏     | 486246/1171184 [00:20<00:29, 23372.27it/s]\u001b[A\n",
      " 42%|████▏     | 488650/1171184 [00:20<00:28, 23566.67it/s]\u001b[A\n",
      " 42%|████▏     | 491009/1171184 [00:20<00:28, 23512.40it/s]\u001b[A\n",
      " 42%|████▏     | 493362/1171184 [00:20<00:29, 23329.24it/s]\u001b[A\n",
      " 42%|████▏     | 495740/1171184 [00:20<00:28, 23461.66it/s]\u001b[A\n",
      " 43%|████▎     | 498160/1171184 [00:20<00:28, 23676.77it/s]\u001b[A\n",
      " 43%|████▎     | 500529/1171184 [00:20<00:28, 23501.74it/s]\u001b[A\n",
      " 43%|████▎     | 502881/1171184 [00:20<00:28, 23474.10it/s]\u001b[A\n",
      " 43%|████▎     | 505230/1171184 [00:21<00:28, 23044.71it/s]\u001b[A\n",
      " 43%|████▎     | 507537/1171184 [00:21<00:28, 22944.90it/s]\u001b[A\n",
      " 44%|████▎     | 509834/1171184 [00:21<00:28, 22948.72it/s]\u001b[A\n",
      " 44%|████▎     | 512131/1171184 [00:21<00:28, 22917.99it/s]\u001b[A\n",
      " 44%|████▍     | 514424/1171184 [00:21<00:28, 22775.41it/s]\u001b[A\n",
      " 44%|████▍     | 516703/1171184 [00:21<00:28, 22726.91it/s]\u001b[A\n",
      " 44%|████▍     | 518994/1171184 [00:21<00:28, 22780.90it/s]\u001b[A\n",
      " 45%|████▍     | 521273/1171184 [00:21<00:28, 22766.35it/s]\u001b[A\n",
      " 45%|████▍     | 523692/1171184 [00:21<00:27, 23172.57it/s]\u001b[A\n",
      " 45%|████▍     | 526034/1171184 [00:21<00:27, 23244.65it/s]\u001b[A\n",
      " 45%|████▌     | 528364/1171184 [00:22<00:27, 23260.82it/s]\u001b[A\n",
      " 45%|████▌     | 530772/1171184 [00:22<00:27, 23495.26it/s]\u001b[A\n",
      " 46%|████▌     | 533123/1171184 [00:22<00:27, 23428.63it/s]\u001b[A\n",
      " 46%|████▌     | 535467/1171184 [00:22<00:27, 23345.68it/s]\u001b[A\n",
      " 46%|████▌     | 537803/1171184 [00:22<00:27, 23133.51it/s]\u001b[A\n",
      " 46%|████▌     | 540118/1171184 [00:22<00:27, 23059.32it/s]\u001b[A\n",
      " 46%|████▋     | 542425/1171184 [00:22<00:27, 22958.34it/s]\u001b[A\n",
      " 47%|████▋     | 544722/1171184 [00:22<00:27, 22900.54it/s]\u001b[A\n",
      " 47%|████▋     | 547058/1171184 [00:22<00:27, 23034.56it/s]\u001b[A\n",
      " 47%|████▋     | 549362/1171184 [00:23<00:27, 22843.95it/s]\u001b[A\n",
      " 47%|████▋     | 551648/1171184 [00:23<00:27, 22740.90it/s]\u001b[A\n",
      " 47%|████▋     | 553923/1171184 [00:23<00:27, 22561.82it/s]\u001b[A\n",
      " 47%|████▋     | 556290/1171184 [00:23<00:26, 22881.22it/s]\u001b[A\n",
      " 48%|████▊     | 558710/1171184 [00:23<00:26, 23261.32it/s]\u001b[A\n",
      " 48%|████▊     | 561048/1171184 [00:23<00:26, 23296.64it/s]\u001b[A\n",
      " 48%|████▊     | 563380/1171184 [00:23<00:26, 23007.61it/s]\u001b[A\n",
      " 48%|████▊     | 565709/1171184 [00:23<00:26, 23089.03it/s]\u001b[A\n",
      " 49%|████▊     | 568127/1171184 [00:23<00:25, 23404.73it/s]\u001b[A\n",
      " 49%|████▊     | 570470/1171184 [00:23<00:25, 23363.33it/s]\u001b[A\n",
      " 49%|████▉     | 572858/1171184 [00:24<00:25, 23514.07it/s]\u001b[A\n",
      " 49%|████▉     | 575213/1171184 [00:24<00:25, 23522.06it/s]\u001b[A\n",
      " 49%|████▉     | 577601/1171184 [00:24<00:25, 23628.05it/s]\u001b[A\n",
      " 50%|████▉     | 579965/1171184 [00:24<00:25, 23575.88it/s]\u001b[A\n",
      " 50%|████▉     | 582349/1171184 [00:24<00:24, 23652.76it/s]\u001b[A\n",
      " 50%|████▉     | 584789/1171184 [00:24<00:24, 23868.63it/s]\u001b[A\n",
      " 50%|█████     | 587177/1171184 [00:24<00:24, 23616.66it/s]\u001b[A\n",
      " 50%|█████     | 589541/1171184 [00:24<00:24, 23621.55it/s]\u001b[A\n",
      " 51%|█████     | 591904/1171184 [00:24<00:24, 23487.95it/s]\u001b[A\n",
      " 51%|█████     | 594254/1171184 [00:24<00:24, 23221.97it/s]\u001b[A\n",
      " 51%|█████     | 596578/1171184 [00:25<00:25, 22861.95it/s]\u001b[A\n",
      " 51%|█████     | 598969/1171184 [00:25<00:24, 23166.00it/s]\u001b[A\n",
      " 51%|█████▏    | 601289/1171184 [00:25<00:24, 23041.44it/s]\u001b[A\n",
      " 52%|█████▏    | 603640/1171184 [00:25<00:24, 23172.36it/s]\u001b[A\n",
      " 52%|█████▏    | 605959/1171184 [00:25<00:25, 22604.15it/s]\u001b[A\n",
      " 52%|█████▏    | 608315/1171184 [00:25<00:24, 22879.46it/s]\u001b[A\n",
      " 52%|█████▏    | 610620/1171184 [00:25<00:24, 22929.14it/s]\u001b[A\n",
      " 52%|█████▏    | 613062/1171184 [00:25<00:23, 23339.66it/s]\u001b[A\n",
      " 53%|█████▎    | 615400/1171184 [00:25<00:23, 23320.88it/s]\u001b[A\n",
      " 53%|█████▎    | 617779/1171184 [00:25<00:23, 23455.73it/s]\u001b[A\n",
      " 53%|█████▎    | 620127/1171184 [00:26<00:23, 23350.51it/s]\u001b[A\n",
      " 53%|█████▎    | 622509/1171184 [00:26<00:23, 23486.54it/s]\u001b[A\n",
      " 53%|█████▎    | 624881/1171184 [00:26<00:23, 23553.84it/s]\u001b[A\n",
      " 54%|█████▎    | 627339/1171184 [00:26<00:22, 23850.91it/s]\u001b[A\n",
      " 54%|█████▍    | 629726/1171184 [00:26<00:23, 23368.24it/s]\u001b[A\n",
      " 54%|█████▍    | 632158/1171184 [00:26<00:22, 23645.50it/s]\u001b[A\n",
      " 54%|█████▍    | 634526/1171184 [00:26<00:22, 23572.93it/s]\u001b[A\n",
      " 54%|█████▍    | 636976/1171184 [00:26<00:22, 23841.05it/s]\u001b[A\n",
      " 55%|█████▍    | 639363/1171184 [00:26<00:22, 23513.06it/s]\u001b[A\n",
      " 55%|█████▍    | 641717/1171184 [00:26<00:22, 23450.05it/s]\u001b[A\n",
      " 55%|█████▍    | 644076/1171184 [00:27<00:22, 23487.23it/s]\u001b[A\n",
      " 55%|█████▌    | 646552/1171184 [00:27<00:21, 23853.57it/s]\u001b[A\n",
      " 55%|█████▌    | 648940/1171184 [00:27<00:22, 23474.43it/s]\u001b[A\n",
      " 56%|█████▌    | 651291/1171184 [00:27<00:22, 23188.46it/s]\u001b[A\n",
      " 56%|█████▌    | 653613/1171184 [00:27<00:22, 23057.43it/s]\u001b[A\n",
      " 56%|█████▌    | 655954/1171184 [00:27<00:22, 23161.05it/s]\u001b[A\n",
      " 56%|█████▌    | 658272/1171184 [00:27<00:22, 22997.30it/s]\u001b[A\n",
      " 56%|█████▋    | 660574/1171184 [00:27<00:22, 22821.34it/s]\u001b[A\n",
      " 57%|█████▋    | 662917/1171184 [00:27<00:22, 22996.32it/s]\u001b[A\n",
      " 57%|█████▋    | 665270/1171184 [00:27<00:21, 23152.26it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 667587/1171184 [00:28<00:21, 23110.15it/s]\u001b[A\n",
      " 57%|█████▋    | 669910/1171184 [00:28<00:21, 23141.89it/s]\u001b[A\n",
      " 57%|█████▋    | 672225/1171184 [00:28<00:21, 22948.54it/s]\u001b[A\n",
      " 58%|█████▊    | 674621/1171184 [00:28<00:21, 23242.26it/s]\u001b[A\n",
      " 58%|█████▊    | 677032/1171184 [00:28<00:21, 23494.76it/s]\u001b[A\n",
      " 58%|█████▊    | 679384/1171184 [00:28<00:20, 23435.24it/s]\u001b[A\n",
      " 58%|█████▊    | 681729/1171184 [00:28<00:21, 23251.81it/s]\u001b[A\n",
      " 58%|█████▊    | 684152/1171184 [00:28<00:20, 23536.71it/s]\u001b[A\n",
      " 59%|█████▊    | 686508/1171184 [00:28<00:20, 23350.48it/s]\u001b[A\n",
      " 59%|█████▉    | 688949/1171184 [00:28<00:20, 23654.64it/s]\u001b[A\n",
      " 59%|█████▉    | 691317/1171184 [00:29<00:20, 23498.68it/s]\u001b[A\n",
      " 59%|█████▉    | 693669/1171184 [00:29<00:20, 23371.62it/s]\u001b[A\n",
      " 59%|█████▉    | 696041/1171184 [00:29<00:20, 23470.82it/s]\u001b[A\n",
      " 60%|█████▉    | 698390/1171184 [00:29<00:20, 23296.67it/s]\u001b[A\n",
      " 60%|█████▉    | 700721/1171184 [00:29<00:20, 23171.57it/s]\u001b[A\n",
      " 60%|██████    | 703104/1171184 [00:29<00:20, 23364.78it/s]\u001b[A\n",
      " 60%|██████    | 705459/1171184 [00:29<00:19, 23419.59it/s]\u001b[A\n",
      " 60%|██████    | 707845/1171184 [00:29<00:19, 23549.69it/s]\u001b[A\n",
      " 61%|██████    | 710212/1171184 [00:29<00:19, 23584.79it/s]\u001b[A\n",
      " 61%|██████    | 712571/1171184 [00:29<00:19, 23505.25it/s]\u001b[A\n",
      " 61%|██████    | 714922/1171184 [00:30<00:19, 23478.98it/s]\u001b[A\n",
      " 61%|██████    | 717295/1171184 [00:30<00:19, 23553.03it/s]\u001b[A\n",
      " 61%|██████▏   | 719651/1171184 [00:30<00:19, 23389.07it/s]\u001b[A\n",
      " 62%|██████▏   | 722097/1171184 [00:30<00:18, 23697.31it/s]\u001b[A\n",
      " 62%|██████▏   | 724469/1171184 [00:30<00:19, 23343.63it/s]\u001b[A\n",
      " 62%|██████▏   | 726806/1171184 [00:30<00:19, 23152.42it/s]\u001b[A\n",
      " 62%|██████▏   | 729225/1171184 [00:30<00:18, 23452.13it/s]\u001b[A\n",
      " 62%|██████▏   | 731573/1171184 [00:36<05:58, 1226.06it/s] \u001b[A\n",
      " 63%|██████▎   | 734275/1171184 [00:36<04:14, 1718.09it/s]\u001b[A\n",
      " 63%|██████▎   | 737251/1171184 [00:37<03:01, 2395.14it/s]\u001b[A\n",
      " 63%|██████▎   | 740260/1171184 [00:37<02:10, 3308.70it/s]\u001b[A\n",
      " 63%|██████▎   | 743258/1171184 [00:37<01:34, 4513.22it/s]\u001b[A\n",
      " 64%|██████▎   | 746128/1171184 [00:37<01:10, 6040.35it/s]\u001b[A\n",
      " 64%|██████▍   | 749106/1171184 [00:37<00:53, 7938.83it/s]\u001b[A\n",
      " 64%|██████▍   | 752280/1171184 [00:37<00:40, 10242.90it/s]\u001b[A\n",
      " 64%|██████▍   | 755411/1171184 [00:37<00:32, 12833.19it/s]\u001b[A\n",
      " 65%|██████▍   | 758504/1171184 [00:37<00:26, 15548.04it/s]\u001b[A\n",
      " 65%|██████▌   | 761507/1171184 [00:37<00:23, 17494.55it/s]\u001b[A\n",
      " 65%|██████▌   | 764351/1171184 [00:37<00:21, 19193.60it/s]\u001b[A\n",
      " 65%|██████▌   | 767086/1171184 [00:38<00:19, 20556.45it/s]\u001b[A\n",
      " 66%|██████▌   | 769740/1171184 [00:38<00:18, 21442.04it/s]\u001b[A\n",
      " 66%|██████▌   | 772313/1171184 [00:38<00:17, 22499.84it/s]\u001b[A\n",
      " 66%|██████▌   | 774877/1171184 [00:38<00:17, 23073.57it/s]\u001b[A\n",
      " 66%|██████▋   | 777408/1171184 [00:38<00:16, 23410.06it/s]\u001b[A\n",
      " 67%|██████▋   | 779907/1171184 [00:38<00:16, 23828.75it/s]\u001b[A\n",
      " 67%|██████▋   | 782402/1171184 [00:38<00:16, 23465.66it/s]\u001b[A\n",
      " 67%|██████▋   | 784829/1171184 [00:38<00:16, 23507.88it/s]\u001b[A\n",
      " 67%|██████▋   | 787236/1171184 [00:38<00:16, 23547.34it/s]\u001b[A\n",
      " 67%|██████▋   | 789662/1171184 [00:39<00:16, 23755.28it/s]\u001b[A\n",
      " 68%|██████▊   | 792066/1171184 [00:39<00:15, 23710.63it/s]\u001b[A\n",
      " 68%|██████▊   | 794457/1171184 [00:39<00:16, 23338.74it/s]\u001b[A\n",
      " 68%|██████▊   | 796806/1171184 [00:39<00:16, 23353.29it/s]\u001b[A\n",
      " 68%|██████▊   | 799159/1171184 [00:39<00:15, 23404.05it/s]\u001b[A\n",
      " 68%|██████▊   | 801507/1171184 [00:39<00:15, 23421.21it/s]\u001b[A\n",
      " 69%|██████▊   | 803984/1171184 [00:39<00:15, 23809.35it/s]\u001b[A\n",
      " 69%|██████▉   | 806371/1171184 [00:39<00:15, 23686.38it/s]\u001b[A\n",
      " 69%|██████▉   | 808744/1171184 [00:39<00:15, 23298.67it/s]\u001b[A\n",
      " 69%|██████▉   | 811136/1171184 [00:39<00:15, 23481.27it/s]\u001b[A\n",
      " 69%|██████▉   | 813488/1171184 [00:40<00:15, 23046.40it/s]\u001b[A\n",
      " 70%|██████▉   | 815858/1171184 [00:40<00:15, 23238.08it/s]\u001b[A\n",
      " 70%|██████▉   | 818186/1171184 [00:40<00:15, 23133.19it/s]\u001b[A\n",
      " 70%|███████   | 820513/1171184 [00:40<00:15, 23173.39it/s]\u001b[A\n",
      " 70%|███████   | 822832/1171184 [00:40<00:15, 22836.98it/s]\u001b[A\n",
      " 70%|███████   | 825186/1171184 [00:40<00:15, 23043.38it/s]\u001b[A\n",
      " 71%|███████   | 827502/1171184 [00:40<00:14, 23077.89it/s]\u001b[A\n",
      " 71%|███████   | 829812/1171184 [00:40<00:14, 22988.74it/s]\u001b[A\n",
      " 71%|███████   | 832112/1171184 [00:40<00:14, 22886.30it/s]\u001b[A\n",
      " 71%|███████   | 834402/1171184 [00:42<01:10, 4804.69it/s] \u001b[A\n",
      " 71%|███████▏  | 837390/1171184 [00:42<00:51, 6421.22it/s]\u001b[A\n",
      " 72%|███████▏  | 840335/1171184 [00:42<00:39, 8389.21it/s]\u001b[A\n",
      " 72%|███████▏  | 843112/1171184 [00:42<00:30, 10610.67it/s]\u001b[A\n",
      " 72%|███████▏  | 845941/1171184 [00:42<00:24, 13058.59it/s]\u001b[A\n",
      " 72%|███████▏  | 848919/1171184 [00:42<00:20, 15703.64it/s]\u001b[A\n",
      " 73%|███████▎  | 852057/1171184 [00:42<00:17, 18471.93it/s]\u001b[A\n",
      " 73%|███████▎  | 855129/1171184 [00:42<00:15, 20980.79it/s]\u001b[A\n",
      " 73%|███████▎  | 858263/1171184 [00:43<00:13, 23289.64it/s]\u001b[A\n",
      " 74%|███████▎  | 861327/1171184 [00:43<00:12, 25094.75it/s]\u001b[A\n",
      " 74%|███████▍  | 864554/1171184 [00:43<00:11, 26887.78it/s]\u001b[A\n",
      " 74%|███████▍  | 867684/1171184 [00:43<00:10, 28073.49it/s]\u001b[A\n",
      " 74%|███████▍  | 870986/1171184 [00:43<00:10, 29393.79it/s]\u001b[A\n",
      " 75%|███████▍  | 874137/1171184 [00:43<00:10, 27155.00it/s]\u001b[A\n",
      " 75%|███████▍  | 877034/1171184 [00:43<00:11, 25811.04it/s]\u001b[A\n",
      " 75%|███████▌  | 879756/1171184 [00:43<00:11, 25091.84it/s]\u001b[A\n",
      " 75%|███████▌  | 882369/1171184 [00:43<00:11, 24275.90it/s]\u001b[A\n",
      " 76%|███████▌  | 884875/1171184 [00:44<00:11, 24100.43it/s]\u001b[A\n",
      " 76%|███████▌  | 887340/1171184 [00:44<00:11, 23671.41it/s]\u001b[A\n",
      " 76%|███████▌  | 889748/1171184 [00:44<00:11, 23763.14it/s]\u001b[A\n",
      " 76%|███████▌  | 892153/1171184 [00:44<00:11, 23734.37it/s]\u001b[A\n",
      " 76%|███████▋  | 894580/1171184 [00:44<00:11, 23891.82it/s]\u001b[A\n",
      " 77%|███████▋  | 897010/1171184 [00:44<00:11, 24011.89it/s]\u001b[A\n",
      " 77%|███████▋  | 899422/1171184 [00:44<00:11, 23864.89it/s]\u001b[A\n",
      " 77%|███████▋  | 901816/1171184 [00:44<00:11, 22970.09it/s]\u001b[A\n",
      " 77%|███████▋  | 904126/1171184 [00:44<00:11, 22855.50it/s]\u001b[A\n",
      " 77%|███████▋  | 906454/1171184 [00:44<00:11, 22981.07it/s]\u001b[A\n",
      " 78%|███████▊  | 908785/1171184 [00:45<00:11, 23063.05it/s]\u001b[A\n",
      " 78%|███████▊  | 911096/1171184 [00:45<00:11, 22344.37it/s]\u001b[A\n",
      " 78%|███████▊  | 913360/1171184 [00:45<00:11, 22428.36it/s]\u001b[A\n",
      " 78%|███████▊  | 915691/1171184 [00:45<00:11, 22683.48it/s]\u001b[A\n",
      " 78%|███████▊  | 918065/1171184 [00:45<00:11, 22989.88it/s]\u001b[A\n",
      " 79%|███████▊  | 920401/1171184 [00:45<00:10, 23099.65it/s]\u001b[A\n",
      " 79%|███████▉  | 922793/1171184 [00:45<00:10, 23339.44it/s]\u001b[A\n",
      " 79%|███████▉  | 925130/1171184 [00:45<00:10, 23233.88it/s]\u001b[A\n",
      " 79%|███████▉  | 927584/1171184 [00:45<00:10, 23608.37it/s]\u001b[A\n",
      " 79%|███████▉  | 929988/1171184 [00:45<00:10, 23732.25it/s]\u001b[A\n",
      " 80%|███████▉  | 932364/1171184 [00:46<00:10, 23488.99it/s]\u001b[A\n",
      " 80%|███████▉  | 934715/1171184 [00:46<00:10, 23323.94it/s]\u001b[A\n",
      " 80%|████████  | 937050/1171184 [00:46<00:10, 23209.13it/s]\u001b[A\n",
      " 80%|████████  | 939449/1171184 [00:46<00:09, 23434.31it/s]\u001b[A\n",
      " 80%|████████  | 941794/1171184 [00:46<00:09, 23375.15it/s]\u001b[A\n",
      " 81%|████████  | 944133/1171184 [00:46<00:09, 22944.78it/s]\u001b[A\n",
      " 81%|████████  | 946430/1171184 [00:46<00:09, 22750.23it/s]\u001b[A\n",
      " 81%|████████  | 948775/1171184 [00:46<00:09, 22955.08it/s]\u001b[A\n",
      " 81%|████████  | 951073/1171184 [00:46<00:09, 22868.87it/s]\u001b[A\n",
      " 81%|████████▏ | 953426/1171184 [00:46<00:09, 23062.65it/s]\u001b[A\n",
      " 82%|████████▏ | 955734/1171184 [00:47<00:09, 22729.19it/s]\u001b[A\n",
      " 82%|████████▏ | 958174/1171184 [00:47<00:09, 23204.85it/s]\u001b[A\n",
      " 82%|████████▏ | 960499/1171184 [00:47<00:09, 23206.53it/s]\u001b[A\n",
      " 82%|████████▏ | 962851/1171184 [00:47<00:08, 23299.43it/s]\u001b[A\n",
      " 82%|████████▏ | 965283/1171184 [00:47<00:08, 23595.81it/s]\u001b[A\n",
      " 83%|████████▎ | 967645/1171184 [00:47<00:08, 23378.53it/s]\u001b[A\n",
      " 83%|████████▎ | 970022/1171184 [00:47<00:08, 23490.51it/s]\u001b[A\n",
      " 83%|████████▎ | 972373/1171184 [00:47<00:08, 23420.84it/s]\u001b[A\n",
      " 83%|████████▎ | 974717/1171184 [00:47<00:08, 23284.76it/s]\u001b[A\n",
      " 83%|████████▎ | 977047/1171184 [00:48<00:08, 23176.61it/s]\u001b[A\n",
      " 84%|████████▎ | 979395/1171184 [00:48<00:08, 23265.80it/s]\u001b[A\n",
      " 84%|████████▍ | 981818/1171184 [00:48<00:08, 23544.79it/s]\u001b[A\n",
      " 84%|████████▍ | 984174/1171184 [00:48<00:07, 23395.67it/s]\u001b[A\n",
      " 84%|████████▍ | 986515/1171184 [00:48<00:07, 23096.44it/s]\u001b[A\n",
      " 84%|████████▍ | 988894/1171184 [00:48<00:07, 23299.76it/s]\u001b[A\n",
      " 85%|████████▍ | 991321/1171184 [00:48<00:07, 23582.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 993691/1171184 [00:48<00:07, 23616.32it/s]\u001b[A\n",
      " 85%|████████▌ | 996119/1171184 [00:48<00:07, 23811.45it/s]\u001b[A\n",
      " 85%|████████▌ | 998502/1171184 [00:48<00:07, 23778.03it/s]\u001b[A\n",
      " 85%|████████▌ | 1000881/1171184 [00:49<00:07, 23631.52it/s]\u001b[A\n",
      " 86%|████████▌ | 1003246/1171184 [00:49<00:07, 23616.42it/s]\u001b[A\n",
      " 86%|████████▌ | 1005609/1171184 [00:49<00:07, 23604.99it/s]\u001b[A\n",
      " 86%|████████▌ | 1008021/1171184 [00:49<00:06, 23755.85it/s]\u001b[A\n",
      " 86%|████████▋ | 1010444/1171184 [00:49<00:06, 23895.49it/s]\u001b[A\n",
      " 86%|████████▋ | 1012892/1171184 [00:49<00:06, 24064.05it/s]\u001b[A\n",
      " 87%|████████▋ | 1015300/1171184 [00:49<00:06, 23523.96it/s]\u001b[A\n",
      " 87%|████████▋ | 1017656/1171184 [00:49<00:06, 23431.01it/s]\u001b[A\n",
      " 87%|████████▋ | 1020093/1171184 [00:49<00:06, 23703.69it/s]\u001b[A\n",
      " 87%|████████▋ | 1022494/1171184 [00:49<00:06, 23794.14it/s]\u001b[A\n",
      " 88%|████████▊ | 1024876/1171184 [00:50<00:06, 23467.97it/s]\u001b[A\n",
      " 88%|████████▊ | 1027226/1171184 [00:50<00:06, 23462.27it/s]\u001b[A\n",
      " 88%|████████▊ | 1029680/1171184 [00:50<00:05, 23774.75it/s]\u001b[A\n",
      " 88%|████████▊ | 1032129/1171184 [00:50<00:05, 23981.70it/s]\u001b[A\n",
      " 88%|████████▊ | 1034530/1171184 [00:50<00:05, 23698.84it/s]\u001b[A\n",
      " 89%|████████▊ | 1036902/1171184 [00:50<00:05, 23526.44it/s]\u001b[A\n",
      " 89%|████████▊ | 1039257/1171184 [00:50<00:05, 23362.21it/s]\u001b[A\n",
      " 89%|████████▉ | 1041595/1171184 [00:50<00:05, 23209.53it/s]\u001b[A\n",
      " 89%|████████▉ | 1044004/1171184 [00:50<00:05, 23466.09it/s]\u001b[A\n",
      " 89%|████████▉ | 1046353/1171184 [00:50<00:05, 23441.03it/s]\u001b[A\n",
      " 90%|████████▉ | 1048714/1171184 [00:51<00:05, 23490.47it/s]\u001b[A\n",
      " 90%|████████▉ | 1051064/1171184 [00:51<00:05, 23459.82it/s]\u001b[A\n",
      " 90%|████████▉ | 1053411/1171184 [00:51<00:05, 23461.89it/s]\u001b[A\n",
      " 90%|█████████ | 1055758/1171184 [00:51<00:04, 23108.80it/s]\u001b[A\n",
      " 90%|█████████ | 1058071/1171184 [00:51<00:04, 22838.91it/s]\u001b[A\n",
      " 91%|█████████ | 1060487/1171184 [00:51<00:04, 23219.79it/s]\u001b[A\n",
      " 91%|█████████ | 1062904/1171184 [00:51<00:04, 23496.49it/s]\u001b[A\n",
      " 91%|█████████ | 1065265/1171184 [00:51<00:04, 23529.41it/s]\u001b[A\n",
      " 91%|█████████ | 1067679/1171184 [00:51<00:04, 23708.00it/s]\u001b[A\n",
      " 91%|█████████▏| 1070052/1171184 [00:51<00:04, 23488.93it/s]\u001b[A\n",
      " 92%|█████████▏| 1072428/1171184 [00:52<00:04, 23568.44it/s]\u001b[A\n",
      " 92%|█████████▏| 1074787/1171184 [00:52<00:04, 23187.64it/s]\u001b[A\n",
      " 92%|█████████▏| 1077108/1171184 [00:52<00:04, 22969.79it/s]\u001b[A\n",
      " 92%|█████████▏| 1079436/1171184 [00:52<00:03, 23060.92it/s]\u001b[A\n",
      " 92%|█████████▏| 1081744/1171184 [00:52<00:04, 22224.94it/s]\u001b[A\n",
      " 93%|█████████▎| 1083975/1171184 [00:52<00:03, 22108.75it/s]\u001b[A\n",
      " 93%|█████████▎| 1086446/1171184 [00:52<00:03, 22828.12it/s]\u001b[A\n",
      " 93%|█████████▎| 1088775/1171184 [00:52<00:03, 22962.94it/s]\u001b[A\n",
      " 93%|█████████▎| 1091158/1171184 [00:52<00:03, 23212.12it/s]\u001b[A\n",
      " 93%|█████████▎| 1093526/1171184 [00:52<00:03, 23347.80it/s]\u001b[A\n",
      " 94%|█████████▎| 1095865/1171184 [00:53<00:03, 23349.44it/s]\u001b[A\n",
      " 94%|█████████▍| 1098203/1171184 [00:53<00:03, 23056.18it/s]\u001b[A\n",
      " 94%|█████████▍| 1100552/1171184 [00:53<00:03, 23181.94it/s]\u001b[A\n",
      " 94%|█████████▍| 1102960/1171184 [00:53<00:02, 23443.69it/s]\u001b[A\n",
      " 94%|█████████▍| 1105342/1171184 [00:53<00:02, 23553.76it/s]\u001b[A\n",
      " 95%|█████████▍| 1107724/1171184 [00:53<00:02, 23631.50it/s]\u001b[A\n",
      " 95%|█████████▍| 1110089/1171184 [00:53<00:02, 23608.23it/s]\u001b[A\n",
      " 95%|█████████▍| 1112451/1171184 [00:53<00:02, 23508.06it/s]\u001b[A\n",
      " 95%|█████████▌| 1114803/1171184 [00:53<00:02, 23412.28it/s]\u001b[A\n",
      " 95%|█████████▌| 1117145/1171184 [00:53<00:02, 23322.64it/s]\u001b[A\n",
      " 96%|█████████▌| 1119519/1171184 [00:54<00:02, 23444.02it/s]\u001b[A\n",
      " 96%|█████████▌| 1121907/1171184 [00:54<00:02, 23570.19it/s]\u001b[A\n",
      " 96%|█████████▌| 1124283/1171184 [00:54<00:01, 23624.10it/s]\u001b[A\n",
      " 96%|█████████▌| 1126646/1171184 [00:54<00:01, 23033.95it/s]\u001b[A\n",
      " 96%|█████████▋| 1128981/1171184 [00:54<00:01, 23127.77it/s]\u001b[A\n",
      " 97%|█████████▋| 1131477/1171184 [00:54<00:01, 23644.45it/s]\u001b[A\n",
      " 97%|█████████▋| 1133852/1171184 [00:54<00:01, 23674.87it/s]\u001b[A\n",
      " 97%|█████████▋| 1136255/1171184 [00:54<00:01, 23778.90it/s]\u001b[A\n",
      " 97%|█████████▋| 1138636/1171184 [00:54<00:01, 23739.27it/s]\u001b[A\n",
      " 97%|█████████▋| 1141012/1171184 [00:54<00:01, 23685.59it/s]\u001b[A\n",
      " 98%|█████████▊| 1143440/1171184 [00:55<00:01, 23856.30it/s]\u001b[A\n",
      " 98%|█████████▊| 1145854/1171184 [00:55<00:01, 23940.12it/s]\u001b[A\n",
      " 98%|█████████▊| 1148249/1171184 [00:55<00:00, 23407.27it/s]\u001b[A\n",
      " 98%|█████████▊| 1150654/1171184 [00:55<00:00, 23592.84it/s]\u001b[A\n",
      " 98%|█████████▊| 1153049/1171184 [00:55<00:00, 23697.86it/s]\u001b[A\n",
      " 99%|█████████▊| 1155688/1171184 [00:55<00:00, 24445.97it/s]\u001b[A\n",
      " 99%|█████████▉| 1158140/1171184 [00:55<00:00, 24175.82it/s]\u001b[A\n",
      " 99%|█████████▉| 1160600/1171184 [00:55<00:00, 24295.87it/s]\u001b[A\n",
      " 99%|█████████▉| 1163082/1171184 [00:55<00:00, 24450.33it/s]\u001b[A\n",
      "100%|█████████▉| 1165531/1171184 [00:56<00:00, 24367.67it/s]\u001b[A\n",
      "100%|█████████▉| 1167971/1171184 [00:56<00:00, 23669.98it/s]\u001b[A\n",
      "100%|██████████| 1171184/1171184 [00:56<00:00, 20816.81it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "with open('./graphs/cell_with_func_markdown_1_26.txt','w') as fout:\n",
    "    for g in tqdm(graphs):\n",
    "        fout.write(json.dumps(g, ensure_ascii=False))\n",
    "        fout.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Markdown for Test Cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "\n",
    "with open('./graphs/temp_cell_test_12_19.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        graphs.append(json.loads(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "818"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [g[\"file\"] for g in graphs]\n",
    "files = list(set(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/bdata/jupyter/_7_1/nb_1193256.py'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2annotation = {}\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "    annotation_info = get_annotation_header(content)\n",
    "    file2annotation[file] = annotation_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "15\n",
      "30\n",
      "37\n",
      "45\n",
      "52\n",
      "62\n",
      "0\n",
      "18\n",
      "25\n",
      "0\n",
      "8\n",
      "18\n",
      "29\n",
      "38\n",
      "47\n",
      "56\n",
      "0\n",
      "10\n",
      "26\n",
      "39\n",
      "103\n",
      "0\n",
      "7\n",
      "16\n",
      "22\n",
      "31\n",
      "37\n",
      "43\n",
      "49\n",
      "55\n",
      "63\n",
      "69\n",
      "75\n",
      "81\n",
      "87\n",
      "93\n",
      "101\n",
      "107\n",
      "113\n",
      "121\n",
      "127\n",
      "135\n",
      "141\n",
      "147\n",
      "153\n",
      "0\n",
      "7\n",
      "54\n",
      "77\n",
      "120\n",
      "130\n",
      "138\n",
      "147\n",
      "0\n",
      "14\n",
      "22\n",
      "44\n",
      "53\n",
      "72\n",
      "82\n",
      "90\n",
      "100\n",
      "0\n",
      "24\n",
      "32\n",
      "42\n",
      "58\n",
      "65\n",
      "89\n",
      "96\n",
      "136\n",
      "154\n",
      "171\n",
      "183\n",
      "200\n",
      "211\n",
      "217\n",
      "229\n",
      "243\n",
      "257\n",
      "267\n",
      "279\n",
      "293\n",
      "307\n",
      "319\n",
      "325\n",
      "331\n",
      "345\n",
      "0\n",
      "11\n",
      "22\n",
      "28\n",
      "35\n",
      "42\n",
      "58\n",
      "65\n",
      "0\n",
      "28\n",
      "37\n",
      "45\n",
      "58\n",
      "85\n",
      "96\n",
      "106\n",
      "113\n",
      "119\n",
      "128\n",
      "137\n",
      "146\n",
      "155\n",
      "164\n",
      "176\n",
      "186\n",
      "198\n",
      "214\n",
      "230\n",
      "256\n",
      "281\n",
      "292\n",
      "310\n",
      "323\n",
      "333\n",
      "339\n",
      "349\n",
      "355\n",
      "361\n",
      "372\n",
      "378\n",
      "394\n",
      "427\n",
      "460\n",
      "486\n",
      "502\n",
      "0\n",
      "14\n",
      "25\n",
      "40\n",
      "50\n",
      "61\n",
      "81\n",
      "97\n",
      "115\n",
      "130\n",
      "0\n",
      "8\n",
      "16\n",
      "22\n",
      "32\n",
      "42\n",
      "53\n",
      "60\n",
      "67\n",
      "74\n",
      "81\n",
      "88\n",
      "95\n",
      "102\n",
      "109\n",
      "116\n",
      "122\n",
      "129\n",
      "136\n",
      "146\n",
      "155\n",
      "0\n",
      "31\n",
      "58\n",
      "92\n",
      "109\n",
      "125\n",
      "133\n",
      "146\n",
      "156\n",
      "0\n",
      "18\n",
      "25\n",
      "32\n",
      "51\n",
      "58\n",
      "71\n",
      "87\n",
      "95\n",
      "105\n",
      "118\n",
      "133\n",
      "0\n",
      "21\n",
      "44\n",
      "53\n",
      "62\n",
      "68\n",
      "81\n",
      "90\n",
      "101\n",
      "114\n",
      "158\n",
      "164\n",
      "173\n",
      "184\n",
      "197\n",
      "0\n",
      "17\n",
      "23\n",
      "29\n",
      "35\n",
      "41\n",
      "47\n",
      "53\n",
      "80\n",
      "86\n",
      "92\n",
      "98\n",
      "104\n",
      "110\n",
      "116\n",
      "122\n",
      "128\n",
      "134\n",
      "140\n",
      "146\n",
      "152\n",
      "158\n",
      "164\n",
      "170\n",
      "176\n",
      "182\n",
      "188\n",
      "194\n",
      "200\n",
      "206\n",
      "212\n",
      "218\n",
      "224\n",
      "230\n",
      "236\n",
      "242\n",
      "248\n",
      "254\n",
      "260\n",
      "266\n",
      "272\n",
      "278\n",
      "284\n",
      "308\n",
      "314\n",
      "320\n",
      "326\n",
      "332\n",
      "338\n",
      "344\n",
      "350\n",
      "356\n",
      "362\n",
      "368\n",
      "374\n",
      "380\n",
      "386\n",
      "0\n",
      "16\n",
      "24\n",
      "33\n",
      "40\n",
      "49\n",
      "0\n",
      "20\n",
      "0\n",
      "9\n",
      "25\n",
      "0\n",
      "7\n",
      "14\n",
      "20\n",
      "26\n",
      "32\n",
      "38\n",
      "44\n",
      "50\n",
      "57\n",
      "63\n",
      "69\n",
      "76\n",
      "82\n",
      "90\n",
      "98\n",
      "104\n",
      "110\n",
      "116\n",
      "123\n",
      "0\n",
      "45\n",
      "53\n",
      "66\n",
      "0\n",
      "13\n",
      "21\n",
      "32\n",
      "78\n",
      "0\n",
      "14\n",
      "26\n",
      "35\n",
      "41\n",
      "47\n",
      "53\n",
      "59\n",
      "65\n",
      "71\n",
      "80\n",
      "89\n",
      "97\n",
      "105\n",
      "113\n",
      "124\n",
      "133\n",
      "141\n",
      "153\n",
      "163\n",
      "174\n",
      "182\n",
      "206\n",
      "215\n",
      "223\n",
      "231\n",
      "258\n",
      "267\n",
      "278\n",
      "291\n",
      "298\n",
      "315\n",
      "324\n",
      "335\n",
      "346\n",
      "360\n",
      "369\n",
      "378\n",
      "387\n",
      "396\n",
      "402\n",
      "411\n",
      "420\n",
      "426\n",
      "434\n",
      "472\n",
      "478\n",
      "518\n",
      "527\n",
      "536\n",
      "545\n",
      "558\n",
      "567\n",
      "577\n",
      "585\n",
      "596\n",
      "606\n",
      "615\n",
      "624\n",
      "634\n",
      "642\n",
      "650\n",
      "658\n",
      "664\n",
      "671\n",
      "679\n",
      "694\n",
      "703\n",
      "718\n",
      "724\n",
      "730\n",
      "0\n",
      "20\n",
      "38\n",
      "44\n",
      "50\n",
      "56\n",
      "65\n",
      "71\n",
      "87\n",
      "98\n",
      "113\n",
      "121\n",
      "129\n",
      "138\n",
      "146\n",
      "156\n",
      "164\n",
      "170\n",
      "176\n",
      "195\n",
      "201\n",
      "220\n",
      "0\n",
      "6\n",
      "16\n",
      "24\n",
      "31\n",
      "37\n",
      "43\n",
      "49\n",
      "55\n",
      "63\n",
      "71\n",
      "78\n",
      "84\n",
      "90\n",
      "118\n",
      "142\n",
      "164\n",
      "183\n",
      "207\n",
      "0\n",
      "9\n",
      "15\n",
      "23\n",
      "30\n",
      "38\n",
      "56\n",
      "72\n",
      "87\n",
      "0\n",
      "15\n",
      "24\n",
      "32\n",
      "43\n",
      "61\n",
      "82\n",
      "88\n",
      "114\n",
      "131\n",
      "139\n",
      "160\n",
      "0\n",
      "0\n",
      "13\n",
      "88\n",
      "163\n",
      "173\n",
      "180\n",
      "188\n",
      "197\n",
      "209\n",
      "221\n",
      "232\n",
      "244\n",
      "264\n",
      "0\n",
      "13\n",
      "20\n",
      "26\n",
      "32\n",
      "38\n",
      "44\n",
      "50\n",
      "56\n",
      "62\n",
      "68\n",
      "75\n",
      "82\n",
      "89\n",
      "96\n",
      "103\n",
      "109\n",
      "116\n",
      "122\n",
      "128\n",
      "134\n",
      "140\n",
      "248\n",
      "461\n",
      "468\n",
      "496\n",
      "524\n",
      "577\n",
      "0\n",
      "0\n",
      "9\n",
      "19\n",
      "26\n",
      "32\n",
      "40\n",
      "53\n",
      "60\n",
      "0\n",
      "13\n",
      "24\n",
      "39\n",
      "48\n",
      "0\n",
      "16\n",
      "47\n",
      "64\n",
      "76\n",
      "82\n",
      "0\n",
      "8\n",
      "14\n",
      "21\n",
      "28\n",
      "36\n",
      "43\n",
      "51\n",
      "63\n",
      "73\n",
      "0\n",
      "7\n",
      "17\n",
      "32\n",
      "44\n",
      "57\n",
      "69\n",
      "82\n",
      "0\n",
      "9\n",
      "27\n",
      "35\n",
      "47\n",
      "55\n",
      "65\n",
      "75\n",
      "84\n",
      "92\n",
      "100\n",
      "108\n",
      "131\n",
      "147\n",
      "154\n",
      "160\n",
      "167\n",
      "175\n",
      "197\n",
      "210\n",
      "217\n",
      "283\n",
      "291\n",
      "303\n",
      "312\n",
      "322\n",
      "331\n",
      "337\n",
      "344\n",
      "380\n",
      "392\n",
      "401\n",
      "416\n",
      "425\n",
      "437\n",
      "448\n",
      "465\n",
      "481\n",
      "495\n",
      "501\n",
      "507\n",
      "0\n",
      "13\n",
      "23\n",
      "29\n",
      "35\n",
      "41\n",
      "47\n",
      "54\n",
      "60\n",
      "68\n",
      "75\n",
      "82\n",
      "89\n",
      "96\n",
      "104\n",
      "0\n",
      "11\n",
      "20\n",
      "28\n",
      "37\n",
      "47\n",
      "55\n",
      "63\n",
      "73\n",
      "88\n",
      "100\n",
      "114\n",
      "129\n",
      "144\n",
      "154\n",
      "160\n",
      "175\n",
      "185\n",
      "191\n",
      "201\n",
      "210\n",
      "219\n",
      "228\n",
      "236\n",
      "246\n",
      "257\n",
      "271\n",
      "287\n",
      "293\n",
      "300\n",
      "309\n",
      "331\n",
      "340\n",
      "353\n",
      "365\n",
      "373\n",
      "379\n",
      "385\n",
      "398\n",
      "404\n",
      "417\n",
      "435\n",
      "443\n",
      "450\n",
      "457\n",
      "495\n",
      "0\n",
      "7\n",
      "14\n",
      "26\n",
      "33\n",
      "40\n",
      "51\n",
      "63\n",
      "75\n",
      "83\n",
      "102\n",
      "113\n",
      "120\n",
      "134\n",
      "150\n",
      "159\n",
      "165\n",
      "171\n",
      "180\n",
      "192\n",
      "0\n",
      "11\n",
      "18\n",
      "25\n",
      "35\n",
      "42\n",
      "50\n",
      "56\n",
      "62\n",
      "68\n",
      "84\n",
      "90\n",
      "96\n",
      "102\n",
      "108\n",
      "114\n",
      "120\n",
      "126\n",
      "139\n",
      "145\n",
      "151\n",
      "157\n",
      "165\n",
      "171\n",
      "177\n",
      "183\n",
      "189\n",
      "0\n",
      "11\n",
      "29\n",
      "73\n",
      "84\n",
      "0\n",
      "37\n",
      "45\n",
      "53\n",
      "83\n",
      "109\n",
      "135\n",
      "153\n",
      "206\n",
      "235\n",
      "0\n",
      "8\n",
      "14\n",
      "20\n",
      "26\n",
      "32\n",
      "38\n",
      "44\n",
      "50\n",
      "56\n",
      "0\n",
      "17\n",
      "29\n",
      "50\n",
      "58\n",
      "64\n",
      "70\n",
      "76\n",
      "84\n",
      "90\n",
      "96\n",
      "0\n",
      "21\n",
      "29\n",
      "35\n",
      "0\n",
      "6\n",
      "12\n",
      "18\n",
      "24\n",
      "30\n",
      "36\n",
      "42\n",
      "51\n",
      "60\n",
      "69\n",
      "75\n",
      "83\n",
      "91\n",
      "99\n",
      "107\n",
      "113\n",
      "0\n",
      "38\n",
      "44\n",
      "50\n",
      "106\n",
      "120\n",
      "141\n",
      "147\n",
      "153\n",
      "160\n",
      "167\n",
      "173\n",
      "192\n",
      "198\n",
      "204\n",
      "221\n",
      "234\n",
      "0\n",
      "7\n",
      "15\n",
      "28\n",
      "47\n",
      "53\n",
      "61\n",
      "68\n",
      "77\n",
      "84\n",
      "92\n",
      "98\n",
      "108\n",
      "0\n",
      "20\n",
      "27\n",
      "33\n",
      "39\n",
      "45\n",
      "56\n",
      "62\n",
      "73\n",
      "79\n",
      "85\n",
      "91\n",
      "104\n",
      "110\n",
      "121\n",
      "127\n",
      "133\n",
      "139\n",
      "145\n",
      "151\n",
      "157\n",
      "168\n",
      "179\n",
      "197\n",
      "208\n",
      "215\n",
      "221\n",
      "227\n",
      "233\n",
      "239\n",
      "245\n",
      "251\n",
      "257\n",
      "263\n",
      "270\n",
      "276\n",
      "284\n",
      "290\n",
      "296\n",
      "303\n",
      "309\n",
      "315\n",
      "321\n",
      "327\n",
      "334\n",
      "340\n",
      "346\n",
      "352\n",
      "358\n",
      "364\n",
      "0\n",
      "7\n",
      "15\n",
      "22\n",
      "30\n",
      "42\n",
      "54\n",
      "66\n",
      "78\n",
      "91\n",
      "102\n",
      "0\n",
      "11\n",
      "23\n",
      "29\n",
      "36\n",
      "0\n",
      "9\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "for g in graphs:\n",
    "    print(g[\"target_lineno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 818/818 [00:00<00:00, 89749.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for g in tqdm(graphs):\n",
    "    file = g[\"file\"]\n",
    "    annotations = find_annotation_before_index(file2annotation[file], g[\"target_lineno\"])\n",
    "    g[\"annotation\"] = annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28117359413202936\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for g in graphs:\n",
    "    if g[\"annotation\"]!=[]:\n",
    "        counter+=1\n",
    "#     print(g[\"annotation\"])\n",
    "print(counter/len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./graphs/temp_cell_test_1_22.txt','w') as fout:\n",
    "    for g in graphs:\n",
    "        fout.write(json.dumps(g,ensure_ascii=False))\n",
    "        fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
